{"version":3,"sources":["../src/index.ts","../../review/src/logger.ts","../../review/src/review-engine.ts","../../review/src/github-api.ts","../../review/src/prompt.ts","../../review/src/delta.ts","../../review/src/format.ts","../../review/src/openrouter.ts"],"sourcesContent":["/**\n * Lien AI Code Review GitHub Action\n *\n * Thin adapter over @liendev/review. Reads GitHub Actions inputs,\n * creates the Octokit instance from @actions/github, and delegates\n * to the shared review engine.\n */\n\nimport * as core from '@actions/core';\nimport * as github from '@actions/github';\nimport {\n  type Logger,\n  type ReviewConfig,\n  type ReviewSetup,\n  type ReviewStyle,\n  createOctokit,\n  orchestrateAnalysis,\n  handleAnalysisOutputs,\n  postReviewIfNeeded,\n} from '@liendev/review';\n\n/**\n * Wrap @actions/core as a Logger\n */\nconst actionsLogger: Logger = {\n  info: (msg: string) => core.info(msg),\n  warning: (msg: string) => core.warning(msg),\n  error: (msg: string) => core.error(msg),\n  debug: (msg: string) => core.debug(msg),\n};\n\n/**\n * Read action inputs into ReviewConfig\n */\nfunction getConfig(): ReviewConfig {\n  const reviewStyle = core.getInput('review_style') || 'line';\n\n  return {\n    openrouterApiKey: core.getInput('openrouter_api_key', { required: true }),\n    model: core.getInput('model') || 'anthropic/claude-sonnet-4',\n    threshold: core.getInput('threshold') || '15',\n    reviewStyle: (reviewStyle === 'summary' ? 'summary' : 'line') as ReviewStyle,\n    enableDeltaTracking: core.getInput('enable_delta_tracking') === 'true',\n    baselineComplexityPath: core.getInput('baseline_complexity') || '',\n  };\n}\n\n/**\n * Get PR context from the GitHub event\n */\nfunction getPRContext() {\n  const { context } = github;\n\n  if (!context.payload.pull_request) {\n    core.warning('This action only works on pull_request events');\n    return null;\n  }\n\n  const pr = context.payload.pull_request;\n\n  return {\n    owner: context.repo.owner,\n    repo: context.repo.repo,\n    pullNumber: pr.number,\n    title: pr.title as string,\n    baseSha: pr.base.sha as string,\n    headSha: pr.head.sha as string,\n  };\n}\n\n/**\n * Set GitHub Action outputs from analysis results\n */\nfunction setOutputs(\n  deltaSummary: { totalDelta: number; improved: number; degraded: number } | null,\n  report: { summary: { totalViolations: number; bySeverity: { error: number; warning: number } } }\n): void {\n  if (deltaSummary) {\n    core.setOutput('total_delta', deltaSummary.totalDelta);\n    core.setOutput('improved', deltaSummary.improved);\n    core.setOutput('degraded', deltaSummary.degraded);\n  }\n\n  core.setOutput('violations', report.summary.totalViolations);\n  core.setOutput('errors', report.summary.bySeverity.error);\n  core.setOutput('warnings', report.summary.bySeverity.warning);\n}\n\n/**\n * Main action logic\n */\nasync function run(): Promise<void> {\n  try {\n    core.info('Starting Lien AI Code Review...');\n    core.info(`Node version: ${process.version}`);\n    core.info(`Working directory: ${process.cwd()}`);\n\n    const config = getConfig();\n    core.info(`Using model: ${config.model}`);\n    core.info(`Complexity threshold: ${config.threshold}`);\n    core.info(`Review style: ${config.reviewStyle}`);\n\n    const githubToken = core.getInput('github_token') || process.env.GITHUB_TOKEN || '';\n    if (!githubToken) {\n      throw new Error('GitHub token is required');\n    }\n\n    const prContext = getPRContext();\n    if (!prContext) {\n      core.info('Not running in PR context, exiting gracefully');\n      return;\n    }\n\n    core.info(`Reviewing PR #${prContext.pullNumber}: ${prContext.title}`);\n\n    // Use @octokit/rest directly instead of @actions/github's wrapper,\n    // because the wrapper puts paginate on the top level but pulls/issues on .rest\n    const octokit = createOctokit(githubToken);\n\n    const setup: ReviewSetup = {\n      config,\n      prContext,\n      octokit,\n      logger: actionsLogger,\n      rootDir: process.cwd(),\n    };\n\n    const analysisResult = await orchestrateAnalysis(setup);\n    if (!analysisResult) {\n      return;\n    }\n\n    const deltaSummary = await handleAnalysisOutputs(analysisResult, setup);\n    setOutputs(deltaSummary, analysisResult.currentReport);\n    await postReviewIfNeeded(analysisResult, setup);\n  } catch (error) {\n    const message = error instanceof Error ? error.message : 'An unexpected error occurred';\n    const stack = error instanceof Error ? error.stack : '';\n    core.error(`Action failed: ${message}`);\n    if (stack) {\n      core.error(`Stack trace:\\n${stack}`);\n    }\n    core.setFailed(message);\n  }\n}\n\n// Run the action\nrun().catch((error) => {\n  core.setFailed(error instanceof Error ? error.message : String(error));\n  process.exit(1);\n});\n","/**\n * Logger interface for review operations.\n * Decouples review logic from @actions/core so it can be used\n * in both the GitHub Action and the GitHub App.\n */\nexport interface Logger {\n  info(message: string): void;\n  warning(message: string): void;\n  error(message: string): void;\n  debug(message: string): void;\n}\n\n/**\n * Simple console-based logger for use outside GitHub Actions\n */\nexport const consoleLogger: Logger = {\n  info: (message: string) => console.log(`[info] ${message}`),\n  warning: (message: string) => console.warn(`[warning] ${message}`),\n  error: (message: string) => console.error(`[error] ${message}`),\n  debug: (message: string) => console.debug(`[debug] ${message}`),\n};\n","/**\n * Review engine ‚Äî orchestrates complexity analysis, delta tracking, and review posting.\n * Extracted from packages/action/src/index.ts for reuse across Action and App.\n */\n\nimport * as fs from 'fs';\nimport { execSync } from 'child_process';\nimport collect from 'collect.js';\nimport {\n  indexCodebase,\n  createVectorDB,\n  ComplexityAnalyzer,\n  RISK_ORDER,\n  type ComplexityReport,\n  type ComplexityViolation,\n} from '@liendev/core';\n\nimport type { Octokit } from '@octokit/rest';\nimport type { PRContext, ReviewConfig, LineComment } from './types.js';\nimport type { Logger } from './logger.js';\nimport {\n  getPRChangedFiles,\n  getFileContent,\n  postPRComment,\n  postPRReview,\n  getPRDiffLines,\n  updatePRDescription,\n} from './github-api.js';\nimport { generateReview, generateLineComments, resetTokenUsage, getTokenUsage } from './openrouter.js';\nimport {\n  buildReviewPrompt,\n  buildNoViolationsMessage,\n  formatReviewComment,\n  getViolationKey,\n  buildDescriptionBadge,\n  buildHeaderLine,\n  getMetricLabel,\n  formatComplexityValue,\n  formatThresholdValue,\n} from './prompt.js';\nimport { formatDeltaValue } from './format.js';\nimport {\n  calculateDeltas,\n  calculateDeltaSummary,\n  formatDelta,\n  formatSeverityEmoji,\n  logDeltaSummary,\n  type ComplexityDelta,\n  type DeltaSummary,\n} from './delta.js';\n\n/**\n * Result of analysis orchestration\n */\nexport interface AnalysisResult {\n  currentReport: ComplexityReport;\n  baselineReport: ComplexityReport | null;\n  deltas: ComplexityDelta[] | null;\n  filesToAnalyze: string[];\n}\n\n/**\n * Setup result for orchestration\n */\nexport interface ReviewSetup {\n  config: ReviewConfig;\n  prContext: PRContext;\n  octokit: Octokit;\n  logger: Logger;\n  rootDir: string;\n}\n\n/**\n * Filter files to only include those that can be analyzed\n * (excludes non-code files, vendor, node_modules, etc.)\n */\nexport function filterAnalyzableFiles(files: string[]): string[] {\n  const codeExtensions = new Set([\n    '.ts',\n    '.tsx',\n    '.js',\n    '.jsx',\n    '.py',\n    '.php',\n  ]);\n\n  const excludePatterns = [\n    /node_modules\\//,\n    /vendor\\//,\n    /dist\\//,\n    /build\\//,\n    /\\.min\\./,\n    /\\.bundle\\./,\n    /\\.generated\\./,\n    /package-lock\\.json/,\n    /yarn\\.lock/,\n    /pnpm-lock\\.yaml/,\n  ];\n\n  return files.filter((file) => {\n    // Check extension\n    const ext = file.slice(file.lastIndexOf('.'));\n    if (!codeExtensions.has(ext)) {\n      return false;\n    }\n\n    // Check exclude patterns\n    for (const pattern of excludePatterns) {\n      if (pattern.test(file)) {\n        return false;\n      }\n    }\n\n    return true;\n  });\n}\n\n/**\n * Get and filter files eligible for complexity analysis\n */\nasync function getFilesToAnalyze(octokit: Octokit, prContext: PRContext, logger: Logger): Promise<string[]> {\n  const allChangedFiles = await getPRChangedFiles(octokit, prContext);\n  logger.info(`Found ${allChangedFiles.length} changed files in PR`);\n\n  const filesToAnalyze = filterAnalyzableFiles(allChangedFiles);\n  logger.info(`${filesToAnalyze.length} files eligible for complexity analysis`);\n\n  return filesToAnalyze;\n}\n\n/**\n * Run complexity analysis using @liendev/core\n */\nexport async function runComplexityAnalysis(\n  files: string[],\n  threshold: string,\n  rootDir: string,\n  logger: Logger\n): Promise<ComplexityReport | null> {\n  if (files.length === 0) {\n    logger.info('No files to analyze');\n    return null;\n  }\n\n  try {\n    // Index the codebase (no config needed - uses defaults)\n    logger.info('Indexing codebase...');\n    await indexCodebase({\n      rootDir,\n    });\n    logger.info('Indexing complete');\n\n    // Load the vector database (uses global config or defaults to LanceDB)\n    const vectorDB = await createVectorDB(rootDir);\n    await vectorDB.initialize();\n\n    // Run complexity analysis (uses default thresholds)\n    logger.info('Analyzing complexity...');\n    const analyzer = new ComplexityAnalyzer(vectorDB);\n    const report = await analyzer.analyze(files);\n    logger.info(`Found ${report.summary.totalViolations} violations`);\n\n    return report;\n  } catch (error) {\n    logger.error(`Failed to run complexity analysis: ${error}`);\n    return null;\n  }\n}\n\n/**\n * Prioritize violations by impact (dependents + severity)\n * High dependents + High severity = Highest priority\n */\nfunction prioritizeViolations(\n  violations: ComplexityViolation[],\n  report: ComplexityReport\n): ComplexityViolation[] {\n  return violations.sort((a, b) => {\n    const fileA = report.files[a.filepath];\n    const fileB = report.files[b.filepath];\n\n    // Priority: High dependents + High severity = Highest priority\n    const impactA = (fileA?.dependentCount || 0) * 10 + RISK_ORDER[fileA?.riskLevel || 'low'];\n    const impactB = (fileB?.dependentCount || 0) * 10 + RISK_ORDER[fileB?.riskLevel || 'low'];\n\n    if (impactB !== impactA) return impactB - impactA;\n\n    // Fallback: severity\n    const severityOrder = { error: 2, warning: 1 };\n    return severityOrder[b.severity] - severityOrder[a.severity];\n  });\n}\n\n/**\n * Sort violations by severity and collect code snippets\n */\nasync function prepareViolationsForReview(\n  report: ComplexityReport,\n  octokit: Octokit,\n  prContext: PRContext,\n  logger: Logger\n): Promise<{ violations: ComplexityViolation[]; codeSnippets: Map<string, string> }> {\n  // Collect violations\n  const allViolations = Object.values(report.files)\n    .flatMap((fileData) => fileData.violations);\n\n  // Prioritize by impact (dependents + severity)\n  const violations = prioritizeViolations(allViolations, report)\n    .slice(0, 10);\n\n  // Collect code snippets\n  const codeSnippets = new Map<string, string>();\n  for (const violation of violations) {\n    const snippet = await getFileContent(\n      octokit,\n      prContext,\n      violation.filepath,\n      violation.startLine,\n      violation.endLine,\n      logger\n    );\n    if (snippet) {\n      codeSnippets.set(getViolationKey(violation), snippet);\n    }\n  }\n  logger.info(`Collected ${codeSnippets.size} code snippets for review`);\n\n  return { violations, codeSnippets };\n}\n\n/**\n * Load baseline complexity report from file\n */\nfunction loadBaselineComplexity(path: string, logger: Logger): ComplexityReport | null {\n  if (!path) {\n    logger.info('No baseline complexity path provided, skipping delta calculation');\n    return null;\n  }\n\n  try {\n    if (!fs.existsSync(path)) {\n      logger.warning(`Baseline complexity file not found: ${path}`);\n      return null;\n    }\n\n    const content = fs.readFileSync(path, 'utf-8');\n    const report = JSON.parse(content) as ComplexityReport;\n\n    if (!report.files || !report.summary) {\n      logger.warning('Baseline complexity file has invalid format');\n      return null;\n    }\n\n    logger.info(`Loaded baseline complexity: ${report.summary.totalViolations} violations`);\n    return report;\n  } catch (error) {\n    logger.warning(`Failed to load baseline complexity: ${error}`);\n    return null;\n  }\n}\n\n/**\n * Analyze base branch complexity for delta tracking\n */\nasync function analyzeBaseBranch(\n  baseSha: string,\n  filesToAnalyze: string[],\n  threshold: string,\n  rootDir: string,\n  logger: Logger\n): Promise<ComplexityReport | null> {\n  try {\n    logger.info(`Checking out base branch at ${baseSha.substring(0, 7)}...`);\n\n    // Save current HEAD\n    const currentHead = execSync('git rev-parse HEAD', { encoding: 'utf-8' }).trim();\n\n    // Checkout base branch\n    execSync(`git checkout --force ${baseSha}`, { stdio: 'pipe' });\n    logger.info('Base branch checked out');\n\n    // Analyze base\n    logger.info('Analyzing base branch complexity...');\n    const baseReport = await runComplexityAnalysis(filesToAnalyze, threshold, rootDir, logger);\n\n    // Restore HEAD\n    execSync(`git checkout --force ${currentHead}`, { stdio: 'pipe' });\n    logger.info('Restored to HEAD');\n\n    if (baseReport) {\n      logger.info(`Base branch: ${baseReport.summary.totalViolations} violations`);\n    }\n\n    return baseReport;\n  } catch (error) {\n    logger.warning(`Failed to analyze base branch: ${error}`);\n    // Attempt to restore HEAD even if analysis failed\n    try {\n      const currentHead = execSync('git rev-parse HEAD', { encoding: 'utf-8' }).trim();\n      execSync(`git checkout --force ${currentHead}`, { stdio: 'pipe' });\n    } catch (restoreError) {\n      logger.warning(`Failed to restore HEAD: ${restoreError}`);\n    }\n    return null;\n  }\n}\n\n/**\n * Get baseline complexity report for delta calculation\n * Handles both delta tracking (analyzes base branch) and legacy baseline file\n */\nasync function getBaselineReport(\n  config: ReviewConfig,\n  prContext: PRContext,\n  filesToAnalyze: string[],\n  rootDir: string,\n  logger: Logger\n): Promise<ComplexityReport | null> {\n  if (config.enableDeltaTracking) {\n    logger.info('Delta tracking enabled - analyzing base branch...');\n    return await analyzeBaseBranch(prContext.baseSha, filesToAnalyze, config.threshold, rootDir, logger);\n  }\n\n  if (config.baselineComplexityPath) {\n    // Backwards compatibility: support old baseline_complexity input\n    logger.warning('baseline_complexity input is deprecated. Use enable_delta_tracking: true instead.');\n    return loadBaselineComplexity(config.baselineComplexityPath, logger);\n  }\n\n  return null;\n}\n\n/**\n * Orchestrate complexity analysis (file discovery, baseline, current analysis)\n * Returns null if no files to analyze or analysis fails\n */\nexport async function orchestrateAnalysis(setup: ReviewSetup): Promise<AnalysisResult | null> {\n  const { config, prContext, octokit, logger, rootDir } = setup;\n\n  const filesToAnalyze = await getFilesToAnalyze(octokit, prContext, logger);\n  if (filesToAnalyze.length === 0) {\n    logger.info('No analyzable files found, skipping review');\n    return null;\n  }\n\n  const baselineReport = await getBaselineReport(config, prContext, filesToAnalyze, rootDir, logger);\n  const currentReport = await runComplexityAnalysis(filesToAnalyze, config.threshold, rootDir, logger);\n\n  if (!currentReport) {\n    logger.warning('Failed to get complexity report');\n    return null;\n  }\n\n  logger.info(`Analysis complete: ${currentReport.summary.totalViolations} violations found`);\n\n  const deltas = baselineReport\n    ? calculateDeltas(baselineReport, currentReport, filesToAnalyze)\n    : null;\n\n  return {\n    currentReport,\n    baselineReport,\n    deltas,\n    filesToAnalyze,\n  };\n}\n\n/**\n * Handle analysis outputs (badge, logging)\n * Updates PR description badge\n */\nexport async function handleAnalysisOutputs(\n  result: AnalysisResult,\n  setup: ReviewSetup\n): Promise<DeltaSummary | null> {\n  const { octokit, prContext, logger } = setup;\n  const deltaSummary = result.deltas ? calculateDeltaSummary(result.deltas) : null;\n\n  if (deltaSummary) {\n    logDeltaSummary(deltaSummary, logger);\n  }\n\n  const badge = buildDescriptionBadge(result.currentReport, deltaSummary, result.deltas);\n  await updatePRDescription(octokit, prContext, badge, logger);\n\n  return deltaSummary;\n}\n\n// ‚îÄ‚îÄ‚îÄ Helper functions for review posting ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n/**\n * Find the best line to comment on for a violation\n * Returns startLine if it's in diff, otherwise first diff line in function range, or null\n */\nfunction findCommentLine(\n  violation: ComplexityViolation,\n  diffLines: Map<string, Set<number>>\n): number | null {\n  const fileLines = diffLines.get(violation.filepath);\n  if (!fileLines) return null;\n\n  // Prefer startLine (function declaration)\n  if (fileLines.has(violation.startLine)) {\n    return violation.startLine;\n  }\n\n  // Find first diff line within the function range\n  for (let line = violation.startLine; line <= violation.endLine; line++) {\n    if (fileLines.has(line)) {\n      return line;\n    }\n  }\n\n  return null;\n}\n\n/**\n * Create a unique key for delta lookups\n */\nfunction createDeltaKey(v: { filepath: string; symbolName: string; metricType: string }): string {\n  return `${v.filepath}::${v.symbolName}::${v.metricType}`;\n}\n\n/**\n * Build delta lookup map from deltas array\n */\nfunction buildDeltaMap(deltas: ComplexityDelta[] | null): Map<string, ComplexityDelta> {\n  if (!deltas) return new Map();\n\n  return new Map(\n    collect(deltas)\n      .map(d => [createDeltaKey(d), d] as [string, ComplexityDelta])\n      .all()\n  );\n}\n\n/**\n * Get emoji for metric type\n */\nfunction getMetricEmoji(metricType: string): string {\n  switch (metricType) {\n    case 'cyclomatic': return 'üîÄ';\n    case 'cognitive': return 'üß†';\n    case 'halstead_effort': return '‚è±Ô∏è';\n    case 'halstead_bugs': return 'üêõ';\n    default: return 'üìä';\n  }\n}\n\n/**\n * Format a single uncovered violation line\n */\nfunction formatUncoveredLine(v: ComplexityViolation, deltaMap: Map<string, ComplexityDelta>): string {\n  const delta = deltaMap.get(createDeltaKey(v));\n  const deltaStr = delta ? ` (${formatDelta(delta.delta)})` : '';\n  const emoji = getMetricEmoji(v.metricType);\n  const metricLabel = getMetricLabel(v.metricType || 'cyclomatic');\n  const valueDisplay = formatComplexityValue(v.metricType || 'cyclomatic', v.complexity);\n  return `* \\`${v.symbolName}\\` in \\`${v.filepath}\\`: ${emoji} ${metricLabel} ${valueDisplay}${deltaStr}`;\n}\n\n/**\n * Build uncovered violations note for summary\n * Splits into new/worsened (shown prominently) vs pre-existing (collapsed)\n */\nfunction buildUncoveredNote(\n  uncoveredViolations: ComplexityViolation[],\n  deltaMap: Map<string, ComplexityDelta>\n): string {\n  if (uncoveredViolations.length === 0) return '';\n\n  // Split uncovered into new/worsened vs pre-existing\n  const newOrWorsened = uncoveredViolations.filter(v => {\n    const delta = deltaMap.get(createDeltaKey(v));\n    return delta && (delta.severity === 'new' || delta.severity === 'warning' || delta.severity === 'error') && (delta.severity === 'new' || delta.delta > 0);\n  });\n\n  const preExisting = uncoveredViolations.filter(v => {\n    const delta = deltaMap.get(createDeltaKey(v));\n    return !delta || delta.delta === 0;\n  });\n\n  let result = '';\n\n  // New/worsened: show prominently (not collapsed)\n  if (newOrWorsened.length > 0) {\n    const list = newOrWorsened.map(v => formatUncoveredLine(v, deltaMap)).join('\\n');\n    result += `\\n\\n‚ö†Ô∏è **${newOrWorsened.length} new/worsened violation${newOrWorsened.length === 1 ? '' : 's'} outside diff:**\\n\\n${list}`;\n  }\n\n  // Pre-existing: collapsed, informational tone\n  if (preExisting.length > 0) {\n    const list = preExisting.map(v => formatUncoveredLine(v, deltaMap)).join('\\n');\n    result += `\\n\\n<details>\\n<summary>‚ÑπÔ∏è ${preExisting.length} pre-existing violation${preExisting.length === 1 ? '' : 's'} outside diff</summary>\\n\\n${list}\\n\\n> *These violations existed before this PR. No action required, but consider the [boy scout rule](https://www.oreilly.com/library/view/97-things-every/9780596809515/ch08.html)!*\\n\\n</details>`;\n  }\n\n  // Fallback: if no delta data, show all in collapsed section (legacy behavior)\n  if (newOrWorsened.length === 0 && preExisting.length === 0) {\n    const list = uncoveredViolations.map(v => formatUncoveredLine(v, deltaMap)).join('\\n');\n    result += `\\n\\n<details>\\n<summary>‚ö†Ô∏è ${uncoveredViolations.length} violation${uncoveredViolations.length === 1 ? '' : 's'} outside diff (no inline comment)</summary>\\n\\n${list}\\n\\n> üí° *These exist in files touched by this PR but the function declarations aren't in the diff. Consider the [boy scout rule](https://www.oreilly.com/library/view/97-things-every/9780596809515/ch08.html)!*\\n\\n</details>`;\n  }\n\n  return result;\n}\n\n/**\n * Build note for skipped pre-existing violations (no inline comment, no LLM cost)\n */\nfunction buildSkippedNote(skippedViolations: ComplexityViolation[]): string {\n  if (skippedViolations.length === 0) return '';\n\n  const skippedList = skippedViolations\n    .map(v => `  - \\`${v.symbolName}\\` in \\`${v.filepath}\\`: complexity ${v.complexity}`)\n    .join('\\n');\n\n  return `\\n\\n<details>\\n<summary>‚ÑπÔ∏è ${skippedViolations.length} pre-existing violation${skippedViolations.length === 1 ? '' : 's'} (unchanged)</summary>\\n\\n${skippedList}\\n\\n> *These violations existed before this PR and haven't changed. No inline comments added to reduce noise.*\\n\\n</details>`;\n}\n\n/**\n * Format token usage cost display\n */\nfunction formatCostDisplay(usage: { totalTokens: number; cost: number }): string {\n  return usage.totalTokens > 0\n    ? `\\n- Tokens: ${usage.totalTokens.toLocaleString()} ($${usage.cost.toFixed(4)})`\n    : '';\n}\n\n/**\n * Group deltas by metric type and sum their values\n */\nfunction groupDeltasByMetric(deltas: ComplexityDelta[]): Record<string, number> {\n  return collect(deltas)\n    .groupBy('metricType')\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    .map((group: any) => group.sum('delta'))\n    .all() as unknown as Record<string, number>;\n}\n\n/**\n * Build metric breakdown string with emojis\n */\nfunction buildMetricBreakdown(deltaByMetric: Record<string, number>): string {\n  const metricOrder = ['cyclomatic', 'cognitive', 'halstead_effort', 'halstead_bugs'];\n  return collect(metricOrder)\n    .map(metricType => {\n      const metricDelta = deltaByMetric[metricType] || 0;\n      const emoji = getMetricEmoji(metricType);\n      const sign = metricDelta >= 0 ? '+' : '';\n      return `${emoji} ${sign}${formatDeltaValue(metricType, metricDelta)}`;\n    })\n    .all()\n    .join(' | ');\n}\n\n/**\n * Format delta display with metric breakdown and summary\n */\nfunction formatDeltaDisplay(deltas: ComplexityDelta[] | null): string {\n  if (!deltas || deltas.length === 0) return '';\n\n  const deltaSummary = calculateDeltaSummary(deltas);\n  const deltaByMetric = groupDeltasByMetric(deltas);\n\n  if (deltaSummary.totalDelta === 0 && deltaSummary.improved === 0 && deltaSummary.newFunctions === 0) {\n    return '\\n\\n**Complexity:** No change from this PR.';\n  }\n\n  const metricBreakdown = buildMetricBreakdown(deltaByMetric);\n  const trend = deltaSummary.totalDelta > 0 ? '‚¨ÜÔ∏è' : deltaSummary.totalDelta < 0 ? '‚¨áÔ∏è' : '‚û°Ô∏è';\n\n  let display = `\\n\\n**Complexity Change:** ${metricBreakdown} ${trend}`;\n  if (deltaSummary.improved > 0) display += ` (${deltaSummary.improved} improved)`;\n  if (deltaSummary.degraded > 0) display += ` (${deltaSummary.degraded} degraded)`;\n  return display;\n}\n\n/**\n * Build review summary body for line comments mode\n */\nfunction buildReviewSummary(\n  report: ComplexityReport,\n  deltas: ComplexityDelta[] | null,\n  uncoveredNote: string\n): string {\n  const { summary } = report;\n  const costDisplay = formatCostDisplay(getTokenUsage());\n  const deltaDisplay = formatDeltaDisplay(deltas);\n  const headerLine = buildHeaderLine(summary.totalViolations, deltas);\n\n  return `<!-- lien-ai-review -->\n## üëÅÔ∏è Veille\n\n${headerLine}${deltaDisplay}\n\nSee inline comments on the diff for specific suggestions.${uncoveredNote}\n\n<details>\n<summary>üìä Analysis Details</summary>\n\n- Files analyzed: ${summary.filesAnalyzed}\n- Average complexity: ${summary.avgComplexity.toFixed(1)}\n- Max complexity: ${summary.maxComplexity}${costDisplay}\n\n</details>\n\n*[Veille](https://lien.dev) by Lien*`;\n}\n\n/**\n * Build line comments from violations and AI comments\n */\nfunction buildLineComments(\n  violationsWithLines: Array<{ violation: ComplexityViolation; commentLine: number }>,\n  aiComments: Map<ComplexityViolation, string>,\n  deltaMap: Map<string, ComplexityDelta>,\n  logger: Logger\n): LineComment[] {\n  return collect(violationsWithLines)\n    .filter(({ violation }) => aiComments.has(violation))\n    .map(({ violation, commentLine }) => {\n      const comment = aiComments.get(violation)!;\n      const delta = deltaMap.get(createDeltaKey(violation));\n      const deltaStr = delta ? ` (${formatDelta(delta.delta)})` : '';\n      const severityEmoji = delta\n        ? formatSeverityEmoji(delta.severity)\n        : (violation.severity === 'error' ? 'üî¥' : 'üü°');\n\n      // If comment is not on symbol's starting line, note where it actually starts\n      const lineNote = commentLine !== violation.startLine\n        ? ` *(\\`${violation.symbolName}\\` starts at line ${violation.startLine})*`\n        : '';\n\n      // Format human-friendly complexity display\n      const metricLabel = getMetricLabel(violation.metricType || 'cyclomatic');\n      const valueDisplay = formatComplexityValue(violation.metricType || 'cyclomatic', violation.complexity);\n      const thresholdDisplay = formatThresholdValue(violation.metricType || 'cyclomatic', violation.threshold);\n\n      logger.info(`Adding comment for ${violation.filepath}:${commentLine} (${violation.symbolName})${deltaStr}`);\n\n      return {\n        path: violation.filepath,\n        line: commentLine,\n        body: `${severityEmoji} **${metricLabel.charAt(0).toUpperCase() + metricLabel.slice(1)}: ${valueDisplay}**${deltaStr} (threshold: ${thresholdDisplay})${lineNote}\\n\\n${comment}`,\n      };\n    })\n    .all() as LineComment[];\n}\n\n/**\n * Partition violations into those with comment lines and those without\n */\nfunction partitionViolationsByDiff(\n  violations: ComplexityViolation[],\n  diffLines: Map<string, Set<number>>\n): {\n  withLines: Array<{ violation: ComplexityViolation; commentLine: number }>;\n  uncovered: ComplexityViolation[];\n} {\n  const withLines: Array<{ violation: ComplexityViolation; commentLine: number }> = [];\n  const uncovered: ComplexityViolation[] = [];\n\n  for (const v of violations) {\n    const commentLine = findCommentLine(v, diffLines);\n    if (commentLine !== null) {\n      withLines.push({ violation: v, commentLine });\n    } else {\n      uncovered.push(v);\n    }\n  }\n\n  return { withLines, uncovered };\n}\n\n/**\n * Filter violations to only new or degraded ones (skip unchanged pre-existing)\n */\nfunction filterNewOrDegraded(\n  violationsWithLines: Array<{ violation: ComplexityViolation; commentLine: number }>,\n  deltaMap: Map<string, ComplexityDelta>\n): Array<{ violation: ComplexityViolation; commentLine: number }> {\n  return violationsWithLines.filter(({ violation }) => {\n    const key = createDeltaKey(violation);\n    const delta = deltaMap.get(key);\n    // Comment if: no baseline data, or new violation, or got worse\n    return !delta || delta.severity === 'new' || delta.delta > 0;\n  });\n}\n\n/**\n * Get list of skipped (unchanged) violations\n */\nfunction getSkippedViolations(\n  violationsWithLines: Array<{ violation: ComplexityViolation; commentLine: number }>,\n  deltaMap: Map<string, ComplexityDelta>\n): ComplexityViolation[] {\n  return violationsWithLines\n    .filter(({ violation }) => {\n      const key = createDeltaKey(violation);\n      const delta = deltaMap.get(key);\n      return delta && delta.severity !== 'new' && delta.delta === 0;\n    })\n    .map(v => v.violation);\n}\n\n/**\n * Violation processing result\n */\ninterface ViolationProcessingResult {\n  withLines: Array<{ violation: ComplexityViolation; commentLine: number }>;\n  uncovered: ComplexityViolation[];\n  newOrDegraded: Array<{ violation: ComplexityViolation; commentLine: number }>;\n  skipped: ComplexityViolation[];\n}\n\n/**\n * Process violations for review (partition, filter, categorize)\n */\nfunction processViolationsForReview(\n  violations: ComplexityViolation[],\n  diffLines: Map<string, Set<number>>,\n  deltaMap: Map<string, ComplexityDelta>\n): ViolationProcessingResult {\n  const { withLines, uncovered } = partitionViolationsByDiff(violations, diffLines);\n  const newOrDegraded = filterNewOrDegraded(withLines, deltaMap);\n  const skipped = getSkippedViolations(withLines, deltaMap);\n\n  return { withLines, uncovered, newOrDegraded, skipped };\n}\n\n/**\n * Handle case when there are no new/degraded violations to comment on\n */\nasync function handleNoNewViolations(\n  octokit: Octokit,\n  prContext: PRContext,\n  violationsWithLines: Array<{ violation: ComplexityViolation; commentLine: number }>,\n  uncoveredViolations: ComplexityViolation[],\n  deltaMap: Map<string, ComplexityDelta>,\n  report: ComplexityReport,\n  deltas: ComplexityDelta[] | null,\n  logger: Logger\n): Promise<void> {\n  if (violationsWithLines.length === 0) {\n    return;\n  }\n\n  const skippedInDiff = getSkippedViolations(violationsWithLines, deltaMap);\n  const uncoveredNote = buildUncoveredNote(uncoveredViolations, deltaMap);\n  const skippedNote = buildSkippedNote(skippedInDiff);\n  const summaryBody = buildReviewSummary(report, deltas, uncoveredNote + skippedNote);\n  await postPRComment(octokit, prContext, summaryBody, logger);\n}\n\n/**\n * Generate AI comments and post review\n */\nasync function generateAndPostReview(\n  octokit: Octokit,\n  prContext: PRContext,\n  processed: ViolationProcessingResult,\n  deltaMap: Map<string, ComplexityDelta>,\n  codeSnippets: Map<string, string>,\n  config: ReviewConfig,\n  report: ComplexityReport,\n  deltas: ComplexityDelta[] | null,\n  logger: Logger\n): Promise<void> {\n  const commentableViolations = processed.newOrDegraded.map(v => v.violation);\n  logger.info(`Generating AI comments for ${commentableViolations.length} new/degraded violations...`);\n\n  const aiComments = await generateLineComments(\n    commentableViolations,\n    codeSnippets,\n    config.openrouterApiKey,\n    config.model,\n    report,\n    logger\n  );\n\n  const lineComments = buildLineComments(processed.newOrDegraded, aiComments, deltaMap, logger);\n  logger.info(`Built ${lineComments.length} line comments for new/degraded violations`);\n\n  const uncoveredNote = buildUncoveredNote(processed.uncovered, deltaMap);\n  const skippedNote = buildSkippedNote(processed.skipped);\n  const summaryBody = buildReviewSummary(report, deltas, uncoveredNote + skippedNote);\n\n  await postPRReview(octokit, prContext, lineComments, summaryBody, logger);\n  logger.info(`Posted review with ${lineComments.length} line comments`);\n}\n\n/**\n * Post review with line-specific comments for all violations\n */\nasync function postLineReview(\n  octokit: Octokit,\n  prContext: PRContext,\n  report: ComplexityReport,\n  violations: ComplexityViolation[],\n  codeSnippets: Map<string, string>,\n  config: ReviewConfig,\n  logger: Logger,\n  deltas: ComplexityDelta[] | null = null\n): Promise<void> {\n  const diffLines = await getPRDiffLines(octokit, prContext);\n  logger.info(`Diff covers ${diffLines.size} files`);\n\n  const deltaMap = buildDeltaMap(deltas);\n  const processed = processViolationsForReview(violations, diffLines, deltaMap);\n\n  logger.info(\n    `${processed.withLines.length}/${violations.length} violations can have inline comments ` +\n    `(${processed.uncovered.length} outside diff)`\n  );\n\n  const skippedCount = processed.withLines.length - processed.newOrDegraded.length;\n  if (skippedCount > 0) {\n    logger.info(`Skipping ${skippedCount} unchanged pre-existing violations (no LLM calls needed)`);\n  }\n\n  if (processed.newOrDegraded.length === 0) {\n    logger.info('No new or degraded violations to comment on');\n    await handleNoNewViolations(\n      octokit,\n      prContext,\n      processed.withLines,\n      processed.uncovered,\n      deltaMap,\n      report,\n      deltas,\n      logger\n    );\n    return;\n  }\n\n  await generateAndPostReview(\n    octokit,\n    prContext,\n    processed,\n    deltaMap,\n    codeSnippets,\n    config,\n    report,\n    deltas,\n    logger\n  );\n}\n\n/**\n * Post review as a single summary comment\n */\nasync function postSummaryReview(\n  octokit: Octokit,\n  prContext: PRContext,\n  report: ComplexityReport,\n  codeSnippets: Map<string, string>,\n  config: ReviewConfig,\n  logger: Logger,\n  isFallback = false,\n  deltas: ComplexityDelta[] | null = null,\n  uncoveredNote: string = ''\n): Promise<void> {\n  const prompt = buildReviewPrompt(report, prContext, codeSnippets, deltas);\n  logger.debug(`Prompt length: ${prompt.length} characters`);\n\n  const aiReview = await generateReview(\n    prompt,\n    config.openrouterApiKey,\n    config.model,\n    logger\n  );\n\n  const usage = getTokenUsage();\n  const comment = formatReviewComment(aiReview, report, isFallback, usage, deltas, uncoveredNote);\n  await postPRComment(octokit, prContext, comment, logger);\n  logger.info('Successfully posted AI review summary comment');\n}\n\n/**\n * Post review if violations are found, or success message if none\n * Handles both summary and line-by-line review modes\n */\nexport async function postReviewIfNeeded(\n  result: AnalysisResult,\n  setup: ReviewSetup\n): Promise<void> {\n  const { config, prContext, octokit, logger } = setup;\n\n  if (result.currentReport.summary.totalViolations === 0) {\n    logger.info('No complexity violations found');\n    // Post success message (will update existing comment if present)\n    const successMessage = buildNoViolationsMessage(prContext, result.deltas);\n    await postPRComment(octokit, prContext, successMessage, logger);\n    return;\n  }\n\n  const { violations, codeSnippets } = await prepareViolationsForReview(\n    result.currentReport,\n    octokit,\n    prContext,\n    logger\n  );\n\n  resetTokenUsage();\n  if (config.reviewStyle === 'summary') {\n    // Get diff lines to identify uncovered violations\n    const diffLines = await getPRDiffLines(octokit, prContext);\n    const deltaMap = buildDeltaMap(result.deltas);\n    const { uncovered } = partitionViolationsByDiff(violations, diffLines);\n    const uncoveredNote = buildUncoveredNote(uncovered, deltaMap);\n\n    await postSummaryReview(\n      octokit,\n      prContext,\n      result.currentReport,\n      codeSnippets,\n      config,\n      logger,\n      false,\n      result.deltas,\n      uncoveredNote\n    );\n  } else {\n    await postLineReview(\n      octokit,\n      prContext,\n      result.currentReport,\n      violations,\n      codeSnippets,\n      config,\n      logger,\n      result.deltas\n    );\n  }\n}\n","/**\n * GitHub API helpers using @octokit/rest\n * Portable across GitHub Actions and GitHub App contexts.\n */\n\nimport { Octokit } from '@octokit/rest';\nimport type { PRContext, LineComment } from './types.js';\nimport type { Logger } from './logger.js';\n\nexport type { Octokit };\n\n/**\n * Create an Octokit instance from a token\n */\nexport function createOctokit(token: string): Octokit {\n  return new Octokit({ auth: token });\n}\n\n/**\n * Get list of files changed in the PR\n */\nexport async function getPRChangedFiles(\n  octokit: Octokit,\n  prContext: PRContext\n): Promise<string[]> {\n  const files: string[] = [];\n  let page = 1;\n  const perPage = 100;\n\n  while (true) {\n    const response = await octokit.pulls.listFiles({\n      owner: prContext.owner,\n      repo: prContext.repo,\n      pull_number: prContext.pullNumber,\n      per_page: perPage,\n      page,\n    });\n\n    for (const file of response.data) {\n      // Only include added or modified files (not deleted)\n      if (file.status !== 'removed') {\n        files.push(file.filename);\n      }\n    }\n\n    if (response.data.length < perPage) {\n      break;\n    }\n    page++;\n  }\n\n  return files;\n}\n\n/**\n * Post a comment on the PR (creates or updates existing Lien comment)\n */\nexport async function postPRComment(\n  octokit: Octokit,\n  prContext: PRContext,\n  body: string,\n  logger: Logger\n): Promise<void> {\n  // Check for existing Lien comment to update instead of creating new\n  const existingComment = await findExistingComment(octokit, prContext);\n\n  if (existingComment) {\n    logger.info(`Updating existing comment ${existingComment.id}`);\n    await octokit.issues.updateComment({\n      owner: prContext.owner,\n      repo: prContext.repo,\n      comment_id: existingComment.id,\n      body,\n    });\n  } else {\n    logger.info('Creating new comment');\n    await octokit.issues.createComment({\n      owner: prContext.owner,\n      repo: prContext.repo,\n      issue_number: prContext.pullNumber,\n      body,\n    });\n  }\n}\n\n/**\n * Find existing Lien review comment to update\n */\nasync function findExistingComment(\n  octokit: Octokit,\n  prContext: PRContext\n): Promise<{ id: number } | null> {\n  const COMMENT_MARKER = '<!-- lien-ai-review -->';\n\n  const comments = await octokit.issues.listComments({\n    owner: prContext.owner,\n    repo: prContext.repo,\n    issue_number: prContext.pullNumber,\n  });\n\n  for (const comment of comments.data) {\n    if (comment.body?.includes(COMMENT_MARKER)) {\n      return { id: comment.id };\n    }\n  }\n\n  return null;\n}\n\n/**\n * Get code snippet from a file at a specific commit\n */\nexport async function getFileContent(\n  octokit: Octokit,\n  prContext: PRContext,\n  filepath: string,\n  startLine: number,\n  endLine: number,\n  logger: Logger\n): Promise<string | null> {\n  try {\n    const response = await octokit.repos.getContent({\n      owner: prContext.owner,\n      repo: prContext.repo,\n      path: filepath,\n      ref: prContext.headSha,\n    });\n\n    if ('content' in response.data) {\n      const content = Buffer.from(response.data.content as string, 'base64').toString(\n        'utf-8'\n      );\n      const lines = content.split('\\n');\n      // Line numbers are 1-based, array is 0-based\n      const snippet = lines.slice(startLine - 1, endLine).join('\\n');\n      return snippet;\n    }\n  } catch (error) {\n    logger.warning(`Failed to get content for ${filepath}: ${error}`);\n  }\n\n  return null;\n}\n\n/**\n * Post a review with line-specific comments\n */\nexport async function postPRReview(\n  octokit: Octokit,\n  prContext: PRContext,\n  comments: LineComment[],\n  summaryBody: string,\n  logger: Logger\n): Promise<void> {\n  if (comments.length === 0) {\n    // No line comments, just post summary as regular comment\n    await postPRComment(octokit, prContext, summaryBody, logger);\n    return;\n  }\n\n  logger.info(`Creating review with ${comments.length} line comments`);\n\n  try {\n    // Create a review with line comments\n    await octokit.pulls.createReview({\n      owner: prContext.owner,\n      repo: prContext.repo,\n      pull_number: prContext.pullNumber,\n      commit_id: prContext.headSha,\n      event: 'COMMENT', // Don't approve or request changes, just comment\n      body: summaryBody,\n      comments: comments.map((c) => ({\n        path: c.path,\n        line: c.line,\n        body: c.body,\n      })),\n    });\n\n    logger.info('Review posted successfully');\n  } catch (error) {\n    // If line comments fail (e.g., lines not in diff), fall back to regular comment\n    logger.warning(`Failed to post line comments: ${error}`);\n    logger.info('Falling back to regular PR comment');\n    await postPRComment(octokit, prContext, summaryBody, logger);\n  }\n}\n\n/**\n * Marker comments for the PR description stats badge\n */\nconst DESCRIPTION_START_MARKER = '<!-- lien-stats -->';\nconst DESCRIPTION_END_MARKER = '<!-- /lien-stats -->';\n\n/**\n * Update the PR description with a stats badge\n * Appends or replaces the stats section at the bottom of the description\n */\nexport async function updatePRDescription(\n  octokit: Octokit,\n  prContext: PRContext,\n  badgeMarkdown: string,\n  logger: Logger\n): Promise<void> {\n  try {\n    // Get current PR\n    const { data: pr } = await octokit.pulls.get({\n      owner: prContext.owner,\n      repo: prContext.repo,\n      pull_number: prContext.pullNumber,\n    });\n\n    const currentBody = pr.body || '';\n    const wrappedBadge = `${DESCRIPTION_START_MARKER}\\n${badgeMarkdown}\\n${DESCRIPTION_END_MARKER}`;\n\n    let newBody: string;\n\n    // Check if we already have a stats section\n    const startIdx = currentBody.indexOf(DESCRIPTION_START_MARKER);\n    const endIdx = currentBody.indexOf(DESCRIPTION_END_MARKER);\n\n    if (startIdx !== -1 && endIdx !== -1 && endIdx > startIdx) {\n      // Replace existing section\n      newBody =\n        currentBody.slice(0, startIdx) +\n        wrappedBadge +\n        currentBody.slice(endIdx + DESCRIPTION_END_MARKER.length);\n      logger.info('Updating existing stats badge in PR description');\n    } else {\n      // Append to end\n      newBody = currentBody.trim() + '\\n\\n---\\n\\n' + wrappedBadge;\n      logger.info('Adding stats badge to PR description');\n    }\n\n    // Update the PR\n    await octokit.pulls.update({\n      owner: prContext.owner,\n      repo: prContext.repo,\n      pull_number: prContext.pullNumber,\n      body: newBody,\n    });\n\n    logger.info('PR description updated with complexity stats');\n  } catch (error) {\n    // Don't fail the action if we can't update the description\n    logger.warning(`Failed to update PR description: ${error}`);\n  }\n}\n\n/**\n * Parse unified diff patch to extract line numbers that can receive comments\n * Exported for testing\n */\nexport function parsePatchLines(patch: string): Set<number> {\n  const lines = new Set<number>();\n  let currentLine = 0;\n\n  for (const patchLine of patch.split('\\n')) {\n    // Hunk header: @@ -start,count +start,count @@\n    const hunkMatch = patchLine.match(/^@@ -\\d+(?:,\\d+)? \\+(\\d+)(?:,\\d+)? @@/);\n    if (hunkMatch) {\n      currentLine = parseInt(hunkMatch[1], 10);\n      continue;\n    }\n\n    // Added or context line (can have comments)\n    if (patchLine.startsWith('+') || patchLine.startsWith(' ')) {\n      if (!patchLine.startsWith('+++')) {\n        lines.add(currentLine);\n        currentLine++;\n      }\n    }\n    // Deleted lines (-) don't increment currentLine\n  }\n\n  return lines;\n}\n\n/**\n * Get lines that are in the PR diff (only these can have line comments)\n * Handles pagination for PRs with 100+ files\n */\nexport async function getPRDiffLines(\n  octokit: Octokit,\n  prContext: PRContext\n): Promise<Map<string, Set<number>>> {\n  const diffLines = new Map<string, Set<number>>();\n\n  // Use pagination to handle PRs with 100+ files\n  const iterator = octokit.paginate.iterator(octokit.pulls.listFiles, {\n    owner: prContext.owner,\n    repo: prContext.repo,\n    pull_number: prContext.pullNumber,\n    per_page: 100,\n  });\n\n  for await (const response of iterator) {\n    for (const file of response.data) {\n      if (!file.patch) continue;\n\n      const lines = parsePatchLines(file.patch);\n      if (lines.size > 0) {\n        diffLines.set(file.filename, lines);\n      }\n    }\n  }\n\n  return diffLines;\n}\n","/**\n * Prompt builder for AI code review\n */\n\nimport collect from 'collect.js';\nimport type { ComplexityReport, ComplexityViolation } from '@liendev/core';\nimport type { PRContext } from './types.js';\nimport type { ComplexityDelta, DeltaSummary } from './delta.js';\nimport { formatDelta } from './delta.js';\nimport { formatTime, formatDeltaValue } from './format.js';\n\n/**\n * Few-shot examples for each complexity metric type.\n * These show the model what a good review comment looks like.\n *\n * Guidelines for these examples:\n * - Keep to 2-3 sentences (~30-40 words)\n * - Name specific functions to extract\n * - Mention line numbers or specific patterns\n * - State the concrete benefit\n */\nconst COMMENT_EXAMPLES: Record<string, string> = {\n  cyclomatic: `The 5 permission cases (lines 45-67) can be extracted to \\`checkAdminAccess()\\`, \\`checkEditorAccess()\\`, \\`checkViewerAccess()\\`. Each returns early if unauthorized, reducing test paths from ~15 to ~5.`,\n\n  cognitive: `The 6 levels of nesting create significant mental load. Flatten with guard clauses: \\`if (!user) return null;\\` at line 23, then \\`if (!hasPermission) throw new UnauthorizedError();\\` at line 28. The remaining logic becomes linear.`,\n\n  halstead_effort: `This function uses 23 unique operators across complex expressions. Extract the date math (lines 34-41) into \\`calculateDaysUntilExpiry()\\` and replace magic numbers (30, 86400) with named constants.`,\n\n  halstead_bugs: `High predicted bug density from complex expressions. The chained ternaries on lines 56-62 should be a lookup object: \\`const STATUS_MAP = { pending: 'yellow', approved: 'green', ... }\\`. Reduces operator count and improves readability.`,\n};\n\n// Default to cyclomatic if metric type not found\nconst DEFAULT_EXAMPLE = COMMENT_EXAMPLES.cyclomatic;\n\n/**\n * Create a unique key for delta lookups\n * Includes metricType since a function can have multiple metric violations\n */\nfunction createDeltaKey(v: { filepath: string; symbolName: string; metricType: string }): string {\n  return `${v.filepath}::${v.symbolName}::${v.metricType}`;\n}\n\n/**\n * Build a lookup map from deltas for quick access\n */\nfunction buildDeltaMap(deltas: ComplexityDelta[] | null): Map<string, ComplexityDelta> {\n  if (!deltas) return new Map();\n\n  return new Map(\n    collect(deltas)\n      .map(d => [createDeltaKey(d), d] as [string, ComplexityDelta])\n      .all()\n  );\n}\n\n/**\n * Get human-readable label for a metric type\n */\nexport function getMetricLabel(metricType: string): string {\n  switch (metricType) {\n    case 'cognitive': return 'mental load';\n    case 'cyclomatic': return 'test paths';\n    case 'halstead_effort': return 'time to understand';\n    case 'halstead_bugs': return 'estimated bugs';\n    default: return 'complexity';\n  }\n}\n\n/**\n * Format complexity value based on metric type for display\n */\nexport function formatComplexityValue(metricType: string, value: number): string {\n  switch (metricType) {\n    case 'halstead_effort':\n      return `~${formatTime(value)}`;\n    case 'halstead_bugs':\n      return value.toFixed(2);\n    case 'cyclomatic':\n      return `${value} tests`;\n    default:\n      return value.toString();\n  }\n}\n\n/**\n * Format threshold value based on metric type for display\n */\nexport function formatThresholdValue(metricType: string, value: number): string {\n  switch (metricType) {\n    case 'halstead_effort':\n      return formatTime(value);\n    case 'halstead_bugs':\n      return value.toFixed(1);\n    default:\n      return value.toString();\n  }\n}\n\n/**\n * Format a single violation line with optional delta\n */\nfunction formatViolationLine(v: ComplexityViolation, deltaMap: Map<string, ComplexityDelta>): string {\n  const delta = deltaMap.get(createDeltaKey(v));\n  const deltaStr = delta ? ` (${formatDelta(delta.delta)})` : '';\n  const metricLabel = getMetricLabel(v.metricType);\n  const valueDisplay = formatComplexityValue(v.metricType, v.complexity);\n  const thresholdDisplay = formatThresholdValue(v.metricType, v.threshold);\n  return `  - ${v.symbolName} (${v.symbolType}): ${metricLabel} ${valueDisplay}${deltaStr} (threshold: ${thresholdDisplay}) [${v.severity}]`;\n}\n\n/**\n * Build dependency context string for a file\n * Shows dependents count, key dependents list, and complexity metrics\n */\nfunction buildDependencyContext(fileData: ComplexityReport['files'][string]): string {\n  if (!fileData.dependentCount || fileData.dependentCount === 0) {\n    return '';\n  }\n\n  const riskEmoji: Record<string, string> = {\n    low: 'üü¢',\n    medium: 'üü°',\n    high: 'üü†',\n    critical: 'üî¥',\n  };\n\n  const emoji = riskEmoji[fileData.riskLevel] || '‚ö™';\n\n  // Build dependents list (only if we have the array and it's not empty)\n  const hasDependentsList = fileData.dependents && fileData.dependents.length > 0;\n  const dependentsList = hasDependentsList\n    ? fileData.dependents.slice(0, 10).map(f => `  - ${f}`).join('\\n')\n    : '';\n\n  const complexityNote = fileData.dependentComplexityMetrics\n    ? `\\n- **Dependent complexity**: Avg ${fileData.dependentComplexityMetrics.averageComplexity.toFixed(1)}, Max ${fileData.dependentComplexityMetrics.maxComplexity}`\n    : '';\n\n  const moreNote = hasDependentsList && fileData.dependents.length > 10\n    ? '\\n  ... (and more)'\n    : '';\n\n  return `\\n**Dependency Impact**: ${emoji} ${fileData.riskLevel.toUpperCase()} risk\n- **Dependents**: ${fileData.dependentCount} file(s) import this\n${dependentsList ? `\\n**Key dependents:**\\n${dependentsList}${moreNote}` : ''}${complexityNote}\n- **Review focus**: Changes here affect ${fileData.dependentCount} other file(s). Extra scrutiny recommended.`;\n}\n\n/**\n * Build file-level context (other violations, file purpose hints)\n * Uses language from violations when available, falls back to file extension\n */\nfunction buildFileContext(filepath: string, fileData: ComplexityReport['files'][string]): string {\n  const parts: string[] = [];\n\n  // Try to get language from violations first (more accurate)\n  const languageFromViolation = fileData.violations[0]?.language;\n\n  // Language/framework hint - use violation language or detect from extension\n  if (languageFromViolation) {\n    const languageMap: Record<string, string> = {\n      'typescript': 'TypeScript',\n      'javascript': 'JavaScript',\n      'php': 'PHP',\n      'python': 'Python',\n      'go': 'Go',\n      'rust': 'Rust',\n      'java': 'Java',\n      'ruby': 'Ruby',\n      'swift': 'Swift',\n      'kotlin': 'Kotlin',\n      'csharp': 'C#',\n      'scala': 'Scala',\n      'cpp': 'C++',\n      'c': 'C',\n    };\n    const displayName = languageMap[languageFromViolation.toLowerCase()] || languageFromViolation;\n    parts.push(`Language: ${displayName}`);\n  } else {\n    // Fallback to file extension detection\n    const ext = filepath.split('.').pop()?.toLowerCase();\n    const languageHints: Record<string, string> = {\n      'ts': 'TypeScript',\n      'tsx': 'TypeScript React',\n      'js': 'JavaScript',\n      'jsx': 'JavaScript React',\n      'mjs': 'JavaScript',\n      'cjs': 'JavaScript',\n      'php': 'PHP',\n      'py': 'Python',\n      'go': 'Go',\n      'rs': 'Rust',\n      'java': 'Java',\n      'rb': 'Ruby',\n      'swift': 'Swift',\n      'kt': 'Kotlin',\n      'cs': 'C#',\n      'scala': 'Scala',\n      'cpp': 'C++',\n      'cc': 'C++',\n      'cxx': 'C++',\n      'c': 'C',\n    };\n    if (ext && languageHints[ext]) {\n      parts.push(`Language: ${languageHints[ext]}`);\n    }\n  }\n\n  // File purpose hint from path (language-agnostic patterns)\n  const pathLower = filepath.toLowerCase();\n  // Common patterns across languages\n  if (pathLower.includes('controller')) parts.push('Type: Controller');\n  if (pathLower.includes('service')) parts.push('Type: Service');\n  if (pathLower.includes('component')) parts.push('Type: Component');\n  if (pathLower.includes('middleware')) parts.push('Type: Middleware');\n  if (pathLower.includes('handler')) parts.push('Type: Handler');\n  if (pathLower.includes('util') || pathLower.includes('helper')) parts.push('Type: Utility');\n  // Go-specific patterns\n  if (pathLower.includes('_test.') || pathLower.endsWith('_test.go')) parts.push('Type: Test');\n  // Java patterns\n  if (pathLower.includes('/model/') || pathLower.includes('/models/')) parts.push('Type: Model');\n  if (pathLower.includes('/repository/') || pathLower.includes('/repositories/')) parts.push('Type: Repository');\n\n  // Other violations in same file\n  if (fileData.violations.length > 1) {\n    parts.push(`${fileData.violations.length} total violations in this file`);\n  }\n\n  return parts.length > 0 ? `\\n*Context: ${parts.join(', ')}*` : '';\n}\n\n/**\n * Check if a violation is new or worsened based on delta data\n */\nfunction isNewOrWorsened(v: ComplexityViolation, deltaMap: Map<string, ComplexityDelta>): boolean {\n  const delta = deltaMap.get(createDeltaKey(v));\n  return !!delta && (delta.severity === 'new' || delta.delta > 0);\n}\n\n/**\n * Build violations summary grouped by file\n * When delta data is available, separates new/worsened from pre-existing\n */\nfunction buildViolationsSummary(\n  files: ComplexityReport['files'],\n  deltaMap: Map<string, ComplexityDelta>\n): string {\n  const hasDeltaData = deltaMap.size > 0;\n\n  if (!hasDeltaData) {\n    // No delta data - show all violations without distinction\n    return Object.entries(files)\n      .filter(([_, data]) => data.violations.length > 0)\n      .map(([filepath, data]) => {\n        const violationList = data.violations\n          .map(v => formatViolationLine(v, deltaMap))\n          .join('\\n');\n        const dependencyContext = buildDependencyContext(data);\n        const fileContext = buildFileContext(filepath, data);\n        return `**${filepath}** (risk: ${data.riskLevel})${fileContext}\\n${violationList}${dependencyContext}`;\n      })\n      .join('\\n\\n');\n  }\n\n  // With delta data, separate into new/worsened vs pre-existing\n  const allViolations = Object.entries(files)\n    .filter(([_, data]) => data.violations.length > 0)\n    .flatMap(([_, data]) => data.violations);\n\n  const newViolations = allViolations.filter(v => isNewOrWorsened(v, deltaMap));\n  const preExisting = allViolations.filter(v => !isNewOrWorsened(v, deltaMap));\n\n  const formatFileGroup = (violations: ComplexityViolation[]) => {\n    const byFile = new Map<string, ComplexityViolation[]>();\n    for (const v of violations) {\n      const existing = byFile.get(v.filepath) || [];\n      existing.push(v);\n      byFile.set(v.filepath, existing);\n    }\n\n    return Array.from(byFile.entries())\n      .map(([filepath, vs]) => {\n        const fileData = files[filepath];\n        const violationList = vs.map(v => formatViolationLine(v, deltaMap)).join('\\n');\n        const dependencyContext = fileData ? buildDependencyContext(fileData) : '';\n        const fileContext = fileData ? buildFileContext(filepath, fileData) : '';\n        return `**${filepath}** (risk: ${fileData?.riskLevel || 'unknown'})${fileContext}\\n${violationList}${dependencyContext}`;\n      })\n      .join('\\n\\n');\n  };\n\n  const sections: string[] = [];\n\n  if (newViolations.length > 0) {\n    sections.push(`### New/Worsened Violations (introduced or worsened in this PR)\\n\\n${formatFileGroup(newViolations)}`);\n  }\n\n  if (preExisting.length > 0) {\n    sections.push(`### Pre-existing Violations (in files touched by this PR)\\n\\n${formatFileGroup(preExisting)}`);\n  }\n\n  return sections.join('\\n\\n');\n}\n\n/**\n * Format a single delta change for display\n */\nfunction formatDeltaChange(d: ComplexityDelta): string {\n  const from = d.baseComplexity ?? 'new';\n  const to = d.headComplexity ?? 'removed';\n  return `  - ${d.symbolName}: ${from} ‚Üí ${to} (${formatDelta(d.delta)})`;\n}\n\n/**\n * Build delta context section showing complexity changes\n */\nfunction buildDeltaContext(deltas: ComplexityDelta[] | null): string {\n  if (!deltas || deltas.length === 0) return '';\n\n  const improved = deltas.filter(d => d.severity === 'improved');\n  const degraded = deltas.filter(d => (d.severity === 'error' || d.severity === 'warning') && d.delta > 0);\n  const newFuncs = deltas.filter(d => d.severity === 'new');\n  const deleted = deltas.filter(d => d.severity === 'deleted');\n\n  const sections = [\n    `\\n## Complexity Changes (vs base branch)`,\n    `- **Degraded**: ${degraded.length} function(s) got more complex`,\n    `- **Improved**: ${improved.length} function(s) got simpler`,\n    `- **New**: ${newFuncs.length} new complex function(s)`,\n    `- **Removed**: ${deleted.length} complex function(s) deleted`,\n  ];\n\n  if (degraded.length > 0) {\n    sections.push(`\\nFunctions that got worse:\\n${degraded.map(formatDeltaChange).join('\\n')}`);\n  }\n  if (improved.length > 0) {\n    sections.push(`\\nFunctions that improved:\\n${improved.map(formatDeltaChange).join('\\n')}`);\n  }\n  if (newFuncs.length > 0) {\n    sections.push(`\\nNew complex functions:\\n${newFuncs.map(d => `  - ${d.symbolName}: complexity ${d.headComplexity}`).join('\\n')}`);\n  }\n\n  return sections.join('\\n');\n}\n\n/**\n * Build code snippets section\n */\nfunction buildSnippetsSection(codeSnippets: Map<string, string>): string {\n  return Array.from(codeSnippets.entries())\n    .map(([key, code]) => {\n      const [filepath, symbolName] = key.split('::');\n      return `### ${filepath} - ${symbolName}\\n\\`\\`\\`\\n${code}\\n\\`\\`\\``;\n    })\n    .join('\\n\\n');\n}\n\n/**\n * Build the review prompt from complexity report\n */\nexport function buildReviewPrompt(\n  report: ComplexityReport,\n  prContext: PRContext,\n  codeSnippets: Map<string, string>,\n  deltas: ComplexityDelta[] | null = null\n): string {\n  const { summary, files } = report;\n  const deltaMap = buildDeltaMap(deltas);\n  const violationsByFile = Object.entries(files).filter(([_, data]) => data.violations.length > 0);\n  const violationsSummary = buildViolationsSummary(files, deltaMap);\n  const snippetsSection = buildSnippetsSection(codeSnippets);\n  const deltaContext = buildDeltaContext(deltas);\n\n  return `# Code Complexity Review Request\n\n## Context\n- **Repository**: ${prContext.owner}/${prContext.repo}\n- **PR**: #${prContext.pullNumber} - ${prContext.title}\n- **Files with violations**: ${violationsByFile.length}\n- **Total violations**: ${summary.totalViolations} (${summary.bySeverity.error} errors, ${summary.bySeverity.warning} warnings)\n${deltaContext}\n## Complexity Violations Found\n\n${violationsSummary}\n\n## Code Snippets\n\n${snippetsSection || '_No code snippets available_'}\n\n## Your Task\n\n**IMPORTANT**: Before suggesting refactorings, analyze the code snippets below to identify the codebase's patterns:\n- Are utilities implemented as functions or classes?\n- How are similar refactorings done elsewhere in the codebase?\n- What naming conventions are used?\n- How is code organized (modules, files, exports)?\n\nFor each violation:\n1. **Explain** why this complexity is problematic in this specific context\n   - Consider the file type (controller, service, component, etc.) and language\n   - Note if this is the only violation in the file or one of many\n   - Consider dependency impact - high-risk files need extra scrutiny\n2. **Suggest** concrete refactoring steps (not generic advice like \"break into smaller functions\")\n   - Be specific to the language and framework patterns\n   - Consider file type conventions (e.g., controllers often delegate to services)\n   - **Match the existing codebase patterns** - if utilities are functions, suggest functions; if they're classes, suggest classes\n3. **Prioritize** which violations are most important to address - focus on functions that got WORSE (higher delta)\n4. If the complexity seems justified for the use case, say so\n   - Some patterns (orchestration, state machines) may legitimately be complex\n5. Celebrate improvements! If a function got simpler, acknowledge it.\n\nFormat your response as a PR review comment with:\n- A brief summary at the top (2-3 sentences)\n- File-by-file breakdown with specific suggestions\n- Prioritized list of recommended changes\n\nBe concise but actionable. Focus on the highest-impact improvements.`;\n}\n\n/**\n * Build a minimal prompt when there are no violations\n */\nexport function buildNoViolationsMessage(prContext: PRContext, deltas: ComplexityDelta[] | null = null): string {\n  let deltaMessage = '';\n\n  if (deltas && deltas.length > 0) {\n    const improved = deltas.filter(d => d.severity === 'improved' || d.severity === 'deleted');\n    if (improved.length > 0) {\n      deltaMessage = `\\n\\nüéâ **Great job!** This PR improved complexity in ${improved.length} function(s).`;\n    }\n  }\n\n  return `<!-- lien-ai-review -->\n## ‚úÖ Lien Complexity Analysis\n\nNo complexity violations found in PR #${prContext.pullNumber}.\n\nAll analyzed functions are within the configured complexity threshold.${deltaMessage}`;\n}\n\n/**\n * Token usage info for display\n */\nexport interface TokenUsageInfo {\n  totalTokens: number;\n  cost: number;\n}\n\n/**\n * Group deltas by metric type and sum their values\n */\nfunction groupDeltasByMetric(deltas: ComplexityDelta[]): Record<string, number> {\n  return collect(deltas)\n    .groupBy('metricType')\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    .map((group: any) => group.sum('delta'))\n    .all() as unknown as Record<string, number>;\n}\n\n/**\n * Build metric breakdown string with emojis\n * Note: getMetricEmoji is defined below (line ~441) to avoid duplication\n */\nfunction buildMetricBreakdownForDisplay(deltaByMetric: Record<string, number>): string {\n  const metricOrder = ['cyclomatic', 'cognitive', 'halstead_effort', 'halstead_bugs'];\n  const emojiMap: Record<string, string> = {\n    cyclomatic: 'üîÄ',\n    cognitive: 'üß†',\n    halstead_effort: '‚è±Ô∏è',\n    halstead_bugs: 'üêõ',\n  };\n  return collect(metricOrder)\n    .map(metricType => {\n      const metricDelta = deltaByMetric[metricType] || 0;\n      const emoji = emojiMap[metricType] || 'üìä';\n      const sign = metricDelta >= 0 ? '+' : '';\n      return `${emoji} ${sign}${formatDeltaValue(metricType, metricDelta)}`;\n    })\n    .all()\n    .join(' | ');\n}\n\n/**\n * Categorize deltas into improved vs degraded counts\n */\nfunction categorizeDeltas(deltas: ComplexityDelta[]): { improved: number; degraded: number } {\n  return deltas.reduce((acc, d) => {\n    if (['improved', 'deleted'].includes(d.severity)) acc.improved++;\n    else if (['warning', 'error', 'new'].includes(d.severity)) acc.degraded++;\n    return acc;\n  }, { improved: 0, degraded: 0 });\n}\n\n/**\n * Determine trend emoji based on total delta\n */\nfunction getTrendEmoji(totalDelta: number): string {\n  if (totalDelta > 0) return '‚¨ÜÔ∏è';\n  if (totalDelta < 0) return '‚¨áÔ∏è';\n  return '‚û°Ô∏è';\n}\n\n/**\n * Format delta display with per-metric breakdown\n * When all deltas are zero, shows a simple \"no change\" message\n */\nfunction formatDeltaDisplay(deltas: ComplexityDelta[] | null | undefined): string {\n  if (!deltas || deltas.length === 0) return '';\n\n  const { improved, degraded } = categorizeDeltas(deltas);\n  const deltaByMetric = groupDeltasByMetric(deltas);\n  const totalDelta = Object.values(deltaByMetric).reduce((sum, v) => sum + v, 0);\n\n  // When nothing changed, keep it simple\n  // Note: pre-existing violations may have severity 'warning' but delta=0\n  if (totalDelta === 0 && improved === 0) {\n    return '\\n\\n**Complexity:** No change from this PR.';\n  }\n\n  const metricBreakdown = buildMetricBreakdownForDisplay(deltaByMetric);\n  const trend = getTrendEmoji(totalDelta);\n\n  let display = `\\n\\n**Complexity Change:** ${metricBreakdown} ${trend}`;\n  if (improved > 0) display += ` | ${improved} improved`;\n  if (degraded > 0) display += ` | ${degraded} degraded`;\n  return display;\n}\n\n/**\n * Format token usage stats for display\n */\nfunction formatTokenStats(tokenUsage: TokenUsageInfo | undefined): string {\n  if (!tokenUsage || tokenUsage.totalTokens <= 0) return '';\n  return `\\n- Tokens: ${tokenUsage.totalTokens.toLocaleString()} ($${tokenUsage.cost.toFixed(4)})`;\n}\n\n/**\n * Format fallback note for boy scout rule\n */\nfunction formatFallbackNote(isFallback: boolean): string {\n  if (!isFallback) return '';\n  return `\\n\\n> üí° *These violations exist in files touched by this PR but not on changed lines. Consider the [boy scout rule](https://www.oreilly.com/library/view/97-things-every/9780596809515/ch08.html): leave the code cleaner than you found it!*\\n`;\n}\n\n/**\n * Count new/worsened vs pre-existing violations from deltas\n */\nfunction countViolationsByNovelty(\n  totalViolations: number,\n  deltas: ComplexityDelta[] | null | undefined\n): { newCount: number; preExistingCount: number; improvedCount: number } {\n  if (!deltas || deltas.length === 0) {\n    return { newCount: 0, preExistingCount: 0, improvedCount: 0 };\n  }\n\n  const newCount = deltas.filter(d =>\n    d.severity === 'new' || d.severity === 'warning' || d.severity === 'error'\n  ).filter(d => d.severity === 'new' || d.delta > 0).length;\n\n  const improvedCount = deltas.filter(d => d.severity === 'improved').length;\n\n  const preExistingCount = Math.max(0, totalViolations - newCount);\n\n  return { newCount, preExistingCount, improvedCount };\n}\n\n/**\n * Build the header line distinguishing new vs pre-existing violations\n */\nexport function buildHeaderLine(\n  totalViolations: number,\n  deltas: ComplexityDelta[] | null | undefined\n): string {\n  const { newCount, preExistingCount, improvedCount } = countViolationsByNovelty(totalViolations, deltas);\n\n  // No delta data available - fall back to old behavior\n  if (!deltas || deltas.length === 0) {\n    return `${totalViolations} issue${totalViolations === 1 ? '' : 's'} spotted in this PR.`;\n  }\n\n  const parts: string[] = [];\n\n  if (newCount > 0) {\n    parts.push(`${newCount} new issue${newCount === 1 ? '' : 's'} spotted in this PR.`);\n  } else {\n    parts.push('No new complexity introduced.');\n  }\n\n  if (improvedCount > 0) {\n    parts.push(`${improvedCount} function${improvedCount === 1 ? '' : 's'} improved.`);\n  }\n\n  if (preExistingCount > 0) {\n    parts.push(`${preExistingCount} pre-existing issue${preExistingCount === 1 ? '' : 's'} in touched files.`);\n  }\n\n  return parts.join(' ');\n}\n\n/**\n * Format the AI review as a GitHub comment\n */\nexport function formatReviewComment(\n  aiReview: string,\n  report: ComplexityReport,\n  isFallback = false,\n  tokenUsage?: TokenUsageInfo,\n  deltas?: ComplexityDelta[] | null,\n  uncoveredNote: string = ''\n): string {\n  const { summary } = report;\n  const deltaDisplay = formatDeltaDisplay(deltas);\n  const fallbackNote = formatFallbackNote(isFallback);\n  const tokenStats = formatTokenStats(tokenUsage);\n\n  const headerLine = buildHeaderLine(summary.totalViolations, deltas);\n\n  return `<!-- lien-ai-review -->\n## üëÅÔ∏è Veille\n\n${headerLine}${deltaDisplay}${fallbackNote}\n\n---\n\n${aiReview}\n\n---${uncoveredNote}\n\n<details>\n<summary>üìä Analysis Details</summary>\n\n- Files analyzed: ${summary.filesAnalyzed}\n- Average complexity: ${summary.avgComplexity.toFixed(1)}\n- Max complexity: ${summary.maxComplexity}${tokenStats}\n\n</details>\n\n*[Veille](https://lien.dev) by Lien*`;\n}\n\n/**\n * Get the key for a violation (for code snippet mapping)\n */\nexport function getViolationKey(violation: ComplexityViolation): string {\n  return `${violation.filepath}::${violation.symbolName}`;\n}\n\n/**\n * Determine human-friendly status message based on violations and delta.\n * Prioritizes positive messaging when PR improves complexity.\n */\nfunction determineStatus(\n  report: ComplexityReport | null,\n  deltaSummary: DeltaSummary | null\n): { emoji: string; message: string } {\n  const violations = report?.summary.totalViolations ?? 0;\n  const errors = report?.summary.bySeverity.error ?? 0;\n  const delta = deltaSummary?.totalDelta ?? 0;\n  const newViolations = deltaSummary?.newFunctions ?? 0;\n  const preExisting = Math.max(0, violations - newViolations);\n\n  // PR improved complexity - celebrate it!\n  if (delta < 0) {\n    if (preExisting > 0) {\n      return {\n        emoji: '‚úÖ',\n        message: `**Improved!** Complexity reduced by ${Math.abs(delta)}. ${preExisting} pre-existing issue${preExisting === 1 ? '' : 's'} remain${preExisting === 1 ? 's' : ''} in touched files.`,\n      };\n    }\n    return { emoji: '‚úÖ', message: `**Improved!** This PR reduces complexity by ${Math.abs(delta)}.` };\n  }\n\n  // New violations introduced - these need attention\n  if (newViolations > 0 && errors > 0) {\n    return {\n      emoji: 'üî¥',\n      message: `**Review required** - ${newViolations} new function${newViolations === 1 ? ' is' : 's are'} too complex.`,\n    };\n  }\n\n  if (newViolations > 0) {\n    return {\n      emoji: '‚ö†Ô∏è',\n      message: `**Needs attention** - ${newViolations} new function${newViolations === 1 ? ' is' : 's are'} more complex than recommended.`,\n    };\n  }\n\n  // Only pre-existing violations (no new ones)\n  if (violations > 0) {\n    return {\n      emoji: '‚û°Ô∏è',\n      message: `**Stable** - ${preExisting} pre-existing issue${preExisting === 1 ? '' : 's'} in touched files (none introduced).`,\n    };\n  }\n\n  // No violations at all\n  if (delta > 0) {\n    return { emoji: '‚û°Ô∏è', message: '**Stable** - Complexity increased slightly but within limits.' };\n  }\n\n  return { emoji: '‚úÖ', message: '**Good** - No complexity issues found.' };\n}\n\n/**\n * Get emoji for metric type\n */\nfunction getMetricEmoji(metricType: string): string {\n  switch (metricType) {\n    case 'cyclomatic': return 'üîÄ';\n    case 'cognitive': return 'üß†';\n    case 'halstead_effort': return '‚è±Ô∏è';\n    case 'halstead_bugs': return 'üêõ';\n    default: return 'üìä';\n  }\n}\n\n/**\n * Build metric breakdown table for violations\n */\nfunction buildMetricTable(\n  report: ComplexityReport | null,\n  deltas: ComplexityDelta[] | null\n): string {\n  if (!report || report.summary.totalViolations === 0) return '';\n\n  const byMetric = collect(Object.values(report.files))\n    .flatMap(f => f.violations)\n    .countBy('metricType')\n    .all() as unknown as Record<string, number>;\n\n  const deltaByMetric: Record<string, number> = deltas\n    ? collect(deltas)\n        .groupBy('metricType')\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        .map((group: any) => group.sum('delta'))\n        .all() as unknown as Record<string, number>\n    : {};\n\n  const metricOrder = ['cyclomatic', 'cognitive', 'halstead_effort', 'halstead_bugs'];\n  const rows = collect(metricOrder)\n    .filter(metricType => byMetric[metricType] > 0)\n    .map(metricType => {\n      const emoji = getMetricEmoji(metricType);\n      const label = getMetricLabel(metricType);\n      const count = byMetric[metricType];\n      const delta = deltaByMetric[metricType] || 0;\n      const deltaStr = deltas ? (delta >= 0 ? `+${delta}` : `${delta}`) : '‚Äî';\n      return `| ${emoji} ${label} | ${count} | ${deltaStr} |`;\n    })\n    .all() as string[];\n\n  if (rows.length === 0) return '';\n\n  return `\n| Metric | Violations | Change |\n|--------|:----------:|:------:|\n${rows.join('\\n')}\n`;\n}\n\n/**\n * Build dependency impact summary\n */\nfunction buildImpactSummary(report: ComplexityReport | null): string {\n  if (!report) return '';\n\n  const filesWithDependents = Object.values(report.files)\n    .filter(f => f.dependentCount && f.dependentCount > 0);\n\n  if (filesWithDependents.length === 0) return '';\n\n  const totalDependents = filesWithDependents.reduce((sum, f) => sum + (f.dependentCount || 0), 0);\n  const highRiskFiles = filesWithDependents.filter(f =>\n    ['high', 'critical'].includes(f.riskLevel)\n  ).length;\n\n  if (highRiskFiles === 0) return '';\n\n  return `\\nüîó **Impact**: ${highRiskFiles} high-risk file(s) with ${totalDependents} total dependents`;\n}\n\n/**\n * Build the PR description stats badge\n * Human-friendly summary with metrics table\n */\nexport function buildDescriptionBadge(\n  report: ComplexityReport | null,\n  deltaSummary: DeltaSummary | null,\n  deltas: ComplexityDelta[] | null\n): string {\n  const status = determineStatus(report, deltaSummary);\n  const metricTable = buildMetricTable(report, deltas);\n  const impactSummary = buildImpactSummary(report);\n\n  return `### üëÅÔ∏è Veille\n\n${status.emoji} ${status.message}${impactSummary}\n${metricTable}\n*[Veille](https://lien.dev) by Lien*`;\n}\n\n/**\n * Build Halstead details string for prompts\n */\nfunction formatHalsteadContext(violation: ComplexityViolation): string {\n  if (!violation.metricType?.startsWith('halstead_')) return '';\n  if (!violation.halsteadDetails) return '';\n\n  const details = violation.halsteadDetails;\n  return `\\n**Halstead Metrics**: Volume: ${details.volume?.toLocaleString()}, Difficulty: ${details.difficulty?.toFixed(1)}, Effort: ${details.effort?.toLocaleString()}, Est. bugs: ${details.bugs?.toFixed(3)}`;\n}\n\n/**\n * Build a prompt for generating a single line comment for a violation\n */\nexport function buildLineCommentPrompt(\n  violation: ComplexityViolation,\n  codeSnippet: string | null\n): string {\n  const snippetSection = codeSnippet\n    ? `\\n\\n**Code:**\\n\\`\\`\\`\\n${codeSnippet}\\n\\`\\`\\``\n    : '';\n\n  const metricType = violation.metricType || 'cyclomatic';\n  const metricLabel = getMetricLabel(metricType);\n  const valueDisplay = formatComplexityValue(metricType, violation.complexity);\n  const thresholdDisplay = formatThresholdValue(metricType, violation.threshold);\n  const halsteadContext = formatHalsteadContext(violation);\n\n  return `You are reviewing code for complexity. Generate an actionable review comment.\n\n**Function**: \\`${violation.symbolName}\\` (${violation.symbolType})\n**Complexity**: ${valueDisplay} ${metricLabel} (threshold: ${thresholdDisplay})${halsteadContext}\n${snippetSection}\n\n**IMPORTANT**: Before suggesting refactorings, analyze the code snippet above to identify the codebase's patterns (functions vs classes, naming conventions, module organization). Match your suggestions to those patterns.\n\nWrite a code review comment that includes:\n\n1. **Problem** (1 sentence): What specific pattern makes this complex (e.g., \"5 levels of nested conditionals\", \"switch with embedded if-chains\", \"many unique operators\")\n\n2. **Refactoring** (2-3 sentences): Concrete steps to reduce complexity. Be SPECIFIC:\n   - Name the exact functions to extract (e.g., \"Extract \\`handleAdminDelete()\\` and \\`handleModeratorDelete()\\`\")\n   - Suggest specific patterns (strategy, lookup table, early returns)\n   - For Halstead metrics: suggest introducing named constants, reducing operator variety, or extracting complex expressions\n   - If applicable, show a brief code sketch\n   - **Match the existing codebase patterns** - if utilities are functions, suggest functions; if they're classes, suggest classes\n\n3. **Benefit** (1 sentence): What improves (testability, readability, etc.)\n\nFormat as a single cohesive comment without headers. Be direct and specific to THIS code.`;\n}\n\n/**\n * Build a summary comment when using line-specific reviews\n */\nexport function buildLineSummaryComment(\n  report: ComplexityReport,\n  prContext: PRContext\n): string {\n  const { summary } = report;\n  const emoji = summary.bySeverity.error > 0 ? 'üî¥' : 'üü°';\n\n  return `<!-- lien-ai-review -->\n## ${emoji} Veille\n\n${summary.totalViolations} issue${summary.totalViolations === 1 ? '' : 's'} spotted in this PR.\n\nSee inline comments below for specific suggestions.\n\n<details>\n<summary>üìä Details</summary>\n\n- Files analyzed: ${summary.filesAnalyzed}\n- Average complexity: ${summary.avgComplexity.toFixed(1)}\n- Max complexity: ${summary.maxComplexity}\n\n</details>\n\n*[Veille](https://lien.dev) by Lien*`;\n}\n\n/**\n * Get the example that matches the most common metric type in the violations.\n * This ensures the example is relevant to what we're reviewing.\n */\nfunction getExampleForPrimaryMetric(violations: ComplexityViolation[]): string {\n  if (violations.length === 0) return DEFAULT_EXAMPLE;\n\n  const counts = collect(violations)\n    .countBy((v: ComplexityViolation) => v.metricType || 'cyclomatic')\n    .all() as Record<string, number>;\n\n  const maxType = Object.entries(counts)\n    .reduce(\n      (max, [type, count]) =>\n        count > max.count ? { type, count } : max,\n      { type: 'cyclomatic', count: 0 }\n    ).type;\n\n  return COMMENT_EXAMPLES[maxType] || DEFAULT_EXAMPLE;\n}\n\n/**\n * Build a batched prompt for generating multiple line comments at once\n * This is more efficient than individual prompts as:\n * - System prompt only sent once\n * - AI has full context of all violations\n * - Fewer API calls = faster + cheaper\n */\nexport function buildBatchedCommentsPrompt(\n  violations: ComplexityViolation[],\n  codeSnippets: Map<string, string>,\n  report: ComplexityReport\n): string {\n  const violationsText = violations\n    .map((v, i) => {\n      const key = `${v.filepath}::${v.symbolName}`;\n      const snippet = codeSnippets.get(key);\n      const snippetSection = snippet\n        ? `\\nCode:\\n\\`\\`\\`\\n${snippet}\\n\\`\\`\\``\n        : '';\n\n      const metricType = v.metricType || 'cyclomatic';\n      const metricLabel = getMetricLabel(metricType);\n      const valueDisplay = formatComplexityValue(metricType, v.complexity);\n      const thresholdDisplay = formatThresholdValue(metricType, v.threshold);\n      const halsteadContext = formatHalsteadContext(v);\n\n      // Add dependency context for this violation's file\n      const fileData = report.files[v.filepath];\n      const dependencyContext = fileData ? buildDependencyContext(fileData) : '';\n\n      // Add file-level context (language, type, other violations)\n      const fileContext = fileData ? buildFileContext(v.filepath, fileData) : '';\n\n      return `### ${i + 1}. ${v.filepath}::${v.symbolName}\n- **Function**: \\`${v.symbolName}\\` (${v.symbolType})\n- **Complexity**: ${valueDisplay} ${metricLabel} (threshold: ${thresholdDisplay})${halsteadContext}\n- **Severity**: ${v.severity}${fileContext}${dependencyContext}${snippetSection}`;\n    })\n    .join('\\n\\n');\n\n  // Build JSON keys for the response format\n  const jsonKeys = violations\n    .map((v) => `  \"${v.filepath}::${v.symbolName}\": \"your comment here\"`)\n    .join(',\\n');\n\n  return `You are a senior engineer reviewing code for complexity. Generate thoughtful, context-aware review comments.\n\n## Violations to Review\n\n${violationsText}\n\n## Instructions\n\n**IMPORTANT**: Before suggesting refactorings, analyze the code snippets provided to identify the codebase's patterns:\n- Are utilities implemented as functions or classes?\n- How are similar refactorings done elsewhere in the codebase?\n- What naming conventions are used?\n\nFor each violation, write a code review comment that:\n\n1. **Identifies the specific pattern** causing complexity (not just \"too complex\")\n   - Is it nested conditionals? Long parameter lists? Multiple responsibilities?\n   - For Halstead metrics: many unique operators/operands, complex expressions\n   - Be specific: \"5 levels of nesting\" not \"deeply nested\"\n\n2. **Suggests a concrete fix** with a short code example (3-5 lines)\n   - Consider: early returns, guard clauses, lookup tables, extracting helpers, strategy pattern\n   - For Halstead: named constants, reducing operator variety, extracting complex expressions\n   - Name specific functions: \"Extract \\`handleAdminCase()\\`\" not \"extract a function\"\n   - Choose the SIMPLEST fix that addresses the issue (KISS principle)\n   - **Match the existing codebase patterns** - if utilities are functions, suggest functions; if they're classes, suggest classes\n\n3. **Acknowledges context** when relevant\n   - If this is an orchestration function, complexity may be acceptable\n   - If the logic is inherently complex (state machines, parsers), say so\n   - Don't suggest over-engineering for marginal gains\n\nBe direct and specific to THIS code. Avoid generic advice like \"break into smaller functions.\"\n\n**Example of a good comment:**\n\"${getExampleForPrimaryMetric(violations)}\"\n\nWrite comments of similar quality and specificity for each violation below.\n\nIMPORTANT: Do NOT include headers like \"Complexity: X\" or emojis - we add those.\n\n## Response Format\n\nRespond with ONLY valid JSON. Each key is \"filepath::symbolName\", value is the comment text.\nUse \\\\n for newlines within comments.\n\n\\`\\`\\`json\n{\n${jsonKeys}\n}\n\\`\\`\\``;\n}\n","/**\n * Complexity delta calculation\n * Compares base branch complexity to head branch complexity\n */\n\nimport collect from 'collect.js';\nimport type {\n  ComplexityReport,\n  ComplexityViolation,\n} from '@liendev/core';\nimport type { Logger } from './logger.js';\n\n/**\n * Complexity delta for a single function/method\n */\nexport interface ComplexityDelta {\n  filepath: string;\n  symbolName: string;\n  symbolType: string;\n  startLine: number;\n  metricType: string; // which metric this delta is for\n  baseComplexity: number | null; // null = new function\n  headComplexity: number | null; // null = deleted function\n  delta: number; // positive = worse, negative = better\n  threshold: number;\n  severity: 'warning' | 'error' | 'improved' | 'new' | 'deleted';\n}\n\n/**\n * Summary of complexity changes in a PR\n */\nexport interface DeltaSummary {\n  totalDelta: number; // net change across all functions\n  improved: number; // count of functions that got simpler\n  degraded: number; // count of functions that got more complex\n  newFunctions: number; // count of new functions with violations\n  deletedFunctions: number; // count of deleted functions (freed complexity)\n  unchanged: number; // count of functions with same complexity\n}\n\n/**\n * Create a key for a function+metric to match across base/head\n * Includes metricType since a function can have multiple metric violations\n */\nfunction getFunctionKey(filepath: string, symbolName: string, metricType: string): string {\n  return `${filepath}::${symbolName}::${metricType}`;\n}\n\n/**\n * Build a map of function complexities from a report\n */\nfunction buildComplexityMap(\n  report: ComplexityReport | null,\n  files: string[]\n): Map<string, { complexity: number; violation: ComplexityViolation }> {\n  if (!report) return new Map();\n\n  type MapEntry = [string, { complexity: number; violation: ComplexityViolation }];\n\n  // Flatten violations from all requested files and build map entries\n  const entries = collect(files)\n    .map(filepath => ({ filepath, fileData: report.files[filepath] }))\n    .filter(({ fileData }) => !!fileData)\n    .flatMap(({ filepath, fileData }) =>\n      fileData.violations.map(violation => [\n        getFunctionKey(filepath, violation.symbolName, violation.metricType),\n        { complexity: violation.complexity, violation }\n      ] as MapEntry)\n    )\n    .all() as unknown as MapEntry[];\n\n  return new Map(entries);\n}\n\n/**\n * Determine severity based on complexity change\n */\nfunction determineSeverity(\n  baseComplexity: number | null,\n  headComplexity: number,\n  delta: number,\n  threshold: number\n): ComplexityDelta['severity'] {\n  if (baseComplexity === null) return 'new';\n  if (delta < 0) return 'improved';\n  return headComplexity >= threshold * 2 ? 'error' : 'warning';\n}\n\n/**\n * Create a delta object from violation data\n */\nfunction createDelta(\n  violation: ComplexityViolation,\n  baseComplexity: number | null,\n  headComplexity: number | null,\n  severity: ComplexityDelta['severity']\n): ComplexityDelta {\n  const delta = baseComplexity !== null && headComplexity !== null\n    ? headComplexity - baseComplexity\n    : headComplexity ?? -(baseComplexity ?? 0);\n\n  return {\n    filepath: violation.filepath,\n    symbolName: violation.symbolName,\n    symbolType: violation.symbolType,\n    startLine: violation.startLine,\n    metricType: violation.metricType,\n    baseComplexity,\n    headComplexity,\n    delta,\n    threshold: violation.threshold,\n    severity,\n  };\n}\n\n/**\n * Calculate complexity deltas between base and head\n */\nexport function calculateDeltas(\n  baseReport: ComplexityReport | null,\n  headReport: ComplexityReport,\n  changedFiles: string[]\n): ComplexityDelta[] {\n  const baseMap = buildComplexityMap(baseReport, changedFiles);\n  const headMap = buildComplexityMap(headReport, changedFiles);\n  const seenBaseKeys = new Set<string>();\n\n  // Process head violations\n  const headDeltas = collect(Array.from(headMap.entries()))\n    .map(([key, headData]) => {\n      const baseData = baseMap.get(key);\n      if (baseData) seenBaseKeys.add(key);\n\n      const baseComplexity = baseData?.complexity ?? null;\n      const headComplexity = headData.complexity;\n      const delta = baseComplexity !== null ? headComplexity - baseComplexity : headComplexity;\n      const severity = determineSeverity(baseComplexity, headComplexity, delta, headData.violation.threshold);\n\n      return createDelta(headData.violation, baseComplexity, headComplexity, severity);\n    })\n    .all() as ComplexityDelta[];\n\n  // Process deleted functions (in base but not in head)\n  const deletedDeltas = collect(Array.from(baseMap.entries()))\n    .filter(([key]) => !seenBaseKeys.has(key))\n    .map(([_, baseData]) => createDelta(baseData.violation, baseData.complexity, null, 'deleted'))\n    .all() as ComplexityDelta[];\n\n  const deltas = [...headDeltas, ...deletedDeltas];\n\n  // Sort by delta (worst first), then by absolute complexity\n  deltas.sort((a, b) => {\n    // Errors first, then warnings, then new, then improved, then deleted\n    const severityOrder = { error: 0, warning: 1, new: 2, improved: 3, deleted: 4 };\n    if (severityOrder[a.severity] !== severityOrder[b.severity]) {\n      return severityOrder[a.severity] - severityOrder[b.severity];\n    }\n    // Within same severity, sort by delta (worse first)\n    return b.delta - a.delta;\n  });\n\n  return deltas;\n}\n\n/**\n * Calculate summary statistics for deltas\n */\nexport function calculateDeltaSummary(deltas: ComplexityDelta[]): DeltaSummary {\n  const collection = collect(deltas);\n\n  // Categorize each delta\n  const categorized = collection.map(d => {\n    if (d.severity === 'improved') return 'improved';\n    if (d.severity === 'new') return 'new';\n    if (d.severity === 'deleted') return 'deleted';\n    // error/warning: check delta direction\n    if (d.delta > 0) return 'degraded';\n    if (d.delta === 0) return 'unchanged';\n    return 'improved';\n  });\n\n  const counts = categorized.countBy().all() as unknown as Record<string, number>;\n\n  return {\n    totalDelta: collection.sum('delta') as number,\n    improved: counts['improved'] || 0,\n    degraded: counts['degraded'] || 0,\n    newFunctions: counts['new'] || 0,\n    deletedFunctions: counts['deleted'] || 0,\n    unchanged: counts['unchanged'] || 0,\n  };\n}\n\n/**\n * Format delta for display\n */\nexport function formatDelta(delta: number): string {\n  if (delta > 0) return `+${delta} ‚¨ÜÔ∏è`;\n  if (delta < 0) return `${delta} ‚¨áÔ∏è`;\n  return '¬±0';\n}\n\n/**\n * Format severity emoji\n */\nexport function formatSeverityEmoji(severity: ComplexityDelta['severity']): string {\n  switch (severity) {\n    case 'error':\n      return 'üî¥';\n    case 'warning':\n      return 'üü°';\n    case 'improved':\n      return 'üü¢';\n    case 'new':\n      return 'üÜï';\n    case 'deleted':\n      return 'üóëÔ∏è';\n  }\n}\n\n/**\n * Log delta summary\n */\nexport function logDeltaSummary(summary: DeltaSummary, logger: Logger): void {\n  const sign = summary.totalDelta >= 0 ? '+' : '';\n  logger.info(`Complexity delta: ${sign}${summary.totalDelta}`);\n  logger.info(`  Degraded: ${summary.degraded}, Improved: ${summary.improved}`);\n  logger.info(`  New: ${summary.newFunctions}, Deleted: ${summary.deletedFunctions}`);\n}\n","/**\n * Format time in minutes as human-readable (e.g., \"7h 54m\", \"-7h 54m\", or \"45m\")\n * Handles both positive values (for thresholds) and negative values (for deltas).\n * Rounds total minutes first to avoid edge cases like \"1h 60m\".\n */\nexport function formatTime(minutes: number): string {\n  const sign = minutes < 0 ? '-' : '';\n  const roundedMinutes = Math.round(Math.abs(minutes));\n  if (roundedMinutes >= 60) {\n    const hours = Math.floor(roundedMinutes / 60);\n    const mins = roundedMinutes % 60;\n    return mins > 0 ? `${sign}${hours}h ${mins}m` : `${sign}${hours}h`;\n  }\n  return `${sign}${roundedMinutes}m`;\n}\n\n/**\n * Format delta value for display based on metric type.\n * - halstead_bugs: 2 decimal places\n * - halstead_effort: human-readable time (e.g., \"-7h 54m\")\n * - others: rounded integer\n */\nexport function formatDeltaValue(metricType: string, delta: number): string {\n  if (metricType === 'halstead_bugs') {\n    return delta.toFixed(2);\n  }\n  // halstead_effort is stored in minutes - format as hours for readability\n  if (metricType === 'halstead_effort') {\n    return formatTime(delta);\n  }\n  return String(Math.round(delta));\n}\n","/**\n * OpenRouter API client for LLM access\n */\n\nimport type { ComplexityViolation, ComplexityReport } from '@liendev/core';\nimport type { Logger } from './logger.js';\nimport { buildBatchedCommentsPrompt } from './prompt.js';\n\n/**\n * OpenRouter API response structure\n * Cost is returned in usage.cost when usage accounting is enabled\n * See: https://openrouter.ai/docs/guides/guides/usage-accounting\n */\nexport interface OpenRouterResponse {\n  id: string;\n  choices: Array<{\n    message: {\n      role: string;\n      content: string;\n    };\n    finish_reason: string;\n  }>;\n  usage?: {\n    prompt_tokens: number;\n    completion_tokens: number;\n    total_tokens: number;\n    cost?: number; // Returned when usage: { include: true } is set in request\n  };\n}\n\nconst OPENROUTER_API_URL = 'https://openrouter.ai/api/v1/chat/completions';\n\n/**\n * Token usage tracking\n */\nexport interface TokenUsage {\n  promptTokens: number;\n  completionTokens: number;\n  totalTokens: number;\n  cost: number; // Actual cost from OpenRouter API\n}\n\n/**\n * Global token usage accumulator\n */\nlet totalUsage: TokenUsage = {\n  promptTokens: 0,\n  completionTokens: 0,\n  totalTokens: 0,\n  cost: 0,\n};\n\n/**\n * Reset token usage (call at start of review)\n */\nexport function resetTokenUsage(): void {\n  totalUsage = {\n    promptTokens: 0,\n    completionTokens: 0,\n    totalTokens: 0,\n    cost: 0,\n  };\n}\n\n/**\n * Get current token usage\n */\nexport function getTokenUsage(): TokenUsage {\n  return { ...totalUsage };\n}\n\n/**\n * Accumulate token usage from API response\n * Cost is returned in usage.cost when usage accounting is enabled\n */\nfunction trackUsage(\n  usage: { prompt_tokens: number; completion_tokens: number; total_tokens: number; cost?: number } | undefined\n): void {\n  if (!usage) return;\n\n  totalUsage.promptTokens += usage.prompt_tokens;\n  totalUsage.completionTokens += usage.completion_tokens;\n  totalUsage.totalTokens += usage.total_tokens;\n  totalUsage.cost += usage.cost || 0;\n}\n\n/**\n * Parse JSON comments response from AI, handling markdown code blocks\n * Returns null if parsing fails after retry attempts\n * Exported for testing\n */\nexport function parseCommentsResponse(content: string, logger: Logger): Record<string, string> | null {\n  // Try extracting JSON from markdown code block first\n  const codeBlockMatch = content.match(/```(?:json)?\\s*([\\s\\S]*?)```/);\n  const jsonStr = (codeBlockMatch ? codeBlockMatch[1] : content).trim();\n\n  logger.info(`Parsing JSON response (${jsonStr.length} chars)`);\n\n  try {\n    const parsed = JSON.parse(jsonStr);\n    logger.info(`Successfully parsed ${Object.keys(parsed).length} comments`);\n    return parsed;\n  } catch (parseError) {\n    logger.warning(`Initial JSON parse failed: ${parseError}`);\n  }\n\n  // Aggressive retry: extract any JSON object from response\n  const objectMatch = content.match(/\\{[\\s\\S]*\\}/);\n  if (objectMatch) {\n    try {\n      const parsed = JSON.parse(objectMatch[0]);\n      logger.info(`Recovered JSON with aggressive parsing: ${Object.keys(parsed).length} comments`);\n      return parsed;\n    } catch (retryError) {\n      logger.warning(`Retry parsing also failed: ${retryError}`);\n    }\n  }\n\n  logger.warning(`Full response content:\\n${content}`);\n  return null;\n}\n\n/**\n * Generate an AI review using OpenRouter\n */\nexport async function generateReview(\n  prompt: string,\n  apiKey: string,\n  model: string,\n  logger: Logger\n): Promise<string> {\n  logger.info(`Calling OpenRouter with model: ${model}`);\n\n  const response = await fetch(OPENROUTER_API_URL, {\n    method: 'POST',\n    headers: {\n      Authorization: `Bearer ${apiKey}`,\n      'Content-Type': 'application/json',\n      'HTTP-Referer': 'https://github.com/getlien/lien',\n      'X-Title': 'Veille by Lien',\n    },\n    body: JSON.stringify({\n      model,\n      messages: [\n        {\n          role: 'system',\n          content:\n            'You are an expert code reviewer. Provide actionable, specific feedback on code complexity issues. Be concise but thorough. Before suggesting refactorings, analyze the code snippets provided to identify the codebase\\'s architectural patterns (e.g., functions vs classes, module organization, naming conventions). Then suggest refactorings that match those existing patterns.',\n        },\n        {\n          role: 'user',\n          content: prompt,\n        },\n      ],\n      max_tokens: 2000,\n      temperature: 0.3, // Lower temperature for more consistent reviews\n      // Enable usage accounting to get cost data\n      // https://openrouter.ai/docs/guides/guides/usage-accounting\n      usage: {\n        include: true,\n      },\n    }),\n  });\n\n  if (!response.ok) {\n    const errorText = await response.text();\n    throw new Error(\n      `OpenRouter API error (${response.status}): ${errorText}`\n    );\n  }\n\n  const data = (await response.json()) as OpenRouterResponse;\n\n  if (!data.choices || data.choices.length === 0) {\n    throw new Error('No response from OpenRouter');\n  }\n\n  const review = data.choices[0].message.content;\n\n  // Cost is in usage.cost when usage accounting is enabled\n  if (data.usage) {\n    trackUsage(data.usage);\n    const costStr = data.usage.cost ? ` ($${data.usage.cost.toFixed(6)})` : '';\n    logger.info(\n      `Tokens: ${data.usage.prompt_tokens} in, ${data.usage.completion_tokens} out${costStr}`\n    );\n  }\n\n  return review;\n}\n\n/**\n * Call OpenRouter API with batched comments prompt\n */\nasync function callBatchedCommentsAPI(\n  prompt: string,\n  apiKey: string,\n  model: string\n): Promise<OpenRouterResponse> {\n  const response = await fetch(OPENROUTER_API_URL, {\n    method: 'POST',\n    headers: {\n      Authorization: `Bearer ${apiKey}`,\n      'Content-Type': 'application/json',\n      'HTTP-Referer': 'https://github.com/getlien/lien',\n      'X-Title': 'Veille by Lien',\n    },\n    body: JSON.stringify({\n      model,\n      messages: [\n        {\n          role: 'system',\n          content:\n            'You are an expert code reviewer. Write detailed, actionable comments with specific refactoring suggestions. Respond ONLY with valid JSON. Before suggesting refactorings, analyze the code snippets provided to identify the codebase\\'s architectural patterns (e.g., functions vs classes, module organization, naming conventions). Then suggest refactorings that match those existing patterns.',\n        },\n        { role: 'user', content: prompt },\n      ],\n      max_tokens: 4096,\n      temperature: 0.3,\n      usage: { include: true },\n    }),\n  });\n\n  if (!response.ok) {\n    const errorText = await response.text();\n    throw new Error(`OpenRouter API error (${response.status}): ${errorText}`);\n  }\n\n  const data = (await response.json()) as OpenRouterResponse;\n\n  if (!data.choices || data.choices.length === 0) {\n    throw new Error('No response from OpenRouter');\n  }\n\n  return data;\n}\n\n/**\n * Map parsed comments to violations, with fallback for missing comments\n * Exported for testing\n */\nexport function mapCommentsToViolations(\n  commentsMap: Record<string, string> | null,\n  violations: ComplexityViolation[],\n  logger: Logger\n): Map<ComplexityViolation, string> {\n  const results = new Map<ComplexityViolation, string>();\n  const fallbackMessage = (v: ComplexityViolation) =>\n    `This ${v.symbolType} exceeds the complexity threshold. Consider refactoring to improve readability and testability.`;\n\n  if (!commentsMap) {\n    for (const violation of violations) {\n      results.set(violation, fallbackMessage(violation));\n    }\n    return results;\n  }\n\n  for (const violation of violations) {\n    const key = `${violation.filepath}::${violation.symbolName}`;\n    const comment = commentsMap[key];\n\n    if (comment) {\n      results.set(violation, comment.replace(/\\\\n/g, '\\n'));\n    } else {\n      logger.warning(`No comment generated for ${key}`);\n      results.set(violation, fallbackMessage(violation));\n    }\n  }\n\n  return results;\n}\n\n/**\n * Generate line comments for multiple violations in a single API call\n *\n * This is more efficient than individual calls:\n * - System prompt only sent once (saves ~100 tokens per violation)\n * - AI has full context of all violations (can identify patterns)\n * - Single API call = faster execution\n */\nexport async function generateLineComments(\n  violations: ComplexityViolation[],\n  codeSnippets: Map<string, string>,\n  apiKey: string,\n  model: string,\n  report: ComplexityReport,\n  logger: Logger\n): Promise<Map<ComplexityViolation, string>> {\n  if (violations.length === 0) {\n    return new Map();\n  }\n\n  logger.info(`Generating comments for ${violations.length} violations in single batch`);\n\n  const prompt = buildBatchedCommentsPrompt(violations, codeSnippets, report);\n  const data = await callBatchedCommentsAPI(prompt, apiKey, model);\n\n  if (data.usage) {\n    trackUsage(data.usage);\n    const costStr = data.usage.cost ? ` ($${data.usage.cost.toFixed(6)})` : '';\n    logger.info(`Batch tokens: ${data.usage.prompt_tokens} in, ${data.usage.completion_tokens} out${costStr}`);\n  }\n\n  const commentsMap = parseCommentsResponse(data.choices[0].message.content, logger);\n  return mapCommentsToViolations(commentsMap, violations, logger);\n}\n"],"mappings":";AAQA,YAAY,UAAU;AACtB,YAAY,YAAY;;;AEJxB,YAAY,QAAQ;AACpB,SAAS,gBAAgB;AACzB,OAAOA,cAAa;AACpB;EACE;EACA;EACA;EACA;OAGK;ACVP,SAAS,eAAe;ACDxB,OAAOA,cAAa;ACCpB,OAAO,aAAa;AFSb,SAAS,cAAc,OAAwB;AACpD,SAAO,IAAI,QAAQ,EAAE,MAAM,MAAM,CAAC;AACpC;AAKA,eAAsB,kBACpB,SACA,WACmB;AACnB,QAAM,QAAkB,CAAC;AACzB,MAAI,OAAO;AACX,QAAM,UAAU;AAEhB,SAAO,MAAM;AACX,UAAM,WAAW,MAAM,QAAQ,MAAM,UAAU;MAC7C,OAAO,UAAU;MACjB,MAAM,UAAU;MAChB,aAAa,UAAU;MACvB,UAAU;MACV;IACF,CAAC;AAED,eAAW,QAAQ,SAAS,MAAM;AAEhC,UAAI,KAAK,WAAW,WAAW;AAC7B,cAAM,KAAK,KAAK,QAAQ;MAC1B;IACF;AAEA,QAAI,SAAS,KAAK,SAAS,SAAS;AAClC;IACF;AACA;EACF;AAEA,SAAO;AACT;AAKA,eAAsB,cACpB,SACA,WACA,MACA,QACe;AAEf,QAAM,kBAAkB,MAAM,oBAAoB,SAAS,SAAS;AAEpE,MAAI,iBAAiB;AACnB,WAAO,KAAK,6BAA6B,gBAAgB,EAAE,EAAE;AAC7D,UAAM,QAAQ,OAAO,cAAc;MACjC,OAAO,UAAU;MACjB,MAAM,UAAU;MAChB,YAAY,gBAAgB;MAC5B;IACF,CAAC;EACH,OAAO;AACL,WAAO,KAAK,sBAAsB;AAClC,UAAM,QAAQ,OAAO,cAAc;MACjC,OAAO,UAAU;MACjB,MAAM,UAAU;MAChB,cAAc,UAAU;MACxB;IACF,CAAC;EACH;AACF;AAKA,eAAe,oBACb,SACA,WACgC;AAChC,QAAM,iBAAiB;AAEvB,QAAM,WAAW,MAAM,QAAQ,OAAO,aAAa;IACjD,OAAO,UAAU;IACjB,MAAM,UAAU;IAChB,cAAc,UAAU;EAC1B,CAAC;AAED,aAAW,WAAW,SAAS,MAAM;AACnC,QAAI,QAAQ,MAAM,SAAS,cAAc,GAAG;AAC1C,aAAO,EAAE,IAAI,QAAQ,GAAG;IAC1B;EACF;AAEA,SAAO;AACT;AAKA,eAAsB,eACpB,SACA,WACA,UACA,WACA,SACA,QACwB;AACxB,MAAI;AACF,UAAM,WAAW,MAAM,QAAQ,MAAM,WAAW;MAC9C,OAAO,UAAU;MACjB,MAAM,UAAU;MAChB,MAAM;MACN,KAAK,UAAU;IACjB,CAAC;AAED,QAAI,aAAa,SAAS,MAAM;AAC9B,YAAM,UAAU,OAAO,KAAK,SAAS,KAAK,SAAmB,QAAQ,EAAE;QACrE;MACF;AACA,YAAM,QAAQ,QAAQ,MAAM,IAAI;AAEhC,YAAM,UAAU,MAAM,MAAM,YAAY,GAAG,OAAO,EAAE,KAAK,IAAI;AAC7D,aAAO;IACT;EACF,SAASC,QAAO;AACd,WAAO,QAAQ,6BAA6B,QAAQ,KAAKA,MAAK,EAAE;EAClE;AAEA,SAAO;AACT;AAKA,eAAsB,aACpB,SACA,WACA,UACA,aACA,QACe;AACf,MAAI,SAAS,WAAW,GAAG;AAEzB,UAAM,cAAc,SAAS,WAAW,aAAa,MAAM;AAC3D;EACF;AAEA,SAAO,KAAK,wBAAwB,SAAS,MAAM,gBAAgB;AAEnE,MAAI;AAEF,UAAM,QAAQ,MAAM,aAAa;MAC/B,OAAO,UAAU;MACjB,MAAM,UAAU;MAChB,aAAa,UAAU;MACvB,WAAW,UAAU;MACrB,OAAO;;MACP,MAAM;MACN,UAAU,SAAS,IAAI,CAAC,OAAO;QAC7B,MAAM,EAAE;QACR,MAAM,EAAE;QACR,MAAM,EAAE;MACV,EAAE;IACJ,CAAC;AAED,WAAO,KAAK,4BAA4B;EAC1C,SAASA,QAAO;AAEd,WAAO,QAAQ,iCAAiCA,MAAK,EAAE;AACvD,WAAO,KAAK,oCAAoC;AAChD,UAAM,cAAc,SAAS,WAAW,aAAa,MAAM;EAC7D;AACF;AAKA,IAAM,2BAA2B;AACjC,IAAM,yBAAyB;AAM/B,eAAsB,oBACpB,SACA,WACA,eACA,QACe;AACf,MAAI;AAEF,UAAM,EAAE,MAAM,GAAG,IAAI,MAAM,QAAQ,MAAM,IAAI;MAC3C,OAAO,UAAU;MACjB,MAAM,UAAU;MAChB,aAAa,UAAU;IACzB,CAAC;AAED,UAAM,cAAc,GAAG,QAAQ;AAC/B,UAAM,eAAe,GAAG,wBAAwB;EAAK,aAAa;EAAK,sBAAsB;AAE7F,QAAI;AAGJ,UAAM,WAAW,YAAY,QAAQ,wBAAwB;AAC7D,UAAM,SAAS,YAAY,QAAQ,sBAAsB;AAEzD,QAAI,aAAa,MAAM,WAAW,MAAM,SAAS,UAAU;AAEzD,gBACE,YAAY,MAAM,GAAG,QAAQ,IAC7B,eACA,YAAY,MAAM,SAAS,uBAAuB,MAAM;AAC1D,aAAO,KAAK,iDAAiD;IAC/D,OAAO;AAEL,gBAAU,YAAY,KAAK,IAAI,gBAAgB;AAC/C,aAAO,KAAK,sCAAsC;IACpD;AAGA,UAAM,QAAQ,MAAM,OAAO;MACzB,OAAO,UAAU;MACjB,MAAM,UAAU;MAChB,aAAa,UAAU;MACvB,MAAM;IACR,CAAC;AAED,WAAO,KAAK,8CAA8C;EAC5D,SAASA,QAAO;AAEd,WAAO,QAAQ,oCAAoCA,MAAK,EAAE;EAC5D;AACF;AAMO,SAAS,gBAAgB,OAA4B;AAC1D,QAAM,QAAQ,oBAAI,IAAY;AAC9B,MAAI,cAAc;AAElB,aAAW,aAAa,MAAM,MAAM,IAAI,GAAG;AAEzC,UAAM,YAAY,UAAU,MAAM,uCAAuC;AACzE,QAAI,WAAW;AACb,oBAAc,SAAS,UAAU,CAAC,GAAG,EAAE;AACvC;IACF;AAGA,QAAI,UAAU,WAAW,GAAG,KAAK,UAAU,WAAW,GAAG,GAAG;AAC1D,UAAI,CAAC,UAAU,WAAW,KAAK,GAAG;AAChC,cAAM,IAAI,WAAW;AACrB;MACF;IACF;EAEF;AAEA,SAAO;AACT;AAMA,eAAsB,eACpB,SACA,WACmC;AACnC,QAAM,YAAY,oBAAI,IAAyB;AAG/C,QAAM,WAAW,QAAQ,SAAS,SAAS,QAAQ,MAAM,WAAW;IAClE,OAAO,UAAU;IACjB,MAAM,UAAU;IAChB,aAAa,UAAU;IACvB,UAAU;EACZ,CAAC;AAED,mBAAiB,YAAY,UAAU;AACrC,eAAW,QAAQ,SAAS,MAAM;AAChC,UAAI,CAAC,KAAK,MAAO;AAEjB,YAAM,QAAQ,gBAAgB,KAAK,KAAK;AACxC,UAAI,MAAM,OAAO,GAAG;AAClB,kBAAU,IAAI,KAAK,UAAU,KAAK;MACpC;IACF;EACF;AAEA,SAAO;AACT;AEvQA,SAAS,eAAe,UAAkB,YAAoB,YAA4B;AACxF,SAAO,GAAG,QAAQ,KAAK,UAAU,KAAK,UAAU;AAClD;AAKA,SAAS,mBACP,QACA,OACqE;AACrE,MAAI,CAAC,OAAQ,QAAO,oBAAI,IAAI;AAK5B,QAAM,UAAU,QAAQ,KAAK,EAC1B,IAAI,CAAA,cAAa,EAAE,UAAU,UAAU,OAAO,MAAM,QAAQ,EAAE,EAAE,EAChE,OAAO,CAAC,EAAE,SAAS,MAAM,CAAC,CAAC,QAAQ,EACnC;IAAQ,CAAC,EAAE,UAAU,SAAS,MAC7B,SAAS,WAAW,IAAI,CAAA,cAAa;MACnC,eAAe,UAAU,UAAU,YAAY,UAAU,UAAU;MACnE,EAAE,YAAY,UAAU,YAAY,UAAU;IAChD,CAAa;EACf,EACC,IAAI;AAEP,SAAO,IAAI,IAAI,OAAO;AACxB;AAKA,SAAS,kBACP,gBACA,gBACA,OACA,WAC6B;AAC7B,MAAI,mBAAmB,KAAM,QAAO;AACpC,MAAI,QAAQ,EAAG,QAAO;AACtB,SAAO,kBAAkB,YAAY,IAAI,UAAU;AACrD;AAKA,SAAS,YACP,WACA,gBACA,gBACA,UACiB;AACjB,QAAM,QAAQ,mBAAmB,QAAQ,mBAAmB,OACxD,iBAAiB,iBACjB,kBAAkB,EAAE,kBAAkB;AAE1C,SAAO;IACL,UAAU,UAAU;IACpB,YAAY,UAAU;IACtB,YAAY,UAAU;IACtB,WAAW,UAAU;IACrB,YAAY,UAAU;IACtB;IACA;IACA;IACA,WAAW,UAAU;IACrB;EACF;AACF;AAKO,SAAS,gBACd,YACA,YACA,cACmB;AACnB,QAAM,UAAU,mBAAmB,YAAY,YAAY;AAC3D,QAAM,UAAU,mBAAmB,YAAY,YAAY;AAC3D,QAAM,eAAe,oBAAI,IAAY;AAGrC,QAAM,aAAa,QAAQ,MAAM,KAAK,QAAQ,QAAQ,CAAC,CAAC,EACrD,IAAI,CAAC,CAAC,KAAK,QAAQ,MAAM;AACxB,UAAM,WAAW,QAAQ,IAAI,GAAG;AAChC,QAAI,SAAU,cAAa,IAAI,GAAG;AAElC,UAAM,iBAAiB,UAAU,cAAc;AAC/C,UAAM,iBAAiB,SAAS;AAChC,UAAM,QAAQ,mBAAmB,OAAO,iBAAiB,iBAAiB;AAC1E,UAAM,WAAW,kBAAkB,gBAAgB,gBAAgB,OAAO,SAAS,UAAU,SAAS;AAEtG,WAAO,YAAY,SAAS,WAAW,gBAAgB,gBAAgB,QAAQ;EACjF,CAAC,EACA,IAAI;AAGP,QAAM,gBAAgB,QAAQ,MAAM,KAAK,QAAQ,QAAQ,CAAC,CAAC,EACxD,OAAO,CAAC,CAAC,GAAG,MAAM,CAAC,aAAa,IAAI,GAAG,CAAC,EACxC,IAAI,CAAC,CAAC,GAAG,QAAQ,MAAM,YAAY,SAAS,WAAW,SAAS,YAAY,MAAM,SAAS,CAAC,EAC5F,IAAI;AAEP,QAAM,SAAS,CAAC,GAAG,YAAY,GAAG,aAAa;AAG/C,SAAO,KAAK,CAAC,GAAG,MAAM;AAEpB,UAAM,gBAAgB,EAAE,OAAO,GAAG,SAAS,GAAG,KAAK,GAAG,UAAU,GAAG,SAAS,EAAE;AAC9E,QAAI,cAAc,EAAE,QAAQ,MAAM,cAAc,EAAE,QAAQ,GAAG;AAC3D,aAAO,cAAc,EAAE,QAAQ,IAAI,cAAc,EAAE,QAAQ;IAC7D;AAEA,WAAO,EAAE,QAAQ,EAAE;EACrB,CAAC;AAED,SAAO;AACT;AAKO,SAAS,sBAAsB,QAAyC;AAC7E,QAAM,aAAa,QAAQ,MAAM;AAGjC,QAAM,cAAc,WAAW,IAAI,CAAA,MAAK;AACtC,QAAI,EAAE,aAAa,WAAY,QAAO;AACtC,QAAI,EAAE,aAAa,MAAO,QAAO;AACjC,QAAI,EAAE,aAAa,UAAW,QAAO;AAErC,QAAI,EAAE,QAAQ,EAAG,QAAO;AACxB,QAAI,EAAE,UAAU,EAAG,QAAO;AAC1B,WAAO;EACT,CAAC;AAED,QAAM,SAAS,YAAY,QAAQ,EAAE,IAAI;AAEzC,SAAO;IACL,YAAY,WAAW,IAAI,OAAO;IAClC,UAAU,OAAO,UAAU,KAAK;IAChC,UAAU,OAAO,UAAU,KAAK;IAChC,cAAc,OAAO,KAAK,KAAK;IAC/B,kBAAkB,OAAO,SAAS,KAAK;IACvC,WAAW,OAAO,WAAW,KAAK;EACpC;AACF;AAKO,SAAS,YAAY,OAAuB;AACjD,MAAI,QAAQ,EAAG,QAAO,IAAI,KAAK;AAC/B,MAAI,QAAQ,EAAG,QAAO,GAAG,KAAK;AAC9B,SAAO;AACT;AAKO,SAAS,oBAAoB,UAA+C;AACjF,UAAQ,UAAU;IAChB,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;EACX;AACF;AAKO,SAAS,gBAAgB,SAAuB,QAAsB;AAC3E,QAAM,OAAO,QAAQ,cAAc,IAAI,MAAM;AAC7C,SAAO,KAAK,qBAAqB,IAAI,GAAG,QAAQ,UAAU,EAAE;AAC5D,SAAO,KAAK,eAAe,QAAQ,QAAQ,eAAe,QAAQ,QAAQ,EAAE;AAC5E,SAAO,KAAK,UAAU,QAAQ,YAAY,cAAc,QAAQ,gBAAgB,EAAE;AACpF;AC/NO,SAAS,WAAW,SAAyB;AAClD,QAAM,OAAO,UAAU,IAAI,MAAM;AACjC,QAAM,iBAAiB,KAAK,MAAM,KAAK,IAAI,OAAO,CAAC;AACnD,MAAI,kBAAkB,IAAI;AACxB,UAAM,QAAQ,KAAK,MAAM,iBAAiB,EAAE;AAC5C,UAAM,OAAO,iBAAiB;AAC9B,WAAO,OAAO,IAAI,GAAG,IAAI,GAAG,KAAK,KAAK,IAAI,MAAM,GAAG,IAAI,GAAG,KAAK;EACjE;AACA,SAAO,GAAG,IAAI,GAAG,cAAc;AACjC;AAQO,SAAS,iBAAiB,YAAoB,OAAuB;AAC1E,MAAI,eAAe,iBAAiB;AAClC,WAAO,MAAM,QAAQ,CAAC;EACxB;AAEA,MAAI,eAAe,mBAAmB;AACpC,WAAO,WAAW,KAAK;EACzB;AACA,SAAO,OAAO,KAAK,MAAM,KAAK,CAAC;AACjC;AFVA,IAAM,mBAA2C;EAC/C,YAAY;EAEZ,WAAW;EAEX,iBAAiB;EAEjB,eAAe;AACjB;AAGA,IAAM,kBAAkB,iBAAiB;AAMzC,SAAS,eAAe,GAAyE;AAC/F,SAAO,GAAG,EAAE,QAAQ,KAAK,EAAE,UAAU,KAAK,EAAE,UAAU;AACxD;AAKA,SAAS,cAAc,QAAgE;AACrF,MAAI,CAAC,OAAQ,QAAO,oBAAI,IAAI;AAE5B,SAAO,IAAI;IACTC,SAAQ,MAAM,EACX,IAAI,CAAA,MAAK,CAAC,eAAe,CAAC,GAAG,CAAC,CAA8B,EAC5D,IAAI;EACT;AACF;AAKO,SAAS,eAAe,YAA4B;AACzD,UAAQ,YAAY;IAClB,KAAK;AAAa,aAAO;IACzB,KAAK;AAAc,aAAO;IAC1B,KAAK;AAAmB,aAAO;IAC/B,KAAK;AAAiB,aAAO;IAC7B;AAAS,aAAO;EAClB;AACF;AAKO,SAAS,sBAAsB,YAAoB,OAAuB;AAC/E,UAAQ,YAAY;IAClB,KAAK;AACH,aAAO,IAAI,WAAW,KAAK,CAAC;IAC9B,KAAK;AACH,aAAO,MAAM,QAAQ,CAAC;IACxB,KAAK;AACH,aAAO,GAAG,KAAK;IACjB;AACE,aAAO,MAAM,SAAS;EAC1B;AACF;AAKO,SAAS,qBAAqB,YAAoB,OAAuB;AAC9E,UAAQ,YAAY;IAClB,KAAK;AACH,aAAO,WAAW,KAAK;IACzB,KAAK;AACH,aAAO,MAAM,QAAQ,CAAC;IACxB;AACE,aAAO,MAAM,SAAS;EAC1B;AACF;AAKA,SAAS,oBAAoB,GAAwB,UAAgD;AACnG,QAAM,QAAQ,SAAS,IAAI,eAAe,CAAC,CAAC;AAC5C,QAAM,WAAW,QAAQ,KAAK,YAAY,MAAM,KAAK,CAAC,MAAM;AAC5D,QAAM,cAAc,eAAe,EAAE,UAAU;AAC/C,QAAM,eAAe,sBAAsB,EAAE,YAAY,EAAE,UAAU;AACrE,QAAM,mBAAmB,qBAAqB,EAAE,YAAY,EAAE,SAAS;AACvE,SAAO,OAAO,EAAE,UAAU,KAAK,EAAE,UAAU,MAAM,WAAW,IAAI,YAAY,GAAG,QAAQ,gBAAgB,gBAAgB,MAAM,EAAE,QAAQ;AACzI;AAMA,SAAS,uBAAuB,UAAqD;AACnF,MAAI,CAAC,SAAS,kBAAkB,SAAS,mBAAmB,GAAG;AAC7D,WAAO;EACT;AAEA,QAAM,YAAoC;IACxC,KAAK;IACL,QAAQ;IACR,MAAM;IACN,UAAU;EACZ;AAEA,QAAM,QAAQ,UAAU,SAAS,SAAS,KAAK;AAG/C,QAAM,oBAAoB,SAAS,cAAc,SAAS,WAAW,SAAS;AAC9E,QAAM,iBAAiB,oBACnB,SAAS,WAAW,MAAM,GAAG,EAAE,EAAE,IAAI,CAAA,MAAK,OAAO,CAAC,EAAE,EAAE,KAAK,IAAI,IAC/D;AAEJ,QAAM,iBAAiB,SAAS,6BAC5B;kCAAqC,SAAS,2BAA2B,kBAAkB,QAAQ,CAAC,CAAC,SAAS,SAAS,2BAA2B,aAAa,KAC/J;AAEJ,QAAM,WAAW,qBAAqB,SAAS,WAAW,SAAS,KAC/D,uBACA;AAEJ,SAAO;yBAA4B,KAAK,IAAI,SAAS,UAAU,YAAY,CAAC;oBAC1D,SAAS,cAAc;EACzC,iBAAiB;;EAA0B,cAAc,GAAG,QAAQ,KAAK,EAAE,GAAG,cAAc;0CACpD,SAAS,cAAc;AACjE;AAMA,SAAS,iBAAiB,UAAkB,UAAqD;AAC/F,QAAM,QAAkB,CAAC;AAGzB,QAAM,wBAAwB,SAAS,WAAW,CAAC,GAAG;AAGtD,MAAI,uBAAuB;AACzB,UAAM,cAAsC;MAC1C,cAAc;MACd,cAAc;MACd,OAAO;MACP,UAAU;MACV,MAAM;MACN,QAAQ;MACR,QAAQ;MACR,QAAQ;MACR,SAAS;MACT,UAAU;MACV,UAAU;MACV,SAAS;MACT,OAAO;MACP,KAAK;IACP;AACA,UAAM,cAAc,YAAY,sBAAsB,YAAY,CAAC,KAAK;AACxE,UAAM,KAAK,aAAa,WAAW,EAAE;EACvC,OAAO;AAEL,UAAM,MAAM,SAAS,MAAM,GAAG,EAAE,IAAI,GAAG,YAAY;AACnD,UAAM,gBAAwC;MAC5C,MAAM;MACN,OAAO;MACP,MAAM;MACN,OAAO;MACP,OAAO;MACP,OAAO;MACP,OAAO;MACP,MAAM;MACN,MAAM;MACN,MAAM;MACN,QAAQ;MACR,MAAM;MACN,SAAS;MACT,MAAM;MACN,MAAM;MACN,SAAS;MACT,OAAO;MACP,MAAM;MACN,OAAO;MACP,KAAK;IACP;AACA,QAAI,OAAO,cAAc,GAAG,GAAG;AAC7B,YAAM,KAAK,aAAa,cAAc,GAAG,CAAC,EAAE;IAC9C;EACF;AAGA,QAAM,YAAY,SAAS,YAAY;AAEvC,MAAI,UAAU,SAAS,YAAY,EAAG,OAAM,KAAK,kBAAkB;AACnE,MAAI,UAAU,SAAS,SAAS,EAAG,OAAM,KAAK,eAAe;AAC7D,MAAI,UAAU,SAAS,WAAW,EAAG,OAAM,KAAK,iBAAiB;AACjE,MAAI,UAAU,SAAS,YAAY,EAAG,OAAM,KAAK,kBAAkB;AACnE,MAAI,UAAU,SAAS,SAAS,EAAG,OAAM,KAAK,eAAe;AAC7D,MAAI,UAAU,SAAS,MAAM,KAAK,UAAU,SAAS,QAAQ,EAAG,OAAM,KAAK,eAAe;AAE1F,MAAI,UAAU,SAAS,QAAQ,KAAK,UAAU,SAAS,UAAU,EAAG,OAAM,KAAK,YAAY;AAE3F,MAAI,UAAU,SAAS,SAAS,KAAK,UAAU,SAAS,UAAU,EAAG,OAAM,KAAK,aAAa;AAC7F,MAAI,UAAU,SAAS,cAAc,KAAK,UAAU,SAAS,gBAAgB,EAAG,OAAM,KAAK,kBAAkB;AAG7G,MAAI,SAAS,WAAW,SAAS,GAAG;AAClC,UAAM,KAAK,GAAG,SAAS,WAAW,MAAM,gCAAgC;EAC1E;AAEA,SAAO,MAAM,SAAS,IAAI;YAAe,MAAM,KAAK,IAAI,CAAC,MAAM;AACjE;AAKA,SAAS,gBAAgB,GAAwB,UAAiD;AAChG,QAAM,QAAQ,SAAS,IAAI,eAAe,CAAC,CAAC;AAC5C,SAAO,CAAC,CAAC,UAAU,MAAM,aAAa,SAAS,MAAM,QAAQ;AAC/D;AAMA,SAAS,uBACP,OACA,UACQ;AACR,QAAM,eAAe,SAAS,OAAO;AAErC,MAAI,CAAC,cAAc;AAEjB,WAAO,OAAO,QAAQ,KAAK,EACxB,OAAO,CAAC,CAAC,GAAG,IAAI,MAAM,KAAK,WAAW,SAAS,CAAC,EAChD,IAAI,CAAC,CAAC,UAAU,IAAI,MAAM;AACzB,YAAM,gBAAgB,KAAK,WACxB,IAAI,CAAA,MAAK,oBAAoB,GAAG,QAAQ,CAAC,EACzC,KAAK,IAAI;AACZ,YAAM,oBAAoB,uBAAuB,IAAI;AACrD,YAAM,cAAc,iBAAiB,UAAU,IAAI;AACnD,aAAO,KAAK,QAAQ,aAAa,KAAK,SAAS,IAAI,WAAW;EAAK,aAAa,GAAG,iBAAiB;IACtG,CAAC,EACA,KAAK,MAAM;EAChB;AAGA,QAAM,gBAAgB,OAAO,QAAQ,KAAK,EACvC,OAAO,CAAC,CAAC,GAAG,IAAI,MAAM,KAAK,WAAW,SAAS,CAAC,EAChD,QAAQ,CAAC,CAAC,GAAG,IAAI,MAAM,KAAK,UAAU;AAEzC,QAAM,gBAAgB,cAAc,OAAO,CAAA,MAAK,gBAAgB,GAAG,QAAQ,CAAC;AAC5E,QAAM,cAAc,cAAc,OAAO,CAAA,MAAK,CAAC,gBAAgB,GAAG,QAAQ,CAAC;AAE3E,QAAM,kBAAkB,CAAC,eAAsC;AAC7D,UAAM,SAAS,oBAAI,IAAmC;AACtD,eAAW,KAAK,YAAY;AAC1B,YAAM,WAAW,OAAO,IAAI,EAAE,QAAQ,KAAK,CAAC;AAC5C,eAAS,KAAK,CAAC;AACf,aAAO,IAAI,EAAE,UAAU,QAAQ;IACjC;AAEA,WAAO,MAAM,KAAK,OAAO,QAAQ,CAAC,EAC/B,IAAI,CAAC,CAAC,UAAU,EAAE,MAAM;AACvB,YAAM,WAAW,MAAM,QAAQ;AAC/B,YAAM,gBAAgB,GAAG,IAAI,CAAA,MAAK,oBAAoB,GAAG,QAAQ,CAAC,EAAE,KAAK,IAAI;AAC7E,YAAM,oBAAoB,WAAW,uBAAuB,QAAQ,IAAI;AACxE,YAAM,cAAc,WAAW,iBAAiB,UAAU,QAAQ,IAAI;AACtE,aAAO,KAAK,QAAQ,aAAa,UAAU,aAAa,SAAS,IAAI,WAAW;EAAK,aAAa,GAAG,iBAAiB;IACxH,CAAC,EACA,KAAK,MAAM;EAChB;AAEA,QAAM,WAAqB,CAAC;AAE5B,MAAI,cAAc,SAAS,GAAG;AAC5B,aAAS,KAAK;;EAAsE,gBAAgB,aAAa,CAAC,EAAE;EACtH;AAEA,MAAI,YAAY,SAAS,GAAG;AAC1B,aAAS,KAAK;;EAAgE,gBAAgB,WAAW,CAAC,EAAE;EAC9G;AAEA,SAAO,SAAS,KAAK,MAAM;AAC7B;AAKA,SAAS,kBAAkB,GAA4B;AACrD,QAAM,OAAO,EAAE,kBAAkB;AACjC,QAAM,KAAK,EAAE,kBAAkB;AAC/B,SAAO,OAAO,EAAE,UAAU,KAAK,IAAI,WAAM,EAAE,KAAK,YAAY,EAAE,KAAK,CAAC;AACtE;AAKA,SAAS,kBAAkB,QAA0C;AACnE,MAAI,CAAC,UAAU,OAAO,WAAW,EAAG,QAAO;AAE3C,QAAM,WAAW,OAAO,OAAO,CAAA,MAAK,EAAE,aAAa,UAAU;AAC7D,QAAM,WAAW,OAAO,OAAO,CAAA,OAAM,EAAE,aAAa,WAAW,EAAE,aAAa,cAAc,EAAE,QAAQ,CAAC;AACvG,QAAM,WAAW,OAAO,OAAO,CAAA,MAAK,EAAE,aAAa,KAAK;AACxD,QAAM,UAAU,OAAO,OAAO,CAAA,MAAK,EAAE,aAAa,SAAS;AAE3D,QAAM,WAAW;IACf;;IACA,mBAAmB,SAAS,MAAM;IAClC,mBAAmB,SAAS,MAAM;IAClC,cAAc,SAAS,MAAM;IAC7B,kBAAkB,QAAQ,MAAM;EAClC;AAEA,MAAI,SAAS,SAAS,GAAG;AACvB,aAAS,KAAK;;EAAgC,SAAS,IAAI,iBAAiB,EAAE,KAAK,IAAI,CAAC,EAAE;EAC5F;AACA,MAAI,SAAS,SAAS,GAAG;AACvB,aAAS,KAAK;;EAA+B,SAAS,IAAI,iBAAiB,EAAE,KAAK,IAAI,CAAC,EAAE;EAC3F;AACA,MAAI,SAAS,SAAS,GAAG;AACvB,aAAS,KAAK;;EAA6B,SAAS,IAAI,CAAA,MAAK,OAAO,EAAE,UAAU,gBAAgB,EAAE,cAAc,EAAE,EAAE,KAAK,IAAI,CAAC,EAAE;EAClI;AAEA,SAAO,SAAS,KAAK,IAAI;AAC3B;AAKA,SAAS,qBAAqB,cAA2C;AACvE,SAAO,MAAM,KAAK,aAAa,QAAQ,CAAC,EACrC,IAAI,CAAC,CAAC,KAAK,IAAI,MAAM;AACpB,UAAM,CAAC,UAAU,UAAU,IAAI,IAAI,MAAM,IAAI;AAC7C,WAAO,OAAO,QAAQ,MAAM,UAAU;;EAAa,IAAI;;EACzD,CAAC,EACA,KAAK,MAAM;AAChB;AAKO,SAAS,kBACd,QACA,WACA,cACA,SAAmC,MAC3B;AACR,QAAM,EAAE,SAAS,MAAM,IAAI;AAC3B,QAAM,WAAW,cAAc,MAAM;AACrC,QAAM,mBAAmB,OAAO,QAAQ,KAAK,EAAE,OAAO,CAAC,CAAC,GAAG,IAAI,MAAM,KAAK,WAAW,SAAS,CAAC;AAC/F,QAAM,oBAAoB,uBAAuB,OAAO,QAAQ;AAChE,QAAM,kBAAkB,qBAAqB,YAAY;AACzD,QAAM,eAAe,kBAAkB,MAAM;AAE7C,SAAO;;;oBAGW,UAAU,KAAK,IAAI,UAAU,IAAI;aACxC,UAAU,UAAU,MAAM,UAAU,KAAK;+BACvB,iBAAiB,MAAM;0BAC5B,QAAQ,eAAe,KAAK,QAAQ,WAAW,KAAK,YAAY,QAAQ,WAAW,OAAO;EAClH,YAAY;;;EAGZ,iBAAiB;;;;EAIjB,mBAAmB,8BAA8B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA8BnD;AAKO,SAAS,yBAAyB,WAAsB,SAAmC,MAAc;AAC9G,MAAI,eAAe;AAEnB,MAAI,UAAU,OAAO,SAAS,GAAG;AAC/B,UAAM,WAAW,OAAO,OAAO,CAAA,MAAK,EAAE,aAAa,cAAc,EAAE,aAAa,SAAS;AACzF,QAAI,SAAS,SAAS,GAAG;AACvB,qBAAe;;0DAAwD,SAAS,MAAM;IACxF;EACF;AAEA,SAAO;;;wCAG+B,UAAU,UAAU;;wEAEY,YAAY;AACpF;AAaA,SAAS,oBAAoB,QAAmD;AAC9E,SAAOA,SAAQ,MAAM,EAClB,QAAQ,YAAY,EAEpB,IAAI,CAAC,UAAe,MAAM,IAAI,OAAO,CAAC,EACtC,IAAI;AACT;AAMA,SAAS,+BAA+B,eAA+C;AACrF,QAAM,cAAc,CAAC,cAAc,aAAa,mBAAmB,eAAe;AAClF,QAAM,WAAmC;IACvC,YAAY;IACZ,WAAW;IACX,iBAAiB;IACjB,eAAe;EACjB;AACA,SAAOA,SAAQ,WAAW,EACvB,IAAI,CAAA,eAAc;AACjB,UAAM,cAAc,cAAc,UAAU,KAAK;AACjD,UAAM,QAAQ,SAAS,UAAU,KAAK;AACtC,UAAM,OAAO,eAAe,IAAI,MAAM;AACtC,WAAO,GAAG,KAAK,IAAI,IAAI,GAAG,iBAAiB,YAAY,WAAW,CAAC;EACrE,CAAC,EACA,IAAI,EACJ,KAAK,KAAK;AACf;AAKA,SAAS,iBAAiB,QAAmE;AAC3F,SAAO,OAAO,OAAO,CAAC,KAAK,MAAM;AAC/B,QAAI,CAAC,YAAY,SAAS,EAAE,SAAS,EAAE,QAAQ,EAAG,KAAI;aAC7C,CAAC,WAAW,SAAS,KAAK,EAAE,SAAS,EAAE,QAAQ,EAAG,KAAI;AAC/D,WAAO;EACT,GAAG,EAAE,UAAU,GAAG,UAAU,EAAE,CAAC;AACjC;AAKA,SAAS,cAAc,YAA4B;AACjD,MAAI,aAAa,EAAG,QAAO;AAC3B,MAAI,aAAa,EAAG,QAAO;AAC3B,SAAO;AACT;AAMA,SAAS,mBAAmB,QAAsD;AAChF,MAAI,CAAC,UAAU,OAAO,WAAW,EAAG,QAAO;AAE3C,QAAM,EAAE,UAAU,SAAS,IAAI,iBAAiB,MAAM;AACtD,QAAM,gBAAgB,oBAAoB,MAAM;AAChD,QAAM,aAAa,OAAO,OAAO,aAAa,EAAE,OAAO,CAAC,KAAK,MAAM,MAAM,GAAG,CAAC;AAI7E,MAAI,eAAe,KAAK,aAAa,GAAG;AACtC,WAAO;EACT;AAEA,QAAM,kBAAkB,+BAA+B,aAAa;AACpE,QAAM,QAAQ,cAAc,UAAU;AAEtC,MAAI,UAAU;;yBAA8B,eAAe,IAAI,KAAK;AACpE,MAAI,WAAW,EAAG,YAAW,MAAM,QAAQ;AAC3C,MAAI,WAAW,EAAG,YAAW,MAAM,QAAQ;AAC3C,SAAO;AACT;AAKA,SAAS,iBAAiB,YAAgD;AACxE,MAAI,CAAC,cAAc,WAAW,eAAe,EAAG,QAAO;AACvD,SAAO;YAAe,WAAW,YAAY,eAAe,CAAC,MAAM,WAAW,KAAK,QAAQ,CAAC,CAAC;AAC/F;AAKA,SAAS,mBAAmB,YAA6B;AACvD,MAAI,CAAC,WAAY,QAAO;AACxB,SAAO;;;;AACT;AAKA,SAAS,yBACP,iBACA,QACuE;AACvE,MAAI,CAAC,UAAU,OAAO,WAAW,GAAG;AAClC,WAAO,EAAE,UAAU,GAAG,kBAAkB,GAAG,eAAe,EAAE;EAC9D;AAEA,QAAM,WAAW,OAAO;IAAO,CAAA,MAC7B,EAAE,aAAa,SAAS,EAAE,aAAa,aAAa,EAAE,aAAa;EACrE,EAAE,OAAO,CAAA,MAAK,EAAE,aAAa,SAAS,EAAE,QAAQ,CAAC,EAAE;AAEnD,QAAM,gBAAgB,OAAO,OAAO,CAAA,MAAK,EAAE,aAAa,UAAU,EAAE;AAEpE,QAAM,mBAAmB,KAAK,IAAI,GAAG,kBAAkB,QAAQ;AAE/D,SAAO,EAAE,UAAU,kBAAkB,cAAc;AACrD;AAKO,SAAS,gBACd,iBACA,QACQ;AACR,QAAM,EAAE,UAAU,kBAAkB,cAAc,IAAI,yBAAyB,iBAAiB,MAAM;AAGtG,MAAI,CAAC,UAAU,OAAO,WAAW,GAAG;AAClC,WAAO,GAAG,eAAe,SAAS,oBAAoB,IAAI,KAAK,GAAG;EACpE;AAEA,QAAM,QAAkB,CAAC;AAEzB,MAAI,WAAW,GAAG;AAChB,UAAM,KAAK,GAAG,QAAQ,aAAa,aAAa,IAAI,KAAK,GAAG,sBAAsB;EACpF,OAAO;AACL,UAAM,KAAK,+BAA+B;EAC5C;AAEA,MAAI,gBAAgB,GAAG;AACrB,UAAM,KAAK,GAAG,aAAa,YAAY,kBAAkB,IAAI,KAAK,GAAG,YAAY;EACnF;AAEA,MAAI,mBAAmB,GAAG;AACxB,UAAM,KAAK,GAAG,gBAAgB,sBAAsB,qBAAqB,IAAI,KAAK,GAAG,oBAAoB;EAC3G;AAEA,SAAO,MAAM,KAAK,GAAG;AACvB;AAKO,SAAS,oBACd,UACA,QACA,aAAa,OACb,YACA,QACA,gBAAwB,IAChB;AACR,QAAM,EAAE,QAAQ,IAAI;AACpB,QAAM,eAAe,mBAAmB,MAAM;AAC9C,QAAM,eAAe,mBAAmB,UAAU;AAClD,QAAM,aAAa,iBAAiB,UAAU;AAE9C,QAAM,aAAa,gBAAgB,QAAQ,iBAAiB,MAAM;AAElE,SAAO;;;EAGP,UAAU,GAAG,YAAY,GAAG,YAAY;;;;EAIxC,QAAQ;;KAEL,aAAa;;;;;oBAKE,QAAQ,aAAa;wBACjB,QAAQ,cAAc,QAAQ,CAAC,CAAC;oBACpC,QAAQ,aAAa,GAAG,UAAU;;;;;AAKtD;AAKO,SAAS,gBAAgB,WAAwC;AACtE,SAAO,GAAG,UAAU,QAAQ,KAAK,UAAU,UAAU;AACvD;AAMA,SAAS,gBACP,QACA,cACoC;AACpC,QAAM,aAAa,QAAQ,QAAQ,mBAAmB;AACtD,QAAM,SAAS,QAAQ,QAAQ,WAAW,SAAS;AACnD,QAAM,QAAQ,cAAc,cAAc;AAC1C,QAAM,gBAAgB,cAAc,gBAAgB;AACpD,QAAM,cAAc,KAAK,IAAI,GAAG,aAAa,aAAa;AAG1D,MAAI,QAAQ,GAAG;AACb,QAAI,cAAc,GAAG;AACnB,aAAO;QACL,OAAO;QACP,SAAS,uCAAuC,KAAK,IAAI,KAAK,CAAC,KAAK,WAAW,sBAAsB,gBAAgB,IAAI,KAAK,GAAG,UAAU,gBAAgB,IAAI,MAAM,EAAE;MACzK;IACF;AACA,WAAO,EAAE,OAAO,UAAK,SAAS,+CAA+C,KAAK,IAAI,KAAK,CAAC,IAAI;EAClG;AAGA,MAAI,gBAAgB,KAAK,SAAS,GAAG;AACnC,WAAO;MACL,OAAO;MACP,SAAS,yBAAyB,aAAa,gBAAgB,kBAAkB,IAAI,QAAQ,OAAO;IACtG;EACF;AAEA,MAAI,gBAAgB,GAAG;AACrB,WAAO;MACL,OAAO;MACP,SAAS,yBAAyB,aAAa,gBAAgB,kBAAkB,IAAI,QAAQ,OAAO;IACtG;EACF;AAGA,MAAI,aAAa,GAAG;AAClB,WAAO;MACL,OAAO;MACP,SAAS,gBAAgB,WAAW,sBAAsB,gBAAgB,IAAI,KAAK,GAAG;IACxF;EACF;AAGA,MAAI,QAAQ,GAAG;AACb,WAAO,EAAE,OAAO,gBAAM,SAAS,gEAAgE;EACjG;AAEA,SAAO,EAAE,OAAO,UAAK,SAAS,yCAAyC;AACzE;AAKA,SAAS,eAAe,YAA4B;AAClD,UAAQ,YAAY;IAClB,KAAK;AAAc,aAAO;IAC1B,KAAK;AAAa,aAAO;IACzB,KAAK;AAAmB,aAAO;IAC/B,KAAK;AAAiB,aAAO;IAC7B;AAAS,aAAO;EAClB;AACF;AAKA,SAAS,iBACP,QACA,QACQ;AACR,MAAI,CAAC,UAAU,OAAO,QAAQ,oBAAoB,EAAG,QAAO;AAE5D,QAAM,WAAWA,SAAQ,OAAO,OAAO,OAAO,KAAK,CAAC,EACjD,QAAQ,CAAA,MAAK,EAAE,UAAU,EACzB,QAAQ,YAAY,EACpB,IAAI;AAEP,QAAM,gBAAwC,SAC1CA,SAAQ,MAAM,EACX,QAAQ,YAAY,EAEpB,IAAI,CAAC,UAAe,MAAM,IAAI,OAAO,CAAC,EACtC,IAAI,IACP,CAAC;AAEL,QAAM,cAAc,CAAC,cAAc,aAAa,mBAAmB,eAAe;AAClF,QAAM,OAAOA,SAAQ,WAAW,EAC7B,OAAO,CAAA,eAAc,SAAS,UAAU,IAAI,CAAC,EAC7C,IAAI,CAAA,eAAc;AACjB,UAAM,QAAQ,eAAe,UAAU;AACvC,UAAM,QAAQ,eAAe,UAAU;AACvC,UAAM,QAAQ,SAAS,UAAU;AACjC,UAAM,QAAQ,cAAc,UAAU,KAAK;AAC3C,UAAM,WAAW,SAAU,SAAS,IAAI,IAAI,KAAK,KAAK,GAAG,KAAK,KAAM;AACpE,WAAO,KAAK,KAAK,IAAI,KAAK,MAAM,KAAK,MAAM,QAAQ;EACrD,CAAC,EACA,IAAI;AAEP,MAAI,KAAK,WAAW,EAAG,QAAO;AAE9B,SAAO;;;EAGP,KAAK,KAAK,IAAI,CAAC;;AAEjB;AAKA,SAAS,mBAAmB,QAAyC;AACnE,MAAI,CAAC,OAAQ,QAAO;AAEpB,QAAM,sBAAsB,OAAO,OAAO,OAAO,KAAK,EACnD,OAAO,CAAA,MAAK,EAAE,kBAAkB,EAAE,iBAAiB,CAAC;AAEvD,MAAI,oBAAoB,WAAW,EAAG,QAAO;AAE7C,QAAM,kBAAkB,oBAAoB,OAAO,CAAC,KAAK,MAAM,OAAO,EAAE,kBAAkB,IAAI,CAAC;AAC/F,QAAM,gBAAgB,oBAAoB;IAAO,CAAA,MAC/C,CAAC,QAAQ,UAAU,EAAE,SAAS,EAAE,SAAS;EAC3C,EAAE;AAEF,MAAI,kBAAkB,EAAG,QAAO;AAEhC,SAAO;wBAAoB,aAAa,2BAA2B,eAAe;AACpF;AAMO,SAAS,sBACd,QACA,cACA,QACQ;AACR,QAAM,SAAS,gBAAgB,QAAQ,YAAY;AACnD,QAAM,cAAc,iBAAiB,QAAQ,MAAM;AACnD,QAAM,gBAAgB,mBAAmB,MAAM;AAE/C,SAAO;;EAEP,OAAO,KAAK,IAAI,OAAO,OAAO,GAAG,aAAa;EAC9C,WAAW;;AAEb;AAKA,SAAS,sBAAsB,WAAwC;AACrE,MAAI,CAAC,UAAU,YAAY,WAAW,WAAW,EAAG,QAAO;AAC3D,MAAI,CAAC,UAAU,gBAAiB,QAAO;AAEvC,QAAM,UAAU,UAAU;AAC1B,SAAO;gCAAmC,QAAQ,QAAQ,eAAe,CAAC,iBAAiB,QAAQ,YAAY,QAAQ,CAAC,CAAC,aAAa,QAAQ,QAAQ,eAAe,CAAC,gBAAgB,QAAQ,MAAM,QAAQ,CAAC,CAAC;AAChN;AA4EA,SAAS,2BAA2B,YAA2C;AAC7E,MAAI,WAAW,WAAW,EAAG,QAAO;AAEpC,QAAM,SAASC,SAAQ,UAAU,EAC9B,QAAQ,CAAC,MAA2B,EAAE,cAAc,YAAY,EAChE,IAAI;AAEP,QAAM,UAAU,OAAO,QAAQ,MAAM,EAClC;IACC,CAAC,KAAK,CAAC,MAAM,KAAK,MAChB,QAAQ,IAAI,QAAQ,EAAE,MAAM,MAAM,IAAI;IACxC,EAAE,MAAM,cAAc,OAAO,EAAE;EACjC,EAAE;AAEJ,SAAO,iBAAiB,OAAO,KAAK;AACtC;AASO,SAAS,2BACd,YACA,cACA,QACQ;AACR,QAAM,iBAAiB,WACpB,IAAI,CAAC,GAAG,MAAM;AACb,UAAM,MAAM,GAAG,EAAE,QAAQ,KAAK,EAAE,UAAU;AAC1C,UAAM,UAAU,aAAa,IAAI,GAAG;AACpC,UAAM,iBAAiB,UACnB;;;EAAoB,OAAO;UAC3B;AAEJ,UAAM,aAAa,EAAE,cAAc;AACnC,UAAM,cAAc,eAAe,UAAU;AAC7C,UAAM,eAAe,sBAAsB,YAAY,EAAE,UAAU;AACnE,UAAM,mBAAmB,qBAAqB,YAAY,EAAE,SAAS;AACrE,UAAM,kBAAkB,sBAAsB,CAAC;AAG/C,UAAM,WAAW,OAAO,MAAM,EAAE,QAAQ;AACxC,UAAM,oBAAoB,WAAW,uBAAuB,QAAQ,IAAI;AAGxE,UAAM,cAAc,WAAW,iBAAiB,EAAE,UAAU,QAAQ,IAAI;AAExE,WAAO,OAAO,IAAI,CAAC,KAAK,EAAE,QAAQ,KAAK,EAAE,UAAU;oBACrC,EAAE,UAAU,OAAO,EAAE,UAAU;oBAC/B,YAAY,IAAI,WAAW,gBAAgB,gBAAgB,IAAI,eAAe;kBAChF,EAAE,QAAQ,GAAG,WAAW,GAAG,iBAAiB,GAAG,cAAc;EAC3E,CAAC,EACA,KAAK,MAAM;AAGd,QAAM,WAAW,WACd,IAAI,CAAC,MAAM,MAAM,EAAE,QAAQ,KAAK,EAAE,UAAU,wBAAwB,EACpE,KAAK,KAAK;AAEb,SAAO;;;;EAIP,cAAc;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GA+Bb,2BAA2B,UAAU,CAAC;;;;;;;;;;;;;EAavC,QAAQ;;;AAGV;AGz8BA,IAAM,qBAAqB;AAe3B,IAAI,aAAyB;EAC3B,cAAc;EACd,kBAAkB;EAClB,aAAa;EACb,MAAM;AACR;AAKO,SAAS,kBAAwB;AACtC,eAAa;IACX,cAAc;IACd,kBAAkB;IAClB,aAAa;IACb,MAAM;EACR;AACF;AAKO,SAAS,gBAA4B;AAC1C,SAAO,EAAE,GAAG,WAAW;AACzB;AAMA,SAAS,WACP,OACM;AACN,MAAI,CAAC,MAAO;AAEZ,aAAW,gBAAgB,MAAM;AACjC,aAAW,oBAAoB,MAAM;AACrC,aAAW,eAAe,MAAM;AAChC,aAAW,QAAQ,MAAM,QAAQ;AACnC;AAOO,SAAS,sBAAsB,SAAiB,QAA+C;AAEpG,QAAM,iBAAiB,QAAQ,MAAM,8BAA8B;AACnE,QAAM,WAAW,iBAAiB,eAAe,CAAC,IAAI,SAAS,KAAK;AAEpE,SAAO,KAAK,0BAA0B,QAAQ,MAAM,SAAS;AAE7D,MAAI;AACF,UAAM,SAAS,KAAK,MAAM,OAAO;AACjC,WAAO,KAAK,uBAAuB,OAAO,KAAK,MAAM,EAAE,MAAM,WAAW;AACxE,WAAO;EACT,SAAS,YAAY;AACnB,WAAO,QAAQ,8BAA8B,UAAU,EAAE;EAC3D;AAGA,QAAM,cAAc,QAAQ,MAAM,aAAa;AAC/C,MAAI,aAAa;AACf,QAAI;AACF,YAAM,SAAS,KAAK,MAAM,YAAY,CAAC,CAAC;AACxC,aAAO,KAAK,2CAA2C,OAAO,KAAK,MAAM,EAAE,MAAM,WAAW;AAC5F,aAAO;IACT,SAAS,YAAY;AACnB,aAAO,QAAQ,8BAA8B,UAAU,EAAE;IAC3D;EACF;AAEA,SAAO,QAAQ;EAA2B,OAAO,EAAE;AACnD,SAAO;AACT;AAKA,eAAsB,eACpB,QACA,QACA,OACA,QACiB;AACjB,SAAO,KAAK,kCAAkC,KAAK,EAAE;AAErD,QAAM,WAAW,MAAM,MAAM,oBAAoB;IAC/C,QAAQ;IACR,SAAS;MACP,eAAe,UAAU,MAAM;MAC/B,gBAAgB;MAChB,gBAAgB;MAChB,WAAW;IACb;IACA,MAAM,KAAK,UAAU;MACnB;MACA,UAAU;QACR;UACE,MAAM;UACN,SACE;QACJ;QACA;UACE,MAAM;UACN,SAAS;QACX;MACF;MACA,YAAY;MACZ,aAAa;;;;MAGb,OAAO;QACL,SAAS;MACX;IACF,CAAC;EACH,CAAC;AAED,MAAI,CAAC,SAAS,IAAI;AAChB,UAAM,YAAY,MAAM,SAAS,KAAK;AACtC,UAAM,IAAI;MACR,yBAAyB,SAAS,MAAM,MAAM,SAAS;IACzD;EACF;AAEA,QAAM,OAAQ,MAAM,SAAS,KAAK;AAElC,MAAI,CAAC,KAAK,WAAW,KAAK,QAAQ,WAAW,GAAG;AAC9C,UAAM,IAAI,MAAM,6BAA6B;EAC/C;AAEA,QAAM,SAAS,KAAK,QAAQ,CAAC,EAAE,QAAQ;AAGvC,MAAI,KAAK,OAAO;AACd,eAAW,KAAK,KAAK;AACrB,UAAM,UAAU,KAAK,MAAM,OAAO,MAAM,KAAK,MAAM,KAAK,QAAQ,CAAC,CAAC,MAAM;AACxE,WAAO;MACL,WAAW,KAAK,MAAM,aAAa,QAAQ,KAAK,MAAM,iBAAiB,OAAO,OAAO;IACvF;EACF;AAEA,SAAO;AACT;AAKA,eAAe,uBACb,QACA,QACA,OAC6B;AAC7B,QAAM,WAAW,MAAM,MAAM,oBAAoB;IAC/C,QAAQ;IACR,SAAS;MACP,eAAe,UAAU,MAAM;MAC/B,gBAAgB;MAChB,gBAAgB;MAChB,WAAW;IACb;IACA,MAAM,KAAK,UAAU;MACnB;MACA,UAAU;QACR;UACE,MAAM;UACN,SACE;QACJ;QACA,EAAE,MAAM,QAAQ,SAAS,OAAO;MAClC;MACA,YAAY;MACZ,aAAa;MACb,OAAO,EAAE,SAAS,KAAK;IACzB,CAAC;EACH,CAAC;AAED,MAAI,CAAC,SAAS,IAAI;AAChB,UAAM,YAAY,MAAM,SAAS,KAAK;AACtC,UAAM,IAAI,MAAM,yBAAyB,SAAS,MAAM,MAAM,SAAS,EAAE;EAC3E;AAEA,QAAM,OAAQ,MAAM,SAAS,KAAK;AAElC,MAAI,CAAC,KAAK,WAAW,KAAK,QAAQ,WAAW,GAAG;AAC9C,UAAM,IAAI,MAAM,6BAA6B;EAC/C;AAEA,SAAO;AACT;AAMO,SAAS,wBACd,aACA,YACA,QACkC;AAClC,QAAM,UAAU,oBAAI,IAAiC;AACrD,QAAM,kBAAkB,CAAC,MACvB,QAAQ,EAAE,UAAU;AAEtB,MAAI,CAAC,aAAa;AAChB,eAAW,aAAa,YAAY;AAClC,cAAQ,IAAI,WAAW,gBAAgB,SAAS,CAAC;IACnD;AACA,WAAO;EACT;AAEA,aAAW,aAAa,YAAY;AAClC,UAAM,MAAM,GAAG,UAAU,QAAQ,KAAK,UAAU,UAAU;AAC1D,UAAM,UAAU,YAAY,GAAG;AAE/B,QAAI,SAAS;AACX,cAAQ,IAAI,WAAW,QAAQ,QAAQ,QAAQ,IAAI,CAAC;IACtD,OAAO;AACL,aAAO,QAAQ,4BAA4B,GAAG,EAAE;AAChD,cAAQ,IAAI,WAAW,gBAAgB,SAAS,CAAC;IACnD;EACF;AAEA,SAAO;AACT;AAUA,eAAsB,qBACpB,YACA,cACA,QACA,OACA,QACA,QAC2C;AAC3C,MAAI,WAAW,WAAW,GAAG;AAC3B,WAAO,oBAAI,IAAI;EACjB;AAEA,SAAO,KAAK,2BAA2B,WAAW,MAAM,6BAA6B;AAErF,QAAM,SAAS,2BAA2B,YAAY,cAAc,MAAM;AAC1E,QAAM,OAAO,MAAM,uBAAuB,QAAQ,QAAQ,KAAK;AAE/D,MAAI,KAAK,OAAO;AACd,eAAW,KAAK,KAAK;AACrB,UAAM,UAAU,KAAK,MAAM,OAAO,MAAM,KAAK,MAAM,KAAK,QAAQ,CAAC,CAAC,MAAM;AACxE,WAAO,KAAK,iBAAiB,KAAK,MAAM,aAAa,QAAQ,KAAK,MAAM,iBAAiB,OAAO,OAAO,EAAE;EAC3G;AAEA,QAAM,cAAc,sBAAsB,KAAK,QAAQ,CAAC,EAAE,QAAQ,SAAS,MAAM;AACjF,SAAO,wBAAwB,aAAa,YAAY,MAAM;AAChE;ALrOO,SAAS,sBAAsB,OAA2B;AAC/D,QAAM,iBAAiB,oBAAI,IAAI;IAC7B;IACA;IACA;IACA;IACA;IACA;EACF,CAAC;AAED,QAAM,kBAAkB;IACtB;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;EACF;AAEA,SAAO,MAAM,OAAO,CAAC,SAAS;AAE5B,UAAM,MAAM,KAAK,MAAM,KAAK,YAAY,GAAG,CAAC;AAC5C,QAAI,CAAC,eAAe,IAAI,GAAG,GAAG;AAC5B,aAAO;IACT;AAGA,eAAW,WAAW,iBAAiB;AACrC,UAAI,QAAQ,KAAK,IAAI,GAAG;AACtB,eAAO;MACT;IACF;AAEA,WAAO;EACT,CAAC;AACH;AAKA,eAAe,kBAAkB,SAAkB,WAAsB,QAAmC;AAC1G,QAAM,kBAAkB,MAAM,kBAAkB,SAAS,SAAS;AAClE,SAAO,KAAK,SAAS,gBAAgB,MAAM,sBAAsB;AAEjE,QAAM,iBAAiB,sBAAsB,eAAe;AAC5D,SAAO,KAAK,GAAG,eAAe,MAAM,yCAAyC;AAE7E,SAAO;AACT;AAKA,eAAsB,sBACpB,OACA,WACA,SACA,QACkC;AAClC,MAAI,MAAM,WAAW,GAAG;AACtB,WAAO,KAAK,qBAAqB;AACjC,WAAO;EACT;AAEA,MAAI;AAEF,WAAO,KAAK,sBAAsB;AAClC,UAAM,cAAc;MAClB;IACF,CAAC;AACD,WAAO,KAAK,mBAAmB;AAG/B,UAAM,WAAW,MAAM,eAAe,OAAO;AAC7C,UAAM,SAAS,WAAW;AAG1B,WAAO,KAAK,yBAAyB;AACrC,UAAM,WAAW,IAAI,mBAAmB,QAAQ;AAChD,UAAM,SAAS,MAAM,SAAS,QAAQ,KAAK;AAC3C,WAAO,KAAK,SAAS,OAAO,QAAQ,eAAe,aAAa;AAEhE,WAAO;EACT,SAASC,QAAO;AACd,WAAO,MAAM,sCAAsCA,MAAK,EAAE;AAC1D,WAAO;EACT;AACF;AAMA,SAAS,qBACP,YACA,QACuB;AACvB,SAAO,WAAW,KAAK,CAAC,GAAG,MAAM;AAC/B,UAAM,QAAQ,OAAO,MAAM,EAAE,QAAQ;AACrC,UAAM,QAAQ,OAAO,MAAM,EAAE,QAAQ;AAGrC,UAAM,WAAW,OAAO,kBAAkB,KAAK,KAAK,WAAW,OAAO,aAAa,KAAK;AACxF,UAAM,WAAW,OAAO,kBAAkB,KAAK,KAAK,WAAW,OAAO,aAAa,KAAK;AAExF,QAAI,YAAY,QAAS,QAAO,UAAU;AAG1C,UAAM,gBAAgB,EAAE,OAAO,GAAG,SAAS,EAAE;AAC7C,WAAO,cAAc,EAAE,QAAQ,IAAI,cAAc,EAAE,QAAQ;EAC7D,CAAC;AACH;AAKA,eAAe,2BACb,QACA,SACA,WACA,QACmF;AAEnF,QAAM,gBAAgB,OAAO,OAAO,OAAO,KAAK,EAC7C,QAAQ,CAAC,aAAa,SAAS,UAAU;AAG5C,QAAM,aAAa,qBAAqB,eAAe,MAAM,EAC1D,MAAM,GAAG,EAAE;AAGd,QAAM,eAAe,oBAAI,IAAoB;AAC7C,aAAW,aAAa,YAAY;AAClC,UAAM,UAAU,MAAM;MACpB;MACA;MACA,UAAU;MACV,UAAU;MACV,UAAU;MACV;IACF;AACA,QAAI,SAAS;AACX,mBAAa,IAAI,gBAAgB,SAAS,GAAG,OAAO;IACtD;EACF;AACA,SAAO,KAAK,aAAa,aAAa,IAAI,2BAA2B;AAErE,SAAO,EAAE,YAAY,aAAa;AACpC;AAKA,SAAS,uBAAuB,MAAc,QAAyC;AACrF,MAAI,CAAC,MAAM;AACT,WAAO,KAAK,kEAAkE;AAC9E,WAAO;EACT;AAEA,MAAI;AACF,QAAI,CAAI,cAAW,IAAI,GAAG;AACxB,aAAO,QAAQ,uCAAuC,IAAI,EAAE;AAC5D,aAAO;IACT;AAEA,UAAM,UAAa,gBAAa,MAAM,OAAO;AAC7C,UAAM,SAAS,KAAK,MAAM,OAAO;AAEjC,QAAI,CAAC,OAAO,SAAS,CAAC,OAAO,SAAS;AACpC,aAAO,QAAQ,6CAA6C;AAC5D,aAAO;IACT;AAEA,WAAO,KAAK,+BAA+B,OAAO,QAAQ,eAAe,aAAa;AACtF,WAAO;EACT,SAASA,QAAO;AACd,WAAO,QAAQ,uCAAuCA,MAAK,EAAE;AAC7D,WAAO;EACT;AACF;AAKA,eAAe,kBACb,SACA,gBACA,WACA,SACA,QACkC;AAClC,MAAI;AACF,WAAO,KAAK,+BAA+B,QAAQ,UAAU,GAAG,CAAC,CAAC,KAAK;AAGvE,UAAM,cAAc,SAAS,sBAAsB,EAAE,UAAU,QAAQ,CAAC,EAAE,KAAK;AAG/E,aAAS,wBAAwB,OAAO,IAAI,EAAE,OAAO,OAAO,CAAC;AAC7D,WAAO,KAAK,yBAAyB;AAGrC,WAAO,KAAK,qCAAqC;AACjD,UAAM,aAAa,MAAM,sBAAsB,gBAAgB,WAAW,SAAS,MAAM;AAGzF,aAAS,wBAAwB,WAAW,IAAI,EAAE,OAAO,OAAO,CAAC;AACjE,WAAO,KAAK,kBAAkB;AAE9B,QAAI,YAAY;AACd,aAAO,KAAK,gBAAgB,WAAW,QAAQ,eAAe,aAAa;IAC7E;AAEA,WAAO;EACT,SAASA,QAAO;AACd,WAAO,QAAQ,kCAAkCA,MAAK,EAAE;AAExD,QAAI;AACF,YAAM,cAAc,SAAS,sBAAsB,EAAE,UAAU,QAAQ,CAAC,EAAE,KAAK;AAC/E,eAAS,wBAAwB,WAAW,IAAI,EAAE,OAAO,OAAO,CAAC;IACnE,SAAS,cAAc;AACrB,aAAO,QAAQ,2BAA2B,YAAY,EAAE;IAC1D;AACA,WAAO;EACT;AACF;AAMA,eAAe,kBACb,QACA,WACA,gBACA,SACA,QACkC;AAClC,MAAI,OAAO,qBAAqB;AAC9B,WAAO,KAAK,mDAAmD;AAC/D,WAAO,MAAM,kBAAkB,UAAU,SAAS,gBAAgB,OAAO,WAAW,SAAS,MAAM;EACrG;AAEA,MAAI,OAAO,wBAAwB;AAEjC,WAAO,QAAQ,mFAAmF;AAClG,WAAO,uBAAuB,OAAO,wBAAwB,MAAM;EACrE;AAEA,SAAO;AACT;AAMA,eAAsB,oBAAoB,OAAoD;AAC5F,QAAM,EAAE,QAAQ,WAAW,SAAS,QAAQ,QAAQ,IAAI;AAExD,QAAM,iBAAiB,MAAM,kBAAkB,SAAS,WAAW,MAAM;AACzE,MAAI,eAAe,WAAW,GAAG;AAC/B,WAAO,KAAK,4CAA4C;AACxD,WAAO;EACT;AAEA,QAAM,iBAAiB,MAAM,kBAAkB,QAAQ,WAAW,gBAAgB,SAAS,MAAM;AACjG,QAAM,gBAAgB,MAAM,sBAAsB,gBAAgB,OAAO,WAAW,SAAS,MAAM;AAEnG,MAAI,CAAC,eAAe;AAClB,WAAO,QAAQ,iCAAiC;AAChD,WAAO;EACT;AAEA,SAAO,KAAK,sBAAsB,cAAc,QAAQ,eAAe,mBAAmB;AAE1F,QAAM,SAAS,iBACX,gBAAgB,gBAAgB,eAAe,cAAc,IAC7D;AAEJ,SAAO;IACL;IACA;IACA;IACA;EACF;AACF;AAMA,eAAsB,sBACpB,QACA,OAC8B;AAC9B,QAAM,EAAE,SAAS,WAAW,OAAO,IAAI;AACvC,QAAM,eAAe,OAAO,SAAS,sBAAsB,OAAO,MAAM,IAAI;AAE5E,MAAI,cAAc;AAChB,oBAAgB,cAAc,MAAM;EACtC;AAEA,QAAM,QAAQ,sBAAsB,OAAO,eAAe,cAAc,OAAO,MAAM;AACrF,QAAM,oBAAoB,SAAS,WAAW,OAAO,MAAM;AAE3D,SAAO;AACT;AAQA,SAAS,gBACP,WACA,WACe;AACf,QAAM,YAAY,UAAU,IAAI,UAAU,QAAQ;AAClD,MAAI,CAAC,UAAW,QAAO;AAGvB,MAAI,UAAU,IAAI,UAAU,SAAS,GAAG;AACtC,WAAO,UAAU;EACnB;AAGA,WAAS,OAAO,UAAU,WAAW,QAAQ,UAAU,SAAS,QAAQ;AACtE,QAAI,UAAU,IAAI,IAAI,GAAG;AACvB,aAAO;IACT;EACF;AAEA,SAAO;AACT;AAKA,SAASC,gBAAe,GAAyE;AAC/F,SAAO,GAAG,EAAE,QAAQ,KAAK,EAAE,UAAU,KAAK,EAAE,UAAU;AACxD;AAKA,SAASC,eAAc,QAAgE;AACrF,MAAI,CAAC,OAAQ,QAAO,oBAAI,IAAI;AAE5B,SAAO,IAAI;IACTH,SAAQ,MAAM,EACX,IAAI,CAAA,MAAK,CAACE,gBAAe,CAAC,GAAG,CAAC,CAA8B,EAC5D,IAAI;EACT;AACF;AAKA,SAASE,gBAAe,YAA4B;AAClD,UAAQ,YAAY;IAClB,KAAK;AAAc,aAAO;IAC1B,KAAK;AAAa,aAAO;IACzB,KAAK;AAAmB,aAAO;IAC/B,KAAK;AAAiB,aAAO;IAC7B;AAAS,aAAO;EAClB;AACF;AAKA,SAAS,oBAAoB,GAAwB,UAAgD;AACnG,QAAM,QAAQ,SAAS,IAAIF,gBAAe,CAAC,CAAC;AAC5C,QAAM,WAAW,QAAQ,KAAK,YAAY,MAAM,KAAK,CAAC,MAAM;AAC5D,QAAM,QAAQE,gBAAe,EAAE,UAAU;AACzC,QAAM,cAAc,eAAe,EAAE,cAAc,YAAY;AAC/D,QAAM,eAAe,sBAAsB,EAAE,cAAc,cAAc,EAAE,UAAU;AACrF,SAAO,OAAO,EAAE,UAAU,WAAW,EAAE,QAAQ,OAAO,KAAK,IAAI,WAAW,IAAI,YAAY,GAAG,QAAQ;AACvG;AAMA,SAAS,mBACP,qBACA,UACQ;AACR,MAAI,oBAAoB,WAAW,EAAG,QAAO;AAG7C,QAAM,gBAAgB,oBAAoB,OAAO,CAAA,MAAK;AACpD,UAAM,QAAQ,SAAS,IAAIF,gBAAe,CAAC,CAAC;AAC5C,WAAO,UAAU,MAAM,aAAa,SAAS,MAAM,aAAa,aAAa,MAAM,aAAa,aAAa,MAAM,aAAa,SAAS,MAAM,QAAQ;EACzJ,CAAC;AAED,QAAM,cAAc,oBAAoB,OAAO,CAAA,MAAK;AAClD,UAAM,QAAQ,SAAS,IAAIA,gBAAe,CAAC,CAAC;AAC5C,WAAO,CAAC,SAAS,MAAM,UAAU;EACnC,CAAC;AAED,MAAI,SAAS;AAGb,MAAI,cAAc,SAAS,GAAG;AAC5B,UAAM,OAAO,cAAc,IAAI,CAAA,MAAK,oBAAoB,GAAG,QAAQ,CAAC,EAAE,KAAK,IAAI;AAC/E,cAAU;;iBAAY,cAAc,MAAM,0BAA0B,cAAc,WAAW,IAAI,KAAK,GAAG;;EAAuB,IAAI;EACtI;AAGA,MAAI,YAAY,SAAS,GAAG;AAC1B,UAAM,OAAO,YAAY,IAAI,CAAA,MAAK,oBAAoB,GAAG,QAAQ,CAAC,EAAE,KAAK,IAAI;AAC7E,cAAU;;;wBAA8B,YAAY,MAAM,0BAA0B,YAAY,WAAW,IAAI,KAAK,GAAG;;EAA8B,IAAI;;;;;EAC3J;AAGA,MAAI,cAAc,WAAW,KAAK,YAAY,WAAW,GAAG;AAC1D,UAAM,OAAO,oBAAoB,IAAI,CAAA,MAAK,oBAAoB,GAAG,QAAQ,CAAC,EAAE,KAAK,IAAI;AACrF,cAAU;;;wBAA8B,oBAAoB,MAAM,aAAa,oBAAoB,WAAW,IAAI,KAAK,GAAG;;EAAkD,IAAI;;;;;EAClL;AAEA,SAAO;AACT;AAKA,SAAS,iBAAiB,mBAAkD;AAC1E,MAAI,kBAAkB,WAAW,EAAG,QAAO;AAE3C,QAAM,cAAc,kBACjB,IAAI,CAAA,MAAK,SAAS,EAAE,UAAU,WAAW,EAAE,QAAQ,kBAAkB,EAAE,UAAU,EAAE,EACnF,KAAK,IAAI;AAEZ,SAAO;;;wBAA8B,kBAAkB,MAAM,0BAA0B,kBAAkB,WAAW,IAAI,KAAK,GAAG;;EAA6B,WAAW;;;;;AAC1K;AAKA,SAAS,kBAAkB,OAAsD;AAC/E,SAAO,MAAM,cAAc,IACvB;YAAe,MAAM,YAAY,eAAe,CAAC,MAAM,MAAM,KAAK,QAAQ,CAAC,CAAC,MAC5E;AACN;AAKA,SAASG,qBAAoB,QAAmD;AAC9E,SAAOL,SAAQ,MAAM,EAClB,QAAQ,YAAY,EAEpB,IAAI,CAAC,UAAe,MAAM,IAAI,OAAO,CAAC,EACtC,IAAI;AACT;AAKA,SAAS,qBAAqB,eAA+C;AAC3E,QAAM,cAAc,CAAC,cAAc,aAAa,mBAAmB,eAAe;AAClF,SAAOA,SAAQ,WAAW,EACvB,IAAI,CAAA,eAAc;AACjB,UAAM,cAAc,cAAc,UAAU,KAAK;AACjD,UAAM,QAAQI,gBAAe,UAAU;AACvC,UAAM,OAAO,eAAe,IAAI,MAAM;AACtC,WAAO,GAAG,KAAK,IAAI,IAAI,GAAG,iBAAiB,YAAY,WAAW,CAAC;EACrE,CAAC,EACA,IAAI,EACJ,KAAK,KAAK;AACf;AAKA,SAASE,oBAAmB,QAA0C;AACpE,MAAI,CAAC,UAAU,OAAO,WAAW,EAAG,QAAO;AAE3C,QAAM,eAAe,sBAAsB,MAAM;AACjD,QAAM,gBAAgBD,qBAAoB,MAAM;AAEhD,MAAI,aAAa,eAAe,KAAK,aAAa,aAAa,KAAK,aAAa,iBAAiB,GAAG;AACnG,WAAO;EACT;AAEA,QAAM,kBAAkB,qBAAqB,aAAa;AAC1D,QAAM,QAAQ,aAAa,aAAa,IAAI,iBAAO,aAAa,aAAa,IAAI,iBAAO;AAExF,MAAI,UAAU;;yBAA8B,eAAe,IAAI,KAAK;AACpE,MAAI,aAAa,WAAW,EAAG,YAAW,KAAK,aAAa,QAAQ;AACpE,MAAI,aAAa,WAAW,EAAG,YAAW,KAAK,aAAa,QAAQ;AACpE,SAAO;AACT;AAKA,SAAS,mBACP,QACA,QACA,eACQ;AACR,QAAM,EAAE,QAAQ,IAAI;AACpB,QAAM,cAAc,kBAAkB,cAAc,CAAC;AACrD,QAAM,eAAeC,oBAAmB,MAAM;AAC9C,QAAM,aAAa,gBAAgB,QAAQ,iBAAiB,MAAM;AAElE,SAAO;;;EAGP,UAAU,GAAG,YAAY;;2DAEgC,aAAa;;;;;oBAKpD,QAAQ,aAAa;wBACjB,QAAQ,cAAc,QAAQ,CAAC,CAAC;oBACpC,QAAQ,aAAa,GAAG,WAAW;;;;;AAKvD;AAKA,SAAS,kBACP,qBACA,YACA,UACA,QACe;AACf,SAAON,SAAQ,mBAAmB,EAC/B,OAAO,CAAC,EAAE,UAAU,MAAM,WAAW,IAAI,SAAS,CAAC,EACnD,IAAI,CAAC,EAAE,WAAW,YAAY,MAAM;AACnC,UAAM,UAAU,WAAW,IAAI,SAAS;AACxC,UAAM,QAAQ,SAAS,IAAIE,gBAAe,SAAS,CAAC;AACpD,UAAM,WAAW,QAAQ,KAAK,YAAY,MAAM,KAAK,CAAC,MAAM;AAC5D,UAAM,gBAAgB,QAClB,oBAAoB,MAAM,QAAQ,IACjC,UAAU,aAAa,UAAU,cAAO;AAG7C,UAAM,WAAW,gBAAgB,UAAU,YACvC,QAAQ,UAAU,UAAU,qBAAqB,UAAU,SAAS,OACpE;AAGJ,UAAM,cAAc,eAAe,UAAU,cAAc,YAAY;AACvE,UAAM,eAAe,sBAAsB,UAAU,cAAc,cAAc,UAAU,UAAU;AACrG,UAAM,mBAAmB,qBAAqB,UAAU,cAAc,cAAc,UAAU,SAAS;AAEvG,WAAO,KAAK,sBAAsB,UAAU,QAAQ,IAAI,WAAW,KAAK,UAAU,UAAU,IAAI,QAAQ,EAAE;AAE1G,WAAO;MACL,MAAM,UAAU;MAChB,MAAM;MACN,MAAM,GAAG,aAAa,MAAM,YAAY,OAAO,CAAC,EAAE,YAAY,IAAI,YAAY,MAAM,CAAC,CAAC,KAAK,YAAY,KAAK,QAAQ,gBAAgB,gBAAgB,IAAI,QAAQ;;EAAO,OAAO;IAChL;EACF,CAAC,EACA,IAAI;AACT;AAKA,SAAS,0BACP,YACA,WAIA;AACA,QAAM,YAA4E,CAAC;AACnF,QAAM,YAAmC,CAAC;AAE1C,aAAW,KAAK,YAAY;AAC1B,UAAM,cAAc,gBAAgB,GAAG,SAAS;AAChD,QAAI,gBAAgB,MAAM;AACxB,gBAAU,KAAK,EAAE,WAAW,GAAG,YAAY,CAAC;IAC9C,OAAO;AACL,gBAAU,KAAK,CAAC;IAClB;EACF;AAEA,SAAO,EAAE,WAAW,UAAU;AAChC;AAKA,SAAS,oBACP,qBACA,UACgE;AAChE,SAAO,oBAAoB,OAAO,CAAC,EAAE,UAAU,MAAM;AACnD,UAAM,MAAMA,gBAAe,SAAS;AACpC,UAAM,QAAQ,SAAS,IAAI,GAAG;AAE9B,WAAO,CAAC,SAAS,MAAM,aAAa,SAAS,MAAM,QAAQ;EAC7D,CAAC;AACH;AAKA,SAAS,qBACP,qBACA,UACuB;AACvB,SAAO,oBACJ,OAAO,CAAC,EAAE,UAAU,MAAM;AACzB,UAAM,MAAMA,gBAAe,SAAS;AACpC,UAAM,QAAQ,SAAS,IAAI,GAAG;AAC9B,WAAO,SAAS,MAAM,aAAa,SAAS,MAAM,UAAU;EAC9D,CAAC,EACA,IAAI,CAAA,MAAK,EAAE,SAAS;AACzB;AAeA,SAAS,2BACP,YACA,WACA,UAC2B;AAC3B,QAAM,EAAE,WAAW,UAAU,IAAI,0BAA0B,YAAY,SAAS;AAChF,QAAM,gBAAgB,oBAAoB,WAAW,QAAQ;AAC7D,QAAM,UAAU,qBAAqB,WAAW,QAAQ;AAExD,SAAO,EAAE,WAAW,WAAW,eAAe,QAAQ;AACxD;AAKA,eAAe,sBACb,SACA,WACA,qBACA,qBACA,UACA,QACA,QACA,QACe;AACf,MAAI,oBAAoB,WAAW,GAAG;AACpC;EACF;AAEA,QAAM,gBAAgB,qBAAqB,qBAAqB,QAAQ;AACxE,QAAM,gBAAgB,mBAAmB,qBAAqB,QAAQ;AACtE,QAAM,cAAc,iBAAiB,aAAa;AAClD,QAAM,cAAc,mBAAmB,QAAQ,QAAQ,gBAAgB,WAAW;AAClF,QAAM,cAAc,SAAS,WAAW,aAAa,MAAM;AAC7D;AAKA,eAAe,sBACb,SACA,WACA,WACA,UACA,cACA,QACA,QACA,QACA,QACe;AACf,QAAM,wBAAwB,UAAU,cAAc,IAAI,CAAA,MAAK,EAAE,SAAS;AAC1E,SAAO,KAAK,8BAA8B,sBAAsB,MAAM,6BAA6B;AAEnG,QAAM,aAAa,MAAM;IACvB;IACA;IACA,OAAO;IACP,OAAO;IACP;IACA;EACF;AAEA,QAAM,eAAe,kBAAkB,UAAU,eAAe,YAAY,UAAU,MAAM;AAC5F,SAAO,KAAK,SAAS,aAAa,MAAM,4CAA4C;AAEpF,QAAM,gBAAgB,mBAAmB,UAAU,WAAW,QAAQ;AACtE,QAAM,cAAc,iBAAiB,UAAU,OAAO;AACtD,QAAM,cAAc,mBAAmB,QAAQ,QAAQ,gBAAgB,WAAW;AAElF,QAAM,aAAa,SAAS,WAAW,cAAc,aAAa,MAAM;AACxE,SAAO,KAAK,sBAAsB,aAAa,MAAM,gBAAgB;AACvE;AAKA,eAAe,eACb,SACA,WACA,QACA,YACA,cACA,QACA,QACA,SAAmC,MACpB;AACf,QAAM,YAAY,MAAM,eAAe,SAAS,SAAS;AACzD,SAAO,KAAK,eAAe,UAAU,IAAI,QAAQ;AAEjD,QAAM,WAAWC,eAAc,MAAM;AACrC,QAAM,YAAY,2BAA2B,YAAY,WAAW,QAAQ;AAE5E,SAAO;IACL,GAAG,UAAU,UAAU,MAAM,IAAI,WAAW,MAAM,yCAC9C,UAAU,UAAU,MAAM;EAChC;AAEA,QAAM,eAAe,UAAU,UAAU,SAAS,UAAU,cAAc;AAC1E,MAAI,eAAe,GAAG;AACpB,WAAO,KAAK,YAAY,YAAY,0DAA0D;EAChG;AAEA,MAAI,UAAU,cAAc,WAAW,GAAG;AACxC,WAAO,KAAK,6CAA6C;AACzD,UAAM;MACJ;MACA;MACA,UAAU;MACV,UAAU;MACV;MACA;MACA;MACA;IACF;AACA;EACF;AAEA,QAAM;IACJ;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;EACF;AACF;AAKA,eAAe,kBACb,SACA,WACA,QACA,cACA,QACA,QACA,aAAa,OACb,SAAmC,MACnC,gBAAwB,IACT;AACf,QAAM,SAAS,kBAAkB,QAAQ,WAAW,cAAc,MAAM;AACxE,SAAO,MAAM,kBAAkB,OAAO,MAAM,aAAa;AAEzD,QAAM,WAAW,MAAM;IACrB;IACA,OAAO;IACP,OAAO;IACP;EACF;AAEA,QAAM,QAAQ,cAAc;AAC5B,QAAM,UAAU,oBAAoB,UAAU,QAAQ,YAAY,OAAO,QAAQ,aAAa;AAC9F,QAAM,cAAc,SAAS,WAAW,SAAS,MAAM;AACvD,SAAO,KAAK,+CAA+C;AAC7D;AAMA,eAAsB,mBACpB,QACA,OACe;AACf,QAAM,EAAE,QAAQ,WAAW,SAAS,OAAO,IAAI;AAE/C,MAAI,OAAO,cAAc,QAAQ,oBAAoB,GAAG;AACtD,WAAO,KAAK,gCAAgC;AAE5C,UAAM,iBAAiB,yBAAyB,WAAW,OAAO,MAAM;AACxE,UAAM,cAAc,SAAS,WAAW,gBAAgB,MAAM;AAC9D;EACF;AAEA,QAAM,EAAE,YAAY,aAAa,IAAI,MAAM;IACzC,OAAO;IACP;IACA;IACA;EACF;AAEA,kBAAgB;AAChB,MAAI,OAAO,gBAAgB,WAAW;AAEpC,UAAM,YAAY,MAAM,eAAe,SAAS,SAAS;AACzD,UAAM,WAAWA,eAAc,OAAO,MAAM;AAC5C,UAAM,EAAE,UAAU,IAAI,0BAA0B,YAAY,SAAS;AACrE,UAAM,gBAAgB,mBAAmB,WAAW,QAAQ;AAE5D,UAAM;MACJ;MACA;MACA,OAAO;MACP;MACA;MACA;MACA;MACA,OAAO;MACP;IACF;EACF,OAAO;AACL,UAAM;MACJ;MACA;MACA,OAAO;MACP;MACA;MACA;MACA;MACA,OAAO;IACT;EACF;AACF;;;AF74BA,IAAM,gBAAwB;AAAA,EAC5B,MAAM,CAAC,QAAqB,UAAK,GAAG;AAAA,EACpC,SAAS,CAAC,QAAqB,aAAQ,GAAG;AAAA,EAC1C,OAAO,CAAC,QAAqB,WAAM,GAAG;AAAA,EACtC,OAAO,CAAC,QAAqB,WAAM,GAAG;AACxC;AAKA,SAAS,YAA0B;AACjC,QAAM,cAAmB,cAAS,cAAc,KAAK;AAErD,SAAO;AAAA,IACL,kBAAuB,cAAS,sBAAsB,EAAE,UAAU,KAAK,CAAC;AAAA,IACxE,OAAY,cAAS,OAAO,KAAK;AAAA,IACjC,WAAgB,cAAS,WAAW,KAAK;AAAA,IACzC,aAAc,gBAAgB,YAAY,YAAY;AAAA,IACtD,qBAA0B,cAAS,uBAAuB,MAAM;AAAA,IAChE,wBAA6B,cAAS,qBAAqB,KAAK;AAAA,EAClE;AACF;AAKA,SAAS,eAAe;AACtB,QAAM,EAAE,QAAQ,IAAI;AAEpB,MAAI,CAAC,QAAQ,QAAQ,cAAc;AACjC,IAAK,aAAQ,+CAA+C;AAC5D,WAAO;AAAA,EACT;AAEA,QAAM,KAAK,QAAQ,QAAQ;AAE3B,SAAO;AAAA,IACL,OAAO,QAAQ,KAAK;AAAA,IACpB,MAAM,QAAQ,KAAK;AAAA,IACnB,YAAY,GAAG;AAAA,IACf,OAAO,GAAG;AAAA,IACV,SAAS,GAAG,KAAK;AAAA,IACjB,SAAS,GAAG,KAAK;AAAA,EACnB;AACF;AAKA,SAAS,WACP,cACA,QACM;AACN,MAAI,cAAc;AAChB,IAAK,eAAU,eAAe,aAAa,UAAU;AACrD,IAAK,eAAU,YAAY,aAAa,QAAQ;AAChD,IAAK,eAAU,YAAY,aAAa,QAAQ;AAAA,EAClD;AAEA,EAAK,eAAU,cAAc,OAAO,QAAQ,eAAe;AAC3D,EAAK,eAAU,UAAU,OAAO,QAAQ,WAAW,KAAK;AACxD,EAAK,eAAU,YAAY,OAAO,QAAQ,WAAW,OAAO;AAC9D;AAKA,eAAe,MAAqB;AAClC,MAAI;AACF,IAAK,UAAK,iCAAiC;AAC3C,IAAK,UAAK,iBAAiB,QAAQ,OAAO,EAAE;AAC5C,IAAK,UAAK,sBAAsB,QAAQ,IAAI,CAAC,EAAE;AAE/C,UAAM,SAAS,UAAU;AACzB,IAAK,UAAK,gBAAgB,OAAO,KAAK,EAAE;AACxC,IAAK,UAAK,yBAAyB,OAAO,SAAS,EAAE;AACrD,IAAK,UAAK,iBAAiB,OAAO,WAAW,EAAE;AAE/C,UAAM,cAAmB,cAAS,cAAc,KAAK,QAAQ,IAAI,gBAAgB;AACjF,QAAI,CAAC,aAAa;AAChB,YAAM,IAAI,MAAM,0BAA0B;AAAA,IAC5C;AAEA,UAAM,YAAY,aAAa;AAC/B,QAAI,CAAC,WAAW;AACd,MAAK,UAAK,+CAA+C;AACzD;AAAA,IACF;AAEA,IAAK,UAAK,iBAAiB,UAAU,UAAU,KAAK,UAAU,KAAK,EAAE;AAIrE,UAAM,UAAU,cAAc,WAAW;AAEzC,UAAM,QAAqB;AAAA,MACzB;AAAA,MACA;AAAA,MACA;AAAA,MACA,QAAQ;AAAA,MACR,SAAS,QAAQ,IAAI;AAAA,IACvB;AAEA,UAAM,iBAAiB,MAAM,oBAAoB,KAAK;AACtD,QAAI,CAAC,gBAAgB;AACnB;AAAA,IACF;AAEA,UAAM,eAAe,MAAM,sBAAsB,gBAAgB,KAAK;AACtE,eAAW,cAAc,eAAe,aAAa;AACrD,UAAM,mBAAmB,gBAAgB,KAAK;AAAA,EAChD,SAASI,QAAO;AACd,UAAM,UAAUA,kBAAiB,QAAQA,OAAM,UAAU;AACzD,UAAM,QAAQA,kBAAiB,QAAQA,OAAM,QAAQ;AACrD,IAAK,WAAM,kBAAkB,OAAO,EAAE;AACtC,QAAI,OAAO;AACT,MAAK,WAAM;AAAA,EAAiB,KAAK,EAAE;AAAA,IACrC;AACA,IAAK,eAAU,OAAO;AAAA,EACxB;AACF;AAGA,IAAI,EAAE,MAAM,CAACA,WAAU;AACrB,EAAK,eAAUA,kBAAiB,QAAQA,OAAM,UAAU,OAAOA,MAAK,CAAC;AACrE,UAAQ,KAAK,CAAC;AAChB,CAAC;","names":["collect","error","collect","collect","error","createDeltaKey","buildDeltaMap","getMetricEmoji","groupDeltasByMetric","formatDeltaDisplay","error"]}