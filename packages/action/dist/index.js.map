{"version":3,"sources":["../../../node_modules/balanced-match/index.js","../../../node_modules/brace-expansion/index.js","../../../node_modules/ignore/index.js","../src/index.ts","../../core/src/indexer/index.ts","../../../node_modules/yocto-queue/index.js","../../../node_modules/p-limit/index.js","../../../node_modules/minimatch/src/index.ts","../../../node_modules/minimatch/src/assert-valid-pattern.ts","../../../node_modules/minimatch/src/brace-expressions.ts","../../../node_modules/minimatch/src/unescape.ts","../../../node_modules/minimatch/src/ast.ts","../../../node_modules/minimatch/src/escape.ts","../../../node_modules/lru-cache/src/index.ts","../../../node_modules/path-scurry/src/index.ts","../../../node_modules/minipass/src/index.ts","../../core/node_modules/glob/src/glob.ts","../../core/node_modules/glob/src/pattern.ts","../../core/node_modules/minipass/index.mjs","../../core/node_modules/glob/src/ignore.ts","../../core/node_modules/glob/src/processor.ts","../../core/node_modules/glob/src/walker.ts","../../core/node_modules/glob/src/has-magic.ts","../../core/node_modules/glob/src/index.ts","../../core/src/indexer/scanner.ts","../../core/src/indexer/symbol-extractor.ts","../../core/src/indexer/ast/parser.ts","../../core/src/indexer/ast/complexity/cyclomatic.ts","../../core/src/indexer/ast/complexity/cognitive.ts","../../core/src/indexer/ast/complexity/halstead.ts","../../core/src/indexer/ast/symbols.ts","../../core/src/indexer/ast/traversers/typescript.ts","../../core/src/indexer/ast/traversers/php.ts","../../core/src/indexer/ast/traversers/python.ts","../../core/src/indexer/ast/traversers/index.ts","../../core/src/indexer/ast/chunker.ts","../../core/src/indexer/liquid-chunker.ts","../../core/src/indexer/json-template-chunker.ts","../../core/src/indexer/chunker.ts","../../core/src/embeddings/local.ts","../../core/src/errors/codes.ts","../../core/src/errors/index.ts","../../core/src/constants.ts","../../core/src/vectordb/lancedb.ts","../../core/src/embeddings/types.ts","../../core/src/vectordb/version.ts","../../core/src/vectordb/relevance.ts","../../core/src/vectordb/intent-classifier.ts","../../core/src/vectordb/boosting/strategies.ts","../../core/src/vectordb/boosting/composer.ts","../../core/src/vectordb/query.ts","../../core/src/vectordb/batch-insert.ts","../../core/src/vectordb/maintenance.ts","../../core/src/config/service.ts","../../core/src/config/schema.ts","../../core/src/config/merge.ts","../../core/src/config/migration.ts","../../core/src/indexer/manifest.ts","../../core/src/utils/version.ts","../../core/src/git/utils.ts","../../core/src/git/tracker.ts","../../core/src/indexer/change-detector.ts","../../core/src/indexer/incremental.ts","../../core/src/utils/result.ts","../../core/src/indexer/chunk-batch-processor.ts","../../core/src/insights/types.ts","../../core/src/utils/path-matching.ts","../../core/src/indexer/dependency-analyzer.ts","../../core/src/insights/complexity-analyzer.ts","../../core/src/index.ts","../src/github.ts","../src/openrouter.ts","../src/prompt.ts","../src/delta.ts","../src/format.ts"],"sourcesContent":["'use strict';\nmodule.exports = balanced;\nfunction balanced(a, b, str) {\n  if (a instanceof RegExp) a = maybeMatch(a, str);\n  if (b instanceof RegExp) b = maybeMatch(b, str);\n\n  var r = range(a, b, str);\n\n  return r && {\n    start: r[0],\n    end: r[1],\n    pre: str.slice(0, r[0]),\n    body: str.slice(r[0] + a.length, r[1]),\n    post: str.slice(r[1] + b.length)\n  };\n}\n\nfunction maybeMatch(reg, str) {\n  var m = str.match(reg);\n  return m ? m[0] : null;\n}\n\nbalanced.range = range;\nfunction range(a, b, str) {\n  var begs, beg, left, right, result;\n  var ai = str.indexOf(a);\n  var bi = str.indexOf(b, ai + 1);\n  var i = ai;\n\n  if (ai >= 0 && bi > 0) {\n    if(a===b) {\n      return [ai, bi];\n    }\n    begs = [];\n    left = str.length;\n\n    while (i >= 0 && !result) {\n      if (i == ai) {\n        begs.push(i);\n        ai = str.indexOf(a, i + 1);\n      } else if (begs.length == 1) {\n        result = [ begs.pop(), bi ];\n      } else {\n        beg = begs.pop();\n        if (beg < left) {\n          left = beg;\n          right = bi;\n        }\n\n        bi = str.indexOf(b, i + 1);\n      }\n\n      i = ai < bi && ai >= 0 ? ai : bi;\n    }\n\n    if (begs.length) {\n      result = [ left, right ];\n    }\n  }\n\n  return result;\n}\n","var balanced = require('balanced-match');\n\nmodule.exports = expandTop;\n\nvar escSlash = '\\0SLASH'+Math.random()+'\\0';\nvar escOpen = '\\0OPEN'+Math.random()+'\\0';\nvar escClose = '\\0CLOSE'+Math.random()+'\\0';\nvar escComma = '\\0COMMA'+Math.random()+'\\0';\nvar escPeriod = '\\0PERIOD'+Math.random()+'\\0';\n\nfunction numeric(str) {\n  return parseInt(str, 10) == str\n    ? parseInt(str, 10)\n    : str.charCodeAt(0);\n}\n\nfunction escapeBraces(str) {\n  return str.split('\\\\\\\\').join(escSlash)\n            .split('\\\\{').join(escOpen)\n            .split('\\\\}').join(escClose)\n            .split('\\\\,').join(escComma)\n            .split('\\\\.').join(escPeriod);\n}\n\nfunction unescapeBraces(str) {\n  return str.split(escSlash).join('\\\\')\n            .split(escOpen).join('{')\n            .split(escClose).join('}')\n            .split(escComma).join(',')\n            .split(escPeriod).join('.');\n}\n\n\n// Basically just str.split(\",\"), but handling cases\n// where we have nested braced sections, which should be\n// treated as individual members, like {a,{b,c},d}\nfunction parseCommaParts(str) {\n  if (!str)\n    return [''];\n\n  var parts = [];\n  var m = balanced('{', '}', str);\n\n  if (!m)\n    return str.split(',');\n\n  var pre = m.pre;\n  var body = m.body;\n  var post = m.post;\n  var p = pre.split(',');\n\n  p[p.length-1] += '{' + body + '}';\n  var postParts = parseCommaParts(post);\n  if (post.length) {\n    p[p.length-1] += postParts.shift();\n    p.push.apply(p, postParts);\n  }\n\n  parts.push.apply(parts, p);\n\n  return parts;\n}\n\nfunction expandTop(str) {\n  if (!str)\n    return [];\n\n  // I don't know why Bash 4.3 does this, but it does.\n  // Anything starting with {} will have the first two bytes preserved\n  // but *only* at the top level, so {},a}b will not expand to anything,\n  // but a{},b}c will be expanded to [a}c,abc].\n  // One could argue that this is a bug in Bash, but since the goal of\n  // this module is to match Bash's rules, we escape a leading {}\n  if (str.substr(0, 2) === '{}') {\n    str = '\\\\{\\\\}' + str.substr(2);\n  }\n\n  return expand(escapeBraces(str), true).map(unescapeBraces);\n}\n\nfunction embrace(str) {\n  return '{' + str + '}';\n}\nfunction isPadded(el) {\n  return /^-?0\\d/.test(el);\n}\n\nfunction lte(i, y) {\n  return i <= y;\n}\nfunction gte(i, y) {\n  return i >= y;\n}\n\nfunction expand(str, isTop) {\n  var expansions = [];\n\n  var m = balanced('{', '}', str);\n  if (!m) return [str];\n\n  // no need to expand pre, since it is guaranteed to be free of brace-sets\n  var pre = m.pre;\n  var post = m.post.length\n    ? expand(m.post, false)\n    : [''];\n\n  if (/\\$$/.test(m.pre)) {    \n    for (var k = 0; k < post.length; k++) {\n      var expansion = pre+ '{' + m.body + '}' + post[k];\n      expansions.push(expansion);\n    }\n  } else {\n    var isNumericSequence = /^-?\\d+\\.\\.-?\\d+(?:\\.\\.-?\\d+)?$/.test(m.body);\n    var isAlphaSequence = /^[a-zA-Z]\\.\\.[a-zA-Z](?:\\.\\.-?\\d+)?$/.test(m.body);\n    var isSequence = isNumericSequence || isAlphaSequence;\n    var isOptions = m.body.indexOf(',') >= 0;\n    if (!isSequence && !isOptions) {\n      // {a},b}\n      if (m.post.match(/,(?!,).*\\}/)) {\n        str = m.pre + '{' + m.body + escClose + m.post;\n        return expand(str);\n      }\n      return [str];\n    }\n\n    var n;\n    if (isSequence) {\n      n = m.body.split(/\\.\\./);\n    } else {\n      n = parseCommaParts(m.body);\n      if (n.length === 1) {\n        // x{{a,b}}y ==> x{a}y x{b}y\n        n = expand(n[0], false).map(embrace);\n        if (n.length === 1) {\n          return post.map(function(p) {\n            return m.pre + n[0] + p;\n          });\n        }\n      }\n    }\n\n    // at this point, n is the parts, and we know it's not a comma set\n    // with a single entry.\n    var N;\n\n    if (isSequence) {\n      var x = numeric(n[0]);\n      var y = numeric(n[1]);\n      var width = Math.max(n[0].length, n[1].length)\n      var incr = n.length == 3\n        ? Math.abs(numeric(n[2]))\n        : 1;\n      var test = lte;\n      var reverse = y < x;\n      if (reverse) {\n        incr *= -1;\n        test = gte;\n      }\n      var pad = n.some(isPadded);\n\n      N = [];\n\n      for (var i = x; test(i, y); i += incr) {\n        var c;\n        if (isAlphaSequence) {\n          c = String.fromCharCode(i);\n          if (c === '\\\\')\n            c = '';\n        } else {\n          c = String(i);\n          if (pad) {\n            var need = width - c.length;\n            if (need > 0) {\n              var z = new Array(need + 1).join('0');\n              if (i < 0)\n                c = '-' + z + c.slice(1);\n              else\n                c = z + c;\n            }\n          }\n        }\n        N.push(c);\n      }\n    } else {\n      N = [];\n\n      for (var j = 0; j < n.length; j++) {\n        N.push.apply(N, expand(n[j], false));\n      }\n    }\n\n    for (var j = 0; j < N.length; j++) {\n      for (var k = 0; k < post.length; k++) {\n        var expansion = pre + N[j] + post[k];\n        if (!isTop || isSequence || expansion)\n          expansions.push(expansion);\n      }\n    }\n  }\n\n  return expansions;\n}\n\n","// A simple implementation of make-array\nfunction makeArray (subject) {\n  return Array.isArray(subject)\n    ? subject\n    : [subject]\n}\n\nconst EMPTY = ''\nconst SPACE = ' '\nconst ESCAPE = '\\\\'\nconst REGEX_TEST_BLANK_LINE = /^\\s+$/\nconst REGEX_INVALID_TRAILING_BACKSLASH = /(?:[^\\\\]|^)\\\\$/\nconst REGEX_REPLACE_LEADING_EXCAPED_EXCLAMATION = /^\\\\!/\nconst REGEX_REPLACE_LEADING_EXCAPED_HASH = /^\\\\#/\nconst REGEX_SPLITALL_CRLF = /\\r?\\n/g\n// /foo,\n// ./foo,\n// ../foo,\n// .\n// ..\nconst REGEX_TEST_INVALID_PATH = /^\\.*\\/|^\\.+$/\n\nconst SLASH = '/'\n\n// Do not use ternary expression here, since \"istanbul ignore next\" is buggy\nlet TMP_KEY_IGNORE = 'node-ignore'\n/* istanbul ignore else */\nif (typeof Symbol !== 'undefined') {\n  TMP_KEY_IGNORE = Symbol.for('node-ignore')\n}\nconst KEY_IGNORE = TMP_KEY_IGNORE\n\nconst define = (object, key, value) =>\n  Object.defineProperty(object, key, {value})\n\nconst REGEX_REGEXP_RANGE = /([0-z])-([0-z])/g\n\nconst RETURN_FALSE = () => false\n\n// Sanitize the range of a regular expression\n// The cases are complicated, see test cases for details\nconst sanitizeRange = range => range.replace(\n  REGEX_REGEXP_RANGE,\n  (match, from, to) => from.charCodeAt(0) <= to.charCodeAt(0)\n    ? match\n    // Invalid range (out of order) which is ok for gitignore rules but\n    //   fatal for JavaScript regular expression, so eliminate it.\n    : EMPTY\n)\n\n// See fixtures #59\nconst cleanRangeBackSlash = slashes => {\n  const {length} = slashes\n  return slashes.slice(0, length - length % 2)\n}\n\n// > If the pattern ends with a slash,\n// > it is removed for the purpose of the following description,\n// > but it would only find a match with a directory.\n// > In other words, foo/ will match a directory foo and paths underneath it,\n// > but will not match a regular file or a symbolic link foo\n// >  (this is consistent with the way how pathspec works in general in Git).\n// '`foo/`' will not match regular file '`foo`' or symbolic link '`foo`'\n// -> ignore-rules will not deal with it, because it costs extra `fs.stat` call\n//      you could use option `mark: true` with `glob`\n\n// '`foo/`' should not continue with the '`..`'\nconst REPLACERS = [\n\n  // > Trailing spaces are ignored unless they are quoted with backslash (\"\\\")\n  [\n    // (a\\ ) -> (a )\n    // (a  ) -> (a)\n    // (a \\ ) -> (a  )\n    /\\\\?\\s+$/,\n    match => match.indexOf('\\\\') === 0\n      ? SPACE\n      : EMPTY\n  ],\n\n  // replace (\\ ) with ' '\n  [\n    /\\\\\\s/g,\n    () => SPACE\n  ],\n\n  // Escape metacharacters\n  // which is written down by users but means special for regular expressions.\n\n  // > There are 12 characters with special meanings:\n  // > - the backslash \\,\n  // > - the caret ^,\n  // > - the dollar sign $,\n  // > - the period or dot .,\n  // > - the vertical bar or pipe symbol |,\n  // > - the question mark ?,\n  // > - the asterisk or star *,\n  // > - the plus sign +,\n  // > - the opening parenthesis (,\n  // > - the closing parenthesis ),\n  // > - and the opening square bracket [,\n  // > - the opening curly brace {,\n  // > These special characters are often called \"metacharacters\".\n  [\n    /[\\\\$.|*+(){^]/g,\n    match => `\\\\${match}`\n  ],\n\n  [\n    // > a question mark (?) matches a single character\n    /(?!\\\\)\\?/g,\n    () => '[^/]'\n  ],\n\n  // leading slash\n  [\n\n    // > A leading slash matches the beginning of the pathname.\n    // > For example, \"/*.c\" matches \"cat-file.c\" but not \"mozilla-sha1/sha1.c\".\n    // A leading slash matches the beginning of the pathname\n    /^\\//,\n    () => '^'\n  ],\n\n  // replace special metacharacter slash after the leading slash\n  [\n    /\\//g,\n    () => '\\\\/'\n  ],\n\n  [\n    // > A leading \"**\" followed by a slash means match in all directories.\n    // > For example, \"**/foo\" matches file or directory \"foo\" anywhere,\n    // > the same as pattern \"foo\".\n    // > \"**/foo/bar\" matches file or directory \"bar\" anywhere that is directly\n    // >   under directory \"foo\".\n    // Notice that the '*'s have been replaced as '\\\\*'\n    /^\\^*\\\\\\*\\\\\\*\\\\\\//,\n\n    // '**/foo' <-> 'foo'\n    () => '^(?:.*\\\\/)?'\n  ],\n\n  // starting\n  [\n    // there will be no leading '/'\n    //   (which has been replaced by section \"leading slash\")\n    // If starts with '**', adding a '^' to the regular expression also works\n    /^(?=[^^])/,\n    function startingReplacer () {\n      // If has a slash `/` at the beginning or middle\n      return !/\\/(?!$)/.test(this)\n        // > Prior to 2.22.1\n        // > If the pattern does not contain a slash /,\n        // >   Git treats it as a shell glob pattern\n        // Actually, if there is only a trailing slash,\n        //   git also treats it as a shell glob pattern\n\n        // After 2.22.1 (compatible but clearer)\n        // > If there is a separator at the beginning or middle (or both)\n        // > of the pattern, then the pattern is relative to the directory\n        // > level of the particular .gitignore file itself.\n        // > Otherwise the pattern may also match at any level below\n        // > the .gitignore level.\n        ? '(?:^|\\\\/)'\n\n        // > Otherwise, Git treats the pattern as a shell glob suitable for\n        // >   consumption by fnmatch(3)\n        : '^'\n    }\n  ],\n\n  // two globstars\n  [\n    // Use lookahead assertions so that we could match more than one `'/**'`\n    /\\\\\\/\\\\\\*\\\\\\*(?=\\\\\\/|$)/g,\n\n    // Zero, one or several directories\n    // should not use '*', or it will be replaced by the next replacer\n\n    // Check if it is not the last `'/**'`\n    (_, index, str) => index + 6 < str.length\n\n      // case: /**/\n      // > A slash followed by two consecutive asterisks then a slash matches\n      // >   zero or more directories.\n      // > For example, \"a/**/b\" matches \"a/b\", \"a/x/b\", \"a/x/y/b\" and so on.\n      // '/**/'\n      ? '(?:\\\\/[^\\\\/]+)*'\n\n      // case: /**\n      // > A trailing `\"/**\"` matches everything inside.\n\n      // #21: everything inside but it should not include the current folder\n      : '\\\\/.+'\n  ],\n\n  // normal intermediate wildcards\n  [\n    // Never replace escaped '*'\n    // ignore rule '\\*' will match the path '*'\n\n    // 'abc.*/' -> go\n    // 'abc.*'  -> skip this rule,\n    //    coz trailing single wildcard will be handed by [trailing wildcard]\n    /(^|[^\\\\]+)(\\\\\\*)+(?=.+)/g,\n\n    // '*.js' matches '.js'\n    // '*.js' doesn't match 'abc'\n    (_, p1, p2) => {\n      // 1.\n      // > An asterisk \"*\" matches anything except a slash.\n      // 2.\n      // > Other consecutive asterisks are considered regular asterisks\n      // > and will match according to the previous rules.\n      const unescaped = p2.replace(/\\\\\\*/g, '[^\\\\/]*')\n      return p1 + unescaped\n    }\n  ],\n\n  [\n    // unescape, revert step 3 except for back slash\n    // For example, if a user escape a '\\\\*',\n    // after step 3, the result will be '\\\\\\\\\\\\*'\n    /\\\\\\\\\\\\(?=[$.|*+(){^])/g,\n    () => ESCAPE\n  ],\n\n  [\n    // '\\\\\\\\' -> '\\\\'\n    /\\\\\\\\/g,\n    () => ESCAPE\n  ],\n\n  [\n    // > The range notation, e.g. [a-zA-Z],\n    // > can be used to match one of the characters in a range.\n\n    // `\\` is escaped by step 3\n    /(\\\\)?\\[([^\\]/]*?)(\\\\*)($|\\])/g,\n    (match, leadEscape, range, endEscape, close) => leadEscape === ESCAPE\n      // '\\\\[bar]' -> '\\\\\\\\[bar\\\\]'\n      ? `\\\\[${range}${cleanRangeBackSlash(endEscape)}${close}`\n      : close === ']'\n        ? endEscape.length % 2 === 0\n          // A normal case, and it is a range notation\n          // '[bar]'\n          // '[bar\\\\\\\\]'\n          ? `[${sanitizeRange(range)}${endEscape}]`\n          // Invalid range notaton\n          // '[bar\\\\]' -> '[bar\\\\\\\\]'\n          : '[]'\n        : '[]'\n  ],\n\n  // ending\n  [\n    // 'js' will not match 'js.'\n    // 'ab' will not match 'abc'\n    /(?:[^*])$/,\n\n    // WTF!\n    // https://git-scm.com/docs/gitignore\n    // changes in [2.22.1](https://git-scm.com/docs/gitignore/2.22.1)\n    // which re-fixes #24, #38\n\n    // > If there is a separator at the end of the pattern then the pattern\n    // > will only match directories, otherwise the pattern can match both\n    // > files and directories.\n\n    // 'js*' will not match 'a.js'\n    // 'js/' will not match 'a.js'\n    // 'js' will match 'a.js' and 'a.js/'\n    match => /\\/$/.test(match)\n      // foo/ will not match 'foo'\n      ? `${match}$`\n      // foo matches 'foo' and 'foo/'\n      : `${match}(?=$|\\\\/$)`\n  ],\n\n  // trailing wildcard\n  [\n    /(\\^|\\\\\\/)?\\\\\\*$/,\n    (_, p1) => {\n      const prefix = p1\n        // '\\^':\n        // '/*' does not match EMPTY\n        // '/*' does not match everything\n\n        // '\\\\\\/':\n        // 'abc/*' does not match 'abc/'\n        ? `${p1}[^/]+`\n\n        // 'a*' matches 'a'\n        // 'a*' matches 'aa'\n        : '[^/]*'\n\n      return `${prefix}(?=$|\\\\/$)`\n    }\n  ],\n]\n\n// A simple cache, because an ignore rule only has only one certain meaning\nconst regexCache = Object.create(null)\n\n// @param {pattern}\nconst makeRegex = (pattern, ignoreCase) => {\n  let source = regexCache[pattern]\n\n  if (!source) {\n    source = REPLACERS.reduce(\n      (prev, current) => prev.replace(current[0], current[1].bind(pattern)),\n      pattern\n    )\n    regexCache[pattern] = source\n  }\n\n  return ignoreCase\n    ? new RegExp(source, 'i')\n    : new RegExp(source)\n}\n\nconst isString = subject => typeof subject === 'string'\n\n// > A blank line matches no files, so it can serve as a separator for readability.\nconst checkPattern = pattern => pattern\n  && isString(pattern)\n  && !REGEX_TEST_BLANK_LINE.test(pattern)\n  && !REGEX_INVALID_TRAILING_BACKSLASH.test(pattern)\n\n  // > A line starting with # serves as a comment.\n  && pattern.indexOf('#') !== 0\n\nconst splitPattern = pattern => pattern.split(REGEX_SPLITALL_CRLF)\n\nclass IgnoreRule {\n  constructor (\n    origin,\n    pattern,\n    negative,\n    regex\n  ) {\n    this.origin = origin\n    this.pattern = pattern\n    this.negative = negative\n    this.regex = regex\n  }\n}\n\nconst createRule = (pattern, ignoreCase) => {\n  const origin = pattern\n  let negative = false\n\n  // > An optional prefix \"!\" which negates the pattern;\n  if (pattern.indexOf('!') === 0) {\n    negative = true\n    pattern = pattern.substr(1)\n  }\n\n  pattern = pattern\n  // > Put a backslash (\"\\\") in front of the first \"!\" for patterns that\n  // >   begin with a literal \"!\", for example, `\"\\!important!.txt\"`.\n  .replace(REGEX_REPLACE_LEADING_EXCAPED_EXCLAMATION, '!')\n  // > Put a backslash (\"\\\") in front of the first hash for patterns that\n  // >   begin with a hash.\n  .replace(REGEX_REPLACE_LEADING_EXCAPED_HASH, '#')\n\n  const regex = makeRegex(pattern, ignoreCase)\n\n  return new IgnoreRule(\n    origin,\n    pattern,\n    negative,\n    regex\n  )\n}\n\nconst throwError = (message, Ctor) => {\n  throw new Ctor(message)\n}\n\nconst checkPath = (path, originalPath, doThrow) => {\n  if (!isString(path)) {\n    return doThrow(\n      `path must be a string, but got \\`${originalPath}\\``,\n      TypeError\n    )\n  }\n\n  // We don't know if we should ignore EMPTY, so throw\n  if (!path) {\n    return doThrow(`path must not be empty`, TypeError)\n  }\n\n  // Check if it is a relative path\n  if (checkPath.isNotRelative(path)) {\n    const r = '`path.relative()`d'\n    return doThrow(\n      `path should be a ${r} string, but got \"${originalPath}\"`,\n      RangeError\n    )\n  }\n\n  return true\n}\n\nconst isNotRelative = path => REGEX_TEST_INVALID_PATH.test(path)\n\ncheckPath.isNotRelative = isNotRelative\ncheckPath.convert = p => p\n\nclass Ignore {\n  constructor ({\n    ignorecase = true,\n    ignoreCase = ignorecase,\n    allowRelativePaths = false\n  } = {}) {\n    define(this, KEY_IGNORE, true)\n\n    this._rules = []\n    this._ignoreCase = ignoreCase\n    this._allowRelativePaths = allowRelativePaths\n    this._initCache()\n  }\n\n  _initCache () {\n    this._ignoreCache = Object.create(null)\n    this._testCache = Object.create(null)\n  }\n\n  _addPattern (pattern) {\n    // #32\n    if (pattern && pattern[KEY_IGNORE]) {\n      this._rules = this._rules.concat(pattern._rules)\n      this._added = true\n      return\n    }\n\n    if (checkPattern(pattern)) {\n      const rule = createRule(pattern, this._ignoreCase)\n      this._added = true\n      this._rules.push(rule)\n    }\n  }\n\n  // @param {Array<string> | string | Ignore} pattern\n  add (pattern) {\n    this._added = false\n\n    makeArray(\n      isString(pattern)\n        ? splitPattern(pattern)\n        : pattern\n    ).forEach(this._addPattern, this)\n\n    // Some rules have just added to the ignore,\n    // making the behavior changed.\n    if (this._added) {\n      this._initCache()\n    }\n\n    return this\n  }\n\n  // legacy\n  addPattern (pattern) {\n    return this.add(pattern)\n  }\n\n  //          |           ignored : unignored\n  // negative |   0:0   |   0:1   |   1:0   |   1:1\n  // -------- | ------- | ------- | ------- | --------\n  //     0    |  TEST   |  TEST   |  SKIP   |    X\n  //     1    |  TESTIF |  SKIP   |  TEST   |    X\n\n  // - SKIP: always skip\n  // - TEST: always test\n  // - TESTIF: only test if checkUnignored\n  // - X: that never happen\n\n  // @param {boolean} whether should check if the path is unignored,\n  //   setting `checkUnignored` to `false` could reduce additional\n  //   path matching.\n\n  // @returns {TestResult} true if a file is ignored\n  _testOne (path, checkUnignored) {\n    let ignored = false\n    let unignored = false\n\n    this._rules.forEach(rule => {\n      const {negative} = rule\n      if (\n        unignored === negative && ignored !== unignored\n        || negative && !ignored && !unignored && !checkUnignored\n      ) {\n        return\n      }\n\n      const matched = rule.regex.test(path)\n\n      if (matched) {\n        ignored = !negative\n        unignored = negative\n      }\n    })\n\n    return {\n      ignored,\n      unignored\n    }\n  }\n\n  // @returns {TestResult}\n  _test (originalPath, cache, checkUnignored, slices) {\n    const path = originalPath\n      // Supports nullable path\n      && checkPath.convert(originalPath)\n\n    checkPath(\n      path,\n      originalPath,\n      this._allowRelativePaths\n        ? RETURN_FALSE\n        : throwError\n    )\n\n    return this._t(path, cache, checkUnignored, slices)\n  }\n\n  _t (path, cache, checkUnignored, slices) {\n    if (path in cache) {\n      return cache[path]\n    }\n\n    if (!slices) {\n      // path/to/a.js\n      // ['path', 'to', 'a.js']\n      slices = path.split(SLASH)\n    }\n\n    slices.pop()\n\n    // If the path has no parent directory, just test it\n    if (!slices.length) {\n      return cache[path] = this._testOne(path, checkUnignored)\n    }\n\n    const parent = this._t(\n      slices.join(SLASH) + SLASH,\n      cache,\n      checkUnignored,\n      slices\n    )\n\n    // If the path contains a parent directory, check the parent first\n    return cache[path] = parent.ignored\n      // > It is not possible to re-include a file if a parent directory of\n      // >   that file is excluded.\n      ? parent\n      : this._testOne(path, checkUnignored)\n  }\n\n  ignores (path) {\n    return this._test(path, this._ignoreCache, false).ignored\n  }\n\n  createFilter () {\n    return path => !this.ignores(path)\n  }\n\n  filter (paths) {\n    return makeArray(paths).filter(this.createFilter())\n  }\n\n  // @returns {TestResult}\n  test (path) {\n    return this._test(path, this._testCache, true)\n  }\n}\n\nconst factory = options => new Ignore(options)\n\nconst isPathValid = path =>\n  checkPath(path && checkPath.convert(path), path, RETURN_FALSE)\n\nfactory.isPathValid = isPathValid\n\n// Fixes typescript\nfactory.default = factory\n\nmodule.exports = factory\n\n// Windows\n// --------------------------------------------------------------\n/* istanbul ignore if */\nif (\n  // Detect `process` so that it can run in browsers.\n  typeof process !== 'undefined'\n  && (\n    process.env && process.env.IGNORE_TEST_WIN32\n    || process.platform === 'win32'\n  )\n) {\n  /* eslint no-control-regex: \"off\" */\n  const makePosix = str => /^\\\\\\\\\\?\\\\/.test(str)\n  || /[\"<>|\\u0000-\\u001F]+/u.test(str)\n    ? str\n    : str.replace(/\\\\/g, '/')\n\n  checkPath.convert = makePosix\n\n  // 'C:\\\\foo'     <- 'C:\\\\foo' has been converted to 'C:/'\n  // 'd:\\\\foo'\n  const REGIX_IS_WINDOWS_PATH_ABSOLUTE = /^[a-z]:\\//i\n  checkPath.isNotRelative = path =>\n    REGIX_IS_WINDOWS_PATH_ABSOLUTE.test(path)\n    || isNotRelative(path)\n}\n","/**\n * Lien AI Code Review GitHub Action\n *\n * Entry point for the action. Orchestrates:\n * 1. Getting PR changed files\n * 2. Running complexity analysis (with delta from base branch)\n * 3. Generating AI review\n * 4. Posting comment to PR (line-specific or summary)\n */\n\nimport * as core from '@actions/core';\nimport * as fs from 'fs';\nimport { execSync } from 'child_process';\nimport collect from 'collect.js';\nimport {\n  indexCodebase,\n  VectorDB,\n  ComplexityAnalyzer,\n  loadConfig,\n  createDefaultConfig,\n  type ComplexityReport,\n  type ComplexityViolation,\n  type LienConfig,\n} from '@liendev/core';\n\nimport {\n  getPRContext,\n  getPRChangedFiles,\n  getFileContent,\n  postPRComment,\n  postPRReview,\n  getPRDiffLines,\n  createOctokit,\n  updatePRDescription,\n  type LineComment,\n  type PRContext,\n} from './github.js';\nimport { generateReview, generateLineComments, resetTokenUsage, getTokenUsage } from './openrouter.js';\nimport {\n  buildReviewPrompt,\n  buildNoViolationsMessage,\n  formatReviewComment,\n  getViolationKey,\n  buildDescriptionBadge,\n  getMetricLabel,\n  formatComplexityValue,\n  formatThresholdValue,\n} from './prompt.js';\nimport { formatDeltaValue } from './format.js';\nimport {\n  calculateDeltas,\n  calculateDeltaSummary,\n  formatDelta,\n  formatSeverityEmoji,\n  logDeltaSummary,\n  type ComplexityDelta,\n} from './delta.js';\n\ntype ReviewStyle = 'line' | 'summary';\n\n/**\n * Action configuration\n */\ninterface ActionConfig {\n  openrouterApiKey: string;\n  model: string;\n  threshold: string;\n  githubToken: string;\n  reviewStyle: ReviewStyle;\n  enableDeltaTracking: boolean;\n  baselineComplexityPath: string; // deprecated, kept for backwards compat\n}\n\n/**\n * Get action configuration from inputs\n */\nfunction getConfig(): ActionConfig {\n  const reviewStyle = core.getInput('review_style') || 'line';\n  const enableDeltaTracking = core.getInput('enable_delta_tracking') === 'true';\n  \n  return {\n    openrouterApiKey: core.getInput('openrouter_api_key', { required: true }),\n    model: core.getInput('model') || 'anthropic/claude-sonnet-4',\n    threshold: core.getInput('threshold') || '15',\n    githubToken: core.getInput('github_token') || process.env.GITHUB_TOKEN || '',\n    reviewStyle: reviewStyle === 'summary' ? 'summary' : 'line',\n    enableDeltaTracking,\n    baselineComplexityPath: core.getInput('baseline_complexity') || '',\n  };\n}\n\n/**\n * Load baseline complexity report from file\n */\nfunction loadBaselineComplexity(path: string): ComplexityReport | null {\n  if (!path) {\n    core.info('No baseline complexity path provided, skipping delta calculation');\n    return null;\n  }\n\n  try {\n    if (!fs.existsSync(path)) {\n      core.warning(`Baseline complexity file not found: ${path}`);\n      return null;\n    }\n\n    const content = fs.readFileSync(path, 'utf-8');\n    const report = JSON.parse(content) as ComplexityReport;\n    \n    if (!report.files || !report.summary) {\n      core.warning('Baseline complexity file has invalid format');\n      return null;\n    }\n\n    core.info(`Loaded baseline complexity: ${report.summary.totalViolations} violations`);\n    return report;\n  } catch (error) {\n    core.warning(`Failed to load baseline complexity: ${error}`);\n    return null;\n  }\n}\n\ntype Octokit = ReturnType<typeof createOctokit>;\ntype Config = ActionConfig;\n\n/**\n * Setup and validate PR analysis prerequisites\n */\nfunction setupPRAnalysis(): { config: Config; prContext: PRContext; octokit: Octokit } | null {\n  const config = getConfig();\n  core.info(`Using model: ${config.model}`);\n  core.info(`Complexity threshold: ${config.threshold}`);\n  core.info(`Review style: ${config.reviewStyle}`);\n\n  if (!config.githubToken) {\n    throw new Error('GitHub token is required');\n  }\n\n  const prContext = getPRContext();\n  if (!prContext) {\n    core.warning('Not running in PR context, skipping');\n    return null;\n  }\n\n  core.info(`Reviewing PR #${prContext.pullNumber}: ${prContext.title}`);\n  return { config, prContext, octokit: createOctokit(config.githubToken) };\n}\n\n/**\n * Filter files to only include those that can be analyzed\n * (excludes non-code files, vendor, node_modules, etc.)\n */\nfunction filterAnalyzableFiles(files: string[]): string[] {\n  const codeExtensions = new Set([\n    '.ts',\n    '.tsx',\n    '.js',\n    '.jsx',\n    '.py',\n    '.php',\n  ]);\n\n  const excludePatterns = [\n    /node_modules\\//,\n    /vendor\\//,\n    /dist\\//,\n    /build\\//,\n    /\\.min\\./,\n    /\\.bundle\\./,\n    /\\.generated\\./,\n    /package-lock\\.json/,\n    /yarn\\.lock/,\n    /pnpm-lock\\.yaml/,\n  ];\n\n  return files.filter((file) => {\n    // Check extension\n    const ext = file.slice(file.lastIndexOf('.'));\n    if (!codeExtensions.has(ext)) {\n      return false;\n    }\n\n    // Check exclude patterns\n    for (const pattern of excludePatterns) {\n      if (pattern.test(file)) {\n        return false;\n      }\n    }\n\n    return true;\n  });\n}\n\n/**\n * Get and filter files eligible for complexity analysis\n */\nasync function getFilesToAnalyze(octokit: Octokit, prContext: PRContext): Promise<string[]> {\n  const allChangedFiles = await getPRChangedFiles(octokit, prContext);\n  core.info(`Found ${allChangedFiles.length} changed files in PR`);\n\n  const filesToAnalyze = filterAnalyzableFiles(allChangedFiles);\n  core.info(`${filesToAnalyze.length} files eligible for complexity analysis`);\n\n  return filesToAnalyze;\n}\n\n/**\n * Run complexity analysis using @liendev/core\n */\nasync function runComplexityAnalysis(\n  files: string[],\n  threshold: string\n): Promise<ComplexityReport | null> {\n  if (files.length === 0) {\n    core.info('No files to analyze');\n    return null;\n  }\n\n  try {\n    const rootDir = process.cwd();\n    \n    // Load or create config\n    let config: LienConfig;\n    try {\n      config = await loadConfig(rootDir);\n      core.info('Loaded lien config');\n    } catch {\n      core.info('No lien config found, using defaults');\n      config = createDefaultConfig();\n    }\n    \n    // Override threshold from action input\n    const thresholdNum = parseInt(threshold, 10);\n    config.complexity = {\n      ...config.complexity,\n      enabled: true,\n      thresholds: {\n        testPaths: thresholdNum,\n        mentalLoad: thresholdNum,\n        timeToUnderstandMinutes: 60,\n        estimatedBugs: 1.5,\n        ...config.complexity?.thresholds,\n      },\n    };\n\n    // Index the codebase\n    core.info('üìÅ Indexing codebase...');\n    await indexCodebase({\n      rootDir,\n      config,\n    });\n    core.info('‚úì Indexing complete');\n\n    // Load the vector database\n    const vectorDB = await VectorDB.load(rootDir);\n\n    // Run complexity analysis\n    core.info('üîç Analyzing complexity...');\n    const analyzer = new ComplexityAnalyzer(vectorDB, config);\n    const report = await analyzer.analyze(files);\n    core.info(`‚úì Found ${report.summary.totalViolations} violations`);\n\n    return report;\n  } catch (error) {\n    core.error(`Failed to run complexity analysis: ${error}`);\n    return null;\n  }\n}\n\n/**\n * Sort violations by severity and collect code snippets\n */\nasync function prepareViolationsForReview(\n  report: ComplexityReport,\n  octokit: Octokit,\n  prContext: PRContext\n): Promise<{ violations: ComplexityViolation[]; codeSnippets: Map<string, string> }> {\n  // Collect and sort violations\n  const violations = Object.values(report.files)\n    .flatMap((fileData) => fileData.violations)\n    .sort((a, b) => {\n      if (a.severity !== b.severity) return a.severity === 'error' ? -1 : 1;\n      return b.complexity - a.complexity;\n    })\n    .slice(0, 10);\n\n  // Collect code snippets\n  const codeSnippets = new Map<string, string>();\n  for (const violation of violations) {\n    const snippet = await getFileContent(\n      octokit,\n      prContext,\n      violation.filepath,\n      violation.startLine,\n      violation.endLine\n    );\n    if (snippet) {\n      codeSnippets.set(getViolationKey(violation), snippet);\n    }\n  }\n  core.info(`Collected ${codeSnippets.size} code snippets for review`);\n\n  return { violations, codeSnippets };\n}\n\n/**\n * Analyze base branch complexity for delta tracking\n */\nasync function analyzeBaseBranch(\n  baseSha: string,\n  filesToAnalyze: string[],\n  threshold: string\n): Promise<ComplexityReport | null> {\n  try {\n    core.info(`Checking out base branch at ${baseSha.substring(0, 7)}...`);\n    \n    // Save current HEAD\n    const currentHead = execSync('git rev-parse HEAD', { encoding: 'utf-8' }).trim();\n    \n    // Checkout base branch\n    execSync(`git checkout --force ${baseSha}`, { stdio: 'pipe' });\n    core.info('‚úì Base branch checked out');\n    \n    // Analyze base\n    core.info('Analyzing base branch complexity...');\n    const baseReport = await runComplexityAnalysis(filesToAnalyze, threshold);\n    \n    // Restore HEAD\n    execSync(`git checkout --force ${currentHead}`, { stdio: 'pipe' });\n    core.info('‚úì Restored to HEAD');\n    \n    if (baseReport) {\n      core.info(`Base branch: ${baseReport.summary.totalViolations} violations`);\n    }\n    \n    return baseReport;\n  } catch (error) {\n    core.warning(`Failed to analyze base branch: ${error}`);\n    // Attempt to restore HEAD even if analysis failed\n    try {\n      const currentHead = execSync('git rev-parse HEAD', { encoding: 'utf-8' }).trim();\n      execSync(`git checkout --force ${currentHead}`, { stdio: 'pipe' });\n    } catch (restoreError) {\n      core.warning(`Failed to restore HEAD: ${restoreError}`);\n    }\n    return null;\n  }\n}\n\n/**\n * Main action logic - orchestrates the review flow\n */\nasync function run(): Promise<void> {\n  try {\n    core.info('üöÄ Starting Lien AI Code Review...');\n    core.info(`Node version: ${process.version}`);\n    core.info(`Working directory: ${process.cwd()}`);\n    \n    const setup = setupPRAnalysis();\n    if (!setup) {\n      core.info('‚ö†Ô∏è Setup returned null, exiting gracefully');\n      return;\n    }\n    const { config, prContext, octokit } = setup;\n\n    const filesToAnalyze = await getFilesToAnalyze(octokit, prContext);\n    if (filesToAnalyze.length === 0) {\n      core.info('No analyzable files found, skipping review');\n      return;\n    }\n\n    // Get baseline complexity for delta calculation\n    let baselineReport: ComplexityReport | null = null;\n    \n    if (config.enableDeltaTracking) {\n      core.info('üîÑ Delta tracking enabled - analyzing base branch...');\n      baselineReport = await analyzeBaseBranch(prContext.baseSha, filesToAnalyze, config.threshold);\n    } else if (config.baselineComplexityPath) {\n      // Backwards compatibility: support old baseline_complexity input\n      core.warning('baseline_complexity input is deprecated. Use enable_delta_tracking: true instead.');\n      baselineReport = loadBaselineComplexity(config.baselineComplexityPath);\n    }\n\n    const report = await runComplexityAnalysis(filesToAnalyze, config.threshold);\n    if (!report) {\n      core.warning('Failed to get complexity report');\n      return;\n    }\n    core.info(`Analysis complete: ${report.summary.totalViolations} violations found`);\n\n    // Calculate deltas if we have a baseline\n    const deltas = baselineReport\n      ? calculateDeltas(baselineReport, report, filesToAnalyze)\n      : null;\n\n    const deltaSummary = deltas ? calculateDeltaSummary(deltas) : null;\n\n    if (deltaSummary) {\n      logDeltaSummary(deltaSummary);\n      core.setOutput('total_delta', deltaSummary.totalDelta);\n      core.setOutput('improved', deltaSummary.improved);\n      core.setOutput('degraded', deltaSummary.degraded);\n    }\n\n    // Always update PR description with stats badge\n    const badge = buildDescriptionBadge(report, deltaSummary, deltas);\n    await updatePRDescription(octokit, prContext, badge);\n\n    if (report.summary.totalViolations === 0) {\n      core.info('No complexity violations found');\n      // Skip the regular comment - the description badge is sufficient\n      return;\n    }\n\n    const { violations, codeSnippets } = await prepareViolationsForReview(report, octokit, prContext);\n\n    resetTokenUsage();\n    if (config.reviewStyle === 'summary') {\n      await postSummaryReview(octokit, prContext, report, codeSnippets, config, false, deltas);\n    } else {\n      await postLineReview(octokit, prContext, report, violations, codeSnippets, config, deltas);\n    }\n\n    core.setOutput('violations', report.summary.totalViolations);\n    core.setOutput('errors', report.summary.bySeverity.error);\n    core.setOutput('warnings', report.summary.bySeverity.warning);\n  } catch (error) {\n    const message = error instanceof Error ? error.message : 'An unexpected error occurred';\n    const stack = error instanceof Error ? error.stack : '';\n    \n    core.error(`Action failed: ${message}`);\n    if (stack) {\n      core.error(`Stack trace:\\n${stack}`);\n    }\n    \n    core.setFailed(message);\n  }\n}\n\n/**\n * Find the best line to comment on for a violation\n * Returns startLine if it's in diff, otherwise first diff line in function range, or null\n */\nfunction findCommentLine(\n  violation: ComplexityViolation,\n  diffLines: Map<string, Set<number>>\n): number | null {\n  const fileLines = diffLines.get(violation.filepath);\n  if (!fileLines) return null;\n\n  // Prefer startLine (function declaration)\n  if (fileLines.has(violation.startLine)) {\n    return violation.startLine;\n  }\n\n  // Find first diff line within the function range\n  for (let line = violation.startLine; line <= violation.endLine; line++) {\n    if (fileLines.has(line)) {\n      return line;\n    }\n  }\n\n  return null;\n}\n\n/**\n * Create a unique key for delta lookups\n * Includes metricType since a function can have multiple metric violations\n */\nfunction createDeltaKey(v: { filepath: string; symbolName: string; metricType: string }): string {\n  return `${v.filepath}::${v.symbolName}::${v.metricType}`;\n}\n\n/**\n * Build delta lookup map from deltas array\n */\nfunction buildDeltaMap(deltas: ComplexityDelta[] | null): Map<string, ComplexityDelta> {\n  if (!deltas) return new Map();\n  \n  return new Map(\n    collect(deltas)\n      .map(d => [createDeltaKey(d), d] as [string, ComplexityDelta])\n      .all()\n  );\n}\n\n/**\n * Build line comments from violations and AI comments\n */\nfunction buildLineComments(\n  violationsWithLines: Array<{ violation: ComplexityViolation; commentLine: number }>,\n  aiComments: Map<ComplexityViolation, string>,\n  deltaMap: Map<string, ComplexityDelta>\n): LineComment[] {\n  return collect(violationsWithLines)\n    .filter(({ violation }) => aiComments.has(violation))\n    .map(({ violation, commentLine }) => {\n      const comment = aiComments.get(violation)!;\n      const delta = deltaMap.get(createDeltaKey(violation));\n      const deltaStr = delta ? ` (${formatDelta(delta.delta)})` : '';\n      const severityEmoji = delta \n        ? formatSeverityEmoji(delta.severity)\n        : (violation.severity === 'error' ? 'üî¥' : 'üü°');\n      \n      // If comment is not on symbol's starting line, note where it actually starts\n      const lineNote = commentLine !== violation.startLine \n        ? ` *(\\`${violation.symbolName}\\` starts at line ${violation.startLine})*`\n        : '';\n      \n      // Format human-friendly complexity display\n      const metricLabel = getMetricLabel(violation.metricType || 'cyclomatic');\n      const valueDisplay = formatComplexityValue(violation.metricType || 'cyclomatic', violation.complexity);\n      const thresholdDisplay = formatThresholdValue(violation.metricType || 'cyclomatic', violation.threshold);\n      \n      core.info(`Adding comment for ${violation.filepath}:${commentLine} (${violation.symbolName})${deltaStr}`);\n      \n      return {\n        path: violation.filepath,\n        line: commentLine,\n        body: `${severityEmoji} **${metricLabel.charAt(0).toUpperCase() + metricLabel.slice(1)}: ${valueDisplay}**${deltaStr} (threshold: ${thresholdDisplay})${lineNote}\\n\\n${comment}`,\n      };\n    })\n    .all() as LineComment[];\n}\n\n/**\n * Get emoji for metric type\n */\nfunction getMetricEmoji(metricType: string): string {\n  switch (metricType) {\n    case 'cyclomatic': return 'üîÄ';\n    case 'cognitive': return 'üß†';\n    case 'halstead_effort': return '‚è±Ô∏è';\n    case 'halstead_bugs': return 'üêõ';\n    default: return 'üìä';\n  }\n}\n\n/**\n * Build uncovered violations note for summary\n */\nfunction buildUncoveredNote(\n  uncoveredViolations: ComplexityViolation[],\n  deltaMap: Map<string, ComplexityDelta>\n): string {\n  if (uncoveredViolations.length === 0) return '';\n\n  const uncoveredList = uncoveredViolations\n    .map(v => {\n      const delta = deltaMap.get(createDeltaKey(v));\n      const deltaStr = delta ? ` (${formatDelta(delta.delta)})` : '';\n      const emoji = getMetricEmoji(v.metricType);\n      const metricLabel = getMetricLabel(v.metricType || 'cyclomatic');\n      const valueDisplay = formatComplexityValue(v.metricType || 'cyclomatic', v.complexity);\n      return `* \\`${v.symbolName}\\` in \\`${v.filepath}\\`: ${emoji} ${metricLabel} ${valueDisplay}${deltaStr}`;\n    })\n    .join('\\n');\n\n  return `\\n\\n<details>\\n<summary>‚ö†Ô∏è ${uncoveredViolations.length} violation${uncoveredViolations.length === 1 ? '' : 's'} outside diff (no inline comment)</summary>\\n\\n${uncoveredList}\\n\\n> üí° *These exist in files touched by this PR but the function declarations aren't in the diff. Consider the [boy scout rule](https://www.oreilly.com/library/view/97-things-every/9780596809515/ch08.html)!*\\n\\n</details>`;\n}\n\n/**\n * Build note for skipped pre-existing violations (no inline comment, no LLM cost)\n */\nfunction buildSkippedNote(skippedViolations: ComplexityViolation[]): string {\n  if (skippedViolations.length === 0) return '';\n\n  const skippedList = skippedViolations\n    .map(v => `  - \\`${v.symbolName}\\` in \\`${v.filepath}\\`: complexity ${v.complexity}`)\n    .join('\\n');\n\n  return `\\n\\n<details>\\n<summary>‚ÑπÔ∏è ${skippedViolations.length} pre-existing violation${skippedViolations.length === 1 ? '' : 's'} (unchanged)</summary>\\n\\n${skippedList}\\n\\n> *These violations existed before this PR and haven't changed. No inline comments added to reduce noise.*\\n\\n</details>`;\n}\n\n/**\n * Format token usage cost display\n */\nfunction formatCostDisplay(usage: { totalTokens: number; cost: number }): string {\n  return usage.totalTokens > 0\n    ? `\\n- Tokens: ${usage.totalTokens.toLocaleString()} ($${usage.cost.toFixed(4)})`\n    : '';\n}\n\n/**\n * Group deltas by metric type and sum their values\n */\nfunction groupDeltasByMetric(deltas: ComplexityDelta[]): Record<string, number> {\n  // Note: collect.js groupBy returns groups needing sum() - types are limited\n  return collect(deltas)\n    .groupBy('metricType')\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    .map((group: any) => group.sum('delta'))\n    .all() as unknown as Record<string, number>;\n}\n\n/**\n * Build metric breakdown string with emojis\n */\nfunction buildMetricBreakdown(deltaByMetric: Record<string, number>): string {\n  const metricOrder = ['cyclomatic', 'cognitive', 'halstead_effort', 'halstead_bugs'];\n  return collect(metricOrder)\n    .map(metricType => {\n      const metricDelta = deltaByMetric[metricType] || 0;\n      const emoji = getMetricEmoji(metricType);\n      const sign = metricDelta >= 0 ? '+' : '';\n      return `${emoji} ${sign}${formatDeltaValue(metricType, metricDelta)}`;\n    })\n    .all()\n    .join(' | ');\n}\n\n/**\n * Format delta display with metric breakdown and summary\n */\nfunction formatDeltaDisplay(deltas: ComplexityDelta[] | null): string {\n  if (!deltas || deltas.length === 0) return '';\n\n  const deltaSummary = calculateDeltaSummary(deltas);\n  const deltaByMetric = groupDeltasByMetric(deltas);\n  const metricBreakdown = buildMetricBreakdown(deltaByMetric);\n  const trend = deltaSummary.totalDelta > 0 ? '‚¨ÜÔ∏è' : deltaSummary.totalDelta < 0 ? '‚¨áÔ∏è' : '‚û°Ô∏è';\n\n  let display = `\\n\\n**Complexity Change:** ${metricBreakdown} ${trend}`;\n  if (deltaSummary.improved > 0) display += ` (${deltaSummary.improved} improved)`;\n  if (deltaSummary.degraded > 0) display += ` (${deltaSummary.degraded} degraded)`;\n  return display;\n}\n\n/**\n * Build review summary body for line comments mode\n */\nfunction buildReviewSummary(\n  report: ComplexityReport,\n  deltas: ComplexityDelta[] | null,\n  uncoveredNote: string\n): string {\n  const { summary } = report;\n  const costDisplay = formatCostDisplay(getTokenUsage());\n  const deltaDisplay = formatDeltaDisplay(deltas);\n\n  return `<!-- lien-ai-review -->\n## üëÅÔ∏è Veille\n\n${summary.totalViolations} issue${summary.totalViolations === 1 ? '' : 's'} spotted in this PR.${deltaDisplay}\n\nSee inline comments on the diff for specific suggestions.${uncoveredNote}\n\n<details>\n<summary>üìä Analysis Details</summary>\n\n- Files analyzed: ${summary.filesAnalyzed}\n- Average complexity: ${summary.avgComplexity.toFixed(1)}\n- Max complexity: ${summary.maxComplexity}${costDisplay}\n\n</details>\n\n*[Veille](https://lien.dev) by Lien*`;\n}\n\n/**\n * Post review with line-specific comments for all violations\n */\nasync function postLineReview(\n  octokit: ReturnType<typeof createOctokit>,\n  prContext: PRContext,\n  report: ComplexityReport,\n  violations: ComplexityViolation[],\n  codeSnippets: Map<string, string>,\n  config: ActionConfig,\n  deltas: ComplexityDelta[] | null = null\n): Promise<void> {\n  const diffLines = await getPRDiffLines(octokit, prContext);\n  core.info(`Diff covers ${diffLines.size} files`);\n\n  // Partition violations into those we can comment on and those we can't\n  const violationsWithLines: Array<{ violation: ComplexityViolation; commentLine: number }> = [];\n  const uncoveredViolations: ComplexityViolation[] = [];\n\n  for (const v of violations) {\n    const commentLine = findCommentLine(v, diffLines);\n    if (commentLine !== null) {\n      violationsWithLines.push({ violation: v, commentLine });\n    } else {\n      uncoveredViolations.push(v);\n    }\n  }\n\n  core.info(\n    `${violationsWithLines.length}/${violations.length} violations can have inline comments ` +\n    `(${uncoveredViolations.length} outside diff)`\n  );\n\n  const deltaMap = buildDeltaMap(deltas);\n\n  // Filter to only new or degraded violations (skip unchanged pre-existing ones)\n  // This saves LLM costs and prevents duplicate comments on each push\n  const newOrDegradedViolations = violationsWithLines.filter(({ violation }) => {\n    const key = createDeltaKey(violation);\n    const delta = deltaMap.get(key);\n    // Comment if: no baseline data, or new violation, or got worse\n    return !delta || delta.severity === 'new' || delta.delta > 0;\n  });\n\n  const skippedCount = violationsWithLines.length - newOrDegradedViolations.length;\n  if (skippedCount > 0) {\n    core.info(`Skipping ${skippedCount} unchanged pre-existing violations (no LLM calls needed)`);\n  }\n\n  if (newOrDegradedViolations.length === 0) {\n    core.info('No new or degraded violations to comment on');\n    // Still post a summary if there are violations, just no inline comments needed\n    if (violationsWithLines.length > 0) {\n      // Only include actual uncovered violations (outside diff)\n      const uncoveredNote = buildUncoveredNote(uncoveredViolations, deltaMap);\n      // Build skipped note for unchanged violations in the diff (not \"outside diff\")\n      const skippedInDiff = violationsWithLines\n        .filter(({ violation }) => {\n          const key = createDeltaKey(violation);\n          const delta = deltaMap.get(key);\n          return delta && delta.severity !== 'new' && delta.delta === 0;\n        })\n        .map(v => v.violation);\n      const skippedNote = buildSkippedNote(skippedInDiff);\n      const summaryBody = buildReviewSummary(report, deltas, uncoveredNote + skippedNote);\n      await postPRComment(octokit, prContext, summaryBody);\n    }\n    return;\n  }\n\n  // Generate AI comments only for new/degraded violations\n  const commentableViolations = newOrDegradedViolations.map(v => v.violation);\n  core.info(`Generating AI comments for ${commentableViolations.length} new/degraded violations...`);\n  const aiComments = await generateLineComments(\n    commentableViolations,\n    codeSnippets,\n    config.openrouterApiKey,\n    config.model\n  );\n\n  // Build and post review (only for new/degraded)\n  const lineComments = buildLineComments(newOrDegradedViolations, aiComments, deltaMap);\n  core.info(`Built ${lineComments.length} line comments for new/degraded violations`);\n\n  // Include skipped (pre-existing unchanged) violations in skipped note\n  // Note: delta === 0 means truly unchanged; delta < 0 means improved (not \"unchanged\")\n  const skippedViolations = violationsWithLines\n    .filter(({ violation }) => {\n      const key = createDeltaKey(violation);\n      const delta = deltaMap.get(key);\n      return delta && delta.severity !== 'new' && delta.delta === 0;\n    })\n    .map(v => v.violation);\n\n  const uncoveredNote = buildUncoveredNote(uncoveredViolations, deltaMap);\n  const skippedNote = buildSkippedNote(skippedViolations);\n  const summaryBody = buildReviewSummary(report, deltas, uncoveredNote + skippedNote);\n\n  await postPRReview(octokit, prContext, lineComments, summaryBody);\n  core.info(`Posted review with ${lineComments.length} line comments`);\n}\n\n/**\n * Post review as a single summary comment\n * @param isFallback - true if this is a fallback because violations aren't on diff lines\n * @param deltas - complexity deltas for delta display\n */\nasync function postSummaryReview(\n  octokit: ReturnType<typeof createOctokit>,\n  prContext: PRContext,\n  report: ComplexityReport,\n  codeSnippets: Map<string, string>,\n  config: ActionConfig,\n  isFallback = false,\n  deltas: ComplexityDelta[] | null = null\n): Promise<void> {\n  const prompt = buildReviewPrompt(report, prContext, codeSnippets, deltas);\n  core.debug(`Prompt length: ${prompt.length} characters`);\n\n  const aiReview = await generateReview(\n    prompt,\n    config.openrouterApiKey,\n    config.model\n  );\n\n  const usage = getTokenUsage();\n  const comment = formatReviewComment(aiReview, report, isFallback, usage, deltas);\n  await postPRComment(octokit, prContext, comment);\n  core.info('Successfully posted AI review summary comment');\n}\n\n// Run the action\nrun().catch((error) => {\n  core.setFailed(error instanceof Error ? error.message : String(error));\n  process.exit(1);\n});\n","/**\n * Core indexing module - programmatic API without CLI dependencies.\n * \n * This module provides the core indexing functionality that can be used by:\n * - @liendev/cli (with UI wrapper)\n * - @liendev/action (directly)\n * - @liendev/cloud (worker processes)\n * - Third-party integrations\n */\n\nimport fs from 'fs/promises';\nimport pLimit from 'p-limit';\nimport { scanCodebase, scanCodebaseWithFrameworks } from './scanner.js';\nimport { chunkFile } from './chunker.js';\nimport { LocalEmbeddings } from '../embeddings/local.js';\nimport { VectorDB } from '../vectordb/lancedb.js';\nimport { configService } from '../config/service.js';\nimport { writeVersionFile } from '../vectordb/version.js';\nimport { isLegacyConfig, isModernConfig, type LienConfig, type LegacyLienConfig } from '../config/schema.js';\nimport { ManifestManager } from './manifest.js';\nimport { isGitAvailable, isGitRepo } from '../git/utils.js';\nimport { GitStateTracker } from '../git/tracker.js';\nimport { detectChanges } from './change-detector.js';\nimport { indexMultipleFiles } from './incremental.js';\nimport type { EmbeddingService } from '../embeddings/types.js';\nimport { ChunkBatchProcessor } from './chunk-batch-processor.js';\n\n/**\n * Options for indexing a codebase\n */\nexport interface IndexingOptions {\n  /** Root directory to index (defaults to cwd) */\n  rootDir?: string;\n  /** Show verbose output */\n  verbose?: boolean;\n  /** Force full reindex, skip incremental */\n  force?: boolean;\n  /** Pre-initialized embedding service (for warm workers) */\n  embeddings?: EmbeddingService;\n  /** Pre-loaded config (skip loading from disk) */\n  config?: LienConfig;\n  /** Progress callback for external UI */\n  onProgress?: (progress: IndexingProgress) => void;\n}\n\n/**\n * Progress information during indexing\n */\nexport interface IndexingProgress {\n  phase: 'initializing' | 'scanning' | 'embedding' | 'indexing' | 'saving' | 'complete';\n  message: string;\n  filesTotal?: number;\n  filesProcessed?: number;\n  chunksProcessed?: number;\n}\n\n/**\n * Result of indexing operation\n */\nexport interface IndexingResult {\n  success: boolean;\n  filesIndexed: number;\n  chunksCreated: number;\n  durationMs: number;\n  incremental: boolean;\n  error?: string;\n}\n\n/** Extracted config values with defaults for indexing */\ninterface IndexingConfig {\n  concurrency: number;\n  embeddingBatchSize: number;\n  chunkSize: number;\n  chunkOverlap: number;\n  useAST: boolean;\n  astFallback: 'line-based' | 'error';\n}\n\n/** Extract indexing config values with defaults */\nfunction getIndexingConfig(config: LienConfig | LegacyLienConfig): IndexingConfig {\n  if (isModernConfig(config)) {\n    return {\n      concurrency: config.core.concurrency,\n      embeddingBatchSize: config.core.embeddingBatchSize,\n      chunkSize: config.core.chunkSize,\n      chunkOverlap: config.core.chunkOverlap,\n      useAST: config.chunking.useAST,\n      astFallback: config.chunking.astFallback,\n    };\n  }\n  // Legacy defaults\n  return {\n    concurrency: 4,\n    embeddingBatchSize: 50,\n    chunkSize: 75,\n    chunkOverlap: 10,\n    useAST: true,\n    astFallback: 'line-based',\n  };\n}\n\n/** Scan files based on config type */\nasync function scanFilesToIndex(\n  rootDir: string,\n  config: LienConfig | LegacyLienConfig\n): Promise<string[]> {\n  if (isModernConfig(config) && config.frameworks.length > 0) {\n    return scanCodebaseWithFrameworks(rootDir, config);\n  }\n  if (isLegacyConfig(config)) {\n    return scanCodebase({\n      rootDir,\n      includePatterns: config.indexing.include,\n      excludePatterns: config.indexing.exclude,\n    });\n  }\n  return scanCodebase({ rootDir, includePatterns: [], excludePatterns: [] });\n}\n\n/**\n * Update git state after indexing (if in a git repo).\n */\nasync function updateGitState(\n  rootDir: string,\n  vectorDB: VectorDB,\n  manifest: ManifestManager\n): Promise<void> {\n  const gitAvailable = await isGitAvailable();\n  const isRepo = await isGitRepo(rootDir);\n  \n  if (!gitAvailable || !isRepo) {\n    return;\n  }\n  \n  const gitTracker = new GitStateTracker(rootDir, vectorDB.dbPath);\n  await gitTracker.initialize();\n  const gitState = gitTracker.getState();\n  \n  if (gitState) {\n    await manifest.updateGitState(gitState);\n  }\n}\n\n/**\n * Handle file deletions during incremental indexing.\n */\nasync function handleDeletions(\n  deletedFiles: string[],\n  vectorDB: VectorDB,\n  manifest: ManifestManager\n): Promise<number> {\n  if (deletedFiles.length === 0) {\n    return 0;\n  }\n  \n  let removedCount = 0;\n  \n  for (const filepath of deletedFiles) {\n    try {\n      await vectorDB.deleteByFile(filepath);\n      await manifest.removeFile(filepath);\n      removedCount++;\n    } catch {\n      // Continue on error, just count failures\n    }\n  }\n  \n  return removedCount;\n}\n\n/**\n * Handle file updates (additions and modifications) during incremental indexing.\n */\nasync function handleUpdates(\n  addedFiles: string[],\n  modifiedFiles: string[],\n  vectorDB: VectorDB,\n  embeddings: EmbeddingService,\n  config: LienConfig | LegacyLienConfig,\n  options: IndexingOptions\n): Promise<number> {\n  const filesToIndex = [...addedFiles, ...modifiedFiles];\n  \n  if (filesToIndex.length === 0) {\n    return 0;\n  }\n  \n  const count = await indexMultipleFiles(\n    filesToIndex,\n    vectorDB,\n    embeddings,\n    config,\n    { verbose: options.verbose }\n  );\n  \n  await writeVersionFile(vectorDB.dbPath);\n  return count;\n}\n\n/**\n * Try incremental indexing if a manifest exists.\n * Returns result if incremental completed, null if full index needed.\n */\nasync function tryIncrementalIndex(\n  rootDir: string,\n  vectorDB: VectorDB,\n  config: LienConfig | LegacyLienConfig,\n  options: IndexingOptions,\n  startTime: number\n): Promise<IndexingResult | null> {\n  const manifest = new ManifestManager(vectorDB.dbPath);\n  const savedManifest = await manifest.load();\n  \n  if (!savedManifest) {\n    return null; // No manifest, need full index\n  }\n  \n  const changes = await detectChanges(rootDir, vectorDB, config);\n  \n  if (changes.reason === 'full') {\n    return null;\n  }\n  \n  const totalChanges = changes.added.length + changes.modified.length;\n  const totalDeleted = changes.deleted.length;\n  \n  if (totalChanges === 0 && totalDeleted === 0) {\n    options.onProgress?.({\n      phase: 'complete',\n      message: 'Index is up to date - no changes detected',\n      filesTotal: 0,\n      filesProcessed: 0,\n    });\n    return {\n      success: true,\n      filesIndexed: 0,\n      chunksCreated: 0,\n      durationMs: Date.now() - startTime,\n      incremental: true,\n    };\n  }\n  \n  options.onProgress?.({\n    phase: 'embedding',\n    message: `Detected ${totalChanges} files to index, ${totalDeleted} to remove`,\n  });\n  \n  // Initialize embeddings for incremental update\n  const embeddings = options.embeddings ?? new LocalEmbeddings();\n  if (!options.embeddings) {\n    await embeddings.initialize();\n  }\n  \n  // Process changes\n  await handleDeletions(changes.deleted, vectorDB, manifest);\n  const indexedCount = await handleUpdates(\n    changes.added,\n    changes.modified,\n    vectorDB,\n    embeddings,\n    config,\n    options\n  );\n  \n  // Update git state\n  await updateGitState(rootDir, vectorDB, manifest);\n  \n  options.onProgress?.({\n    phase: 'complete',\n    message: `Updated ${indexedCount} file${indexedCount !== 1 ? 's' : ''}, removed ${totalDeleted}`,\n    filesTotal: totalChanges + totalDeleted,\n    filesProcessed: indexedCount + totalDeleted,\n  });\n  \n  return {\n    success: true,\n    filesIndexed: indexedCount,\n    chunksCreated: 0, // Not tracked in incremental mode\n    durationMs: Date.now() - startTime,\n    incremental: true,\n  };\n}\n\n/**\n * Process a single file for indexing.\n * Extracts chunks and adds them to the batch processor.\n *\n * @returns true if file was processed successfully, false if skipped\n */\nasync function processFileForIndexing(\n  file: string,\n  batchProcessor: ChunkBatchProcessor,\n  indexConfig: IndexingConfig,\n  progressTracker: { incrementFiles: () => void },\n  _verbose: boolean\n): Promise<boolean> {\n  try {\n    // Get file stats to capture actual modification time\n    const stats = await fs.stat(file);\n    const content = await fs.readFile(file, 'utf-8');\n\n    const chunks = chunkFile(file, content, {\n      chunkSize: indexConfig.chunkSize,\n      chunkOverlap: indexConfig.chunkOverlap,\n      useAST: indexConfig.useAST,\n      astFallback: indexConfig.astFallback,\n    });\n\n    if (chunks.length === 0) {\n      progressTracker.incrementFiles();\n      return false;\n    }\n\n    // Add chunks to batch processor (handles mutex internally)\n    await batchProcessor.addChunks(chunks, file, stats.mtimeMs);\n    progressTracker.incrementFiles();\n\n    return true;\n  } catch {\n    progressTracker.incrementFiles();\n    return false;\n  }\n}\n\n/**\n * Perform a full index of the codebase.\n */\nasync function performFullIndex(\n  rootDir: string,\n  vectorDB: VectorDB,\n  config: LienConfig | LegacyLienConfig,\n  options: IndexingOptions,\n  startTime: number\n): Promise<IndexingResult> {\n  // 1. Clear existing index (required for schema changes)\n  options.onProgress?.({ phase: 'initializing', message: 'Clearing existing index...' });\n  await vectorDB.clear();\n\n  // 2. Scan for files\n  options.onProgress?.({ phase: 'scanning', message: 'Scanning codebase...' });\n  const files = await scanFilesToIndex(rootDir, config);\n\n  if (files.length === 0) {\n    return {\n      success: false,\n      filesIndexed: 0,\n      chunksCreated: 0,\n      durationMs: Date.now() - startTime,\n      incremental: false,\n      error: 'No files found to index',\n    };\n  }\n\n  // 3. Initialize embeddings model\n  options.onProgress?.({ \n    phase: 'embedding', \n    message: 'Loading embedding model...',\n    filesTotal: files.length,\n  });\n  \n  const embeddings = options.embeddings ?? new LocalEmbeddings();\n  if (!options.embeddings) {\n    await embeddings.initialize();\n  }\n\n  // 4. Setup processing infrastructure\n  const indexConfig = getIndexingConfig(config);\n  const processedCount = { value: 0 };\n  \n  // Create a simple progress tracker that works with callbacks\n  const progressTracker = {\n    incrementFiles: () => {\n      processedCount.value++;\n      options.onProgress?.({\n        phase: 'indexing',\n        message: `Processing files...`,\n        filesTotal: files.length,\n        filesProcessed: processedCount.value,\n      });\n    },\n    incrementChunks: () => {},\n    getProcessedCount: () => processedCount.value,\n    start: () => {},\n    stop: () => {},\n  };\n  \n  const batchProcessor = new ChunkBatchProcessor(vectorDB, embeddings, {\n    batchThreshold: 100,\n    embeddingBatchSize: indexConfig.embeddingBatchSize,\n  }, progressTracker);\n\n  options.onProgress?.({ \n    phase: 'indexing', \n    message: `Processing ${files.length} files...`,\n    filesTotal: files.length,\n    filesProcessed: 0,\n  });\n\n  try {\n    // 5. Process files with concurrency limit\n    const limit = pLimit(indexConfig.concurrency);\n    const filePromises = files.map(file =>\n      limit(() => processFileForIndexing(\n        file,\n        batchProcessor,\n        indexConfig,\n        progressTracker,\n        options.verbose ?? false\n      ))\n    );\n\n    await Promise.all(filePromises);\n\n    // 6. Flush remaining chunks\n    await batchProcessor.flush();\n  } catch (error) {\n    return {\n      success: false,\n      filesIndexed: processedCount.value,\n      chunksCreated: 0,\n      durationMs: Date.now() - startTime,\n      incremental: false,\n      error: error instanceof Error ? error.message : String(error),\n    };\n  }\n\n  // 7. Save results\n  options.onProgress?.({ phase: 'saving', message: 'Saving index manifest...' });\n  const { processedChunks, indexedFiles } = batchProcessor.getResults();\n  \n  const manifest = new ManifestManager(vectorDB.dbPath);\n  await manifest.updateFiles(\n    indexedFiles.map(entry => ({\n      filepath: entry.filepath,\n      lastModified: entry.mtime,\n      chunkCount: entry.chunkCount,\n    }))\n  );\n\n  // Save git state if in a git repo\n  await updateGitState(rootDir, vectorDB, manifest);\n\n  // Write version file to mark successful completion\n  await writeVersionFile(vectorDB.dbPath);\n\n  options.onProgress?.({ \n    phase: 'complete', \n    message: 'Indexing complete',\n    filesTotal: files.length,\n    filesProcessed: processedCount.value,\n    chunksProcessed: processedChunks,\n  });\n\n  return {\n    success: true,\n    filesIndexed: processedCount.value,\n    chunksCreated: processedChunks,\n    durationMs: Date.now() - startTime,\n    incremental: false,\n  };\n}\n\n/**\n * Index a codebase, creating vector embeddings for semantic search.\n * \n * This is the main entry point for indexing. It:\n * - Tries incremental indexing first (if not forced)\n * - Falls back to full indexing if needed\n * - Provides progress callbacks for UI integration\n * \n * @param options - Indexing options\n * @returns Indexing result with stats\n * \n * @example\n * ```typescript\n * // Basic usage\n * const result = await indexCodebase({ rootDir: '/path/to/project' });\n * \n * // With progress callback\n * const result = await indexCodebase({\n *   rootDir: '/path/to/project',\n *   onProgress: (p) => console.log(`${p.phase}: ${p.message}`)\n * });\n * \n * // With pre-initialized embeddings (warm worker)\n * const embeddings = new LocalEmbeddings();\n * await embeddings.initialize();\n * const result = await indexCodebase({ embeddings });\n * ```\n */\nexport async function indexCodebase(options: IndexingOptions = {}): Promise<IndexingResult> {\n  const rootDir = options.rootDir ?? process.cwd();\n  const startTime = Date.now();\n  \n  try {\n    options.onProgress?.({ phase: 'initializing', message: 'Loading configuration...' });\n    \n    // Load configuration\n    const config = options.config ?? await configService.load(rootDir);\n    \n    // Initialize vector database\n    options.onProgress?.({ phase: 'initializing', message: 'Initializing vector database...' });\n    const vectorDB = new VectorDB(rootDir);\n    await vectorDB.initialize();\n    \n    // Try incremental indexing first (unless forced)\n    if (!options.force) {\n      const incrementalResult = await tryIncrementalIndex(rootDir, vectorDB, config, options, startTime);\n      if (incrementalResult) {\n        return incrementalResult;\n      }\n    }\n    \n    // Fall back to full index\n    return await performFullIndex(rootDir, vectorDB, config, options, startTime);\n    \n  } catch (error) {\n    return {\n      success: false,\n      filesIndexed: 0,\n      chunksCreated: 0,\n      durationMs: Date.now() - startTime,\n      incremental: false,\n      error: error instanceof Error ? error.message : String(error),\n    };\n  }\n}\n\n// Re-export types for convenience\nexport type { FileIndexEntry } from './chunk-batch-processor.js';\n","/*\nHow it works:\n`this.#head` is an instance of `Node` which keeps track of its current value and nests another instance of `Node` that keeps the value that comes after it. When a value is provided to `.enqueue()`, the code needs to iterate through `this.#head`, going deeper and deeper to find the last value. However, iterating through every single item is slow. This problem is solved by saving a reference to the last value as `this.#tail` so that it can reference it to add a new value.\n*/\n\nclass Node {\n\tvalue;\n\tnext;\n\n\tconstructor(value) {\n\t\tthis.value = value;\n\t}\n}\n\nexport default class Queue {\n\t#head;\n\t#tail;\n\t#size;\n\n\tconstructor() {\n\t\tthis.clear();\n\t}\n\n\tenqueue(value) {\n\t\tconst node = new Node(value);\n\n\t\tif (this.#head) {\n\t\t\tthis.#tail.next = node;\n\t\t\tthis.#tail = node;\n\t\t} else {\n\t\t\tthis.#head = node;\n\t\t\tthis.#tail = node;\n\t\t}\n\n\t\tthis.#size++;\n\t}\n\n\tdequeue() {\n\t\tconst current = this.#head;\n\t\tif (!current) {\n\t\t\treturn;\n\t\t}\n\n\t\tthis.#head = this.#head.next;\n\t\tthis.#size--;\n\n\t\t// Clean up tail reference when queue becomes empty\n\t\tif (!this.#head) {\n\t\t\tthis.#tail = undefined;\n\t\t}\n\n\t\treturn current.value;\n\t}\n\n\tpeek() {\n\t\tif (!this.#head) {\n\t\t\treturn;\n\t\t}\n\n\t\treturn this.#head.value;\n\n\t\t// TODO: Node.js 18.\n\t\t// return this.#head?.value;\n\t}\n\n\tclear() {\n\t\tthis.#head = undefined;\n\t\tthis.#tail = undefined;\n\t\tthis.#size = 0;\n\t}\n\n\tget size() {\n\t\treturn this.#size;\n\t}\n\n\t* [Symbol.iterator]() {\n\t\tlet current = this.#head;\n\n\t\twhile (current) {\n\t\t\tyield current.value;\n\t\t\tcurrent = current.next;\n\t\t}\n\t}\n\n\t* drain() {\n\t\twhile (this.#head) {\n\t\t\tyield this.dequeue();\n\t\t}\n\t}\n}\n","import Queue from 'yocto-queue';\nimport {AsyncResource} from '#async_hooks';\n\nexport default function pLimit(concurrency) {\n\tif (!((Number.isInteger(concurrency) || concurrency === Number.POSITIVE_INFINITY) && concurrency > 0)) {\n\t\tthrow new TypeError('Expected `concurrency` to be a number from 1 and up');\n\t}\n\n\tconst queue = new Queue();\n\tlet activeCount = 0;\n\n\tconst next = () => {\n\t\tactiveCount--;\n\n\t\tif (queue.size > 0) {\n\t\t\tqueue.dequeue()();\n\t\t}\n\t};\n\n\tconst run = async (function_, resolve, arguments_) => {\n\t\tactiveCount++;\n\n\t\tconst result = (async () => function_(...arguments_))();\n\n\t\tresolve(result);\n\n\t\ttry {\n\t\t\tawait result;\n\t\t} catch {}\n\n\t\tnext();\n\t};\n\n\tconst enqueue = (function_, resolve, arguments_) => {\n\t\tqueue.enqueue(\n\t\t\tAsyncResource.bind(run.bind(undefined, function_, resolve, arguments_)),\n\t\t);\n\n\t\t(async () => {\n\t\t\t// This function needs to wait until the next microtask before comparing\n\t\t\t// `activeCount` to `concurrency`, because `activeCount` is updated asynchronously\n\t\t\t// when the run function is dequeued and called. The comparison in the if-statement\n\t\t\t// needs to happen asynchronously as well to get an up-to-date value for `activeCount`.\n\t\t\tawait Promise.resolve();\n\n\t\t\tif (activeCount < concurrency && queue.size > 0) {\n\t\t\t\tqueue.dequeue()();\n\t\t\t}\n\t\t})();\n\t};\n\n\tconst generator = (function_, ...arguments_) => new Promise(resolve => {\n\t\tenqueue(function_, resolve, arguments_);\n\t});\n\n\tObject.defineProperties(generator, {\n\t\tactiveCount: {\n\t\t\tget: () => activeCount,\n\t\t},\n\t\tpendingCount: {\n\t\t\tget: () => queue.size,\n\t\t},\n\t\tclearQueue: {\n\t\t\tvalue() {\n\t\t\t\tqueue.clear();\n\t\t\t},\n\t\t},\n\t});\n\n\treturn generator;\n}\n","import expand from 'brace-expansion'\nimport { assertValidPattern } from './assert-valid-pattern.js'\nimport { AST, ExtglobType } from './ast.js'\nimport { escape } from './escape.js'\nimport { unescape } from './unescape.js'\n\ntype Platform =\n  | 'aix'\n  | 'android'\n  | 'darwin'\n  | 'freebsd'\n  | 'haiku'\n  | 'linux'\n  | 'openbsd'\n  | 'sunos'\n  | 'win32'\n  | 'cygwin'\n  | 'netbsd'\n\nexport interface MinimatchOptions {\n  nobrace?: boolean\n  nocomment?: boolean\n  nonegate?: boolean\n  debug?: boolean\n  noglobstar?: boolean\n  noext?: boolean\n  nonull?: boolean\n  windowsPathsNoEscape?: boolean\n  allowWindowsEscape?: boolean\n  partial?: boolean\n  dot?: boolean\n  nocase?: boolean\n  nocaseMagicOnly?: boolean\n  magicalBraces?: boolean\n  matchBase?: boolean\n  flipNegate?: boolean\n  preserveMultipleSlashes?: boolean\n  optimizationLevel?: number\n  platform?: Platform\n  windowsNoMagicRoot?: boolean\n}\n\nexport const minimatch = (\n  p: string,\n  pattern: string,\n  options: MinimatchOptions = {}\n) => {\n  assertValidPattern(pattern)\n\n  // shortcut: comments match nothing.\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    return false\n  }\n\n  return new Minimatch(pattern, options).match(p)\n}\n\n// Optimized checking for the most common glob patterns.\nconst starDotExtRE = /^\\*+([^+@!?\\*\\[\\(]*)$/\nconst starDotExtTest = (ext: string) => (f: string) =>\n  !f.startsWith('.') && f.endsWith(ext)\nconst starDotExtTestDot = (ext: string) => (f: string) => f.endsWith(ext)\nconst starDotExtTestNocase = (ext: string) => {\n  ext = ext.toLowerCase()\n  return (f: string) => !f.startsWith('.') && f.toLowerCase().endsWith(ext)\n}\nconst starDotExtTestNocaseDot = (ext: string) => {\n  ext = ext.toLowerCase()\n  return (f: string) => f.toLowerCase().endsWith(ext)\n}\nconst starDotStarRE = /^\\*+\\.\\*+$/\nconst starDotStarTest = (f: string) => !f.startsWith('.') && f.includes('.')\nconst starDotStarTestDot = (f: string) =>\n  f !== '.' && f !== '..' && f.includes('.')\nconst dotStarRE = /^\\.\\*+$/\nconst dotStarTest = (f: string) => f !== '.' && f !== '..' && f.startsWith('.')\nconst starRE = /^\\*+$/\nconst starTest = (f: string) => f.length !== 0 && !f.startsWith('.')\nconst starTestDot = (f: string) => f.length !== 0 && f !== '.' && f !== '..'\nconst qmarksRE = /^\\?+([^+@!?\\*\\[\\(]*)?$/\nconst qmarksTestNocase = ([$0, ext = '']: RegExpMatchArray) => {\n  const noext = qmarksTestNoExt([$0])\n  if (!ext) return noext\n  ext = ext.toLowerCase()\n  return (f: string) => noext(f) && f.toLowerCase().endsWith(ext)\n}\nconst qmarksTestNocaseDot = ([$0, ext = '']: RegExpMatchArray) => {\n  const noext = qmarksTestNoExtDot([$0])\n  if (!ext) return noext\n  ext = ext.toLowerCase()\n  return (f: string) => noext(f) && f.toLowerCase().endsWith(ext)\n}\nconst qmarksTestDot = ([$0, ext = '']: RegExpMatchArray) => {\n  const noext = qmarksTestNoExtDot([$0])\n  return !ext ? noext : (f: string) => noext(f) && f.endsWith(ext)\n}\nconst qmarksTest = ([$0, ext = '']: RegExpMatchArray) => {\n  const noext = qmarksTestNoExt([$0])\n  return !ext ? noext : (f: string) => noext(f) && f.endsWith(ext)\n}\nconst qmarksTestNoExt = ([$0]: RegExpMatchArray) => {\n  const len = $0.length\n  return (f: string) => f.length === len && !f.startsWith('.')\n}\nconst qmarksTestNoExtDot = ([$0]: RegExpMatchArray) => {\n  const len = $0.length\n  return (f: string) => f.length === len && f !== '.' && f !== '..'\n}\n\n/* c8 ignore start */\nconst defaultPlatform: Platform = (\n  typeof process === 'object' && process\n    ? (typeof process.env === 'object' &&\n        process.env &&\n        process.env.__MINIMATCH_TESTING_PLATFORM__) ||\n      process.platform\n    : 'posix'\n) as Platform\ntype Sep = '\\\\' | '/'\nconst path: { [k: string]: { sep: Sep } } = {\n  win32: { sep: '\\\\' },\n  posix: { sep: '/' },\n}\n/* c8 ignore stop */\n\nexport const sep = defaultPlatform === 'win32' ? path.win32.sep : path.posix.sep\nminimatch.sep = sep\n\nexport const GLOBSTAR = Symbol('globstar **')\nminimatch.GLOBSTAR = GLOBSTAR\n\n// any single thing other than /\n// don't need to escape / when using new RegExp()\nconst qmark = '[^/]'\n\n// * => any number of characters\nconst star = qmark + '*?'\n\n// ** when dots are allowed.  Anything goes, except .. and .\n// not (^ or / followed by one or two dots followed by $ or /),\n// followed by anything, any number of times.\nconst twoStarDot = '(?:(?!(?:\\\\/|^)(?:\\\\.{1,2})($|\\\\/)).)*?'\n\n// not a ^ or / followed by a dot,\n// followed by anything, any number of times.\nconst twoStarNoDot = '(?:(?!(?:\\\\/|^)\\\\.).)*?'\n\nexport const filter =\n  (pattern: string, options: MinimatchOptions = {}) =>\n  (p: string) =>\n    minimatch(p, pattern, options)\nminimatch.filter = filter\n\nconst ext = (a: MinimatchOptions, b: MinimatchOptions = {}) =>\n  Object.assign({}, a, b)\n\nexport const defaults = (def: MinimatchOptions): typeof minimatch => {\n  if (!def || typeof def !== 'object' || !Object.keys(def).length) {\n    return minimatch\n  }\n\n  const orig = minimatch\n\n  const m = (p: string, pattern: string, options: MinimatchOptions = {}) =>\n    orig(p, pattern, ext(def, options))\n\n  return Object.assign(m, {\n    Minimatch: class Minimatch extends orig.Minimatch {\n      constructor(pattern: string, options: MinimatchOptions = {}) {\n        super(pattern, ext(def, options))\n      }\n      static defaults(options: MinimatchOptions) {\n        return orig.defaults(ext(def, options)).Minimatch\n      }\n    },\n\n    AST: class AST extends orig.AST {\n      /* c8 ignore start */\n      constructor(\n        type: ExtglobType | null,\n        parent?: AST,\n        options: MinimatchOptions = {}\n      ) {\n        super(type, parent, ext(def, options))\n      }\n      /* c8 ignore stop */\n\n      static fromGlob(pattern: string, options: MinimatchOptions = {}) {\n        return orig.AST.fromGlob(pattern, ext(def, options))\n      }\n    },\n\n    unescape: (\n      s: string,\n      options: Pick<MinimatchOptions, 'windowsPathsNoEscape'> = {}\n    ) => orig.unescape(s, ext(def, options)),\n\n    escape: (\n      s: string,\n      options: Pick<MinimatchOptions, 'windowsPathsNoEscape'> = {}\n    ) => orig.escape(s, ext(def, options)),\n\n    filter: (pattern: string, options: MinimatchOptions = {}) =>\n      orig.filter(pattern, ext(def, options)),\n\n    defaults: (options: MinimatchOptions) => orig.defaults(ext(def, options)),\n\n    makeRe: (pattern: string, options: MinimatchOptions = {}) =>\n      orig.makeRe(pattern, ext(def, options)),\n\n    braceExpand: (pattern: string, options: MinimatchOptions = {}) =>\n      orig.braceExpand(pattern, ext(def, options)),\n\n    match: (list: string[], pattern: string, options: MinimatchOptions = {}) =>\n      orig.match(list, pattern, ext(def, options)),\n\n    sep: orig.sep,\n    GLOBSTAR: GLOBSTAR as typeof GLOBSTAR,\n  })\n}\nminimatch.defaults = defaults\n\n// Brace expansion:\n// a{b,c}d -> abd acd\n// a{b,}c -> abc ac\n// a{0..3}d -> a0d a1d a2d a3d\n// a{b,c{d,e}f}g -> abg acdfg acefg\n// a{b,c}d{e,f}g -> abdeg acdeg abdeg abdfg\n//\n// Invalid sets are not expanded.\n// a{2..}b -> a{2..}b\n// a{b}c -> a{b}c\nexport const braceExpand = (\n  pattern: string,\n  options: MinimatchOptions = {}\n) => {\n  assertValidPattern(pattern)\n\n  // Thanks to Yeting Li <https://github.com/yetingli> for\n  // improving this regexp to avoid a ReDOS vulnerability.\n  if (options.nobrace || !/\\{(?:(?!\\{).)*\\}/.test(pattern)) {\n    // shortcut. no need to expand.\n    return [pattern]\n  }\n\n  return expand(pattern)\n}\nminimatch.braceExpand = braceExpand\n\n// parse a component of the expanded set.\n// At this point, no pattern may contain \"/\" in it\n// so we're going to return a 2d array, where each entry is the full\n// pattern, split on '/', and then turned into a regular expression.\n// A regexp is made at the end which joins each array with an\n// escaped /, and another full one which joins each regexp with |.\n//\n// Following the lead of Bash 4.1, note that \"**\" only has special meaning\n// when it is the *only* thing in a path portion.  Otherwise, any series\n// of * is equivalent to a single *.  Globstar behavior is enabled by\n// default, and can be disabled by setting options.noglobstar.\n\nexport const makeRe = (pattern: string, options: MinimatchOptions = {}) =>\n  new Minimatch(pattern, options).makeRe()\nminimatch.makeRe = makeRe\n\nexport const match = (\n  list: string[],\n  pattern: string,\n  options: MinimatchOptions = {}\n) => {\n  const mm = new Minimatch(pattern, options)\n  list = list.filter(f => mm.match(f))\n  if (mm.options.nonull && !list.length) {\n    list.push(pattern)\n  }\n  return list\n}\nminimatch.match = match\n\n// replace stuff like \\* with *\nconst globMagic = /[?*]|[+@!]\\(.*?\\)|\\[|\\]/\nconst regExpEscape = (s: string) =>\n  s.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&')\n\nexport type MMRegExp = RegExp & {\n  _src?: string\n  _glob?: string\n}\n\nexport type ParseReturnFiltered = string | MMRegExp | typeof GLOBSTAR\nexport type ParseReturn = ParseReturnFiltered | false\n\nexport class Minimatch {\n  options: MinimatchOptions\n  set: ParseReturnFiltered[][]\n  pattern: string\n\n  windowsPathsNoEscape: boolean\n  nonegate: boolean\n  negate: boolean\n  comment: boolean\n  empty: boolean\n  preserveMultipleSlashes: boolean\n  partial: boolean\n  globSet: string[]\n  globParts: string[][]\n  nocase: boolean\n\n  isWindows: boolean\n  platform: Platform\n  windowsNoMagicRoot: boolean\n\n  regexp: false | null | MMRegExp\n  constructor(pattern: string, options: MinimatchOptions = {}) {\n    assertValidPattern(pattern)\n\n    options = options || {}\n    this.options = options\n    this.pattern = pattern\n    this.platform = options.platform || defaultPlatform\n    this.isWindows = this.platform === 'win32'\n    this.windowsPathsNoEscape =\n      !!options.windowsPathsNoEscape || options.allowWindowsEscape === false\n    if (this.windowsPathsNoEscape) {\n      this.pattern = this.pattern.replace(/\\\\/g, '/')\n    }\n    this.preserveMultipleSlashes = !!options.preserveMultipleSlashes\n    this.regexp = null\n    this.negate = false\n    this.nonegate = !!options.nonegate\n    this.comment = false\n    this.empty = false\n    this.partial = !!options.partial\n    this.nocase = !!this.options.nocase\n    this.windowsNoMagicRoot =\n      options.windowsNoMagicRoot !== undefined\n        ? options.windowsNoMagicRoot\n        : !!(this.isWindows && this.nocase)\n\n    this.globSet = []\n    this.globParts = []\n    this.set = []\n\n    // make the set of regexps etc.\n    this.make()\n  }\n\n  hasMagic(): boolean {\n    if (this.options.magicalBraces && this.set.length > 1) {\n      return true\n    }\n    for (const pattern of this.set) {\n      for (const part of pattern) {\n        if (typeof part !== 'string') return true\n      }\n    }\n    return false\n  }\n\n  debug(..._: any[]) {}\n\n  make() {\n    const pattern = this.pattern\n    const options = this.options\n\n    // empty patterns and comments match nothing.\n    if (!options.nocomment && pattern.charAt(0) === '#') {\n      this.comment = true\n      return\n    }\n\n    if (!pattern) {\n      this.empty = true\n      return\n    }\n\n    // step 1: figure out negation, etc.\n    this.parseNegate()\n\n    // step 2: expand braces\n    this.globSet = [...new Set(this.braceExpand())]\n\n    if (options.debug) {\n      this.debug = (...args: any[]) => console.error(...args)\n    }\n\n    this.debug(this.pattern, this.globSet)\n\n    // step 3: now we have a set, so turn each one into a series of\n    // path-portion matching patterns.\n    // These will be regexps, except in the case of \"**\", which is\n    // set to the GLOBSTAR object for globstar behavior,\n    // and will not contain any / characters\n    //\n    // First, we preprocess to make the glob pattern sets a bit simpler\n    // and deduped.  There are some perf-killing patterns that can cause\n    // problems with a glob walk, but we can simplify them down a bit.\n    const rawGlobParts = this.globSet.map(s => this.slashSplit(s))\n    this.globParts = this.preprocess(rawGlobParts)\n    this.debug(this.pattern, this.globParts)\n\n    // glob --> regexps\n    let set = this.globParts.map((s, _, __) => {\n      if (this.isWindows && this.windowsNoMagicRoot) {\n        // check if it's a drive or unc path.\n        const isUNC =\n          s[0] === '' &&\n          s[1] === '' &&\n          (s[2] === '?' || !globMagic.test(s[2])) &&\n          !globMagic.test(s[3])\n        const isDrive = /^[a-z]:/i.test(s[0])\n        if (isUNC) {\n          return [...s.slice(0, 4), ...s.slice(4).map(ss => this.parse(ss))]\n        } else if (isDrive) {\n          return [s[0], ...s.slice(1).map(ss => this.parse(ss))]\n        }\n      }\n      return s.map(ss => this.parse(ss))\n    })\n\n    this.debug(this.pattern, set)\n\n    // filter out everything that didn't compile properly.\n    this.set = set.filter(\n      s => s.indexOf(false) === -1\n    ) as ParseReturnFiltered[][]\n\n    // do not treat the ? in UNC paths as magic\n    if (this.isWindows) {\n      for (let i = 0; i < this.set.length; i++) {\n        const p = this.set[i]\n        if (\n          p[0] === '' &&\n          p[1] === '' &&\n          this.globParts[i][2] === '?' &&\n          typeof p[3] === 'string' &&\n          /^[a-z]:$/i.test(p[3])\n        ) {\n          p[2] = '?'\n        }\n      }\n    }\n\n    this.debug(this.pattern, this.set)\n  }\n\n  // various transforms to equivalent pattern sets that are\n  // faster to process in a filesystem walk.  The goal is to\n  // eliminate what we can, and push all ** patterns as far\n  // to the right as possible, even if it increases the number\n  // of patterns that we have to process.\n  preprocess(globParts: string[][]) {\n    // if we're not in globstar mode, then turn all ** into *\n    if (this.options.noglobstar) {\n      for (let i = 0; i < globParts.length; i++) {\n        for (let j = 0; j < globParts[i].length; j++) {\n          if (globParts[i][j] === '**') {\n            globParts[i][j] = '*'\n          }\n        }\n      }\n    }\n\n    const { optimizationLevel = 1 } = this.options\n\n    if (optimizationLevel >= 2) {\n      // aggressive optimization for the purpose of fs walking\n      globParts = this.firstPhasePreProcess(globParts)\n      globParts = this.secondPhasePreProcess(globParts)\n    } else if (optimizationLevel >= 1) {\n      // just basic optimizations to remove some .. parts\n      globParts = this.levelOneOptimize(globParts)\n    } else {\n      // just collapse multiple ** portions into one\n      globParts = this.adjascentGlobstarOptimize(globParts)\n    }\n\n    return globParts\n  }\n\n  // just get rid of adjascent ** portions\n  adjascentGlobstarOptimize(globParts: string[][]) {\n    return globParts.map(parts => {\n      let gs: number = -1\n      while (-1 !== (gs = parts.indexOf('**', gs + 1))) {\n        let i = gs\n        while (parts[i + 1] === '**') {\n          i++\n        }\n        if (i !== gs) {\n          parts.splice(gs, i - gs)\n        }\n      }\n      return parts\n    })\n  }\n\n  // get rid of adjascent ** and resolve .. portions\n  levelOneOptimize(globParts: string[][]) {\n    return globParts.map(parts => {\n      parts = parts.reduce((set: string[], part) => {\n        const prev = set[set.length - 1]\n        if (part === '**' && prev === '**') {\n          return set\n        }\n        if (part === '..') {\n          if (prev && prev !== '..' && prev !== '.' && prev !== '**') {\n            set.pop()\n            return set\n          }\n        }\n        set.push(part)\n        return set\n      }, [])\n      return parts.length === 0 ? [''] : parts\n    })\n  }\n\n  levelTwoFileOptimize(parts: string | string[]) {\n    if (!Array.isArray(parts)) {\n      parts = this.slashSplit(parts)\n    }\n    let didSomething: boolean = false\n    do {\n      didSomething = false\n      // <pre>/<e>/<rest> -> <pre>/<rest>\n      if (!this.preserveMultipleSlashes) {\n        for (let i = 1; i < parts.length - 1; i++) {\n          const p = parts[i]\n          // don't squeeze out UNC patterns\n          if (i === 1 && p === '' && parts[0] === '') continue\n          if (p === '.' || p === '') {\n            didSomething = true\n            parts.splice(i, 1)\n            i--\n          }\n        }\n        if (\n          parts[0] === '.' &&\n          parts.length === 2 &&\n          (parts[1] === '.' || parts[1] === '')\n        ) {\n          didSomething = true\n          parts.pop()\n        }\n      }\n\n      // <pre>/<p>/../<rest> -> <pre>/<rest>\n      let dd: number = 0\n      while (-1 !== (dd = parts.indexOf('..', dd + 1))) {\n        const p = parts[dd - 1]\n        if (p && p !== '.' && p !== '..' && p !== '**') {\n          didSomething = true\n          parts.splice(dd - 1, 2)\n          dd -= 2\n        }\n      }\n    } while (didSomething)\n    return parts.length === 0 ? [''] : parts\n  }\n\n  // First phase: single-pattern processing\n  // <pre> is 1 or more portions\n  // <rest> is 1 or more portions\n  // <p> is any portion other than ., .., '', or **\n  // <e> is . or ''\n  //\n  // **/.. is *brutal* for filesystem walking performance, because\n  // it effectively resets the recursive walk each time it occurs,\n  // and ** cannot be reduced out by a .. pattern part like a regexp\n  // or most strings (other than .., ., and '') can be.\n  //\n  // <pre>/**/../<p>/<p>/<rest> -> {<pre>/../<p>/<p>/<rest>,<pre>/**/<p>/<p>/<rest>}\n  // <pre>/<e>/<rest> -> <pre>/<rest>\n  // <pre>/<p>/../<rest> -> <pre>/<rest>\n  // **/**/<rest> -> **/<rest>\n  //\n  // **/*/<rest> -> */**/<rest> <== not valid because ** doesn't follow\n  // this WOULD be allowed if ** did follow symlinks, or * didn't\n  firstPhasePreProcess(globParts: string[][]) {\n    let didSomething = false\n    do {\n      didSomething = false\n      // <pre>/**/../<p>/<p>/<rest> -> {<pre>/../<p>/<p>/<rest>,<pre>/**/<p>/<p>/<rest>}\n      for (let parts of globParts) {\n        let gs: number = -1\n        while (-1 !== (gs = parts.indexOf('**', gs + 1))) {\n          let gss: number = gs\n          while (parts[gss + 1] === '**') {\n            // <pre>/**/**/<rest> -> <pre>/**/<rest>\n            gss++\n          }\n          // eg, if gs is 2 and gss is 4, that means we have 3 **\n          // parts, and can remove 2 of them.\n          if (gss > gs) {\n            parts.splice(gs + 1, gss - gs)\n          }\n\n          let next = parts[gs + 1]\n          const p = parts[gs + 2]\n          const p2 = parts[gs + 3]\n          if (next !== '..') continue\n          if (\n            !p ||\n            p === '.' ||\n            p === '..' ||\n            !p2 ||\n            p2 === '.' ||\n            p2 === '..'\n          ) {\n            continue\n          }\n          didSomething = true\n          // edit parts in place, and push the new one\n          parts.splice(gs, 1)\n          const other = parts.slice(0)\n          other[gs] = '**'\n          globParts.push(other)\n          gs--\n        }\n\n        // <pre>/<e>/<rest> -> <pre>/<rest>\n        if (!this.preserveMultipleSlashes) {\n          for (let i = 1; i < parts.length - 1; i++) {\n            const p = parts[i]\n            // don't squeeze out UNC patterns\n            if (i === 1 && p === '' && parts[0] === '') continue\n            if (p === '.' || p === '') {\n              didSomething = true\n              parts.splice(i, 1)\n              i--\n            }\n          }\n          if (\n            parts[0] === '.' &&\n            parts.length === 2 &&\n            (parts[1] === '.' || parts[1] === '')\n          ) {\n            didSomething = true\n            parts.pop()\n          }\n        }\n\n        // <pre>/<p>/../<rest> -> <pre>/<rest>\n        let dd: number = 0\n        while (-1 !== (dd = parts.indexOf('..', dd + 1))) {\n          const p = parts[dd - 1]\n          if (p && p !== '.' && p !== '..' && p !== '**') {\n            didSomething = true\n            const needDot = dd === 1 && parts[dd + 1] === '**'\n            const splin = needDot ? ['.'] : []\n            parts.splice(dd - 1, 2, ...splin)\n            if (parts.length === 0) parts.push('')\n            dd -= 2\n          }\n        }\n      }\n    } while (didSomething)\n\n    return globParts\n  }\n\n  // second phase: multi-pattern dedupes\n  // {<pre>/*/<rest>,<pre>/<p>/<rest>} -> <pre>/*/<rest>\n  // {<pre>/<rest>,<pre>/<rest>} -> <pre>/<rest>\n  // {<pre>/**/<rest>,<pre>/<rest>} -> <pre>/**/<rest>\n  //\n  // {<pre>/**/<rest>,<pre>/**/<p>/<rest>} -> <pre>/**/<rest>\n  // ^-- not valid because ** doens't follow symlinks\n  secondPhasePreProcess(globParts: string[][]): string[][] {\n    for (let i = 0; i < globParts.length - 1; i++) {\n      for (let j = i + 1; j < globParts.length; j++) {\n        const matched = this.partsMatch(\n          globParts[i],\n          globParts[j],\n          !this.preserveMultipleSlashes\n        )\n        if (matched) {\n          globParts[i] = []\n          globParts[j] = matched\n          break\n        }\n      }\n    }\n    return globParts.filter(gs => gs.length)\n  }\n\n  partsMatch(\n    a: string[],\n    b: string[],\n    emptyGSMatch: boolean = false\n  ): false | string[] {\n    let ai = 0\n    let bi = 0\n    let result: string[] = []\n    let which: string = ''\n    while (ai < a.length && bi < b.length) {\n      if (a[ai] === b[bi]) {\n        result.push(which === 'b' ? b[bi] : a[ai])\n        ai++\n        bi++\n      } else if (emptyGSMatch && a[ai] === '**' && b[bi] === a[ai + 1]) {\n        result.push(a[ai])\n        ai++\n      } else if (emptyGSMatch && b[bi] === '**' && a[ai] === b[bi + 1]) {\n        result.push(b[bi])\n        bi++\n      } else if (\n        a[ai] === '*' &&\n        b[bi] &&\n        (this.options.dot || !b[bi].startsWith('.')) &&\n        b[bi] !== '**'\n      ) {\n        if (which === 'b') return false\n        which = 'a'\n        result.push(a[ai])\n        ai++\n        bi++\n      } else if (\n        b[bi] === '*' &&\n        a[ai] &&\n        (this.options.dot || !a[ai].startsWith('.')) &&\n        a[ai] !== '**'\n      ) {\n        if (which === 'a') return false\n        which = 'b'\n        result.push(b[bi])\n        ai++\n        bi++\n      } else {\n        return false\n      }\n    }\n    // if we fall out of the loop, it means they two are identical\n    // as long as their lengths match\n    return a.length === b.length && result\n  }\n\n  parseNegate() {\n    if (this.nonegate) return\n\n    const pattern = this.pattern\n    let negate = false\n    let negateOffset = 0\n\n    for (let i = 0; i < pattern.length && pattern.charAt(i) === '!'; i++) {\n      negate = !negate\n      negateOffset++\n    }\n\n    if (negateOffset) this.pattern = pattern.slice(negateOffset)\n    this.negate = negate\n  }\n\n  // set partial to true to test if, for example,\n  // \"/a/b\" matches the start of \"/*/b/*/d\"\n  // Partial means, if you run out of file before you run\n  // out of pattern, then that's fine, as long as all\n  // the parts match.\n  matchOne(file: string[], pattern: ParseReturn[], partial: boolean = false) {\n    const options = this.options\n\n    // UNC paths like //?/X:/... can match X:/... and vice versa\n    // Drive letters in absolute drive or unc paths are always compared\n    // case-insensitively.\n    if (this.isWindows) {\n      const fileDrive = typeof file[0] === 'string' && /^[a-z]:$/i.test(file[0])\n      const fileUNC =\n        !fileDrive &&\n        file[0] === '' &&\n        file[1] === '' &&\n        file[2] === '?' &&\n        /^[a-z]:$/i.test(file[3])\n\n      const patternDrive =\n        typeof pattern[0] === 'string' && /^[a-z]:$/i.test(pattern[0])\n      const patternUNC =\n        !patternDrive &&\n        pattern[0] === '' &&\n        pattern[1] === '' &&\n        pattern[2] === '?' &&\n        typeof pattern[3] === 'string' &&\n        /^[a-z]:$/i.test(pattern[3])\n\n      const fdi = fileUNC ? 3 : fileDrive ? 0 : undefined\n      const pdi = patternUNC ? 3 : patternDrive ? 0 : undefined\n      if (typeof fdi === 'number' && typeof pdi === 'number') {\n        const [fd, pd]: [string, string] = [file[fdi], pattern[pdi] as string]\n        if (fd.toLowerCase() === pd.toLowerCase()) {\n          pattern[pdi] = fd\n          if (pdi > fdi) {\n            pattern = pattern.slice(pdi)\n          } else if (fdi > pdi) {\n            file = file.slice(fdi)\n          }\n        }\n      }\n    }\n\n    // resolve and reduce . and .. portions in the file as well.\n    // dont' need to do the second phase, because it's only one string[]\n    const { optimizationLevel = 1 } = this.options\n    if (optimizationLevel >= 2) {\n      file = this.levelTwoFileOptimize(file)\n    }\n\n    this.debug('matchOne', this, { file, pattern })\n    this.debug('matchOne', file.length, pattern.length)\n\n    for (\n      var fi = 0, pi = 0, fl = file.length, pl = pattern.length;\n      fi < fl && pi < pl;\n      fi++, pi++\n    ) {\n      this.debug('matchOne loop')\n      var p = pattern[pi]\n      var f = file[fi]\n\n      this.debug(pattern, p, f)\n\n      // should be impossible.\n      // some invalid regexp stuff in the set.\n      /* c8 ignore start */\n      if (p === false) {\n        return false\n      }\n      /* c8 ignore stop */\n\n      if (p === GLOBSTAR) {\n        this.debug('GLOBSTAR', [pattern, p, f])\n\n        // \"**\"\n        // a/**/b/**/c would match the following:\n        // a/b/x/y/z/c\n        // a/x/y/z/b/c\n        // a/b/x/b/x/c\n        // a/b/c\n        // To do this, take the rest of the pattern after\n        // the **, and see if it would match the file remainder.\n        // If so, return success.\n        // If not, the ** \"swallows\" a segment, and try again.\n        // This is recursively awful.\n        //\n        // a/**/b/**/c matching a/b/x/y/z/c\n        // - a matches a\n        // - doublestar\n        //   - matchOne(b/x/y/z/c, b/**/c)\n        //     - b matches b\n        //     - doublestar\n        //       - matchOne(x/y/z/c, c) -> no\n        //       - matchOne(y/z/c, c) -> no\n        //       - matchOne(z/c, c) -> no\n        //       - matchOne(c, c) yes, hit\n        var fr = fi\n        var pr = pi + 1\n        if (pr === pl) {\n          this.debug('** at the end')\n          // a ** at the end will just swallow the rest.\n          // We have found a match.\n          // however, it will not swallow /.x, unless\n          // options.dot is set.\n          // . and .. are *never* matched by **, for explosively\n          // exponential reasons.\n          for (; fi < fl; fi++) {\n            if (\n              file[fi] === '.' ||\n              file[fi] === '..' ||\n              (!options.dot && file[fi].charAt(0) === '.')\n            )\n              return false\n          }\n          return true\n        }\n\n        // ok, let's see if we can swallow whatever we can.\n        while (fr < fl) {\n          var swallowee = file[fr]\n\n          this.debug('\\nglobstar while', file, fr, pattern, pr, swallowee)\n\n          // XXX remove this slice.  Just pass the start index.\n          if (this.matchOne(file.slice(fr), pattern.slice(pr), partial)) {\n            this.debug('globstar found match!', fr, fl, swallowee)\n            // found a match.\n            return true\n          } else {\n            // can't swallow \".\" or \"..\" ever.\n            // can only swallow \".foo\" when explicitly asked.\n            if (\n              swallowee === '.' ||\n              swallowee === '..' ||\n              (!options.dot && swallowee.charAt(0) === '.')\n            ) {\n              this.debug('dot detected!', file, fr, pattern, pr)\n              break\n            }\n\n            // ** swallows a segment, and continue.\n            this.debug('globstar swallow a segment, and continue')\n            fr++\n          }\n        }\n\n        // no match was found.\n        // However, in partial mode, we can't say this is necessarily over.\n        /* c8 ignore start */\n        if (partial) {\n          // ran out of file\n          this.debug('\\n>>> no match, partial?', file, fr, pattern, pr)\n          if (fr === fl) {\n            return true\n          }\n        }\n        /* c8 ignore stop */\n        return false\n      }\n\n      // something other than **\n      // non-magic patterns just have to match exactly\n      // patterns with magic have been turned into regexps.\n      let hit: boolean\n      if (typeof p === 'string') {\n        hit = f === p\n        this.debug('string match', p, f, hit)\n      } else {\n        hit = p.test(f)\n        this.debug('pattern match', p, f, hit)\n      }\n\n      if (!hit) return false\n    }\n\n    // Note: ending in / means that we'll get a final \"\"\n    // at the end of the pattern.  This can only match a\n    // corresponding \"\" at the end of the file.\n    // If the file ends in /, then it can only match a\n    // a pattern that ends in /, unless the pattern just\n    // doesn't have any more for it. But, a/b/ should *not*\n    // match \"a/b/*\", even though \"\" matches against the\n    // [^/]*? pattern, except in partial mode, where it might\n    // simply not be reached yet.\n    // However, a/b/ should still satisfy a/*\n\n    // now either we fell off the end of the pattern, or we're done.\n    if (fi === fl && pi === pl) {\n      // ran out of pattern and filename at the same time.\n      // an exact hit!\n      return true\n    } else if (fi === fl) {\n      // ran out of file, but still had pattern left.\n      // this is ok if we're doing the match as part of\n      // a glob fs traversal.\n      return partial\n    } else if (pi === pl) {\n      // ran out of pattern, still have file left.\n      // this is only acceptable if we're on the very last\n      // empty segment of a file with a trailing slash.\n      // a/* should match a/b/\n      return fi === fl - 1 && file[fi] === ''\n\n      /* c8 ignore start */\n    } else {\n      // should be unreachable.\n      throw new Error('wtf?')\n    }\n    /* c8 ignore stop */\n  }\n\n  braceExpand() {\n    return braceExpand(this.pattern, this.options)\n  }\n\n  parse(pattern: string): ParseReturn {\n    assertValidPattern(pattern)\n\n    const options = this.options\n\n    // shortcuts\n    if (pattern === '**') return GLOBSTAR\n    if (pattern === '') return ''\n\n    // far and away, the most common glob pattern parts are\n    // *, *.*, and *.<ext>  Add a fast check method for those.\n    let m: RegExpMatchArray | null\n    let fastTest: null | ((f: string) => boolean) = null\n    if ((m = pattern.match(starRE))) {\n      fastTest = options.dot ? starTestDot : starTest\n    } else if ((m = pattern.match(starDotExtRE))) {\n      fastTest = (\n        options.nocase\n          ? options.dot\n            ? starDotExtTestNocaseDot\n            : starDotExtTestNocase\n          : options.dot\n          ? starDotExtTestDot\n          : starDotExtTest\n      )(m[1])\n    } else if ((m = pattern.match(qmarksRE))) {\n      fastTest = (\n        options.nocase\n          ? options.dot\n            ? qmarksTestNocaseDot\n            : qmarksTestNocase\n          : options.dot\n          ? qmarksTestDot\n          : qmarksTest\n      )(m)\n    } else if ((m = pattern.match(starDotStarRE))) {\n      fastTest = options.dot ? starDotStarTestDot : starDotStarTest\n    } else if ((m = pattern.match(dotStarRE))) {\n      fastTest = dotStarTest\n    }\n\n    const re = AST.fromGlob(pattern, this.options).toMMPattern()\n    if (fastTest && typeof re === 'object') {\n      // Avoids overriding in frozen environments\n      Reflect.defineProperty(re, 'test', { value: fastTest })\n    }\n    return re\n  }\n\n  makeRe() {\n    if (this.regexp || this.regexp === false) return this.regexp\n\n    // at this point, this.set is a 2d array of partial\n    // pattern strings, or \"**\".\n    //\n    // It's better to use .match().  This function shouldn't\n    // be used, really, but it's pretty convenient sometimes,\n    // when you just want to work with a regex.\n    const set = this.set\n\n    if (!set.length) {\n      this.regexp = false\n      return this.regexp\n    }\n    const options = this.options\n\n    const twoStar = options.noglobstar\n      ? star\n      : options.dot\n      ? twoStarDot\n      : twoStarNoDot\n    const flags = new Set(options.nocase ? ['i'] : [])\n\n    // regexpify non-globstar patterns\n    // if ** is only item, then we just do one twoStar\n    // if ** is first, and there are more, prepend (\\/|twoStar\\/)? to next\n    // if ** is last, append (\\/twoStar|) to previous\n    // if ** is in the middle, append (\\/|\\/twoStar\\/) to previous\n    // then filter out GLOBSTAR symbols\n    let re = set\n      .map(pattern => {\n        const pp: (string | typeof GLOBSTAR)[] = pattern.map(p => {\n          if (p instanceof RegExp) {\n            for (const f of p.flags.split('')) flags.add(f)\n          }\n          return typeof p === 'string'\n            ? regExpEscape(p)\n            : p === GLOBSTAR\n            ? GLOBSTAR\n            : p._src\n        }) as (string | typeof GLOBSTAR)[]\n        pp.forEach((p, i) => {\n          const next = pp[i + 1]\n          const prev = pp[i - 1]\n          if (p !== GLOBSTAR || prev === GLOBSTAR) {\n            return\n          }\n          if (prev === undefined) {\n            if (next !== undefined && next !== GLOBSTAR) {\n              pp[i + 1] = '(?:\\\\/|' + twoStar + '\\\\/)?' + next\n            } else {\n              pp[i] = twoStar\n            }\n          } else if (next === undefined) {\n            pp[i - 1] = prev + '(?:\\\\/|' + twoStar + ')?'\n          } else if (next !== GLOBSTAR) {\n            pp[i - 1] = prev + '(?:\\\\/|\\\\/' + twoStar + '\\\\/)' + next\n            pp[i + 1] = GLOBSTAR\n          }\n        })\n        return pp.filter(p => p !== GLOBSTAR).join('/')\n      })\n      .join('|')\n\n    // need to wrap in parens if we had more than one thing with |,\n    // otherwise only the first will be anchored to ^ and the last to $\n    const [open, close] = set.length > 1 ? ['(?:', ')'] : ['', '']\n    // must match entire pattern\n    // ending in a * or ** will make it less strict.\n    re = '^' + open + re + close + '$'\n\n    // can match anything, as long as it's not this.\n    if (this.negate) re = '^(?!' + re + ').+$'\n\n    try {\n      this.regexp = new RegExp(re, [...flags].join(''))\n      /* c8 ignore start */\n    } catch (ex) {\n      // should be impossible\n      this.regexp = false\n    }\n    /* c8 ignore stop */\n    return this.regexp\n  }\n\n  slashSplit(p: string) {\n    // if p starts with // on windows, we preserve that\n    // so that UNC paths aren't broken.  Otherwise, any number of\n    // / characters are coalesced into one, unless\n    // preserveMultipleSlashes is set to true.\n    if (this.preserveMultipleSlashes) {\n      return p.split('/')\n    } else if (this.isWindows && /^\\/\\/[^\\/]+/.test(p)) {\n      // add an extra '' for the one we lose\n      return ['', ...p.split(/\\/+/)]\n    } else {\n      return p.split(/\\/+/)\n    }\n  }\n\n  match(f: string, partial = this.partial) {\n    this.debug('match', f, this.pattern)\n    // short-circuit in the case of busted things.\n    // comments, etc.\n    if (this.comment) {\n      return false\n    }\n    if (this.empty) {\n      return f === ''\n    }\n\n    if (f === '/' && partial) {\n      return true\n    }\n\n    const options = this.options\n\n    // windows: need to use /, not \\\n    if (this.isWindows) {\n      f = f.split('\\\\').join('/')\n    }\n\n    // treat the test path as a set of pathparts.\n    const ff = this.slashSplit(f)\n    this.debug(this.pattern, 'split', ff)\n\n    // just ONE of the pattern sets in this.set needs to match\n    // in order for it to be valid.  If negating, then just one\n    // match means that we have failed.\n    // Either way, return on the first hit.\n\n    const set = this.set\n    this.debug(this.pattern, 'set', set)\n\n    // Find the basename of the path by looking for the last non-empty segment\n    let filename: string = ff[ff.length - 1]\n    if (!filename) {\n      for (let i = ff.length - 2; !filename && i >= 0; i--) {\n        filename = ff[i]\n      }\n    }\n\n    for (let i = 0; i < set.length; i++) {\n      const pattern = set[i]\n      let file = ff\n      if (options.matchBase && pattern.length === 1) {\n        file = [filename]\n      }\n      const hit = this.matchOne(file, pattern, partial)\n      if (hit) {\n        if (options.flipNegate) {\n          return true\n        }\n        return !this.negate\n      }\n    }\n\n    // didn't get any hits.  this is success if it's a negative\n    // pattern, failure otherwise.\n    if (options.flipNegate) {\n      return false\n    }\n    return this.negate\n  }\n\n  static defaults(def: MinimatchOptions) {\n    return minimatch.defaults(def).Minimatch\n  }\n}\n/* c8 ignore start */\nexport { AST } from './ast.js'\nexport { escape } from './escape.js'\nexport { unescape } from './unescape.js'\n/* c8 ignore stop */\nminimatch.AST = AST\nminimatch.Minimatch = Minimatch\nminimatch.escape = escape\nminimatch.unescape = unescape\n","const MAX_PATTERN_LENGTH = 1024 * 64\nexport const assertValidPattern: (pattern: any) => void = (\n  pattern: any\n): asserts pattern is string => {\n  if (typeof pattern !== 'string') {\n    throw new TypeError('invalid pattern')\n  }\n\n  if (pattern.length > MAX_PATTERN_LENGTH) {\n    throw new TypeError('pattern is too long')\n  }\n}\n","// translate the various posix character classes into unicode properties\n// this works across all unicode locales\n\n// { <posix class>: [<translation>, /u flag required, negated]\nconst posixClasses: { [k: string]: [e: string, u: boolean, n?: boolean] } = {\n  '[:alnum:]': ['\\\\p{L}\\\\p{Nl}\\\\p{Nd}', true],\n  '[:alpha:]': ['\\\\p{L}\\\\p{Nl}', true],\n  '[:ascii:]': ['\\\\x' + '00-\\\\x' + '7f', false],\n  '[:blank:]': ['\\\\p{Zs}\\\\t', true],\n  '[:cntrl:]': ['\\\\p{Cc}', true],\n  '[:digit:]': ['\\\\p{Nd}', true],\n  '[:graph:]': ['\\\\p{Z}\\\\p{C}', true, true],\n  '[:lower:]': ['\\\\p{Ll}', true],\n  '[:print:]': ['\\\\p{C}', true],\n  '[:punct:]': ['\\\\p{P}', true],\n  '[:space:]': ['\\\\p{Z}\\\\t\\\\r\\\\n\\\\v\\\\f', true],\n  '[:upper:]': ['\\\\p{Lu}', true],\n  '[:word:]': ['\\\\p{L}\\\\p{Nl}\\\\p{Nd}\\\\p{Pc}', true],\n  '[:xdigit:]': ['A-Fa-f0-9', false],\n}\n\n// only need to escape a few things inside of brace expressions\n// escapes: [ \\ ] -\nconst braceEscape = (s: string) => s.replace(/[[\\]\\\\-]/g, '\\\\$&')\n// escape all regexp magic characters\nconst regexpEscape = (s: string) =>\n  s.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&')\n\n// everything has already been escaped, we just have to join\nconst rangesToString = (ranges: string[]): string => ranges.join('')\n\nexport type ParseClassResult = [\n  src: string,\n  uFlag: boolean,\n  consumed: number,\n  hasMagic: boolean\n]\n\n// takes a glob string at a posix brace expression, and returns\n// an equivalent regular expression source, and boolean indicating\n// whether the /u flag needs to be applied, and the number of chars\n// consumed to parse the character class.\n// This also removes out of order ranges, and returns ($.) if the\n// entire class just no good.\nexport const parseClass = (\n  glob: string,\n  position: number\n): ParseClassResult => {\n  const pos = position\n  /* c8 ignore start */\n  if (glob.charAt(pos) !== '[') {\n    throw new Error('not in a brace expression')\n  }\n  /* c8 ignore stop */\n  const ranges: string[] = []\n  const negs: string[] = []\n\n  let i = pos + 1\n  let sawStart = false\n  let uflag = false\n  let escaping = false\n  let negate = false\n  let endPos = pos\n  let rangeStart = ''\n  WHILE: while (i < glob.length) {\n    const c = glob.charAt(i)\n    if ((c === '!' || c === '^') && i === pos + 1) {\n      negate = true\n      i++\n      continue\n    }\n\n    if (c === ']' && sawStart && !escaping) {\n      endPos = i + 1\n      break\n    }\n\n    sawStart = true\n    if (c === '\\\\') {\n      if (!escaping) {\n        escaping = true\n        i++\n        continue\n      }\n      // escaped \\ char, fall through and treat like normal char\n    }\n    if (c === '[' && !escaping) {\n      // either a posix class, a collation equivalent, or just a [\n      for (const [cls, [unip, u, neg]] of Object.entries(posixClasses)) {\n        if (glob.startsWith(cls, i)) {\n          // invalid, [a-[] is fine, but not [a-[:alpha]]\n          if (rangeStart) {\n            return ['$.', false, glob.length - pos, true]\n          }\n          i += cls.length\n          if (neg) negs.push(unip)\n          else ranges.push(unip)\n          uflag = uflag || u\n          continue WHILE\n        }\n      }\n    }\n\n    // now it's just a normal character, effectively\n    escaping = false\n    if (rangeStart) {\n      // throw this range away if it's not valid, but others\n      // can still match.\n      if (c > rangeStart) {\n        ranges.push(braceEscape(rangeStart) + '-' + braceEscape(c))\n      } else if (c === rangeStart) {\n        ranges.push(braceEscape(c))\n      }\n      rangeStart = ''\n      i++\n      continue\n    }\n\n    // now might be the start of a range.\n    // can be either c-d or c-] or c<more...>] or c] at this point\n    if (glob.startsWith('-]', i + 1)) {\n      ranges.push(braceEscape(c + '-'))\n      i += 2\n      continue\n    }\n    if (glob.startsWith('-', i + 1)) {\n      rangeStart = c\n      i += 2\n      continue\n    }\n\n    // not the start of a range, just a single character\n    ranges.push(braceEscape(c))\n    i++\n  }\n\n  if (endPos < i) {\n    // didn't see the end of the class, not a valid class,\n    // but might still be valid as a literal match.\n    return ['', false, 0, false]\n  }\n\n  // if we got no ranges and no negates, then we have a range that\n  // cannot possibly match anything, and that poisons the whole glob\n  if (!ranges.length && !negs.length) {\n    return ['$.', false, glob.length - pos, true]\n  }\n\n  // if we got one positive range, and it's a single character, then that's\n  // not actually a magic pattern, it's just that one literal character.\n  // we should not treat that as \"magic\", we should just return the literal\n  // character. [_] is a perfectly valid way to escape glob magic chars.\n  if (\n    negs.length === 0 &&\n    ranges.length === 1 &&\n    /^\\\\?.$/.test(ranges[0]) &&\n    !negate\n  ) {\n    const r = ranges[0].length === 2 ? ranges[0].slice(-1) : ranges[0]\n    return [regexpEscape(r), false, endPos - pos, false]\n  }\n\n  const sranges = '[' + (negate ? '^' : '') + rangesToString(ranges) + ']'\n  const snegs = '[' + (negate ? '' : '^') + rangesToString(negs) + ']'\n  const comb =\n    ranges.length && negs.length\n      ? '(' + sranges + '|' + snegs + ')'\n      : ranges.length\n      ? sranges\n      : snegs\n\n  return [comb, uflag, endPos - pos, true]\n}\n","import { MinimatchOptions } from './index.js'\n/**\n * Un-escape a string that has been escaped with {@link escape}.\n *\n * If the {@link windowsPathsNoEscape} option is used, then square-brace\n * escapes are removed, but not backslash escapes.  For example, it will turn\n * the string `'[*]'` into `*`, but it will not turn `'\\\\*'` into `'*'`,\n * becuase `\\` is a path separator in `windowsPathsNoEscape` mode.\n *\n * When `windowsPathsNoEscape` is not set, then both brace escapes and\n * backslash escapes are removed.\n *\n * Slashes (and backslashes in `windowsPathsNoEscape` mode) cannot be escaped\n * or unescaped.\n */\nexport const unescape = (\n  s: string,\n  {\n    windowsPathsNoEscape = false,\n  }: Pick<MinimatchOptions, 'windowsPathsNoEscape'> = {}\n) => {\n  return windowsPathsNoEscape\n    ? s.replace(/\\[([^\\/\\\\])\\]/g, '$1')\n    : s.replace(/((?!\\\\).|^)\\[([^\\/\\\\])\\]/g, '$1$2').replace(/\\\\([^\\/])/g, '$1')\n}\n","// parse a single path portion\n\nimport { parseClass } from './brace-expressions.js'\nimport { MinimatchOptions, MMRegExp } from './index.js'\nimport { unescape } from './unescape.js'\n\n// classes [] are handled by the parseClass method\n// for positive extglobs, we sub-parse the contents, and combine,\n// with the appropriate regexp close.\n// for negative extglobs, we sub-parse the contents, but then\n// have to include the rest of the pattern, then the parent, etc.,\n// as the thing that cannot be because RegExp negative lookaheads\n// are different from globs.\n//\n// So for example:\n// a@(i|w!(x|y)z|j)b => ^a(i|w((!?(x|y)zb).*)z|j)b$\n//   1   2 3   4 5 6      1   2    3   46      5 6\n//\n// Assembling the extglob requires not just the negated patterns themselves,\n// but also anything following the negative patterns up to the boundary\n// of the current pattern, plus anything following in the parent pattern.\n//\n//\n// So, first, we parse the string into an AST of extglobs, without turning\n// anything into regexps yet.\n//\n// ['a', {@ [['i'], ['w', {!['x', 'y']}, 'z'], ['j']]}, 'b']\n//\n// Then, for all the negative extglobs, we append whatever comes after in\n// each parent as their tail\n//\n// ['a', {@ [['i'], ['w', {!['x', 'y'], 'z', 'b'}, 'z'], ['j']]}, 'b']\n//\n// Lastly, we turn each of these pieces into a regexp, and join\n//\n//                                 v----- .* because there's more following,\n//                                 v    v  otherwise, .+ because it must be\n//                                 v    v  *something* there.\n// ['^a', {@ ['i', 'w(?:(!?(?:x|y).*zb$).*)z', 'j' ]}, 'b$']\n//   copy what follows into here--^^^^^\n// ['^a', '(?:i|w(?:(?!(?:x|y).*zb$).*)z|j)', 'b$']\n// ['^a(?:i|w(?:(?!(?:x|y).*zb$).*)z|j)b$']\n\nexport type ExtglobType = '!' | '?' | '+' | '*' | '@'\nconst types = new Set<ExtglobType>(['!', '?', '+', '*', '@'])\nconst isExtglobType = (c: string): c is ExtglobType =>\n  types.has(c as ExtglobType)\n\n// Patterns that get prepended to bind to the start of either the\n// entire string, or just a single path portion, to prevent dots\n// and/or traversal patterns, when needed.\n// Exts don't need the ^ or / bit, because the root binds that already.\nconst startNoTraversal = '(?!(?:^|/)\\\\.\\\\.?(?:$|/))'\nconst startNoDot = '(?!\\\\.)'\n\n// characters that indicate a start of pattern needs the \"no dots\" bit,\n// because a dot *might* be matched. ( is not in the list, because in\n// the case of a child extglob, it will handle the prevention itself.\nconst addPatternStart = new Set(['[', '.'])\n// cases where traversal is A-OK, no dot prevention needed\nconst justDots = new Set(['..', '.'])\nconst reSpecials = new Set('().*{}+?[]^$\\\\!')\nconst regExpEscape = (s: string) =>\n  s.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&')\n\n// any single thing other than /\nconst qmark = '[^/]'\n\n// * => any number of characters\nconst star = qmark + '*?'\n// use + when we need to ensure that *something* matches, because the * is\n// the only thing in the path portion.\nconst starNoEmpty = qmark + '+?'\n\n// remove the \\ chars that we added if we end up doing a nonmagic compare\n// const deslash = (s: string) => s.replace(/\\\\(.)/g, '$1')\n\nexport class AST {\n  type: ExtglobType | null\n  readonly #root: AST\n\n  #hasMagic?: boolean\n  #uflag: boolean = false\n  #parts: (string | AST)[] = []\n  readonly #parent?: AST\n  readonly #parentIndex: number\n  #negs: AST[]\n  #filledNegs: boolean = false\n  #options: MinimatchOptions\n  #toString?: string\n  // set to true if it's an extglob with no children\n  // (which really means one child of '')\n  #emptyExt: boolean = false\n\n  constructor(\n    type: ExtglobType | null,\n    parent?: AST,\n    options: MinimatchOptions = {}\n  ) {\n    this.type = type\n    // extglobs are inherently magical\n    if (type) this.#hasMagic = true\n    this.#parent = parent\n    this.#root = this.#parent ? this.#parent.#root : this\n    this.#options = this.#root === this ? options : this.#root.#options\n    this.#negs = this.#root === this ? [] : this.#root.#negs\n    if (type === '!' && !this.#root.#filledNegs) this.#negs.push(this)\n    this.#parentIndex = this.#parent ? this.#parent.#parts.length : 0\n  }\n\n  get hasMagic(): boolean | undefined {\n    /* c8 ignore start */\n    if (this.#hasMagic !== undefined) return this.#hasMagic\n    /* c8 ignore stop */\n    for (const p of this.#parts) {\n      if (typeof p === 'string') continue\n      if (p.type || p.hasMagic) return (this.#hasMagic = true)\n    }\n    // note: will be undefined until we generate the regexp src and find out\n    return this.#hasMagic\n  }\n\n  // reconstructs the pattern\n  toString(): string {\n    if (this.#toString !== undefined) return this.#toString\n    if (!this.type) {\n      return (this.#toString = this.#parts.map(p => String(p)).join(''))\n    } else {\n      return (this.#toString =\n        this.type + '(' + this.#parts.map(p => String(p)).join('|') + ')')\n    }\n  }\n\n  #fillNegs() {\n    /* c8 ignore start */\n    if (this !== this.#root) throw new Error('should only call on root')\n    if (this.#filledNegs) return this\n    /* c8 ignore stop */\n\n    // call toString() once to fill this out\n    this.toString()\n    this.#filledNegs = true\n    let n: AST | undefined\n    while ((n = this.#negs.pop())) {\n      if (n.type !== '!') continue\n      // walk up the tree, appending everthing that comes AFTER parentIndex\n      let p: AST | undefined = n\n      let pp = p.#parent\n      while (pp) {\n        for (\n          let i = p.#parentIndex + 1;\n          !pp.type && i < pp.#parts.length;\n          i++\n        ) {\n          for (const part of n.#parts) {\n            /* c8 ignore start */\n            if (typeof part === 'string') {\n              throw new Error('string part in extglob AST??')\n            }\n            /* c8 ignore stop */\n            part.copyIn(pp.#parts[i])\n          }\n        }\n        p = pp\n        pp = p.#parent\n      }\n    }\n    return this\n  }\n\n  push(...parts: (string | AST)[]) {\n    for (const p of parts) {\n      if (p === '') continue\n      /* c8 ignore start */\n      if (typeof p !== 'string' && !(p instanceof AST && p.#parent === this)) {\n        throw new Error('invalid part: ' + p)\n      }\n      /* c8 ignore stop */\n      this.#parts.push(p)\n    }\n  }\n\n  toJSON() {\n    const ret: any[] =\n      this.type === null\n        ? this.#parts.slice().map(p => (typeof p === 'string' ? p : p.toJSON()))\n        : [this.type, ...this.#parts.map(p => (p as AST).toJSON())]\n    if (this.isStart() && !this.type) ret.unshift([])\n    if (\n      this.isEnd() &&\n      (this === this.#root ||\n        (this.#root.#filledNegs && this.#parent?.type === '!'))\n    ) {\n      ret.push({})\n    }\n    return ret\n  }\n\n  isStart(): boolean {\n    if (this.#root === this) return true\n    // if (this.type) return !!this.#parent?.isStart()\n    if (!this.#parent?.isStart()) return false\n    if (this.#parentIndex === 0) return true\n    // if everything AHEAD of this is a negation, then it's still the \"start\"\n    const p = this.#parent\n    for (let i = 0; i < this.#parentIndex; i++) {\n      const pp = p.#parts[i]\n      if (!(pp instanceof AST && pp.type === '!')) {\n        return false\n      }\n    }\n    return true\n  }\n\n  isEnd(): boolean {\n    if (this.#root === this) return true\n    if (this.#parent?.type === '!') return true\n    if (!this.#parent?.isEnd()) return false\n    if (!this.type) return this.#parent?.isEnd()\n    // if not root, it'll always have a parent\n    /* c8 ignore start */\n    const pl = this.#parent ? this.#parent.#parts.length : 0\n    /* c8 ignore stop */\n    return this.#parentIndex === pl - 1\n  }\n\n  copyIn(part: AST | string) {\n    if (typeof part === 'string') this.push(part)\n    else this.push(part.clone(this))\n  }\n\n  clone(parent: AST) {\n    const c = new AST(this.type, parent)\n    for (const p of this.#parts) {\n      c.copyIn(p)\n    }\n    return c\n  }\n\n  static #parseAST(\n    str: string,\n    ast: AST,\n    pos: number,\n    opt: MinimatchOptions\n  ): number {\n    let escaping = false\n    let inBrace = false\n    let braceStart = -1\n    let braceNeg = false\n    if (ast.type === null) {\n      // outside of a extglob, append until we find a start\n      let i = pos\n      let acc = ''\n      while (i < str.length) {\n        const c = str.charAt(i++)\n        // still accumulate escapes at this point, but we do ignore\n        // starts that are escaped\n        if (escaping || c === '\\\\') {\n          escaping = !escaping\n          acc += c\n          continue\n        }\n\n        if (inBrace) {\n          if (i === braceStart + 1) {\n            if (c === '^' || c === '!') {\n              braceNeg = true\n            }\n          } else if (c === ']' && !(i === braceStart + 2 && braceNeg)) {\n            inBrace = false\n          }\n          acc += c\n          continue\n        } else if (c === '[') {\n          inBrace = true\n          braceStart = i\n          braceNeg = false\n          acc += c\n          continue\n        }\n\n        if (!opt.noext && isExtglobType(c) && str.charAt(i) === '(') {\n          ast.push(acc)\n          acc = ''\n          const ext = new AST(c, ast)\n          i = AST.#parseAST(str, ext, i, opt)\n          ast.push(ext)\n          continue\n        }\n        acc += c\n      }\n      ast.push(acc)\n      return i\n    }\n\n    // some kind of extglob, pos is at the (\n    // find the next | or )\n    let i = pos + 1\n    let part = new AST(null, ast)\n    const parts: AST[] = []\n    let acc = ''\n    while (i < str.length) {\n      const c = str.charAt(i++)\n      // still accumulate escapes at this point, but we do ignore\n      // starts that are escaped\n      if (escaping || c === '\\\\') {\n        escaping = !escaping\n        acc += c\n        continue\n      }\n\n      if (inBrace) {\n        if (i === braceStart + 1) {\n          if (c === '^' || c === '!') {\n            braceNeg = true\n          }\n        } else if (c === ']' && !(i === braceStart + 2 && braceNeg)) {\n          inBrace = false\n        }\n        acc += c\n        continue\n      } else if (c === '[') {\n        inBrace = true\n        braceStart = i\n        braceNeg = false\n        acc += c\n        continue\n      }\n\n      if (isExtglobType(c) && str.charAt(i) === '(') {\n        part.push(acc)\n        acc = ''\n        const ext = new AST(c, part)\n        part.push(ext)\n        i = AST.#parseAST(str, ext, i, opt)\n        continue\n      }\n      if (c === '|') {\n        part.push(acc)\n        acc = ''\n        parts.push(part)\n        part = new AST(null, ast)\n        continue\n      }\n      if (c === ')') {\n        if (acc === '' && ast.#parts.length === 0) {\n          ast.#emptyExt = true\n        }\n        part.push(acc)\n        acc = ''\n        ast.push(...parts, part)\n        return i\n      }\n      acc += c\n    }\n\n    // unfinished extglob\n    // if we got here, it was a malformed extglob! not an extglob, but\n    // maybe something else in there.\n    ast.type = null\n    ast.#hasMagic = undefined\n    ast.#parts = [str.substring(pos - 1)]\n    return i\n  }\n\n  static fromGlob(pattern: string, options: MinimatchOptions = {}) {\n    const ast = new AST(null, undefined, options)\n    AST.#parseAST(pattern, ast, 0, options)\n    return ast\n  }\n\n  // returns the regular expression if there's magic, or the unescaped\n  // string if not.\n  toMMPattern(): MMRegExp | string {\n    // should only be called on root\n    /* c8 ignore start */\n    if (this !== this.#root) return this.#root.toMMPattern()\n    /* c8 ignore stop */\n    const glob = this.toString()\n    const [re, body, hasMagic, uflag] = this.toRegExpSource()\n    // if we're in nocase mode, and not nocaseMagicOnly, then we do\n    // still need a regular expression if we have to case-insensitively\n    // match capital/lowercase characters.\n    const anyMagic =\n      hasMagic ||\n      this.#hasMagic ||\n      (this.#options.nocase &&\n        !this.#options.nocaseMagicOnly &&\n        glob.toUpperCase() !== glob.toLowerCase())\n    if (!anyMagic) {\n      return body\n    }\n\n    const flags = (this.#options.nocase ? 'i' : '') + (uflag ? 'u' : '')\n    return Object.assign(new RegExp(`^${re}$`, flags), {\n      _src: re,\n      _glob: glob,\n    })\n  }\n\n  get options() {\n    return this.#options\n  }\n\n  // returns the string match, the regexp source, whether there's magic\n  // in the regexp (so a regular expression is required) and whether or\n  // not the uflag is needed for the regular expression (for posix classes)\n  // TODO: instead of injecting the start/end at this point, just return\n  // the BODY of the regexp, along with the start/end portions suitable\n  // for binding the start/end in either a joined full-path makeRe context\n  // (where we bind to (^|/), or a standalone matchPart context (where\n  // we bind to ^, and not /).  Otherwise slashes get duped!\n  //\n  // In part-matching mode, the start is:\n  // - if not isStart: nothing\n  // - if traversal possible, but not allowed: ^(?!\\.\\.?$)\n  // - if dots allowed or not possible: ^\n  // - if dots possible and not allowed: ^(?!\\.)\n  // end is:\n  // - if not isEnd(): nothing\n  // - else: $\n  //\n  // In full-path matching mode, we put the slash at the START of the\n  // pattern, so start is:\n  // - if first pattern: same as part-matching mode\n  // - if not isStart(): nothing\n  // - if traversal possible, but not allowed: /(?!\\.\\.?(?:$|/))\n  // - if dots allowed or not possible: /\n  // - if dots possible and not allowed: /(?!\\.)\n  // end is:\n  // - if last pattern, same as part-matching mode\n  // - else nothing\n  //\n  // Always put the (?:$|/) on negated tails, though, because that has to be\n  // there to bind the end of the negated pattern portion, and it's easier to\n  // just stick it in now rather than try to inject it later in the middle of\n  // the pattern.\n  //\n  // We can just always return the same end, and leave it up to the caller\n  // to know whether it's going to be used joined or in parts.\n  // And, if the start is adjusted slightly, can do the same there:\n  // - if not isStart: nothing\n  // - if traversal possible, but not allowed: (?:/|^)(?!\\.\\.?$)\n  // - if dots allowed or not possible: (?:/|^)\n  // - if dots possible and not allowed: (?:/|^)(?!\\.)\n  //\n  // But it's better to have a simpler binding without a conditional, for\n  // performance, so probably better to return both start options.\n  //\n  // Then the caller just ignores the end if it's not the first pattern,\n  // and the start always gets applied.\n  //\n  // But that's always going to be $ if it's the ending pattern, or nothing,\n  // so the caller can just attach $ at the end of the pattern when building.\n  //\n  // So the todo is:\n  // - better detect what kind of start is needed\n  // - return both flavors of starting pattern\n  // - attach $ at the end of the pattern when creating the actual RegExp\n  //\n  // Ah, but wait, no, that all only applies to the root when the first pattern\n  // is not an extglob. If the first pattern IS an extglob, then we need all\n  // that dot prevention biz to live in the extglob portions, because eg\n  // +(*|.x*) can match .xy but not .yx.\n  //\n  // So, return the two flavors if it's #root and the first child is not an\n  // AST, otherwise leave it to the child AST to handle it, and there,\n  // use the (?:^|/) style of start binding.\n  //\n  // Even simplified further:\n  // - Since the start for a join is eg /(?!\\.) and the start for a part\n  // is ^(?!\\.), we can just prepend (?!\\.) to the pattern (either root\n  // or start or whatever) and prepend ^ or / at the Regexp construction.\n  toRegExpSource(\n    allowDot?: boolean\n  ): [re: string, body: string, hasMagic: boolean, uflag: boolean] {\n    const dot = allowDot ?? !!this.#options.dot\n    if (this.#root === this) this.#fillNegs()\n    if (!this.type) {\n      const noEmpty = this.isStart() && this.isEnd()\n      const src = this.#parts\n        .map(p => {\n          const [re, _, hasMagic, uflag] =\n            typeof p === 'string'\n              ? AST.#parseGlob(p, this.#hasMagic, noEmpty)\n              : p.toRegExpSource(allowDot)\n          this.#hasMagic = this.#hasMagic || hasMagic\n          this.#uflag = this.#uflag || uflag\n          return re\n        })\n        .join('')\n\n      let start = ''\n      if (this.isStart()) {\n        if (typeof this.#parts[0] === 'string') {\n          // this is the string that will match the start of the pattern,\n          // so we need to protect against dots and such.\n\n          // '.' and '..' cannot match unless the pattern is that exactly,\n          // even if it starts with . or dot:true is set.\n          const dotTravAllowed =\n            this.#parts.length === 1 && justDots.has(this.#parts[0])\n          if (!dotTravAllowed) {\n            const aps = addPatternStart\n            // check if we have a possibility of matching . or ..,\n            // and prevent that.\n            const needNoTrav =\n              // dots are allowed, and the pattern starts with [ or .\n              (dot && aps.has(src.charAt(0))) ||\n              // the pattern starts with \\., and then [ or .\n              (src.startsWith('\\\\.') && aps.has(src.charAt(2))) ||\n              // the pattern starts with \\.\\., and then [ or .\n              (src.startsWith('\\\\.\\\\.') && aps.has(src.charAt(4)))\n            // no need to prevent dots if it can't match a dot, or if a\n            // sub-pattern will be preventing it anyway.\n            const needNoDot = !dot && !allowDot && aps.has(src.charAt(0))\n\n            start = needNoTrav ? startNoTraversal : needNoDot ? startNoDot : ''\n          }\n        }\n      }\n\n      // append the \"end of path portion\" pattern to negation tails\n      let end = ''\n      if (\n        this.isEnd() &&\n        this.#root.#filledNegs &&\n        this.#parent?.type === '!'\n      ) {\n        end = '(?:$|\\\\/)'\n      }\n      const final = start + src + end\n      return [\n        final,\n        unescape(src),\n        (this.#hasMagic = !!this.#hasMagic),\n        this.#uflag,\n      ]\n    }\n\n    // We need to calculate the body *twice* if it's a repeat pattern\n    // at the start, once in nodot mode, then again in dot mode, so a\n    // pattern like *(?) can match 'x.y'\n\n    const repeated = this.type === '*' || this.type === '+'\n    // some kind of extglob\n    const start = this.type === '!' ? '(?:(?!(?:' : '(?:'\n    let body = this.#partsToRegExp(dot)\n\n    if (this.isStart() && this.isEnd() && !body && this.type !== '!') {\n      // invalid extglob, has to at least be *something* present, if it's\n      // the entire path portion.\n      const s = this.toString()\n      this.#parts = [s]\n      this.type = null\n      this.#hasMagic = undefined\n      return [s, unescape(this.toString()), false, false]\n    }\n\n    // XXX abstract out this map method\n    let bodyDotAllowed =\n      !repeated || allowDot || dot || !startNoDot\n        ? ''\n        : this.#partsToRegExp(true)\n    if (bodyDotAllowed === body) {\n      bodyDotAllowed = ''\n    }\n    if (bodyDotAllowed) {\n      body = `(?:${body})(?:${bodyDotAllowed})*?`\n    }\n\n    // an empty !() is exactly equivalent to a starNoEmpty\n    let final = ''\n    if (this.type === '!' && this.#emptyExt) {\n      final = (this.isStart() && !dot ? startNoDot : '') + starNoEmpty\n    } else {\n      const close =\n        this.type === '!'\n          ? // !() must match something,but !(x) can match ''\n            '))' +\n            (this.isStart() && !dot && !allowDot ? startNoDot : '') +\n            star +\n            ')'\n          : this.type === '@'\n          ? ')'\n          : this.type === '?'\n          ? ')?'\n          : this.type === '+' && bodyDotAllowed\n          ? ')'\n          : this.type === '*' && bodyDotAllowed\n          ? `)?`\n          : `)${this.type}`\n      final = start + body + close\n    }\n    return [\n      final,\n      unescape(body),\n      (this.#hasMagic = !!this.#hasMagic),\n      this.#uflag,\n    ]\n  }\n\n  #partsToRegExp(dot: boolean) {\n    return this.#parts\n      .map(p => {\n        // extglob ASTs should only contain parent ASTs\n        /* c8 ignore start */\n        if (typeof p === 'string') {\n          throw new Error('string type in extglob ast??')\n        }\n        /* c8 ignore stop */\n        // can ignore hasMagic, because extglobs are already always magic\n        const [re, _, _hasMagic, uflag] = p.toRegExpSource(dot)\n        this.#uflag = this.#uflag || uflag\n        return re\n      })\n      .filter(p => !(this.isStart() && this.isEnd()) || !!p)\n      .join('|')\n  }\n\n  static #parseGlob(\n    glob: string,\n    hasMagic: boolean | undefined,\n    noEmpty: boolean = false\n  ): [re: string, body: string, hasMagic: boolean, uflag: boolean] {\n    let escaping = false\n    let re = ''\n    let uflag = false\n    for (let i = 0; i < glob.length; i++) {\n      const c = glob.charAt(i)\n      if (escaping) {\n        escaping = false\n        re += (reSpecials.has(c) ? '\\\\' : '') + c\n        continue\n      }\n      if (c === '\\\\') {\n        if (i === glob.length - 1) {\n          re += '\\\\\\\\'\n        } else {\n          escaping = true\n        }\n        continue\n      }\n      if (c === '[') {\n        const [src, needUflag, consumed, magic] = parseClass(glob, i)\n        if (consumed) {\n          re += src\n          uflag = uflag || needUflag\n          i += consumed - 1\n          hasMagic = hasMagic || magic\n          continue\n        }\n      }\n      if (c === '*') {\n        if (noEmpty && glob === '*') re += starNoEmpty\n        else re += star\n        hasMagic = true\n        continue\n      }\n      if (c === '?') {\n        re += qmark\n        hasMagic = true\n        continue\n      }\n      re += regExpEscape(c)\n    }\n    return [re, unescape(glob), !!hasMagic, uflag]\n  }\n}\n","import { MinimatchOptions } from './index.js'\n/**\n * Escape all magic characters in a glob pattern.\n *\n * If the {@link windowsPathsNoEscape | GlobOptions.windowsPathsNoEscape}\n * option is used, then characters are escaped by wrapping in `[]`, because\n * a magic character wrapped in a character class can only be satisfied by\n * that exact character.  In this mode, `\\` is _not_ escaped, because it is\n * not interpreted as a magic character, but instead as a path separator.\n */\nexport const escape = (\n  s: string,\n  {\n    windowsPathsNoEscape = false,\n  }: Pick<MinimatchOptions, 'windowsPathsNoEscape'> = {}\n) => {\n  // don't need to escape +@! because we escape the parens\n  // that make those magic, and escaping ! as [!] isn't valid,\n  // because [!]] is a valid glob class meaning not ']'.\n  return windowsPathsNoEscape\n    ? s.replace(/[?*()[\\]]/g, '[$&]')\n    : s.replace(/[?*()[\\]\\\\]/g, '\\\\$&')\n}\n","/**\n * @module LRUCache\n */\n\n// module-private names and types\ntype Perf = { now: () => number }\nconst perf: Perf =\n  typeof performance === 'object' &&\n  performance &&\n  typeof performance.now === 'function'\n    ? performance\n    : Date\n\nconst warned = new Set<string>()\n\n// either a function or a class\ntype ForC = ((...a: any[]) => any) | { new (...a: any[]): any }\n\n/* c8 ignore start */\nconst PROCESS = (\n  typeof process === 'object' && !!process ? process : {}\n) as { [k: string]: any }\n/* c8 ignore start */\n\nconst emitWarning = (\n  msg: string,\n  type: string,\n  code: string,\n  fn: ForC\n) => {\n  typeof PROCESS.emitWarning === 'function'\n    ? PROCESS.emitWarning(msg, type, code, fn)\n    : console.error(`[${code}] ${type}: ${msg}`)\n}\n\nlet AC = globalThis.AbortController\nlet AS = globalThis.AbortSignal\n\n/* c8 ignore start */\nif (typeof AC === 'undefined') {\n  //@ts-ignore\n  AS = class AbortSignal {\n    onabort?: (...a: any[]) => any\n    _onabort: ((...a: any[]) => any)[] = []\n    reason?: any\n    aborted: boolean = false\n    addEventListener(_: string, fn: (...a: any[]) => any) {\n      this._onabort.push(fn)\n    }\n  }\n  //@ts-ignore\n  AC = class AbortController {\n    constructor() {\n      warnACPolyfill()\n    }\n    signal = new AS()\n    abort(reason: any) {\n      if (this.signal.aborted) return\n      //@ts-ignore\n      this.signal.reason = reason\n      //@ts-ignore\n      this.signal.aborted = true\n      //@ts-ignore\n      for (const fn of this.signal._onabort) {\n        fn(reason)\n      }\n      this.signal.onabort?.(reason)\n    }\n  }\n  let printACPolyfillWarning =\n    PROCESS.env?.LRU_CACHE_IGNORE_AC_WARNING !== '1'\n  const warnACPolyfill = () => {\n    if (!printACPolyfillWarning) return\n    printACPolyfillWarning = false\n    emitWarning(\n      'AbortController is not defined. If using lru-cache in ' +\n        'node 14, load an AbortController polyfill from the ' +\n        '`node-abort-controller` package. A minimal polyfill is ' +\n        'provided for use by LRUCache.fetch(), but it should not be ' +\n        'relied upon in other contexts (eg, passing it to other APIs that ' +\n        'use AbortController/AbortSignal might have undesirable effects). ' +\n        'You may disable this with LRU_CACHE_IGNORE_AC_WARNING=1 in the env.',\n      'NO_ABORT_CONTROLLER',\n      'ENOTSUP',\n      warnACPolyfill\n    )\n  }\n}\n/* c8 ignore stop */\n\nconst shouldWarn = (code: string) => !warned.has(code)\n\nconst TYPE = Symbol('type')\nexport type PosInt = number & { [TYPE]: 'Positive Integer' }\nexport type Index = number & { [TYPE]: 'LRUCache Index' }\n\nconst isPosInt = (n: any): n is PosInt =>\n  n && n === Math.floor(n) && n > 0 && isFinite(n)\n\nexport type UintArray = Uint8Array | Uint16Array | Uint32Array\nexport type NumberArray = UintArray | number[]\n\n/* c8 ignore start */\n// This is a little bit ridiculous, tbh.\n// The maximum array length is 2^32-1 or thereabouts on most JS impls.\n// And well before that point, you're caching the entire world, I mean,\n// that's ~32GB of just integers for the next/prev links, plus whatever\n// else to hold that many keys and values.  Just filling the memory with\n// zeroes at init time is brutal when you get that big.\n// But why not be complete?\n// Maybe in the future, these limits will have expanded.\nconst getUintArray = (max: number) =>\n  !isPosInt(max)\n    ? null\n    : max <= Math.pow(2, 8)\n    ? Uint8Array\n    : max <= Math.pow(2, 16)\n    ? Uint16Array\n    : max <= Math.pow(2, 32)\n    ? Uint32Array\n    : max <= Number.MAX_SAFE_INTEGER\n    ? ZeroArray\n    : null\n/* c8 ignore stop */\n\nclass ZeroArray extends Array<number> {\n  constructor(size: number) {\n    super(size)\n    this.fill(0)\n  }\n}\nexport type { ZeroArray }\nexport type { Stack }\n\nexport type StackLike = Stack | Index[]\nclass Stack {\n  heap: NumberArray\n  length: number\n  // private constructor\n  static #constructing: boolean = false\n  static create(max: number): StackLike {\n    const HeapCls = getUintArray(max)\n    if (!HeapCls) return []\n    Stack.#constructing = true\n    const s = new Stack(max, HeapCls)\n    Stack.#constructing = false\n    return s\n  }\n  constructor(\n    max: number,\n    HeapCls: { new (n: number): NumberArray }\n  ) {\n    /* c8 ignore start */\n    if (!Stack.#constructing) {\n      throw new TypeError('instantiate Stack using Stack.create(n)')\n    }\n    /* c8 ignore stop */\n    this.heap = new HeapCls(max)\n    this.length = 0\n  }\n  push(n: Index) {\n    this.heap[this.length++] = n\n  }\n  pop(): Index {\n    return this.heap[--this.length] as Index\n  }\n}\n\n/**\n * Promise representing an in-progress {@link LRUCache#fetch} call\n */\nexport type BackgroundFetch<V> = Promise<V | undefined> & {\n  __returned: BackgroundFetch<V> | undefined\n  __abortController: AbortController\n  __staleWhileFetching: V | undefined\n}\n\nexport type DisposeTask<K, V> = [\n  value: V,\n  key: K,\n  reason: LRUCache.DisposeReason\n]\n\nexport namespace LRUCache {\n  /**\n   * An integer greater than 0, reflecting the calculated size of items\n   */\n  export type Size = number\n\n  /**\n   * Integer greater than 0, representing some number of milliseconds, or the\n   * time at which a TTL started counting from.\n   */\n  export type Milliseconds = number\n\n  /**\n   * An integer greater than 0, reflecting a number of items\n   */\n  export type Count = number\n\n  /**\n   * The reason why an item was removed from the cache, passed\n   * to the {@link Disposer} methods.\n   *\n   * - `evict`: The item was evicted because it is the least recently used,\n   *   and the cache is full.\n   * - `set`: A new value was set, overwriting the old value being disposed.\n   * - `delete`: The item was explicitly deleted, either by calling\n   *   {@link LRUCache#delete}, {@link LRUCache#clear}, or\n   *   {@link LRUCache#set} with an undefined value.\n   * - `expire`: The item was removed due to exceeding its TTL.\n   * - `fetch`: A {@link OptionsBase#fetchMethod} operation returned\n   *   `undefined` or was aborted, causing the item to be deleted.\n   */\n  export type DisposeReason =\n    | 'evict'\n    | 'set'\n    | 'delete'\n    | 'expire'\n    | 'fetch'\n  /**\n   * A method called upon item removal, passed as the\n   * {@link OptionsBase.dispose} and/or\n   * {@link OptionsBase.disposeAfter} options.\n   */\n  export type Disposer<K, V> = (\n    value: V,\n    key: K,\n    reason: DisposeReason\n  ) => void\n\n  /**\n   * A function that returns the effective calculated size\n   * of an entry in the cache.\n   */\n  export type SizeCalculator<K, V> = (value: V, key: K) => Size\n\n  /**\n   * Options provided to the\n   * {@link OptionsBase.fetchMethod} function.\n   */\n  export interface FetcherOptions<K, V, FC = unknown> {\n    signal: AbortSignal\n    options: FetcherFetchOptions<K, V, FC>\n    /**\n     * Object provided in the {@link FetchOptions.context} option to\n     * {@link LRUCache#fetch}\n     */\n    context: FC\n  }\n\n  /**\n   * Occasionally, it may be useful to track the internal behavior of the\n   * cache, particularly for logging, debugging, or for behavior within the\n   * `fetchMethod`. To do this, you can pass a `status` object to the\n   * {@link LRUCache#fetch}, {@link LRUCache#get}, {@link LRUCache#set},\n   * {@link LRUCache#memo}, and {@link LRUCache#has} methods.\n   *\n   * The `status` option should be a plain JavaScript object. The following\n   * fields will be set on it appropriately, depending on the situation.\n   */\n  export interface Status<V> {\n    /**\n     * The status of a set() operation.\n     *\n     * - add: the item was not found in the cache, and was added\n     * - update: the item was in the cache, with the same value provided\n     * - replace: the item was in the cache, and replaced\n     * - miss: the item was not added to the cache for some reason\n     */\n    set?: 'add' | 'update' | 'replace' | 'miss'\n\n    /**\n     * the ttl stored for the item, or undefined if ttls are not used.\n     */\n    ttl?: Milliseconds\n\n    /**\n     * the start time for the item, or undefined if ttls are not used.\n     */\n    start?: Milliseconds\n\n    /**\n     * The timestamp used for TTL calculation\n     */\n    now?: Milliseconds\n\n    /**\n     * the remaining ttl for the item, or undefined if ttls are not used.\n     */\n    remainingTTL?: Milliseconds\n\n    /**\n     * The calculated size for the item, if sizes are used.\n     */\n    entrySize?: Size\n\n    /**\n     * The total calculated size of the cache, if sizes are used.\n     */\n    totalCalculatedSize?: Size\n\n    /**\n     * A flag indicating that the item was not stored, due to exceeding the\n     * {@link OptionsBase.maxEntrySize}\n     */\n    maxEntrySizeExceeded?: true\n\n    /**\n     * The old value, specified in the case of `set:'update'` or\n     * `set:'replace'`\n     */\n    oldValue?: V\n\n    /**\n     * The results of a {@link LRUCache#has} operation\n     *\n     * - hit: the item was found in the cache\n     * - stale: the item was found in the cache, but is stale\n     * - miss: the item was not found in the cache\n     */\n    has?: 'hit' | 'stale' | 'miss'\n\n    /**\n     * The status of a {@link LRUCache#fetch} operation.\n     * Note that this can change as the underlying fetch() moves through\n     * various states.\n     *\n     * - inflight: there is another fetch() for this key which is in process\n     * - get: there is no {@link OptionsBase.fetchMethod}, so\n     *   {@link LRUCache#get} was called.\n     * - miss: the item is not in cache, and will be fetched.\n     * - hit: the item is in the cache, and was resolved immediately.\n     * - stale: the item is in the cache, but stale.\n     * - refresh: the item is in the cache, and not stale, but\n     *   {@link FetchOptions.forceRefresh} was specified.\n     */\n    fetch?: 'get' | 'inflight' | 'miss' | 'hit' | 'stale' | 'refresh'\n\n    /**\n     * The {@link OptionsBase.fetchMethod} was called\n     */\n    fetchDispatched?: true\n\n    /**\n     * The cached value was updated after a successful call to\n     * {@link OptionsBase.fetchMethod}\n     */\n    fetchUpdated?: true\n\n    /**\n     * The reason for a fetch() rejection.  Either the error raised by the\n     * {@link OptionsBase.fetchMethod}, or the reason for an\n     * AbortSignal.\n     */\n    fetchError?: Error\n\n    /**\n     * The fetch received an abort signal\n     */\n    fetchAborted?: true\n\n    /**\n     * The abort signal received was ignored, and the fetch was allowed to\n     * continue.\n     */\n    fetchAbortIgnored?: true\n\n    /**\n     * The fetchMethod promise resolved successfully\n     */\n    fetchResolved?: true\n\n    /**\n     * The fetchMethod promise was rejected\n     */\n    fetchRejected?: true\n\n    /**\n     * The status of a {@link LRUCache#get} operation.\n     *\n     * - fetching: The item is currently being fetched.  If a previous value\n     *   is present and allowed, that will be returned.\n     * - stale: The item is in the cache, and is stale.\n     * - hit: the item is in the cache\n     * - miss: the item is not in the cache\n     */\n    get?: 'stale' | 'hit' | 'miss'\n\n    /**\n     * A fetch or get operation returned a stale value.\n     */\n    returnedStale?: true\n  }\n\n  /**\n   * options which override the options set in the LRUCache constructor\n   * when calling {@link LRUCache#fetch}.\n   *\n   * This is the union of {@link GetOptions} and {@link SetOptions}, plus\n   * {@link OptionsBase.noDeleteOnFetchRejection},\n   * {@link OptionsBase.allowStaleOnFetchRejection},\n   * {@link FetchOptions.forceRefresh}, and\n   * {@link FetcherOptions.context}\n   *\n   * Any of these may be modified in the {@link OptionsBase.fetchMethod}\n   * function, but the {@link GetOptions} fields will of course have no\n   * effect, as the {@link LRUCache#get} call already happened by the time\n   * the fetchMethod is called.\n   */\n  export interface FetcherFetchOptions<K, V, FC = unknown>\n    extends Pick<\n      OptionsBase<K, V, FC>,\n      | 'allowStale'\n      | 'updateAgeOnGet'\n      | 'noDeleteOnStaleGet'\n      | 'sizeCalculation'\n      | 'ttl'\n      | 'noDisposeOnSet'\n      | 'noUpdateTTL'\n      | 'noDeleteOnFetchRejection'\n      | 'allowStaleOnFetchRejection'\n      | 'ignoreFetchAbort'\n      | 'allowStaleOnFetchAbort'\n    > {\n    status?: Status<V>\n    size?: Size\n  }\n\n  /**\n   * Options that may be passed to the {@link LRUCache#fetch} method.\n   */\n  export interface FetchOptions<K, V, FC>\n    extends FetcherFetchOptions<K, V, FC> {\n    /**\n     * Set to true to force a re-load of the existing data, even if it\n     * is not yet stale.\n     */\n    forceRefresh?: boolean\n    /**\n     * Context provided to the {@link OptionsBase.fetchMethod} as\n     * the {@link FetcherOptions.context} param.\n     *\n     * If the FC type is specified as unknown (the default),\n     * undefined or void, then this is optional.  Otherwise, it will\n     * be required.\n     */\n    context?: FC\n    signal?: AbortSignal\n    status?: Status<V>\n  }\n  /**\n   * Options provided to {@link LRUCache#fetch} when the FC type is something\n   * other than `unknown`, `undefined`, or `void`\n   */\n  export interface FetchOptionsWithContext<K, V, FC>\n    extends FetchOptions<K, V, FC> {\n    context: FC\n  }\n  /**\n   * Options provided to {@link LRUCache#fetch} when the FC type is\n   * `undefined` or `void`\n   */\n  export interface FetchOptionsNoContext<K, V>\n    extends FetchOptions<K, V, undefined> {\n    context?: undefined\n  }\n\n  export interface MemoOptions<K, V, FC = unknown>\n    extends Pick<\n      OptionsBase<K, V, FC>,\n      | 'allowStale'\n      | 'updateAgeOnGet'\n      | 'noDeleteOnStaleGet'\n      | 'sizeCalculation'\n      | 'ttl'\n      | 'noDisposeOnSet'\n      | 'noUpdateTTL'\n      | 'noDeleteOnFetchRejection'\n      | 'allowStaleOnFetchRejection'\n      | 'ignoreFetchAbort'\n      | 'allowStaleOnFetchAbort'\n    > {\n    /**\n     * Set to true to force a re-load of the existing data, even if it\n     * is not yet stale.\n     */\n    forceRefresh?: boolean\n    /**\n     * Context provided to the {@link OptionsBase.memoMethod} as\n     * the {@link MemoizerOptions.context} param.\n     *\n     * If the FC type is specified as unknown (the default),\n     * undefined or void, then this is optional.  Otherwise, it will\n     * be required.\n     */\n    context?: FC\n    status?: Status<V>\n  }\n  /**\n   * Options provided to {@link LRUCache#memo} when the FC type is something\n   * other than `unknown`, `undefined`, or `void`\n   */\n  export interface MemoOptionsWithContext<K, V, FC>\n    extends MemoOptions<K, V, FC> {\n    context: FC\n  }\n  /**\n   * Options provided to {@link LRUCache#memo} when the FC type is\n   * `undefined` or `void`\n   */\n  export interface MemoOptionsNoContext<K, V>\n    extends MemoOptions<K, V, undefined> {\n    context?: undefined\n  }\n\n  /**\n   * Options provided to the\n   * {@link OptionsBase.memoMethod} function.\n   */\n  export interface MemoizerOptions<K, V, FC = unknown> {\n    options: MemoizerMemoOptions<K, V, FC>\n    /**\n     * Object provided in the {@link MemoOptions.context} option to\n     * {@link LRUCache#memo}\n     */\n    context: FC\n  }\n\n  /**\n   * options which override the options set in the LRUCache constructor\n   * when calling {@link LRUCache#memo}.\n   *\n   * This is the union of {@link GetOptions} and {@link SetOptions}, plus\n   * {@link MemoOptions.forceRefresh}, and\n   * {@link MemoerOptions.context}\n   *\n   * Any of these may be modified in the {@link OptionsBase.memoMethod}\n   * function, but the {@link GetOptions} fields will of course have no\n   * effect, as the {@link LRUCache#get} call already happened by the time\n   * the memoMethod is called.\n   */\n  export interface MemoizerMemoOptions<K, V, FC = unknown>\n    extends Pick<\n      OptionsBase<K, V, FC>,\n      | 'allowStale'\n      | 'updateAgeOnGet'\n      | 'noDeleteOnStaleGet'\n      | 'sizeCalculation'\n      | 'ttl'\n      | 'noDisposeOnSet'\n      | 'noUpdateTTL'\n    > {\n    status?: Status<V>\n    size?: Size\n    start?: Milliseconds\n  }\n\n  /**\n   * Options that may be passed to the {@link LRUCache#has} method.\n   */\n  export interface HasOptions<K, V, FC>\n    extends Pick<OptionsBase<K, V, FC>, 'updateAgeOnHas'> {\n    status?: Status<V>\n  }\n\n  /**\n   * Options that may be passed to the {@link LRUCache#get} method.\n   */\n  export interface GetOptions<K, V, FC>\n    extends Pick<\n      OptionsBase<K, V, FC>,\n      'allowStale' | 'updateAgeOnGet' | 'noDeleteOnStaleGet'\n    > {\n    status?: Status<V>\n  }\n\n  /**\n   * Options that may be passed to the {@link LRUCache#peek} method.\n   */\n  export interface PeekOptions<K, V, FC>\n    extends Pick<OptionsBase<K, V, FC>, 'allowStale'> {}\n\n  /**\n   * Options that may be passed to the {@link LRUCache#set} method.\n   */\n  export interface SetOptions<K, V, FC>\n    extends Pick<\n      OptionsBase<K, V, FC>,\n      'sizeCalculation' | 'ttl' | 'noDisposeOnSet' | 'noUpdateTTL'\n    > {\n    /**\n     * If size tracking is enabled, then setting an explicit size\n     * in the {@link LRUCache#set} call will prevent calling the\n     * {@link OptionsBase.sizeCalculation} function.\n     */\n    size?: Size\n    /**\n     * If TTL tracking is enabled, then setting an explicit start\n     * time in the {@link LRUCache#set} call will override the\n     * default time from `performance.now()` or `Date.now()`.\n     *\n     * Note that it must be a valid value for whichever time-tracking\n     * method is in use.\n     */\n    start?: Milliseconds\n    status?: Status<V>\n  }\n\n  /**\n   * The type signature for the {@link OptionsBase.fetchMethod} option.\n   */\n  export type Fetcher<K, V, FC = unknown> = (\n    key: K,\n    staleValue: V | undefined,\n    options: FetcherOptions<K, V, FC>\n  ) => Promise<V | undefined | void> | V | undefined | void\n\n  /**\n   * the type signature for the {@link OptionsBase.memoMethod} option.\n   */\n  export type Memoizer<K, V, FC = unknown> = (\n    key: K,\n    staleValue: V | undefined,\n    options: MemoizerOptions<K, V, FC>\n  ) => V\n\n  /**\n   * Options which may be passed to the {@link LRUCache} constructor.\n   *\n   * Most of these may be overridden in the various options that use\n   * them.\n   *\n   * Despite all being technically optional, the constructor requires that\n   * a cache is at minimum limited by one or more of {@link OptionsBase.max},\n   * {@link OptionsBase.ttl}, or {@link OptionsBase.maxSize}.\n   *\n   * If {@link OptionsBase.ttl} is used alone, then it is strongly advised\n   * (and in fact required by the type definitions here) that the cache\n   * also set {@link OptionsBase.ttlAutopurge}, to prevent potentially\n   * unbounded storage.\n   *\n   * All options are also available on the {@link LRUCache} instance, making\n   * it safe to pass an LRUCache instance as the options argumemnt to\n   * make another empty cache of the same type.\n   *\n   * Some options are marked as read-only, because changing them after\n   * instantiation is not safe. Changing any of the other options will of\n   * course only have an effect on subsequent method calls.\n   */\n  export interface OptionsBase<K, V, FC> {\n    /**\n     * The maximum number of items to store in the cache before evicting\n     * old entries. This is read-only on the {@link LRUCache} instance,\n     * and may not be overridden.\n     *\n     * If set, then storage space will be pre-allocated at construction\n     * time, and the cache will perform significantly faster.\n     *\n     * Note that significantly fewer items may be stored, if\n     * {@link OptionsBase.maxSize} and/or {@link OptionsBase.ttl} are also\n     * set.\n     *\n     * **It is strongly recommended to set a `max` to prevent unbounded growth\n     * of the cache.**\n     */\n    max?: Count\n\n    /**\n     * Max time in milliseconds for items to live in cache before they are\n     * considered stale.  Note that stale items are NOT preemptively removed by\n     * default, and MAY live in the cache, contributing to its LRU max, long\n     * after they have expired, unless {@link OptionsBase.ttlAutopurge} is\n     * set.\n     *\n     * If set to `0` (the default value), then that means \"do not track\n     * TTL\", not \"expire immediately\".\n     *\n     * Also, as this cache is optimized for LRU/MRU operations, some of\n     * the staleness/TTL checks will reduce performance, as they will incur\n     * overhead by deleting items.\n     *\n     * This is not primarily a TTL cache, and does not make strong TTL\n     * guarantees. There is no pre-emptive pruning of expired items, but you\n     * _may_ set a TTL on the cache, and it will treat expired items as missing\n     * when they are fetched, and delete them.\n     *\n     * Optional, but must be a non-negative integer in ms if specified.\n     *\n     * This may be overridden by passing an options object to `cache.set()`.\n     *\n     * At least one of `max`, `maxSize`, or `TTL` is required. This must be a\n     * positive integer if set.\n     *\n     * Even if ttl tracking is enabled, **it is strongly recommended to set a\n     * `max` to prevent unbounded growth of the cache.**\n     *\n     * If ttl tracking is enabled, and `max` and `maxSize` are not set,\n     * and `ttlAutopurge` is not set, then a warning will be emitted\n     * cautioning about the potential for unbounded memory consumption.\n     * (The TypeScript definitions will also discourage this.)\n     */\n    ttl?: Milliseconds\n\n    /**\n     * Minimum amount of time in ms in which to check for staleness.\n     * Defaults to 1, which means that the current time is checked\n     * at most once per millisecond.\n     *\n     * Set to 0 to check the current time every time staleness is tested.\n     * (This reduces performance, and is theoretically unnecessary.)\n     *\n     * Setting this to a higher value will improve performance somewhat\n     * while using ttl tracking, albeit at the expense of keeping stale\n     * items around a bit longer than their TTLs would indicate.\n     *\n     * @default 1\n     */\n    ttlResolution?: Milliseconds\n\n    /**\n     * Preemptively remove stale items from the cache.\n     *\n     * Note that this may *significantly* degrade performance, especially if\n     * the cache is storing a large number of items. It is almost always best\n     * to just leave the stale items in the cache, and let them fall out as new\n     * items are added.\n     *\n     * Note that this means that {@link OptionsBase.allowStale} is a bit\n     * pointless, as stale items will be deleted almost as soon as they\n     * expire.\n     *\n     * Use with caution!\n     */\n    ttlAutopurge?: boolean\n\n    /**\n     * When using time-expiring entries with `ttl`, setting this to `true` will\n     * make each item's age reset to 0 whenever it is retrieved from cache with\n     * {@link LRUCache#get}, causing it to not expire. (It can still fall out\n     * of cache based on recency of use, of course.)\n     *\n     * Has no effect if {@link OptionsBase.ttl} is not set.\n     *\n     * This may be overridden by passing an options object to `cache.get()`.\n     */\n    updateAgeOnGet?: boolean\n\n    /**\n     * When using time-expiring entries with `ttl`, setting this to `true` will\n     * make each item's age reset to 0 whenever its presence in the cache is\n     * checked with {@link LRUCache#has}, causing it to not expire. (It can\n     * still fall out of cache based on recency of use, of course.)\n     *\n     * Has no effect if {@link OptionsBase.ttl} is not set.\n     */\n    updateAgeOnHas?: boolean\n\n    /**\n     * Allow {@link LRUCache#get} and {@link LRUCache#fetch} calls to return\n     * stale data, if available.\n     *\n     * By default, if you set `ttl`, stale items will only be deleted from the\n     * cache when you `get(key)`. That is, it's not preemptively pruning items,\n     * unless {@link OptionsBase.ttlAutopurge} is set.\n     *\n     * If you set `allowStale:true`, it'll return the stale value *as well as*\n     * deleting it. If you don't set this, then it'll return `undefined` when\n     * you try to get a stale entry.\n     *\n     * Note that when a stale entry is fetched, _even if it is returned due to\n     * `allowStale` being set_, it is removed from the cache immediately. You\n     * can suppress this behavior by setting\n     * {@link OptionsBase.noDeleteOnStaleGet}, either in the constructor, or in\n     * the options provided to {@link LRUCache#get}.\n     *\n     * This may be overridden by passing an options object to `cache.get()`.\n     * The `cache.has()` method will always return `false` for stale items.\n     *\n     * Only relevant if a ttl is set.\n     */\n    allowStale?: boolean\n\n    /**\n     * Function that is called on items when they are dropped from the\n     * cache, as `dispose(value, key, reason)`.\n     *\n     * This can be handy if you want to close file descriptors or do\n     * other cleanup tasks when items are no longer stored in the cache.\n     *\n     * **NOTE**: It is called _before_ the item has been fully removed\n     * from the cache, so if you want to put it right back in, you need\n     * to wait until the next tick. If you try to add it back in during\n     * the `dispose()` function call, it will break things in subtle and\n     * weird ways.\n     *\n     * Unlike several other options, this may _not_ be overridden by\n     * passing an option to `set()`, for performance reasons.\n     *\n     * The `reason` will be one of the following strings, corresponding\n     * to the reason for the item's deletion:\n     *\n     * - `evict` Item was evicted to make space for a new addition\n     * - `set` Item was overwritten by a new value\n     * - `expire` Item expired its TTL\n     * - `fetch` Item was deleted due to a failed or aborted fetch, or a\n     *   fetchMethod returning `undefined.\n     * - `delete` Item was removed by explicit `cache.delete(key)`,\n     *   `cache.clear()`, or `cache.set(key, undefined)`.\n     */\n    dispose?: Disposer<K, V>\n\n    /**\n     * The same as {@link OptionsBase.dispose}, but called *after* the entry\n     * is completely removed and the cache is once again in a clean state.\n     *\n     * It is safe to add an item right back into the cache at this point.\n     * However, note that it is *very* easy to inadvertently create infinite\n     * recursion this way.\n     */\n    disposeAfter?: Disposer<K, V>\n\n    /**\n     * Set to true to suppress calling the\n     * {@link OptionsBase.dispose} function if the entry key is\n     * still accessible within the cache.\n     *\n     * This may be overridden by passing an options object to\n     * {@link LRUCache#set}.\n     *\n     * Only relevant if `dispose` or `disposeAfter` are set.\n     */\n    noDisposeOnSet?: boolean\n\n    /**\n     * Boolean flag to tell the cache to not update the TTL when setting a new\n     * value for an existing key (ie, when updating a value rather than\n     * inserting a new value).  Note that the TTL value is _always_ set (if\n     * provided) when adding a new entry into the cache.\n     *\n     * Has no effect if a {@link OptionsBase.ttl} is not set.\n     *\n     * May be passed as an option to {@link LRUCache#set}.\n     */\n    noUpdateTTL?: boolean\n\n    /**\n     * Set to a positive integer to track the sizes of items added to the\n     * cache, and automatically evict items in order to stay below this size.\n     * Note that this may result in fewer than `max` items being stored.\n     *\n     * Attempting to add an item to the cache whose calculated size is greater\n     * that this amount will be a no-op. The item will not be cached, and no\n     * other items will be evicted.\n     *\n     * Optional, must be a positive integer if provided.\n     *\n     * Sets `maxEntrySize` to the same value, unless a different value is\n     * provided for `maxEntrySize`.\n     *\n     * At least one of `max`, `maxSize`, or `TTL` is required. This must be a\n     * positive integer if set.\n     *\n     * Even if size tracking is enabled, **it is strongly recommended to set a\n     * `max` to prevent unbounded growth of the cache.**\n     *\n     * Note also that size tracking can negatively impact performance,\n     * though for most cases, only minimally.\n     */\n    maxSize?: Size\n\n    /**\n     * The maximum allowed size for any single item in the cache.\n     *\n     * If a larger item is passed to {@link LRUCache#set} or returned by a\n     * {@link OptionsBase.fetchMethod} or {@link OptionsBase.memoMethod}, then\n     * it will not be stored in the cache.\n     *\n     * Attempting to add an item whose calculated size is greater than\n     * this amount will not cache the item or evict any old items, but\n     * WILL delete an existing value if one is already present.\n     *\n     * Optional, must be a positive integer if provided. Defaults to\n     * the value of `maxSize` if provided.\n     */\n    maxEntrySize?: Size\n\n    /**\n     * A function that returns a number indicating the item's size.\n     *\n     * Requires {@link OptionsBase.maxSize} to be set.\n     *\n     * If not provided, and {@link OptionsBase.maxSize} or\n     * {@link OptionsBase.maxEntrySize} are set, then all\n     * {@link LRUCache#set} calls **must** provide an explicit\n     * {@link SetOptions.size} or sizeCalculation param.\n     */\n    sizeCalculation?: SizeCalculator<K, V>\n\n    /**\n     * Method that provides the implementation for {@link LRUCache#fetch}\n     *\n     * ```ts\n     * fetchMethod(key, staleValue, { signal, options, context })\n     * ```\n     *\n     * If `fetchMethod` is not provided, then `cache.fetch(key)` is equivalent\n     * to `Promise.resolve(cache.get(key))`.\n     *\n     * If at any time, `signal.aborted` is set to `true`, or if the\n     * `signal.onabort` method is called, or if it emits an `'abort'` event\n     * which you can listen to with `addEventListener`, then that means that\n     * the fetch should be abandoned. This may be passed along to async\n     * functions aware of AbortController/AbortSignal behavior.\n     *\n     * The `fetchMethod` should **only** return `undefined` or a Promise\n     * resolving to `undefined` if the AbortController signaled an `abort`\n     * event. In all other cases, it should return or resolve to a value\n     * suitable for adding to the cache.\n     *\n     * The `options` object is a union of the options that may be provided to\n     * `set()` and `get()`. If they are modified, then that will result in\n     * modifying the settings to `cache.set()` when the value is resolved, and\n     * in the case of\n     * {@link OptionsBase.noDeleteOnFetchRejection} and\n     * {@link OptionsBase.allowStaleOnFetchRejection}, the handling of\n     * `fetchMethod` failures.\n     *\n     * For example, a DNS cache may update the TTL based on the value returned\n     * from a remote DNS server by changing `options.ttl` in the `fetchMethod`.\n     */\n    fetchMethod?: Fetcher<K, V, FC>\n\n    /**\n     * Method that provides the implementation for {@link LRUCache#memo}\n     */\n    memoMethod?: Memoizer<K, V, FC>\n\n    /**\n     * Set to true to suppress the deletion of stale data when a\n     * {@link OptionsBase.fetchMethod} returns a rejected promise.\n     */\n    noDeleteOnFetchRejection?: boolean\n\n    /**\n     * Do not delete stale items when they are retrieved with\n     * {@link LRUCache#get}.\n     *\n     * Note that the `get` return value will still be `undefined`\n     * unless {@link OptionsBase.allowStale} is true.\n     *\n     * When using time-expiring entries with `ttl`, by default stale\n     * items will be removed from the cache when the key is accessed\n     * with `cache.get()`.\n     *\n     * Setting this option will cause stale items to remain in the cache, until\n     * they are explicitly deleted with `cache.delete(key)`, or retrieved with\n     * `noDeleteOnStaleGet` set to `false`.\n     *\n     * This may be overridden by passing an options object to `cache.get()`.\n     *\n     * Only relevant if a ttl is used.\n     */\n    noDeleteOnStaleGet?: boolean\n\n    /**\n     * Set to true to allow returning stale data when a\n     * {@link OptionsBase.fetchMethod} throws an error or returns a rejected\n     * promise.\n     *\n     * This differs from using {@link OptionsBase.allowStale} in that stale\n     * data will ONLY be returned in the case that the {@link LRUCache#fetch}\n     * fails, not any other times.\n     *\n     * If a `fetchMethod` fails, and there is no stale value available, the\n     * `fetch()` will resolve to `undefined`. Ie, all `fetchMethod` errors are\n     * suppressed.\n     *\n     * Implies `noDeleteOnFetchRejection`.\n     *\n     * This may be set in calls to `fetch()`, or defaulted on the constructor,\n     * or overridden by modifying the options object in the `fetchMethod`.\n     */\n    allowStaleOnFetchRejection?: boolean\n\n    /**\n     * Set to true to return a stale value from the cache when the\n     * `AbortSignal` passed to the {@link OptionsBase.fetchMethod} dispatches\n     * an `'abort'` event, whether user-triggered, or due to internal cache\n     * behavior.\n     *\n     * Unless {@link OptionsBase.ignoreFetchAbort} is also set, the underlying\n     * {@link OptionsBase.fetchMethod} will still be considered canceled, and\n     * any value it returns will be ignored and not cached.\n     *\n     * Caveat: since fetches are aborted when a new value is explicitly\n     * set in the cache, this can lead to fetch returning a stale value,\n     * since that was the fallback value _at the moment the `fetch()` was\n     * initiated_, even though the new updated value is now present in\n     * the cache.\n     *\n     * For example:\n     *\n     * ```ts\n     * const cache = new LRUCache<string, any>({\n     *   ttl: 100,\n     *   fetchMethod: async (url, oldValue, { signal }) =>  {\n     *     const res = await fetch(url, { signal })\n     *     return await res.json()\n     *   }\n     * })\n     * cache.set('https://example.com/', { some: 'data' })\n     * // 100ms go by...\n     * const result = cache.fetch('https://example.com/')\n     * cache.set('https://example.com/', { other: 'thing' })\n     * console.log(await result) // { some: 'data' }\n     * console.log(cache.get('https://example.com/')) // { other: 'thing' }\n     * ```\n     */\n    allowStaleOnFetchAbort?: boolean\n\n    /**\n     * Set to true to ignore the `abort` event emitted by the `AbortSignal`\n     * object passed to {@link OptionsBase.fetchMethod}, and still cache the\n     * resulting resolution value, as long as it is not `undefined`.\n     *\n     * When used on its own, this means aborted {@link LRUCache#fetch} calls\n     * are not immediately resolved or rejected when they are aborted, and\n     * instead take the full time to await.\n     *\n     * When used with {@link OptionsBase.allowStaleOnFetchAbort}, aborted\n     * {@link LRUCache#fetch} calls will resolve immediately to their stale\n     * cached value or `undefined`, and will continue to process and eventually\n     * update the cache when they resolve, as long as the resulting value is\n     * not `undefined`, thus supporting a \"return stale on timeout while\n     * refreshing\" mechanism by passing `AbortSignal.timeout(n)` as the signal.\n     *\n     * For example:\n     *\n     * ```ts\n     * const c = new LRUCache({\n     *   ttl: 100,\n     *   ignoreFetchAbort: true,\n     *   allowStaleOnFetchAbort: true,\n     *   fetchMethod: async (key, oldValue, { signal }) => {\n     *     // note: do NOT pass the signal to fetch()!\n     *     // let's say this fetch can take a long time.\n     *     const res = await fetch(`https://slow-backend-server/${key}`)\n     *     return await res.json()\n     *   },\n     * })\n     *\n     * // this will return the stale value after 100ms, while still\n     * // updating in the background for next time.\n     * const val = await c.fetch('key', { signal: AbortSignal.timeout(100) })\n     * ```\n     *\n     * **Note**: regardless of this setting, an `abort` event _is still\n     * emitted on the `AbortSignal` object_, so may result in invalid results\n     * when passed to other underlying APIs that use AbortSignals.\n     *\n     * This may be overridden in the {@link OptionsBase.fetchMethod} or the\n     * call to {@link LRUCache#fetch}.\n     */\n    ignoreFetchAbort?: boolean\n  }\n\n  export interface OptionsMaxLimit<K, V, FC>\n    extends OptionsBase<K, V, FC> {\n    max: Count\n  }\n  export interface OptionsTTLLimit<K, V, FC>\n    extends OptionsBase<K, V, FC> {\n    ttl: Milliseconds\n    ttlAutopurge: boolean\n  }\n  export interface OptionsSizeLimit<K, V, FC>\n    extends OptionsBase<K, V, FC> {\n    maxSize: Size\n  }\n\n  /**\n   * The valid safe options for the {@link LRUCache} constructor\n   */\n  export type Options<K, V, FC> =\n    | OptionsMaxLimit<K, V, FC>\n    | OptionsSizeLimit<K, V, FC>\n    | OptionsTTLLimit<K, V, FC>\n\n  /**\n   * Entry objects used by {@link LRUCache#load} and {@link LRUCache#dump},\n   * and returned by {@link LRUCache#info}.\n   */\n  export interface Entry<V> {\n    value: V\n    ttl?: Milliseconds\n    size?: Size\n    start?: Milliseconds\n  }\n}\n\n/**\n * Default export, the thing you're using this module to get.\n *\n * The `K` and `V` types define the key and value types, respectively. The\n * optional `FC` type defines the type of the `context` object passed to\n * `cache.fetch()` and `cache.memo()`.\n *\n * Keys and values **must not** be `null` or `undefined`.\n *\n * All properties from the options object (with the exception of `max`,\n * `maxSize`, `fetchMethod`, `memoMethod`, `dispose` and `disposeAfter`) are\n * added as normal public members. (The listed options are read-only getters.)\n *\n * Changing any of these will alter the defaults for subsequent method calls.\n */\nexport class LRUCache<K extends {}, V extends {}, FC = unknown>\n  implements Map<K, V>\n{\n  // options that cannot be changed without disaster\n  readonly #max: LRUCache.Count\n  readonly #maxSize: LRUCache.Size\n  readonly #dispose?: LRUCache.Disposer<K, V>\n  readonly #disposeAfter?: LRUCache.Disposer<K, V>\n  readonly #fetchMethod?: LRUCache.Fetcher<K, V, FC>\n  readonly #memoMethod?: LRUCache.Memoizer<K, V, FC>\n\n  /**\n   * {@link LRUCache.OptionsBase.ttl}\n   */\n  ttl: LRUCache.Milliseconds\n\n  /**\n   * {@link LRUCache.OptionsBase.ttlResolution}\n   */\n  ttlResolution: LRUCache.Milliseconds\n  /**\n   * {@link LRUCache.OptionsBase.ttlAutopurge}\n   */\n  ttlAutopurge: boolean\n  /**\n   * {@link LRUCache.OptionsBase.updateAgeOnGet}\n   */\n  updateAgeOnGet: boolean\n  /**\n   * {@link LRUCache.OptionsBase.updateAgeOnHas}\n   */\n  updateAgeOnHas: boolean\n  /**\n   * {@link LRUCache.OptionsBase.allowStale}\n   */\n  allowStale: boolean\n\n  /**\n   * {@link LRUCache.OptionsBase.noDisposeOnSet}\n   */\n  noDisposeOnSet: boolean\n  /**\n   * {@link LRUCache.OptionsBase.noUpdateTTL}\n   */\n  noUpdateTTL: boolean\n  /**\n   * {@link LRUCache.OptionsBase.maxEntrySize}\n   */\n  maxEntrySize: LRUCache.Size\n  /**\n   * {@link LRUCache.OptionsBase.sizeCalculation}\n   */\n  sizeCalculation?: LRUCache.SizeCalculator<K, V>\n  /**\n   * {@link LRUCache.OptionsBase.noDeleteOnFetchRejection}\n   */\n  noDeleteOnFetchRejection: boolean\n  /**\n   * {@link LRUCache.OptionsBase.noDeleteOnStaleGet}\n   */\n  noDeleteOnStaleGet: boolean\n  /**\n   * {@link LRUCache.OptionsBase.allowStaleOnFetchAbort}\n   */\n  allowStaleOnFetchAbort: boolean\n  /**\n   * {@link LRUCache.OptionsBase.allowStaleOnFetchRejection}\n   */\n  allowStaleOnFetchRejection: boolean\n  /**\n   * {@link LRUCache.OptionsBase.ignoreFetchAbort}\n   */\n  ignoreFetchAbort: boolean\n\n  // computed properties\n  #size: LRUCache.Count\n  #calculatedSize: LRUCache.Size\n  #keyMap: Map<K, Index>\n  #keyList: (K | undefined)[]\n  #valList: (V | BackgroundFetch<V> | undefined)[]\n  #next: NumberArray\n  #prev: NumberArray\n  #head: Index\n  #tail: Index\n  #free: StackLike\n  #disposed?: DisposeTask<K, V>[]\n  #sizes?: ZeroArray\n  #starts?: ZeroArray\n  #ttls?: ZeroArray\n\n  #hasDispose: boolean\n  #hasFetchMethod: boolean\n  #hasDisposeAfter: boolean\n\n  /**\n   * Do not call this method unless you need to inspect the\n   * inner workings of the cache.  If anything returned by this\n   * object is modified in any way, strange breakage may occur.\n   *\n   * These fields are private for a reason!\n   *\n   * @internal\n   */\n  static unsafeExposeInternals<\n    K extends {},\n    V extends {},\n    FC extends unknown = unknown\n  >(c: LRUCache<K, V, FC>) {\n    return {\n      // properties\n      starts: c.#starts,\n      ttls: c.#ttls,\n      sizes: c.#sizes,\n      keyMap: c.#keyMap as Map<K, number>,\n      keyList: c.#keyList,\n      valList: c.#valList,\n      next: c.#next,\n      prev: c.#prev,\n      get head() {\n        return c.#head\n      },\n      get tail() {\n        return c.#tail\n      },\n      free: c.#free,\n      // methods\n      isBackgroundFetch: (p: any) => c.#isBackgroundFetch(p),\n      backgroundFetch: (\n        k: K,\n        index: number | undefined,\n        options: LRUCache.FetchOptions<K, V, FC>,\n        context: any\n      ): BackgroundFetch<V> =>\n        c.#backgroundFetch(\n          k,\n          index as Index | undefined,\n          options,\n          context\n        ),\n      moveToTail: (index: number): void =>\n        c.#moveToTail(index as Index),\n      indexes: (options?: { allowStale: boolean }) =>\n        c.#indexes(options),\n      rindexes: (options?: { allowStale: boolean }) =>\n        c.#rindexes(options),\n      isStale: (index: number | undefined) =>\n        c.#isStale(index as Index),\n    }\n  }\n\n  // Protected read-only members\n\n  /**\n   * {@link LRUCache.OptionsBase.max} (read-only)\n   */\n  get max(): LRUCache.Count {\n    return this.#max\n  }\n  /**\n   * {@link LRUCache.OptionsBase.maxSize} (read-only)\n   */\n  get maxSize(): LRUCache.Count {\n    return this.#maxSize\n  }\n  /**\n   * The total computed size of items in the cache (read-only)\n   */\n  get calculatedSize(): LRUCache.Size {\n    return this.#calculatedSize\n  }\n  /**\n   * The number of items stored in the cache (read-only)\n   */\n  get size(): LRUCache.Count {\n    return this.#size\n  }\n  /**\n   * {@link LRUCache.OptionsBase.fetchMethod} (read-only)\n   */\n  get fetchMethod(): LRUCache.Fetcher<K, V, FC> | undefined {\n    return this.#fetchMethod\n  }\n  get memoMethod(): LRUCache.Memoizer<K, V, FC> | undefined {\n    return this.#memoMethod\n  }\n  /**\n   * {@link LRUCache.OptionsBase.dispose} (read-only)\n   */\n  get dispose() {\n    return this.#dispose\n  }\n  /**\n   * {@link LRUCache.OptionsBase.disposeAfter} (read-only)\n   */\n  get disposeAfter() {\n    return this.#disposeAfter\n  }\n\n  constructor(\n    options: LRUCache.Options<K, V, FC> | LRUCache<K, V, FC>\n  ) {\n    const {\n      max = 0,\n      ttl,\n      ttlResolution = 1,\n      ttlAutopurge,\n      updateAgeOnGet,\n      updateAgeOnHas,\n      allowStale,\n      dispose,\n      disposeAfter,\n      noDisposeOnSet,\n      noUpdateTTL,\n      maxSize = 0,\n      maxEntrySize = 0,\n      sizeCalculation,\n      fetchMethod,\n      memoMethod,\n      noDeleteOnFetchRejection,\n      noDeleteOnStaleGet,\n      allowStaleOnFetchRejection,\n      allowStaleOnFetchAbort,\n      ignoreFetchAbort,\n    } = options\n\n    if (max !== 0 && !isPosInt(max)) {\n      throw new TypeError('max option must be a nonnegative integer')\n    }\n\n    const UintArray = max ? getUintArray(max) : Array\n    if (!UintArray) {\n      throw new Error('invalid max value: ' + max)\n    }\n\n    this.#max = max\n    this.#maxSize = maxSize\n    this.maxEntrySize = maxEntrySize || this.#maxSize\n    this.sizeCalculation = sizeCalculation\n    if (this.sizeCalculation) {\n      if (!this.#maxSize && !this.maxEntrySize) {\n        throw new TypeError(\n          'cannot set sizeCalculation without setting maxSize or maxEntrySize'\n        )\n      }\n      if (typeof this.sizeCalculation !== 'function') {\n        throw new TypeError('sizeCalculation set to non-function')\n      }\n    }\n\n    if (\n      memoMethod !== undefined &&\n      typeof memoMethod !== 'function'\n    ) {\n      throw new TypeError('memoMethod must be a function if defined')\n    }\n    this.#memoMethod = memoMethod\n\n    if (\n      fetchMethod !== undefined &&\n      typeof fetchMethod !== 'function'\n    ) {\n      throw new TypeError(\n        'fetchMethod must be a function if specified'\n      )\n    }\n    this.#fetchMethod = fetchMethod\n    this.#hasFetchMethod = !!fetchMethod\n\n    this.#keyMap = new Map()\n    this.#keyList = new Array(max).fill(undefined)\n    this.#valList = new Array(max).fill(undefined)\n    this.#next = new UintArray(max)\n    this.#prev = new UintArray(max)\n    this.#head = 0 as Index\n    this.#tail = 0 as Index\n    this.#free = Stack.create(max)\n    this.#size = 0\n    this.#calculatedSize = 0\n\n    if (typeof dispose === 'function') {\n      this.#dispose = dispose\n    }\n    if (typeof disposeAfter === 'function') {\n      this.#disposeAfter = disposeAfter\n      this.#disposed = []\n    } else {\n      this.#disposeAfter = undefined\n      this.#disposed = undefined\n    }\n    this.#hasDispose = !!this.#dispose\n    this.#hasDisposeAfter = !!this.#disposeAfter\n\n    this.noDisposeOnSet = !!noDisposeOnSet\n    this.noUpdateTTL = !!noUpdateTTL\n    this.noDeleteOnFetchRejection = !!noDeleteOnFetchRejection\n    this.allowStaleOnFetchRejection = !!allowStaleOnFetchRejection\n    this.allowStaleOnFetchAbort = !!allowStaleOnFetchAbort\n    this.ignoreFetchAbort = !!ignoreFetchAbort\n\n    // NB: maxEntrySize is set to maxSize if it's set\n    if (this.maxEntrySize !== 0) {\n      if (this.#maxSize !== 0) {\n        if (!isPosInt(this.#maxSize)) {\n          throw new TypeError(\n            'maxSize must be a positive integer if specified'\n          )\n        }\n      }\n      if (!isPosInt(this.maxEntrySize)) {\n        throw new TypeError(\n          'maxEntrySize must be a positive integer if specified'\n        )\n      }\n      this.#initializeSizeTracking()\n    }\n\n    this.allowStale = !!allowStale\n    this.noDeleteOnStaleGet = !!noDeleteOnStaleGet\n    this.updateAgeOnGet = !!updateAgeOnGet\n    this.updateAgeOnHas = !!updateAgeOnHas\n    this.ttlResolution =\n      isPosInt(ttlResolution) || ttlResolution === 0\n        ? ttlResolution\n        : 1\n    this.ttlAutopurge = !!ttlAutopurge\n    this.ttl = ttl || 0\n    if (this.ttl) {\n      if (!isPosInt(this.ttl)) {\n        throw new TypeError(\n          'ttl must be a positive integer if specified'\n        )\n      }\n      this.#initializeTTLTracking()\n    }\n\n    // do not allow completely unbounded caches\n    if (this.#max === 0 && this.ttl === 0 && this.#maxSize === 0) {\n      throw new TypeError(\n        'At least one of max, maxSize, or ttl is required'\n      )\n    }\n    if (!this.ttlAutopurge && !this.#max && !this.#maxSize) {\n      const code = 'LRU_CACHE_UNBOUNDED'\n      if (shouldWarn(code)) {\n        warned.add(code)\n        const msg =\n          'TTL caching without ttlAutopurge, max, or maxSize can ' +\n          'result in unbounded memory consumption.'\n        emitWarning(msg, 'UnboundedCacheWarning', code, LRUCache)\n      }\n    }\n  }\n\n  /**\n   * Return the number of ms left in the item's TTL. If item is not in cache,\n   * returns `0`. Returns `Infinity` if item is in cache without a defined TTL.\n   */\n  getRemainingTTL(key: K) {\n    return this.#keyMap.has(key) ? Infinity : 0\n  }\n\n  #initializeTTLTracking() {\n    const ttls = new ZeroArray(this.#max)\n    const starts = new ZeroArray(this.#max)\n    this.#ttls = ttls\n    this.#starts = starts\n\n    this.#setItemTTL = (index, ttl, start = perf.now()) => {\n      starts[index] = ttl !== 0 ? start : 0\n      ttls[index] = ttl\n      if (ttl !== 0 && this.ttlAutopurge) {\n        const t = setTimeout(() => {\n          if (this.#isStale(index)) {\n            this.#delete(this.#keyList[index] as K, 'expire')\n          }\n        }, ttl + 1)\n        // unref() not supported on all platforms\n        /* c8 ignore start */\n        if (t.unref) {\n          t.unref()\n        }\n        /* c8 ignore stop */\n      }\n    }\n\n    this.#updateItemAge = index => {\n      starts[index] = ttls[index] !== 0 ? perf.now() : 0\n    }\n\n    this.#statusTTL = (status, index) => {\n      if (ttls[index]) {\n        const ttl = ttls[index]\n        const start = starts[index]\n        /* c8 ignore next */\n        if (!ttl || !start) return\n        status.ttl = ttl\n        status.start = start\n        status.now = cachedNow || getNow()\n        const age = status.now - start\n        status.remainingTTL = ttl - age\n      }\n    }\n\n    // debounce calls to perf.now() to 1s so we're not hitting\n    // that costly call repeatedly.\n    let cachedNow = 0\n    const getNow = () => {\n      const n = perf.now()\n      if (this.ttlResolution > 0) {\n        cachedNow = n\n        const t = setTimeout(\n          () => (cachedNow = 0),\n          this.ttlResolution\n        )\n        // not available on all platforms\n        /* c8 ignore start */\n        if (t.unref) {\n          t.unref()\n        }\n        /* c8 ignore stop */\n      }\n      return n\n    }\n\n    this.getRemainingTTL = key => {\n      const index = this.#keyMap.get(key)\n      if (index === undefined) {\n        return 0\n      }\n      const ttl = ttls[index]\n      const start = starts[index]\n      if (!ttl || !start) {\n        return Infinity\n      }\n      const age = (cachedNow || getNow()) - start\n      return ttl - age\n    }\n\n    this.#isStale = index => {\n      const s = starts[index]\n      const t = ttls[index]\n      return !!t && !!s && (cachedNow || getNow()) - s > t\n    }\n  }\n\n  // conditionally set private methods related to TTL\n  #updateItemAge: (index: Index) => void = () => {}\n  #statusTTL: (status: LRUCache.Status<V>, index: Index) => void =\n    () => {}\n  #setItemTTL: (\n    index: Index,\n    ttl: LRUCache.Milliseconds,\n    start?: LRUCache.Milliseconds\n    // ignore because we never call this if we're not already in TTL mode\n    /* c8 ignore start */\n  ) => void = () => {}\n  /* c8 ignore stop */\n\n  #isStale: (index: Index) => boolean = () => false\n\n  #initializeSizeTracking() {\n    const sizes = new ZeroArray(this.#max)\n    this.#calculatedSize = 0\n    this.#sizes = sizes\n    this.#removeItemSize = index => {\n      this.#calculatedSize -= sizes[index] as number\n      sizes[index] = 0\n    }\n    this.#requireSize = (k, v, size, sizeCalculation) => {\n      // provisionally accept background fetches.\n      // actual value size will be checked when they return.\n      if (this.#isBackgroundFetch(v)) {\n        return 0\n      }\n      if (!isPosInt(size)) {\n        if (sizeCalculation) {\n          if (typeof sizeCalculation !== 'function') {\n            throw new TypeError('sizeCalculation must be a function')\n          }\n          size = sizeCalculation(v, k)\n          if (!isPosInt(size)) {\n            throw new TypeError(\n              'sizeCalculation return invalid (expect positive integer)'\n            )\n          }\n        } else {\n          throw new TypeError(\n            'invalid size value (must be positive integer). ' +\n              'When maxSize or maxEntrySize is used, sizeCalculation ' +\n              'or size must be set.'\n          )\n        }\n      }\n      return size\n    }\n    this.#addItemSize = (\n      index: Index,\n      size: LRUCache.Size,\n      status?: LRUCache.Status<V>\n    ) => {\n      sizes[index] = size\n      if (this.#maxSize) {\n        const maxSize = this.#maxSize - (sizes[index] as number)\n        while (this.#calculatedSize > maxSize) {\n          this.#evict(true)\n        }\n      }\n      this.#calculatedSize += sizes[index] as number\n      if (status) {\n        status.entrySize = size\n        status.totalCalculatedSize = this.#calculatedSize\n      }\n    }\n  }\n\n  #removeItemSize: (index: Index) => void = _i => {}\n  #addItemSize: (\n    index: Index,\n    size: LRUCache.Size,\n    status?: LRUCache.Status<V>\n  ) => void = (_i, _s, _st) => {}\n  #requireSize: (\n    k: K,\n    v: V | BackgroundFetch<V>,\n    size?: LRUCache.Size,\n    sizeCalculation?: LRUCache.SizeCalculator<K, V>\n  ) => LRUCache.Size = (\n    _k: K,\n    _v: V | BackgroundFetch<V>,\n    size?: LRUCache.Size,\n    sizeCalculation?: LRUCache.SizeCalculator<K, V>\n  ) => {\n    if (size || sizeCalculation) {\n      throw new TypeError(\n        'cannot set size without setting maxSize or maxEntrySize on cache'\n      )\n    }\n    return 0\n  };\n\n  *#indexes({ allowStale = this.allowStale } = {}) {\n    if (this.#size) {\n      for (let i = this.#tail; true; ) {\n        if (!this.#isValidIndex(i)) {\n          break\n        }\n        if (allowStale || !this.#isStale(i)) {\n          yield i\n        }\n        if (i === this.#head) {\n          break\n        } else {\n          i = this.#prev[i] as Index\n        }\n      }\n    }\n  }\n\n  *#rindexes({ allowStale = this.allowStale } = {}) {\n    if (this.#size) {\n      for (let i = this.#head; true; ) {\n        if (!this.#isValidIndex(i)) {\n          break\n        }\n        if (allowStale || !this.#isStale(i)) {\n          yield i\n        }\n        if (i === this.#tail) {\n          break\n        } else {\n          i = this.#next[i] as Index\n        }\n      }\n    }\n  }\n\n  #isValidIndex(index: Index) {\n    return (\n      index !== undefined &&\n      this.#keyMap.get(this.#keyList[index] as K) === index\n    )\n  }\n\n  /**\n   * Return a generator yielding `[key, value]` pairs,\n   * in order from most recently used to least recently used.\n   */\n  *entries() {\n    for (const i of this.#indexes()) {\n      if (\n        this.#valList[i] !== undefined &&\n        this.#keyList[i] !== undefined &&\n        !this.#isBackgroundFetch(this.#valList[i])\n      ) {\n        yield [this.#keyList[i], this.#valList[i]] as [K, V]\n      }\n    }\n  }\n\n  /**\n   * Inverse order version of {@link LRUCache.entries}\n   *\n   * Return a generator yielding `[key, value]` pairs,\n   * in order from least recently used to most recently used.\n   */\n  *rentries() {\n    for (const i of this.#rindexes()) {\n      if (\n        this.#valList[i] !== undefined &&\n        this.#keyList[i] !== undefined &&\n        !this.#isBackgroundFetch(this.#valList[i])\n      ) {\n        yield [this.#keyList[i], this.#valList[i]]\n      }\n    }\n  }\n\n  /**\n   * Return a generator yielding the keys in the cache,\n   * in order from most recently used to least recently used.\n   */\n  *keys() {\n    for (const i of this.#indexes()) {\n      const k = this.#keyList[i]\n      if (\n        k !== undefined &&\n        !this.#isBackgroundFetch(this.#valList[i])\n      ) {\n        yield k\n      }\n    }\n  }\n\n  /**\n   * Inverse order version of {@link LRUCache.keys}\n   *\n   * Return a generator yielding the keys in the cache,\n   * in order from least recently used to most recently used.\n   */\n  *rkeys() {\n    for (const i of this.#rindexes()) {\n      const k = this.#keyList[i]\n      if (\n        k !== undefined &&\n        !this.#isBackgroundFetch(this.#valList[i])\n      ) {\n        yield k\n      }\n    }\n  }\n\n  /**\n   * Return a generator yielding the values in the cache,\n   * in order from most recently used to least recently used.\n   */\n  *values() {\n    for (const i of this.#indexes()) {\n      const v = this.#valList[i]\n      if (\n        v !== undefined &&\n        !this.#isBackgroundFetch(this.#valList[i])\n      ) {\n        yield this.#valList[i] as V\n      }\n    }\n  }\n\n  /**\n   * Inverse order version of {@link LRUCache.values}\n   *\n   * Return a generator yielding the values in the cache,\n   * in order from least recently used to most recently used.\n   */\n  *rvalues() {\n    for (const i of this.#rindexes()) {\n      const v = this.#valList[i]\n      if (\n        v !== undefined &&\n        !this.#isBackgroundFetch(this.#valList[i])\n      ) {\n        yield this.#valList[i]\n      }\n    }\n  }\n\n  /**\n   * Iterating over the cache itself yields the same results as\n   * {@link LRUCache.entries}\n   */\n  [Symbol.iterator]() {\n    return this.entries()\n  }\n\n  /**\n   * A String value that is used in the creation of the default string\n   * description of an object. Called by the built-in method\n   * `Object.prototype.toString`.\n   */\n  [Symbol.toStringTag] = 'LRUCache'\n\n  /**\n   * Find a value for which the supplied fn method returns a truthy value,\n   * similar to `Array.find()`. fn is called as `fn(value, key, cache)`.\n   */\n  find(\n    fn: (v: V, k: K, self: LRUCache<K, V, FC>) => boolean,\n    getOptions: LRUCache.GetOptions<K, V, FC> = {}\n  ) {\n    for (const i of this.#indexes()) {\n      const v = this.#valList[i]\n      const value = this.#isBackgroundFetch(v)\n        ? v.__staleWhileFetching\n        : v\n      if (value === undefined) continue\n      if (fn(value, this.#keyList[i] as K, this)) {\n        return this.get(this.#keyList[i] as K, getOptions)\n      }\n    }\n  }\n\n  /**\n   * Call the supplied function on each item in the cache, in order from most\n   * recently used to least recently used.\n   *\n   * `fn` is called as `fn(value, key, cache)`.\n   *\n   * If `thisp` is provided, function will be called in the `this`-context of\n   * the provided object, or the cache if no `thisp` object is provided.\n   *\n   * Does not update age or recenty of use, or iterate over stale values.\n   */\n  forEach(\n    fn: (v: V, k: K, self: LRUCache<K, V, FC>) => any,\n    thisp: any = this\n  ) {\n    for (const i of this.#indexes()) {\n      const v = this.#valList[i]\n      const value = this.#isBackgroundFetch(v)\n        ? v.__staleWhileFetching\n        : v\n      if (value === undefined) continue\n      fn.call(thisp, value, this.#keyList[i] as K, this)\n    }\n  }\n\n  /**\n   * The same as {@link LRUCache.forEach} but items are iterated over in\n   * reverse order.  (ie, less recently used items are iterated over first.)\n   */\n  rforEach(\n    fn: (v: V, k: K, self: LRUCache<K, V, FC>) => any,\n    thisp: any = this\n  ) {\n    for (const i of this.#rindexes()) {\n      const v = this.#valList[i]\n      const value = this.#isBackgroundFetch(v)\n        ? v.__staleWhileFetching\n        : v\n      if (value === undefined) continue\n      fn.call(thisp, value, this.#keyList[i] as K, this)\n    }\n  }\n\n  /**\n   * Delete any stale entries. Returns true if anything was removed,\n   * false otherwise.\n   */\n  purgeStale() {\n    let deleted = false\n    for (const i of this.#rindexes({ allowStale: true })) {\n      if (this.#isStale(i)) {\n        this.#delete(this.#keyList[i] as K, 'expire')\n        deleted = true\n      }\n    }\n    return deleted\n  }\n\n  /**\n   * Get the extended info about a given entry, to get its value, size, and\n   * TTL info simultaneously. Returns `undefined` if the key is not present.\n   *\n   * Unlike {@link LRUCache#dump}, which is designed to be portable and survive\n   * serialization, the `start` value is always the current timestamp, and the\n   * `ttl` is a calculated remaining time to live (negative if expired).\n   *\n   * Always returns stale values, if their info is found in the cache, so be\n   * sure to check for expirations (ie, a negative {@link LRUCache.Entry#ttl})\n   * if relevant.\n   */\n  info(key: K): LRUCache.Entry<V> | undefined {\n    const i = this.#keyMap.get(key)\n    if (i === undefined) return undefined\n    const v = this.#valList[i]\n    const value: V | undefined = this.#isBackgroundFetch(v)\n      ? v.__staleWhileFetching\n      : v\n    if (value === undefined) return undefined\n    const entry: LRUCache.Entry<V> = { value }\n    if (this.#ttls && this.#starts) {\n      const ttl = this.#ttls[i]\n      const start = this.#starts[i]\n      if (ttl && start) {\n        const remain = ttl - (perf.now() - start)\n        entry.ttl = remain\n        entry.start = Date.now()\n      }\n    }\n    if (this.#sizes) {\n      entry.size = this.#sizes[i]\n    }\n    return entry\n  }\n\n  /**\n   * Return an array of [key, {@link LRUCache.Entry}] tuples which can be\n   * passed to {@link LRLUCache#load}.\n   *\n   * The `start` fields are calculated relative to a portable `Date.now()`\n   * timestamp, even if `performance.now()` is available.\n   *\n   * Stale entries are always included in the `dump`, even if\n   * {@link LRUCache.OptionsBase.allowStale} is false.\n   *\n   * Note: this returns an actual array, not a generator, so it can be more\n   * easily passed around.\n   */\n  dump() {\n    const arr: [K, LRUCache.Entry<V>][] = []\n    for (const i of this.#indexes({ allowStale: true })) {\n      const key = this.#keyList[i]\n      const v = this.#valList[i]\n      const value: V | undefined = this.#isBackgroundFetch(v)\n        ? v.__staleWhileFetching\n        : v\n      if (value === undefined || key === undefined) continue\n      const entry: LRUCache.Entry<V> = { value }\n      if (this.#ttls && this.#starts) {\n        entry.ttl = this.#ttls[i]\n        // always dump the start relative to a portable timestamp\n        // it's ok for this to be a bit slow, it's a rare operation.\n        const age = perf.now() - (this.#starts[i] as number)\n        entry.start = Math.floor(Date.now() - age)\n      }\n      if (this.#sizes) {\n        entry.size = this.#sizes[i]\n      }\n      arr.unshift([key, entry])\n    }\n    return arr\n  }\n\n  /**\n   * Reset the cache and load in the items in entries in the order listed.\n   *\n   * The shape of the resulting cache may be different if the same options are\n   * not used in both caches.\n   *\n   * The `start` fields are assumed to be calculated relative to a portable\n   * `Date.now()` timestamp, even if `performance.now()` is available.\n   */\n  load(arr: [K, LRUCache.Entry<V>][]) {\n    this.clear()\n    for (const [key, entry] of arr) {\n      if (entry.start) {\n        // entry.start is a portable timestamp, but we may be using\n        // node's performance.now(), so calculate the offset, so that\n        // we get the intended remaining TTL, no matter how long it's\n        // been on ice.\n        //\n        // it's ok for this to be a bit slow, it's a rare operation.\n        const age = Date.now() - entry.start\n        entry.start = perf.now() - age\n      }\n      this.set(key, entry.value, entry)\n    }\n  }\n\n  /**\n   * Add a value to the cache.\n   *\n   * Note: if `undefined` is specified as a value, this is an alias for\n   * {@link LRUCache#delete}\n   *\n   * Fields on the {@link LRUCache.SetOptions} options param will override\n   * their corresponding values in the constructor options for the scope\n   * of this single `set()` operation.\n   *\n   * If `start` is provided, then that will set the effective start\n   * time for the TTL calculation. Note that this must be a previous\n   * value of `performance.now()` if supported, or a previous value of\n   * `Date.now()` if not.\n   *\n   * Options object may also include `size`, which will prevent\n   * calling the `sizeCalculation` function and just use the specified\n   * number if it is a positive integer, and `noDisposeOnSet` which\n   * will prevent calling a `dispose` function in the case of\n   * overwrites.\n   *\n   * If the `size` (or return value of `sizeCalculation`) for a given\n   * entry is greater than `maxEntrySize`, then the item will not be\n   * added to the cache.\n   *\n   * Will update the recency of the entry.\n   *\n   * If the value is `undefined`, then this is an alias for\n   * `cache.delete(key)`. `undefined` is never stored in the cache.\n   */\n  set(\n    k: K,\n    v: V | BackgroundFetch<V> | undefined,\n    setOptions: LRUCache.SetOptions<K, V, FC> = {}\n  ) {\n    if (v === undefined) {\n      this.delete(k)\n      return this\n    }\n    const {\n      ttl = this.ttl,\n      start,\n      noDisposeOnSet = this.noDisposeOnSet,\n      sizeCalculation = this.sizeCalculation,\n      status,\n    } = setOptions\n    let { noUpdateTTL = this.noUpdateTTL } = setOptions\n\n    const size = this.#requireSize(\n      k,\n      v,\n      setOptions.size || 0,\n      sizeCalculation\n    )\n    // if the item doesn't fit, don't do anything\n    // NB: maxEntrySize set to maxSize by default\n    if (this.maxEntrySize && size > this.maxEntrySize) {\n      if (status) {\n        status.set = 'miss'\n        status.maxEntrySizeExceeded = true\n      }\n      // have to delete, in case something is there already.\n      this.#delete(k, 'set')\n      return this\n    }\n    let index = this.#size === 0 ? undefined : this.#keyMap.get(k)\n    if (index === undefined) {\n      // addition\n      index = (\n        this.#size === 0\n          ? this.#tail\n          : this.#free.length !== 0\n          ? this.#free.pop()\n          : this.#size === this.#max\n          ? this.#evict(false)\n          : this.#size\n      ) as Index\n      this.#keyList[index] = k\n      this.#valList[index] = v\n      this.#keyMap.set(k, index)\n      this.#next[this.#tail] = index\n      this.#prev[index] = this.#tail\n      this.#tail = index\n      this.#size++\n      this.#addItemSize(index, size, status)\n      if (status) status.set = 'add'\n      noUpdateTTL = false\n    } else {\n      // update\n      this.#moveToTail(index)\n      const oldVal = this.#valList[index] as V | BackgroundFetch<V>\n      if (v !== oldVal) {\n        if (this.#hasFetchMethod && this.#isBackgroundFetch(oldVal)) {\n          oldVal.__abortController.abort(new Error('replaced'))\n          const { __staleWhileFetching: s } = oldVal\n          if (s !== undefined && !noDisposeOnSet) {\n            if (this.#hasDispose) {\n              this.#dispose?.(s as V, k, 'set')\n            }\n            if (this.#hasDisposeAfter) {\n              this.#disposed?.push([s as V, k, 'set'])\n            }\n          }\n        } else if (!noDisposeOnSet) {\n          if (this.#hasDispose) {\n            this.#dispose?.(oldVal as V, k, 'set')\n          }\n          if (this.#hasDisposeAfter) {\n            this.#disposed?.push([oldVal as V, k, 'set'])\n          }\n        }\n        this.#removeItemSize(index)\n        this.#addItemSize(index, size, status)\n        this.#valList[index] = v\n        if (status) {\n          status.set = 'replace'\n          const oldValue =\n            oldVal && this.#isBackgroundFetch(oldVal)\n              ? oldVal.__staleWhileFetching\n              : oldVal\n          if (oldValue !== undefined) status.oldValue = oldValue\n        }\n      } else if (status) {\n        status.set = 'update'\n      }\n    }\n    if (ttl !== 0 && !this.#ttls) {\n      this.#initializeTTLTracking()\n    }\n    if (this.#ttls) {\n      if (!noUpdateTTL) {\n        this.#setItemTTL(index, ttl, start)\n      }\n      if (status) this.#statusTTL(status, index)\n    }\n    if (!noDisposeOnSet && this.#hasDisposeAfter && this.#disposed) {\n      const dt = this.#disposed\n      let task: DisposeTask<K, V> | undefined\n      while ((task = dt?.shift())) {\n        this.#disposeAfter?.(...task)\n      }\n    }\n    return this\n  }\n\n  /**\n   * Evict the least recently used item, returning its value or\n   * `undefined` if cache is empty.\n   */\n  pop(): V | undefined {\n    try {\n      while (this.#size) {\n        const val = this.#valList[this.#head]\n        this.#evict(true)\n        if (this.#isBackgroundFetch(val)) {\n          if (val.__staleWhileFetching) {\n            return val.__staleWhileFetching\n          }\n        } else if (val !== undefined) {\n          return val\n        }\n      }\n    } finally {\n      if (this.#hasDisposeAfter && this.#disposed) {\n        const dt = this.#disposed\n        let task: DisposeTask<K, V> | undefined\n        while ((task = dt?.shift())) {\n          this.#disposeAfter?.(...task)\n        }\n      }\n    }\n  }\n\n  #evict(free: boolean) {\n    const head = this.#head\n    const k = this.#keyList[head] as K\n    const v = this.#valList[head] as V\n    if (this.#hasFetchMethod && this.#isBackgroundFetch(v)) {\n      v.__abortController.abort(new Error('evicted'))\n    } else if (this.#hasDispose || this.#hasDisposeAfter) {\n      if (this.#hasDispose) {\n        this.#dispose?.(v, k, 'evict')\n      }\n      if (this.#hasDisposeAfter) {\n        this.#disposed?.push([v, k, 'evict'])\n      }\n    }\n    this.#removeItemSize(head)\n    // if we aren't about to use the index, then null these out\n    if (free) {\n      this.#keyList[head] = undefined\n      this.#valList[head] = undefined\n      this.#free.push(head)\n    }\n    if (this.#size === 1) {\n      this.#head = this.#tail = 0 as Index\n      this.#free.length = 0\n    } else {\n      this.#head = this.#next[head] as Index\n    }\n    this.#keyMap.delete(k)\n    this.#size--\n    return head\n  }\n\n  /**\n   * Check if a key is in the cache, without updating the recency of use.\n   * Will return false if the item is stale, even though it is technically\n   * in the cache.\n   *\n   * Check if a key is in the cache, without updating the recency of\n   * use. Age is updated if {@link LRUCache.OptionsBase.updateAgeOnHas} is set\n   * to `true` in either the options or the constructor.\n   *\n   * Will return `false` if the item is stale, even though it is technically in\n   * the cache. The difference can be determined (if it matters) by using a\n   * `status` argument, and inspecting the `has` field.\n   *\n   * Will not update item age unless\n   * {@link LRUCache.OptionsBase.updateAgeOnHas} is set.\n   */\n  has(k: K, hasOptions: LRUCache.HasOptions<K, V, FC> = {}) {\n    const { updateAgeOnHas = this.updateAgeOnHas, status } =\n      hasOptions\n    const index = this.#keyMap.get(k)\n    if (index !== undefined) {\n      const v = this.#valList[index]\n      if (\n        this.#isBackgroundFetch(v) &&\n        v.__staleWhileFetching === undefined\n      ) {\n        return false\n      }\n      if (!this.#isStale(index)) {\n        if (updateAgeOnHas) {\n          this.#updateItemAge(index)\n        }\n        if (status) {\n          status.has = 'hit'\n          this.#statusTTL(status, index)\n        }\n        return true\n      } else if (status) {\n        status.has = 'stale'\n        this.#statusTTL(status, index)\n      }\n    } else if (status) {\n      status.has = 'miss'\n    }\n    return false\n  }\n\n  /**\n   * Like {@link LRUCache#get} but doesn't update recency or delete stale\n   * items.\n   *\n   * Returns `undefined` if the item is stale, unless\n   * {@link LRUCache.OptionsBase.allowStale} is set.\n   */\n  peek(k: K, peekOptions: LRUCache.PeekOptions<K, V, FC> = {}) {\n    const { allowStale = this.allowStale } = peekOptions\n    const index = this.#keyMap.get(k)\n    if (\n      index === undefined ||\n      (!allowStale && this.#isStale(index))\n    ) {\n      return\n    }\n    const v = this.#valList[index]\n    // either stale and allowed, or forcing a refresh of non-stale value\n    return this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v\n  }\n\n  #backgroundFetch(\n    k: K,\n    index: Index | undefined,\n    options: LRUCache.FetchOptions<K, V, FC>,\n    context: any\n  ): BackgroundFetch<V> {\n    const v = index === undefined ? undefined : this.#valList[index]\n    if (this.#isBackgroundFetch(v)) {\n      return v\n    }\n\n    const ac = new AC()\n    const { signal } = options\n    // when/if our AC signals, then stop listening to theirs.\n    signal?.addEventListener('abort', () => ac.abort(signal.reason), {\n      signal: ac.signal,\n    })\n\n    const fetchOpts = {\n      signal: ac.signal,\n      options,\n      context,\n    }\n\n    const cb = (\n      v: V | undefined,\n      updateCache = false\n    ): V | undefined => {\n      const { aborted } = ac.signal\n      const ignoreAbort = options.ignoreFetchAbort && v !== undefined\n      if (options.status) {\n        if (aborted && !updateCache) {\n          options.status.fetchAborted = true\n          options.status.fetchError = ac.signal.reason\n          if (ignoreAbort) options.status.fetchAbortIgnored = true\n        } else {\n          options.status.fetchResolved = true\n        }\n      }\n      if (aborted && !ignoreAbort && !updateCache) {\n        return fetchFail(ac.signal.reason)\n      }\n      // either we didn't abort, and are still here, or we did, and ignored\n      const bf = p as BackgroundFetch<V>\n      if (this.#valList[index as Index] === p) {\n        if (v === undefined) {\n          if (bf.__staleWhileFetching) {\n            this.#valList[index as Index] = bf.__staleWhileFetching\n          } else {\n            this.#delete(k, 'fetch')\n          }\n        } else {\n          if (options.status) options.status.fetchUpdated = true\n          this.set(k, v, fetchOpts.options)\n        }\n      }\n      return v\n    }\n\n    const eb = (er: any) => {\n      if (options.status) {\n        options.status.fetchRejected = true\n        options.status.fetchError = er\n      }\n      return fetchFail(er)\n    }\n\n    const fetchFail = (er: any): V | undefined => {\n      const { aborted } = ac.signal\n      const allowStaleAborted =\n        aborted && options.allowStaleOnFetchAbort\n      const allowStale =\n        allowStaleAborted || options.allowStaleOnFetchRejection\n      const noDelete = allowStale || options.noDeleteOnFetchRejection\n      const bf = p as BackgroundFetch<V>\n      if (this.#valList[index as Index] === p) {\n        // if we allow stale on fetch rejections, then we need to ensure that\n        // the stale value is not removed from the cache when the fetch fails.\n        const del = !noDelete || bf.__staleWhileFetching === undefined\n        if (del) {\n          this.#delete(k, 'fetch')\n        } else if (!allowStaleAborted) {\n          // still replace the *promise* with the stale value,\n          // since we are done with the promise at this point.\n          // leave it untouched if we're still waiting for an\n          // aborted background fetch that hasn't yet returned.\n          this.#valList[index as Index] = bf.__staleWhileFetching\n        }\n      }\n      if (allowStale) {\n        if (options.status && bf.__staleWhileFetching !== undefined) {\n          options.status.returnedStale = true\n        }\n        return bf.__staleWhileFetching\n      } else if (bf.__returned === bf) {\n        throw er\n      }\n    }\n\n    const pcall = (\n      res: (v: V | undefined) => void,\n      rej: (e: any) => void\n    ) => {\n      const fmp = this.#fetchMethod?.(k, v, fetchOpts)\n      if (fmp && fmp instanceof Promise) {\n        fmp.then(v => res(v === undefined ? undefined : v), rej)\n      }\n      // ignored, we go until we finish, regardless.\n      // defer check until we are actually aborting,\n      // so fetchMethod can override.\n      ac.signal.addEventListener('abort', () => {\n        if (\n          !options.ignoreFetchAbort ||\n          options.allowStaleOnFetchAbort\n        ) {\n          res(undefined)\n          // when it eventually resolves, update the cache.\n          if (options.allowStaleOnFetchAbort) {\n            res = v => cb(v, true)\n          }\n        }\n      })\n    }\n\n    if (options.status) options.status.fetchDispatched = true\n    const p = new Promise(pcall).then(cb, eb)\n    const bf: BackgroundFetch<V> = Object.assign(p, {\n      __abortController: ac,\n      __staleWhileFetching: v,\n      __returned: undefined,\n    })\n\n    if (index === undefined) {\n      // internal, don't expose status.\n      this.set(k, bf, { ...fetchOpts.options, status: undefined })\n      index = this.#keyMap.get(k)\n    } else {\n      this.#valList[index] = bf\n    }\n    return bf\n  }\n\n  #isBackgroundFetch(p: any): p is BackgroundFetch<V> {\n    if (!this.#hasFetchMethod) return false\n    const b = p as BackgroundFetch<V>\n    return (\n      !!b &&\n      b instanceof Promise &&\n      b.hasOwnProperty('__staleWhileFetching') &&\n      b.__abortController instanceof AC\n    )\n  }\n\n  /**\n   * Make an asynchronous cached fetch using the\n   * {@link LRUCache.OptionsBase.fetchMethod} function.\n   *\n   * If the value is in the cache and not stale, then the returned\n   * Promise resolves to the value.\n   *\n   * If not in the cache, or beyond its TTL staleness, then\n   * `fetchMethod(key, staleValue, { options, signal, context })` is\n   * called, and the value returned will be added to the cache once\n   * resolved.\n   *\n   * If called with `allowStale`, and an asynchronous fetch is\n   * currently in progress to reload a stale value, then the former\n   * stale value will be returned.\n   *\n   * If called with `forceRefresh`, then the cached item will be\n   * re-fetched, even if it is not stale. However, if `allowStale` is also\n   * set, then the old value will still be returned. This is useful\n   * in cases where you want to force a reload of a cached value. If\n   * a background fetch is already in progress, then `forceRefresh`\n   * has no effect.\n   *\n   * If multiple fetches for the same key are issued, then they will all be\n   * coalesced into a single call to fetchMethod.\n   *\n   * Note that this means that handling options such as\n   * {@link LRUCache.OptionsBase.allowStaleOnFetchAbort},\n   * {@link LRUCache.FetchOptions.signal},\n   * and {@link LRUCache.OptionsBase.allowStaleOnFetchRejection} will be\n   * determined by the FIRST fetch() call for a given key.\n   *\n   * This is a known (fixable) shortcoming which will be addresed on when\n   * someone complains about it, as the fix would involve added complexity and\n   * may not be worth the costs for this edge case.\n   *\n   * If {@link LRUCache.OptionsBase.fetchMethod} is not specified, then this is\n   * effectively an alias for `Promise.resolve(cache.get(key))`.\n   *\n   * When the fetch method resolves to a value, if the fetch has not\n   * been aborted due to deletion, eviction, or being overwritten,\n   * then it is added to the cache using the options provided.\n   *\n   * If the key is evicted or deleted before the `fetchMethod`\n   * resolves, then the AbortSignal passed to the `fetchMethod` will\n   * receive an `abort` event, and the promise returned by `fetch()`\n   * will reject with the reason for the abort.\n   *\n   * If a `signal` is passed to the `fetch()` call, then aborting the\n   * signal will abort the fetch and cause the `fetch()` promise to\n   * reject with the reason provided.\n   *\n   * **Setting `context`**\n   *\n   * If an `FC` type is set to a type other than `unknown`, `void`, or\n   * `undefined` in the {@link LRUCache} constructor, then all\n   * calls to `cache.fetch()` _must_ provide a `context` option. If\n   * set to `undefined` or `void`, then calls to fetch _must not_\n   * provide a `context` option.\n   *\n   * The `context` param allows you to provide arbitrary data that\n   * might be relevant in the course of fetching the data. It is only\n   * relevant for the course of a single `fetch()` operation, and\n   * discarded afterwards.\n   *\n   * **Note: `fetch()` calls are inflight-unique**\n   *\n   * If you call `fetch()` multiple times with the same key value,\n   * then every call after the first will resolve on the same\n   * promise<sup>1</sup>,\n   * _even if they have different settings that would otherwise change\n   * the behavior of the fetch_, such as `noDeleteOnFetchRejection`\n   * or `ignoreFetchAbort`.\n   *\n   * In most cases, this is not a problem (in fact, only fetching\n   * something once is what you probably want, if you're caching in\n   * the first place). If you are changing the fetch() options\n   * dramatically between runs, there's a good chance that you might\n   * be trying to fit divergent semantics into a single object, and\n   * would be better off with multiple cache instances.\n   *\n   * **1**: Ie, they're not the \"same Promise\", but they resolve at\n   * the same time, because they're both waiting on the same\n   * underlying fetchMethod response.\n   */\n\n  fetch(\n    k: K,\n    fetchOptions: unknown extends FC\n      ? LRUCache.FetchOptions<K, V, FC>\n      : FC extends undefined | void\n      ? LRUCache.FetchOptionsNoContext<K, V>\n      : LRUCache.FetchOptionsWithContext<K, V, FC>\n  ): Promise<undefined | V>\n\n  // this overload not allowed if context is required\n  fetch(\n    k: unknown extends FC\n      ? K\n      : FC extends undefined | void\n      ? K\n      : never,\n    fetchOptions?: unknown extends FC\n      ? LRUCache.FetchOptions<K, V, FC>\n      : FC extends undefined | void\n      ? LRUCache.FetchOptionsNoContext<K, V>\n      : never\n  ): Promise<undefined | V>\n\n  async fetch(\n    k: K,\n    fetchOptions: LRUCache.FetchOptions<K, V, FC> = {}\n  ): Promise<undefined | V> {\n    const {\n      // get options\n      allowStale = this.allowStale,\n      updateAgeOnGet = this.updateAgeOnGet,\n      noDeleteOnStaleGet = this.noDeleteOnStaleGet,\n      // set options\n      ttl = this.ttl,\n      noDisposeOnSet = this.noDisposeOnSet,\n      size = 0,\n      sizeCalculation = this.sizeCalculation,\n      noUpdateTTL = this.noUpdateTTL,\n      // fetch exclusive options\n      noDeleteOnFetchRejection = this.noDeleteOnFetchRejection,\n      allowStaleOnFetchRejection = this.allowStaleOnFetchRejection,\n      ignoreFetchAbort = this.ignoreFetchAbort,\n      allowStaleOnFetchAbort = this.allowStaleOnFetchAbort,\n      context,\n      forceRefresh = false,\n      status,\n      signal,\n    } = fetchOptions\n\n    if (!this.#hasFetchMethod) {\n      if (status) status.fetch = 'get'\n      return this.get(k, {\n        allowStale,\n        updateAgeOnGet,\n        noDeleteOnStaleGet,\n        status,\n      })\n    }\n\n    const options = {\n      allowStale,\n      updateAgeOnGet,\n      noDeleteOnStaleGet,\n      ttl,\n      noDisposeOnSet,\n      size,\n      sizeCalculation,\n      noUpdateTTL,\n      noDeleteOnFetchRejection,\n      allowStaleOnFetchRejection,\n      allowStaleOnFetchAbort,\n      ignoreFetchAbort,\n      status,\n      signal,\n    }\n\n    let index = this.#keyMap.get(k)\n    if (index === undefined) {\n      if (status) status.fetch = 'miss'\n      const p = this.#backgroundFetch(k, index, options, context)\n      return (p.__returned = p)\n    } else {\n      // in cache, maybe already fetching\n      const v = this.#valList[index]\n      if (this.#isBackgroundFetch(v)) {\n        const stale =\n          allowStale && v.__staleWhileFetching !== undefined\n        if (status) {\n          status.fetch = 'inflight'\n          if (stale) status.returnedStale = true\n        }\n        return stale ? v.__staleWhileFetching : (v.__returned = v)\n      }\n\n      // if we force a refresh, that means do NOT serve the cached value,\n      // unless we are already in the process of refreshing the cache.\n      const isStale = this.#isStale(index)\n      if (!forceRefresh && !isStale) {\n        if (status) status.fetch = 'hit'\n        this.#moveToTail(index)\n        if (updateAgeOnGet) {\n          this.#updateItemAge(index)\n        }\n        if (status) this.#statusTTL(status, index)\n        return v\n      }\n\n      // ok, it is stale or a forced refresh, and not already fetching.\n      // refresh the cache.\n      const p = this.#backgroundFetch(k, index, options, context)\n      const hasStale = p.__staleWhileFetching !== undefined\n      const staleVal = hasStale && allowStale\n      if (status) {\n        status.fetch = isStale ? 'stale' : 'refresh'\n        if (staleVal && isStale) status.returnedStale = true\n      }\n      return staleVal ? p.__staleWhileFetching : (p.__returned = p)\n    }\n  }\n\n  /**\n   * In some cases, `cache.fetch()` may resolve to `undefined`, either because\n   * a {@link LRUCache.OptionsBase#fetchMethod} was not provided (turning\n   * `cache.fetch(k)` into just an async wrapper around `cache.get(k)`) or\n   * because `ignoreFetchAbort` was specified (either to the constructor or\n   * in the {@link LRUCache.FetchOptions}). Also, the\n   * {@link OptionsBase.fetchMethod} may return `undefined` or `void`, making\n   * the test even more complicated.\n   *\n   * Because inferring the cases where `undefined` might be returned are so\n   * cumbersome, but testing for `undefined` can also be annoying, this method\n   * can be used, which will reject if `this.fetch()` resolves to undefined.\n   */\n  forceFetch(\n    k: K,\n    fetchOptions: unknown extends FC\n      ? LRUCache.FetchOptions<K, V, FC>\n      : FC extends undefined | void\n      ? LRUCache.FetchOptionsNoContext<K, V>\n      : LRUCache.FetchOptionsWithContext<K, V, FC>\n  ): Promise<V>\n  // this overload not allowed if context is required\n  forceFetch(\n    k: unknown extends FC\n      ? K\n      : FC extends undefined | void\n      ? K\n      : never,\n    fetchOptions?: unknown extends FC\n      ? LRUCache.FetchOptions<K, V, FC>\n      : FC extends undefined | void\n      ? LRUCache.FetchOptionsNoContext<K, V>\n      : never\n  ): Promise<V>\n  async forceFetch(\n    k: K,\n    fetchOptions: LRUCache.FetchOptions<K, V, FC> = {}\n  ): Promise<V> {\n    const v = await this.fetch(\n      k,\n      fetchOptions as unknown extends FC\n        ? LRUCache.FetchOptions<K, V, FC>\n        : FC extends undefined | void\n        ? LRUCache.FetchOptionsNoContext<K, V>\n        : LRUCache.FetchOptionsWithContext<K, V, FC>\n    )\n    if (v === undefined) throw new Error('fetch() returned undefined')\n    return v\n  }\n\n  /**\n   * If the key is found in the cache, then this is equivalent to\n   * {@link LRUCache#get}. If not, in the cache, then calculate the value using\n   * the {@link LRUCache.OptionsBase.memoMethod}, and add it to the cache.\n   *\n   * If an `FC` type is set to a type other than `unknown`, `void`, or\n   * `undefined` in the LRUCache constructor, then all calls to `cache.memo()`\n   * _must_ provide a `context` option. If set to `undefined` or `void`, then\n   * calls to memo _must not_ provide a `context` option.\n   *\n   * The `context` param allows you to provide arbitrary data that might be\n   * relevant in the course of fetching the data. It is only relevant for the\n   * course of a single `memo()` operation, and discarded afterwards.\n   */\n  memo(\n    k: K,\n    memoOptions: unknown extends FC\n      ? LRUCache.MemoOptions<K, V, FC>\n      : FC extends undefined | void\n      ? LRUCache.MemoOptionsNoContext<K, V>\n      : LRUCache.MemoOptionsWithContext<K, V, FC>\n  ): V\n  // this overload not allowed if context is required\n  memo(\n    k: unknown extends FC\n      ? K\n      : FC extends undefined | void\n      ? K\n      : never,\n    memoOptions?: unknown extends FC\n      ? LRUCache.MemoOptions<K, V, FC>\n      : FC extends undefined | void\n      ? LRUCache.MemoOptionsNoContext<K, V>\n      : never\n  ): V\n  memo(k: K, memoOptions: LRUCache.MemoOptions<K, V, FC> = {}) {\n    const memoMethod = this.#memoMethod\n    if (!memoMethod) {\n      throw new Error('no memoMethod provided to constructor')\n    }\n    const { context, forceRefresh, ...options } = memoOptions\n    const v = this.get(k, options)\n    if (!forceRefresh && v !== undefined) return v\n    const vv = memoMethod(k, v, {\n      options,\n      context,\n    } as LRUCache.MemoizerOptions<K, V, FC>)\n    this.set(k, vv, options)\n    return vv\n  }\n\n  /**\n   * Return a value from the cache. Will update the recency of the cache\n   * entry found.\n   *\n   * If the key is not found, get() will return `undefined`.\n   */\n  get(k: K, getOptions: LRUCache.GetOptions<K, V, FC> = {}) {\n    const {\n      allowStale = this.allowStale,\n      updateAgeOnGet = this.updateAgeOnGet,\n      noDeleteOnStaleGet = this.noDeleteOnStaleGet,\n      status,\n    } = getOptions\n    const index = this.#keyMap.get(k)\n    if (index !== undefined) {\n      const value = this.#valList[index]\n      const fetching = this.#isBackgroundFetch(value)\n      if (status) this.#statusTTL(status, index)\n      if (this.#isStale(index)) {\n        if (status) status.get = 'stale'\n        // delete only if not an in-flight background fetch\n        if (!fetching) {\n          if (!noDeleteOnStaleGet) {\n            this.#delete(k, 'expire')\n          }\n          if (status && allowStale) status.returnedStale = true\n          return allowStale ? value : undefined\n        } else {\n          if (\n            status &&\n            allowStale &&\n            value.__staleWhileFetching !== undefined\n          ) {\n            status.returnedStale = true\n          }\n          return allowStale ? value.__staleWhileFetching : undefined\n        }\n      } else {\n        if (status) status.get = 'hit'\n        // if we're currently fetching it, we don't actually have it yet\n        // it's not stale, which means this isn't a staleWhileRefetching.\n        // If it's not stale, and fetching, AND has a __staleWhileFetching\n        // value, then that means the user fetched with {forceRefresh:true},\n        // so it's safe to return that value.\n        if (fetching) {\n          return value.__staleWhileFetching\n        }\n        this.#moveToTail(index)\n        if (updateAgeOnGet) {\n          this.#updateItemAge(index)\n        }\n        return value\n      }\n    } else if (status) {\n      status.get = 'miss'\n    }\n  }\n\n  #connect(p: Index, n: Index) {\n    this.#prev[n] = p\n    this.#next[p] = n\n  }\n\n  #moveToTail(index: Index): void {\n    // if tail already, nothing to do\n    // if head, move head to next[index]\n    // else\n    //   move next[prev[index]] to next[index] (head has no prev)\n    //   move prev[next[index]] to prev[index]\n    // prev[index] = tail\n    // next[tail] = index\n    // tail = index\n    if (index !== this.#tail) {\n      if (index === this.#head) {\n        this.#head = this.#next[index] as Index\n      } else {\n        this.#connect(\n          this.#prev[index] as Index,\n          this.#next[index] as Index\n        )\n      }\n      this.#connect(this.#tail, index)\n      this.#tail = index\n    }\n  }\n\n  /**\n   * Deletes a key out of the cache.\n   *\n   * Returns true if the key was deleted, false otherwise.\n   */\n  delete(k: K) {\n    return this.#delete(k, 'delete')\n  }\n\n  #delete(k: K, reason: LRUCache.DisposeReason) {\n    let deleted = false\n    if (this.#size !== 0) {\n      const index = this.#keyMap.get(k)\n      if (index !== undefined) {\n        deleted = true\n        if (this.#size === 1) {\n          this.#clear(reason)\n        } else {\n          this.#removeItemSize(index)\n          const v = this.#valList[index]\n          if (this.#isBackgroundFetch(v)) {\n            v.__abortController.abort(new Error('deleted'))\n          } else if (this.#hasDispose || this.#hasDisposeAfter) {\n            if (this.#hasDispose) {\n              this.#dispose?.(v as V, k, reason)\n            }\n            if (this.#hasDisposeAfter) {\n              this.#disposed?.push([v as V, k, reason])\n            }\n          }\n          this.#keyMap.delete(k)\n          this.#keyList[index] = undefined\n          this.#valList[index] = undefined\n          if (index === this.#tail) {\n            this.#tail = this.#prev[index] as Index\n          } else if (index === this.#head) {\n            this.#head = this.#next[index] as Index\n          } else {\n            const pi = this.#prev[index] as number\n            this.#next[pi] = this.#next[index] as number\n            const ni = this.#next[index] as number\n            this.#prev[ni] = this.#prev[index] as number\n          }\n          this.#size--\n          this.#free.push(index)\n        }\n      }\n    }\n    if (this.#hasDisposeAfter && this.#disposed?.length) {\n      const dt = this.#disposed\n      let task: DisposeTask<K, V> | undefined\n      while ((task = dt?.shift())) {\n        this.#disposeAfter?.(...task)\n      }\n    }\n    return deleted\n  }\n\n  /**\n   * Clear the cache entirely, throwing away all values.\n   */\n  clear() {\n    return this.#clear('delete')\n  }\n  #clear(reason: LRUCache.DisposeReason) {\n    for (const index of this.#rindexes({ allowStale: true })) {\n      const v = this.#valList[index]\n      if (this.#isBackgroundFetch(v)) {\n        v.__abortController.abort(new Error('deleted'))\n      } else {\n        const k = this.#keyList[index]\n        if (this.#hasDispose) {\n          this.#dispose?.(v as V, k as K, reason)\n        }\n        if (this.#hasDisposeAfter) {\n          this.#disposed?.push([v as V, k as K, reason])\n        }\n      }\n    }\n\n    this.#keyMap.clear()\n    this.#valList.fill(undefined)\n    this.#keyList.fill(undefined)\n    if (this.#ttls && this.#starts) {\n      this.#ttls.fill(0)\n      this.#starts.fill(0)\n    }\n    if (this.#sizes) {\n      this.#sizes.fill(0)\n    }\n    this.#head = 0 as Index\n    this.#tail = 0 as Index\n    this.#free.length = 0\n    this.#calculatedSize = 0\n    this.#size = 0\n    if (this.#hasDisposeAfter && this.#disposed) {\n      const dt = this.#disposed\n      let task: DisposeTask<K, V> | undefined\n      while ((task = dt?.shift())) {\n        this.#disposeAfter?.(...task)\n      }\n    }\n  }\n}\n","import { LRUCache } from 'lru-cache'\nimport { posix, win32 } from 'node:path'\n\nimport { fileURLToPath } from 'node:url'\n\nimport {\n  lstatSync,\n  readdir as readdirCB,\n  readdirSync,\n  readlinkSync,\n  realpathSync as rps,\n} from 'fs'\nimport * as actualFS from 'node:fs'\n\nconst realpathSync = rps.native\n// TODO: test perf of fs/promises realpath vs realpathCB,\n// since the promises one uses realpath.native\n\nimport { lstat, readdir, readlink, realpath } from 'node:fs/promises'\n\nimport { Minipass } from 'minipass'\nimport type { Dirent, Stats } from 'node:fs'\n\n/**\n * An object that will be used to override the default `fs`\n * methods.  Any methods that are not overridden will use Node's\n * built-in implementations.\n *\n * - lstatSync\n * - readdir (callback `withFileTypes` Dirent variant, used for\n *   readdirCB and most walks)\n * - readdirSync\n * - readlinkSync\n * - realpathSync\n * - promises: Object containing the following async methods:\n *   - lstat\n *   - readdir (Dirent variant only)\n *   - readlink\n *   - realpath\n */\nexport interface FSOption {\n  lstatSync?: (path: string) => Stats\n  readdir?: (\n    path: string,\n    options: { withFileTypes: true },\n    cb: (er: NodeJS.ErrnoException | null, entries?: Dirent[]) => any,\n  ) => void\n  readdirSync?: (\n    path: string,\n    options: { withFileTypes: true },\n  ) => Dirent[]\n  readlinkSync?: (path: string) => string\n  realpathSync?: (path: string) => string\n  promises?: {\n    lstat?: (path: string) => Promise<Stats>\n    readdir?: (\n      path: string,\n      options: { withFileTypes: true },\n    ) => Promise<Dirent[]>\n    readlink?: (path: string) => Promise<string>\n    realpath?: (path: string) => Promise<string>\n    [k: string]: any\n  }\n  [k: string]: any\n}\n\ninterface FSValue {\n  lstatSync: (path: string) => Stats\n  readdir: (\n    path: string,\n    options: { withFileTypes: true },\n    cb: (er: NodeJS.ErrnoException | null, entries?: Dirent[]) => any,\n  ) => void\n  readdirSync: (path: string, options: { withFileTypes: true }) => Dirent[]\n  readlinkSync: (path: string) => string\n  realpathSync: (path: string) => string\n  promises: {\n    lstat: (path: string) => Promise<Stats>\n    readdir: (\n      path: string,\n      options: { withFileTypes: true },\n    ) => Promise<Dirent[]>\n    readlink: (path: string) => Promise<string>\n    realpath: (path: string) => Promise<string>\n    [k: string]: any\n  }\n  [k: string]: any\n}\n\nconst defaultFS: FSValue = {\n  lstatSync,\n  readdir: readdirCB,\n  readdirSync,\n  readlinkSync,\n  realpathSync,\n  promises: {\n    lstat,\n    readdir,\n    readlink,\n    realpath,\n  },\n}\n\n// if they just gave us require('fs') then use our default\nconst fsFromOption = (fsOption?: FSOption): FSValue =>\n  !fsOption || fsOption === defaultFS || fsOption === actualFS ?\n    defaultFS\n  : {\n      ...defaultFS,\n      ...fsOption,\n      promises: {\n        ...defaultFS.promises,\n        ...(fsOption.promises || {}),\n      },\n    }\n\n// turn something like //?/c:/ into c:\\\nconst uncDriveRegexp = /^\\\\\\\\\\?\\\\([a-z]:)\\\\?$/i\nconst uncToDrive = (rootPath: string): string =>\n  rootPath.replace(/\\//g, '\\\\').replace(uncDriveRegexp, '$1\\\\')\n\n// windows paths are separated by either / or \\\nconst eitherSep = /[\\\\\\/]/\n\nconst UNKNOWN = 0 // may not even exist, for all we know\nconst IFIFO = 0b0001\nconst IFCHR = 0b0010\nconst IFDIR = 0b0100\nconst IFBLK = 0b0110\nconst IFREG = 0b1000\nconst IFLNK = 0b1010\nconst IFSOCK = 0b1100\nconst IFMT = 0b1111\n\nexport type Type =\n  | 'Unknown'\n  | 'FIFO'\n  | 'CharacterDevice'\n  | 'Directory'\n  | 'BlockDevice'\n  | 'File'\n  | 'SymbolicLink'\n  | 'Socket'\n\n// mask to unset low 4 bits\nconst IFMT_UNKNOWN = ~IFMT\n\n// set after successfully calling readdir() and getting entries.\nconst READDIR_CALLED = 0b0000_0001_0000\n// set after a successful lstat()\nconst LSTAT_CALLED = 0b0000_0010_0000\n// set if an entry (or one of its parents) is definitely not a dir\nconst ENOTDIR = 0b0000_0100_0000\n// set if an entry (or one of its parents) does not exist\n// (can also be set on lstat errors like EACCES or ENAMETOOLONG)\nconst ENOENT = 0b0000_1000_0000\n// cannot have child entries -- also verify &IFMT is either IFDIR or IFLNK\n// set if we fail to readlink\nconst ENOREADLINK = 0b0001_0000_0000\n// set if we know realpath() will fail\nconst ENOREALPATH = 0b0010_0000_0000\n\nconst ENOCHILD = ENOTDIR | ENOENT | ENOREALPATH\nconst TYPEMASK = 0b0011_1111_1111\n\nconst entToType = (s: Dirent | Stats) =>\n  s.isFile() ? IFREG\n  : s.isDirectory() ? IFDIR\n  : s.isSymbolicLink() ? IFLNK\n  : s.isCharacterDevice() ? IFCHR\n  : s.isBlockDevice() ? IFBLK\n  : s.isSocket() ? IFSOCK\n  : s.isFIFO() ? IFIFO\n  : UNKNOWN\n\n// normalize unicode path names\nconst normalizeCache = new Map<string, string>()\nconst normalize = (s: string) => {\n  const c = normalizeCache.get(s)\n  if (c) return c\n  const n = s.normalize('NFKD')\n  normalizeCache.set(s, n)\n  return n\n}\n\nconst normalizeNocaseCache = new Map<string, string>()\nconst normalizeNocase = (s: string) => {\n  const c = normalizeNocaseCache.get(s)\n  if (c) return c\n  const n = normalize(s.toLowerCase())\n  normalizeNocaseCache.set(s, n)\n  return n\n}\n\n/**\n * Options that may be provided to the Path constructor\n */\nexport interface PathOpts {\n  fullpath?: string\n  relative?: string\n  relativePosix?: string\n  parent?: PathBase\n  /**\n   * See {@link FSOption}\n   */\n  fs?: FSOption\n}\n\n/**\n * An LRUCache for storing resolved path strings or Path objects.\n * @internal\n */\nexport class ResolveCache extends LRUCache<string, string> {\n  constructor() {\n    super({ max: 256 })\n  }\n}\n\n// In order to prevent blowing out the js heap by allocating hundreds of\n// thousands of Path entries when walking extremely large trees, the \"children\"\n// in this tree are represented by storing an array of Path entries in an\n// LRUCache, indexed by the parent.  At any time, Path.children() may return an\n// empty array, indicating that it doesn't know about any of its children, and\n// thus has to rebuild that cache.  This is fine, it just means that we don't\n// benefit as much from having the cached entries, but huge directory walks\n// don't blow out the stack, and smaller ones are still as fast as possible.\n//\n//It does impose some complexity when building up the readdir data, because we\n//need to pass a reference to the children array that we started with.\n\n/**\n * an LRUCache for storing child entries.\n * @internal\n */\nexport class ChildrenCache extends LRUCache<PathBase, Children> {\n  constructor(maxSize: number = 16 * 1024) {\n    super({\n      maxSize,\n      // parent + children\n      sizeCalculation: a => a.length + 1,\n    })\n  }\n}\n\n/**\n * Array of Path objects, plus a marker indicating the first provisional entry\n *\n * @internal\n */\nexport type Children = PathBase[] & { provisional: number }\n\nconst setAsCwd = Symbol('PathScurry setAsCwd')\n\n/**\n * Path objects are sort of like a super-powered\n * {@link https://nodejs.org/docs/latest/api/fs.html#class-fsdirent fs.Dirent}\n *\n * Each one represents a single filesystem entry on disk, which may or may not\n * exist. It includes methods for reading various types of information via\n * lstat, readlink, and readdir, and caches all information to the greatest\n * degree possible.\n *\n * Note that fs operations that would normally throw will instead return an\n * \"empty\" value. This is in order to prevent excessive overhead from error\n * stack traces.\n */\nexport abstract class PathBase implements Dirent {\n  /**\n   * the basename of this path\n   *\n   * **Important**: *always* test the path name against any test string\n   * usingthe {@link isNamed} method, and not by directly comparing this\n   * string. Otherwise, unicode path strings that the system sees as identical\n   * will not be properly treated as the same path, leading to incorrect\n   * behavior and possible security issues.\n   */\n  name: string\n  /**\n   * the Path entry corresponding to the path root.\n   *\n   * @internal\n   */\n  root: PathBase\n  /**\n   * All roots found within the current PathScurry family\n   *\n   * @internal\n   */\n  roots: { [k: string]: PathBase }\n  /**\n   * a reference to the parent path, or undefined in the case of root entries\n   *\n   * @internal\n   */\n  parent?: PathBase\n  /**\n   * boolean indicating whether paths are compared case-insensitively\n   * @internal\n   */\n  nocase: boolean\n\n  /**\n   * boolean indicating that this path is the current working directory\n   * of the PathScurry collection that contains it.\n   */\n  isCWD: boolean = false\n\n  /**\n   * the string or regexp used to split paths. On posix, it is `'/'`, and on\n   * windows it is a RegExp matching either `'/'` or `'\\\\'`\n   */\n  abstract splitSep: string | RegExp\n  /**\n   * The path separator string to use when joining paths\n   */\n  abstract sep: string\n\n  // potential default fs override\n  #fs: FSValue\n\n  // Stats fields\n  #dev?: number\n  get dev() {\n    return this.#dev\n  }\n  #mode?: number\n  get mode() {\n    return this.#mode\n  }\n  #nlink?: number\n  get nlink() {\n    return this.#nlink\n  }\n  #uid?: number\n  get uid() {\n    return this.#uid\n  }\n  #gid?: number\n  get gid() {\n    return this.#gid\n  }\n  #rdev?: number\n  get rdev() {\n    return this.#rdev\n  }\n  #blksize?: number\n  get blksize() {\n    return this.#blksize\n  }\n  #ino?: number\n  get ino() {\n    return this.#ino\n  }\n  #size?: number\n  get size() {\n    return this.#size\n  }\n  #blocks?: number\n  get blocks() {\n    return this.#blocks\n  }\n  #atimeMs?: number\n  get atimeMs() {\n    return this.#atimeMs\n  }\n  #mtimeMs?: number\n  get mtimeMs() {\n    return this.#mtimeMs\n  }\n  #ctimeMs?: number\n  get ctimeMs() {\n    return this.#ctimeMs\n  }\n  #birthtimeMs?: number\n  get birthtimeMs() {\n    return this.#birthtimeMs\n  }\n  #atime?: Date\n  get atime() {\n    return this.#atime\n  }\n  #mtime?: Date\n  get mtime() {\n    return this.#mtime\n  }\n  #ctime?: Date\n  get ctime() {\n    return this.#ctime\n  }\n  #birthtime?: Date\n  get birthtime() {\n    return this.#birthtime\n  }\n\n  #matchName: string\n  #depth?: number\n  #fullpath?: string\n  #fullpathPosix?: string\n  #relative?: string\n  #relativePosix?: string\n  #type: number\n  #children: ChildrenCache\n  #linkTarget?: PathBase\n  #realpath?: PathBase\n\n  /**\n   * This property is for compatibility with the Dirent class as of\n   * Node v20, where Dirent['parentPath'] refers to the path of the\n   * directory that was passed to readdir. For root entries, it's the path\n   * to the entry itself.\n   */\n  get parentPath(): string {\n    return (this.parent || this).fullpath()\n  }\n\n  /**\n   * Deprecated alias for Dirent['parentPath'] Somewhat counterintuitively,\n   * this property refers to the *parent* path, not the path object itself.\n   */\n  get path(): string {\n    return this.parentPath\n  }\n\n  /**\n   * Do not create new Path objects directly.  They should always be accessed\n   * via the PathScurry class or other methods on the Path class.\n   *\n   * @internal\n   */\n  constructor(\n    name: string,\n    type: number = UNKNOWN,\n    root: PathBase | undefined,\n    roots: { [k: string]: PathBase },\n    nocase: boolean,\n    children: ChildrenCache,\n    opts: PathOpts,\n  ) {\n    this.name = name\n    this.#matchName = nocase ? normalizeNocase(name) : normalize(name)\n    this.#type = type & TYPEMASK\n    this.nocase = nocase\n    this.roots = roots\n    this.root = root || this\n    this.#children = children\n    this.#fullpath = opts.fullpath\n    this.#relative = opts.relative\n    this.#relativePosix = opts.relativePosix\n    this.parent = opts.parent\n    if (this.parent) {\n      this.#fs = this.parent.#fs\n    } else {\n      this.#fs = fsFromOption(opts.fs)\n    }\n  }\n\n  /**\n   * Returns the depth of the Path object from its root.\n   *\n   * For example, a path at `/foo/bar` would have a depth of 2.\n   */\n  depth(): number {\n    if (this.#depth !== undefined) return this.#depth\n    if (!this.parent) return (this.#depth = 0)\n    return (this.#depth = this.parent.depth() + 1)\n  }\n\n  /**\n   * @internal\n   */\n  abstract getRootString(path: string): string\n  /**\n   * @internal\n   */\n  abstract getRoot(rootPath: string): PathBase\n  /**\n   * @internal\n   */\n  abstract newChild(name: string, type?: number, opts?: PathOpts): PathBase\n\n  /**\n   * @internal\n   */\n  childrenCache() {\n    return this.#children\n  }\n\n  /**\n   * Get the Path object referenced by the string path, resolved from this Path\n   */\n  resolve(path?: string): PathBase {\n    if (!path) {\n      return this\n    }\n    const rootPath = this.getRootString(path)\n    const dir = path.substring(rootPath.length)\n    const dirParts = dir.split(this.splitSep)\n    const result: PathBase =\n      rootPath ?\n        this.getRoot(rootPath).#resolveParts(dirParts)\n      : this.#resolveParts(dirParts)\n    return result\n  }\n\n  #resolveParts(dirParts: string[]) {\n    let p: PathBase = this\n    for (const part of dirParts) {\n      p = p.child(part)\n    }\n    return p\n  }\n\n  /**\n   * Returns the cached children Path objects, if still available.  If they\n   * have fallen out of the cache, then returns an empty array, and resets the\n   * READDIR_CALLED bit, so that future calls to readdir() will require an fs\n   * lookup.\n   *\n   * @internal\n   */\n  children(): Children {\n    const cached = this.#children.get(this)\n    if (cached) {\n      return cached\n    }\n    const children: Children = Object.assign([], { provisional: 0 })\n    this.#children.set(this, children)\n    this.#type &= ~READDIR_CALLED\n    return children\n  }\n\n  /**\n   * Resolves a path portion and returns or creates the child Path.\n   *\n   * Returns `this` if pathPart is `''` or `'.'`, or `parent` if pathPart is\n   * `'..'`.\n   *\n   * This should not be called directly.  If `pathPart` contains any path\n   * separators, it will lead to unsafe undefined behavior.\n   *\n   * Use `Path.resolve()` instead.\n   *\n   * @internal\n   */\n  child(pathPart: string, opts?: PathOpts): PathBase {\n    if (pathPart === '' || pathPart === '.') {\n      return this\n    }\n    if (pathPart === '..') {\n      return this.parent || this\n    }\n\n    // find the child\n    const children = this.children()\n    const name =\n      this.nocase ? normalizeNocase(pathPart) : normalize(pathPart)\n    for (const p of children) {\n      if (p.#matchName === name) {\n        return p\n      }\n    }\n\n    // didn't find it, create provisional child, since it might not\n    // actually exist.  If we know the parent isn't a dir, then\n    // in fact it CAN'T exist.\n    const s = this.parent ? this.sep : ''\n    const fullpath =\n      this.#fullpath ? this.#fullpath + s + pathPart : undefined\n    const pchild = this.newChild(pathPart, UNKNOWN, {\n      ...opts,\n      parent: this,\n      fullpath,\n    })\n\n    if (!this.canReaddir()) {\n      pchild.#type |= ENOENT\n    }\n\n    // don't have to update provisional, because if we have real children,\n    // then provisional is set to children.length, otherwise a lower number\n    children.push(pchild)\n    return pchild\n  }\n\n  /**\n   * The relative path from the cwd. If it does not share an ancestor with\n   * the cwd, then this ends up being equivalent to the fullpath()\n   */\n  relative(): string {\n    if (this.isCWD) return ''\n    if (this.#relative !== undefined) {\n      return this.#relative\n    }\n    const name = this.name\n    const p = this.parent\n    if (!p) {\n      return (this.#relative = this.name)\n    }\n    const pv = p.relative()\n    return pv + (!pv || !p.parent ? '' : this.sep) + name\n  }\n\n  /**\n   * The relative path from the cwd, using / as the path separator.\n   * If it does not share an ancestor with\n   * the cwd, then this ends up being equivalent to the fullpathPosix()\n   * On posix systems, this is identical to relative().\n   */\n  relativePosix(): string {\n    if (this.sep === '/') return this.relative()\n    if (this.isCWD) return ''\n    if (this.#relativePosix !== undefined) return this.#relativePosix\n    const name = this.name\n    const p = this.parent\n    if (!p) {\n      return (this.#relativePosix = this.fullpathPosix())\n    }\n    const pv = p.relativePosix()\n    return pv + (!pv || !p.parent ? '' : '/') + name\n  }\n\n  /**\n   * The fully resolved path string for this Path entry\n   */\n  fullpath(): string {\n    if (this.#fullpath !== undefined) {\n      return this.#fullpath\n    }\n    const name = this.name\n    const p = this.parent\n    if (!p) {\n      return (this.#fullpath = this.name)\n    }\n    const pv = p.fullpath()\n    const fp = pv + (!p.parent ? '' : this.sep) + name\n    return (this.#fullpath = fp)\n  }\n\n  /**\n   * On platforms other than windows, this is identical to fullpath.\n   *\n   * On windows, this is overridden to return the forward-slash form of the\n   * full UNC path.\n   */\n  fullpathPosix(): string {\n    if (this.#fullpathPosix !== undefined) return this.#fullpathPosix\n    if (this.sep === '/') return (this.#fullpathPosix = this.fullpath())\n    if (!this.parent) {\n      const p = this.fullpath().replace(/\\\\/g, '/')\n      if (/^[a-z]:\\//i.test(p)) {\n        return (this.#fullpathPosix = `//?/${p}`)\n      } else {\n        return (this.#fullpathPosix = p)\n      }\n    }\n    const p = this.parent\n    const pfpp = p.fullpathPosix()\n    const fpp = pfpp + (!pfpp || !p.parent ? '' : '/') + this.name\n    return (this.#fullpathPosix = fpp)\n  }\n\n  /**\n   * Is the Path of an unknown type?\n   *\n   * Note that we might know *something* about it if there has been a previous\n   * filesystem operation, for example that it does not exist, or is not a\n   * link, or whether it has child entries.\n   */\n  isUnknown(): boolean {\n    return (this.#type & IFMT) === UNKNOWN\n  }\n\n  isType(type: Type): boolean {\n    return this[`is${type}`]()\n  }\n\n  getType(): Type {\n    return (\n      this.isUnknown() ? 'Unknown'\n      : this.isDirectory() ? 'Directory'\n      : this.isFile() ? 'File'\n      : this.isSymbolicLink() ? 'SymbolicLink'\n      : this.isFIFO() ? 'FIFO'\n      : this.isCharacterDevice() ? 'CharacterDevice'\n      : this.isBlockDevice() ? 'BlockDevice'\n      : /* c8 ignore start */ this.isSocket() ? 'Socket'\n      : 'Unknown'\n    )\n    /* c8 ignore stop */\n  }\n\n  /**\n   * Is the Path a regular file?\n   */\n  isFile(): boolean {\n    return (this.#type & IFMT) === IFREG\n  }\n\n  /**\n   * Is the Path a directory?\n   */\n  isDirectory(): boolean {\n    return (this.#type & IFMT) === IFDIR\n  }\n\n  /**\n   * Is the path a character device?\n   */\n  isCharacterDevice(): boolean {\n    return (this.#type & IFMT) === IFCHR\n  }\n\n  /**\n   * Is the path a block device?\n   */\n  isBlockDevice(): boolean {\n    return (this.#type & IFMT) === IFBLK\n  }\n\n  /**\n   * Is the path a FIFO pipe?\n   */\n  isFIFO(): boolean {\n    return (this.#type & IFMT) === IFIFO\n  }\n\n  /**\n   * Is the path a socket?\n   */\n  isSocket(): boolean {\n    return (this.#type & IFMT) === IFSOCK\n  }\n\n  /**\n   * Is the path a symbolic link?\n   */\n  isSymbolicLink(): boolean {\n    return (this.#type & IFLNK) === IFLNK\n  }\n\n  /**\n   * Return the entry if it has been subject of a successful lstat, or\n   * undefined otherwise.\n   *\n   * Does not read the filesystem, so an undefined result *could* simply\n   * mean that we haven't called lstat on it.\n   */\n  lstatCached(): PathBase | undefined {\n    return this.#type & LSTAT_CALLED ? this : undefined\n  }\n\n  /**\n   * Return the cached link target if the entry has been the subject of a\n   * successful readlink, or undefined otherwise.\n   *\n   * Does not read the filesystem, so an undefined result *could* just mean we\n   * don't have any cached data. Only use it if you are very sure that a\n   * readlink() has been called at some point.\n   */\n  readlinkCached(): PathBase | undefined {\n    return this.#linkTarget\n  }\n\n  /**\n   * Returns the cached realpath target if the entry has been the subject\n   * of a successful realpath, or undefined otherwise.\n   *\n   * Does not read the filesystem, so an undefined result *could* just mean we\n   * don't have any cached data. Only use it if you are very sure that a\n   * realpath() has been called at some point.\n   */\n  realpathCached(): PathBase | undefined {\n    return this.#realpath\n  }\n\n  /**\n   * Returns the cached child Path entries array if the entry has been the\n   * subject of a successful readdir(), or [] otherwise.\n   *\n   * Does not read the filesystem, so an empty array *could* just mean we\n   * don't have any cached data. Only use it if you are very sure that a\n   * readdir() has been called recently enough to still be valid.\n   */\n  readdirCached(): PathBase[] {\n    const children = this.children()\n    return children.slice(0, children.provisional)\n  }\n\n  /**\n   * Return true if it's worth trying to readlink.  Ie, we don't (yet) have\n   * any indication that readlink will definitely fail.\n   *\n   * Returns false if the path is known to not be a symlink, if a previous\n   * readlink failed, or if the entry does not exist.\n   */\n  canReadlink(): boolean {\n    if (this.#linkTarget) return true\n    if (!this.parent) return false\n    // cases where it cannot possibly succeed\n    const ifmt = this.#type & IFMT\n    return !(\n      (ifmt !== UNKNOWN && ifmt !== IFLNK) ||\n      this.#type & ENOREADLINK ||\n      this.#type & ENOENT\n    )\n  }\n\n  /**\n   * Return true if readdir has previously been successfully called on this\n   * path, indicating that cachedReaddir() is likely valid.\n   */\n  calledReaddir(): boolean {\n    return !!(this.#type & READDIR_CALLED)\n  }\n\n  /**\n   * Returns true if the path is known to not exist. That is, a previous lstat\n   * or readdir failed to verify its existence when that would have been\n   * expected, or a parent entry was marked either enoent or enotdir.\n   */\n  isENOENT(): boolean {\n    return !!(this.#type & ENOENT)\n  }\n\n  /**\n   * Return true if the path is a match for the given path name.  This handles\n   * case sensitivity and unicode normalization.\n   *\n   * Note: even on case-sensitive systems, it is **not** safe to test the\n   * equality of the `.name` property to determine whether a given pathname\n   * matches, due to unicode normalization mismatches.\n   *\n   * Always use this method instead of testing the `path.name` property\n   * directly.\n   */\n  isNamed(n: string): boolean {\n    return !this.nocase ?\n        this.#matchName === normalize(n)\n      : this.#matchName === normalizeNocase(n)\n  }\n\n  /**\n   * Return the Path object corresponding to the target of a symbolic link.\n   *\n   * If the Path is not a symbolic link, or if the readlink call fails for any\n   * reason, `undefined` is returned.\n   *\n   * Result is cached, and thus may be outdated if the filesystem is mutated.\n   */\n  async readlink(): Promise<PathBase | undefined> {\n    const target = this.#linkTarget\n    if (target) {\n      return target\n    }\n    if (!this.canReadlink()) {\n      return undefined\n    }\n    /* c8 ignore start */\n    // already covered by the canReadlink test, here for ts grumples\n    if (!this.parent) {\n      return undefined\n    }\n    /* c8 ignore stop */\n    try {\n      const read = await this.#fs.promises.readlink(this.fullpath())\n      const linkTarget = (await this.parent.realpath())?.resolve(read)\n      if (linkTarget) {\n        return (this.#linkTarget = linkTarget)\n      }\n    } catch (er) {\n      this.#readlinkFail((er as NodeJS.ErrnoException).code)\n      return undefined\n    }\n  }\n\n  /**\n   * Synchronous {@link PathBase.readlink}\n   */\n  readlinkSync(): PathBase | undefined {\n    const target = this.#linkTarget\n    if (target) {\n      return target\n    }\n    if (!this.canReadlink()) {\n      return undefined\n    }\n    /* c8 ignore start */\n    // already covered by the canReadlink test, here for ts grumples\n    if (!this.parent) {\n      return undefined\n    }\n    /* c8 ignore stop */\n    try {\n      const read = this.#fs.readlinkSync(this.fullpath())\n      const linkTarget = this.parent.realpathSync()?.resolve(read)\n      if (linkTarget) {\n        return (this.#linkTarget = linkTarget)\n      }\n    } catch (er) {\n      this.#readlinkFail((er as NodeJS.ErrnoException).code)\n      return undefined\n    }\n  }\n\n  #readdirSuccess(children: Children) {\n    // succeeded, mark readdir called bit\n    this.#type |= READDIR_CALLED\n    // mark all remaining provisional children as ENOENT\n    for (let p = children.provisional; p < children.length; p++) {\n      const c = children[p]\n      if (c) c.#markENOENT()\n    }\n  }\n\n  #markENOENT() {\n    // mark as UNKNOWN and ENOENT\n    if (this.#type & ENOENT) return\n    this.#type = (this.#type | ENOENT) & IFMT_UNKNOWN\n    this.#markChildrenENOENT()\n  }\n\n  #markChildrenENOENT() {\n    // all children are provisional and do not exist\n    const children = this.children()\n    children.provisional = 0\n    for (const p of children) {\n      p.#markENOENT()\n    }\n  }\n\n  #markENOREALPATH() {\n    this.#type |= ENOREALPATH\n    this.#markENOTDIR()\n  }\n\n  // save the information when we know the entry is not a dir\n  #markENOTDIR() {\n    // entry is not a directory, so any children can't exist.\n    // this *should* be impossible, since any children created\n    // after it's been marked ENOTDIR should be marked ENOENT,\n    // so it won't even get to this point.\n    /* c8 ignore start */\n    if (this.#type & ENOTDIR) return\n    /* c8 ignore stop */\n    let t = this.#type\n    // this could happen if we stat a dir, then delete it,\n    // then try to read it or one of its children.\n    if ((t & IFMT) === IFDIR) t &= IFMT_UNKNOWN\n    this.#type = t | ENOTDIR\n    this.#markChildrenENOENT()\n  }\n\n  #readdirFail(code: string = '') {\n    // markENOTDIR and markENOENT also set provisional=0\n    if (code === 'ENOTDIR' || code === 'EPERM') {\n      this.#markENOTDIR()\n    } else if (code === 'ENOENT') {\n      this.#markENOENT()\n    } else {\n      this.children().provisional = 0\n    }\n  }\n\n  #lstatFail(code: string = '') {\n    // Windows just raises ENOENT in this case, disable for win CI\n    /* c8 ignore start */\n    if (code === 'ENOTDIR') {\n      // already know it has a parent by this point\n      const p = this.parent as PathBase\n      p.#markENOTDIR()\n    } else if (code === 'ENOENT') {\n      /* c8 ignore stop */\n      this.#markENOENT()\n    }\n  }\n\n  #readlinkFail(code: string = '') {\n    let ter = this.#type\n    ter |= ENOREADLINK\n    if (code === 'ENOENT') ter |= ENOENT\n    // windows gets a weird error when you try to readlink a file\n    if (code === 'EINVAL' || code === 'UNKNOWN') {\n      // exists, but not a symlink, we don't know WHAT it is, so remove\n      // all IFMT bits.\n      ter &= IFMT_UNKNOWN\n    }\n    this.#type = ter\n    // windows just gets ENOENT in this case.  We do cover the case,\n    // just disabled because it's impossible on Windows CI\n    /* c8 ignore start */\n    if (code === 'ENOTDIR' && this.parent) {\n      this.parent.#markENOTDIR()\n    }\n    /* c8 ignore stop */\n  }\n\n  #readdirAddChild(e: Dirent, c: Children) {\n    return (\n      this.#readdirMaybePromoteChild(e, c) ||\n      this.#readdirAddNewChild(e, c)\n    )\n  }\n\n  #readdirAddNewChild(e: Dirent, c: Children): PathBase {\n    // alloc new entry at head, so it's never provisional\n    const type = entToType(e)\n    const child = this.newChild(e.name, type, { parent: this })\n    const ifmt = child.#type & IFMT\n    if (ifmt !== IFDIR && ifmt !== IFLNK && ifmt !== UNKNOWN) {\n      child.#type |= ENOTDIR\n    }\n    c.unshift(child)\n    c.provisional++\n    return child\n  }\n\n  #readdirMaybePromoteChild(e: Dirent, c: Children): PathBase | undefined {\n    for (let p = c.provisional; p < c.length; p++) {\n      const pchild = c[p]\n      const name =\n        this.nocase ? normalizeNocase(e.name) : normalize(e.name)\n      if (name !== pchild!.#matchName) {\n        continue\n      }\n\n      return this.#readdirPromoteChild(e, pchild!, p, c)\n    }\n  }\n\n  #readdirPromoteChild(\n    e: Dirent,\n    p: PathBase,\n    index: number,\n    c: Children,\n  ): PathBase {\n    const v = p.name\n    // retain any other flags, but set ifmt from dirent\n    p.#type = (p.#type & IFMT_UNKNOWN) | entToType(e)\n    // case sensitivity fixing when we learn the true name.\n    if (v !== e.name) p.name = e.name\n\n    // just advance provisional index (potentially off the list),\n    // otherwise we have to splice/pop it out and re-insert at head\n    if (index !== c.provisional) {\n      if (index === c.length - 1) c.pop()\n      else c.splice(index, 1)\n      c.unshift(p)\n    }\n    c.provisional++\n    return p\n  }\n\n  /**\n   * Call lstat() on this Path, and update all known information that can be\n   * determined.\n   *\n   * Note that unlike `fs.lstat()`, the returned value does not contain some\n   * information, such as `mode`, `dev`, `nlink`, and `ino`.  If that\n   * information is required, you will need to call `fs.lstat` yourself.\n   *\n   * If the Path refers to a nonexistent file, or if the lstat call fails for\n   * any reason, `undefined` is returned.  Otherwise the updated Path object is\n   * returned.\n   *\n   * Results are cached, and thus may be out of date if the filesystem is\n   * mutated.\n   */\n  async lstat(): Promise<PathBase | undefined> {\n    if ((this.#type & ENOENT) === 0) {\n      try {\n        this.#applyStat(await this.#fs.promises.lstat(this.fullpath()))\n        return this\n      } catch (er) {\n        this.#lstatFail((er as NodeJS.ErrnoException).code)\n      }\n    }\n  }\n\n  /**\n   * synchronous {@link PathBase.lstat}\n   */\n  lstatSync(): PathBase | undefined {\n    if ((this.#type & ENOENT) === 0) {\n      try {\n        this.#applyStat(this.#fs.lstatSync(this.fullpath()))\n        return this\n      } catch (er) {\n        this.#lstatFail((er as NodeJS.ErrnoException).code)\n      }\n    }\n  }\n\n  #applyStat(st: Stats) {\n    const {\n      atime,\n      atimeMs,\n      birthtime,\n      birthtimeMs,\n      blksize,\n      blocks,\n      ctime,\n      ctimeMs,\n      dev,\n      gid,\n      ino,\n      mode,\n      mtime,\n      mtimeMs,\n      nlink,\n      rdev,\n      size,\n      uid,\n    } = st\n    this.#atime = atime\n    this.#atimeMs = atimeMs\n    this.#birthtime = birthtime\n    this.#birthtimeMs = birthtimeMs\n    this.#blksize = blksize\n    this.#blocks = blocks\n    this.#ctime = ctime\n    this.#ctimeMs = ctimeMs\n    this.#dev = dev\n    this.#gid = gid\n    this.#ino = ino\n    this.#mode = mode\n    this.#mtime = mtime\n    this.#mtimeMs = mtimeMs\n    this.#nlink = nlink\n    this.#rdev = rdev\n    this.#size = size\n    this.#uid = uid\n    const ifmt = entToType(st)\n    // retain any other flags, but set the ifmt\n    this.#type = (this.#type & IFMT_UNKNOWN) | ifmt | LSTAT_CALLED\n    if (ifmt !== UNKNOWN && ifmt !== IFDIR && ifmt !== IFLNK) {\n      this.#type |= ENOTDIR\n    }\n  }\n\n  #onReaddirCB: ((\n    er: NodeJS.ErrnoException | null,\n    entries: Path[],\n  ) => any)[] = []\n  #readdirCBInFlight: boolean = false\n  #callOnReaddirCB(children: Path[]) {\n    this.#readdirCBInFlight = false\n    const cbs = this.#onReaddirCB.slice()\n    this.#onReaddirCB.length = 0\n    cbs.forEach(cb => cb(null, children))\n  }\n\n  /**\n   * Standard node-style callback interface to get list of directory entries.\n   *\n   * If the Path cannot or does not contain any children, then an empty array\n   * is returned.\n   *\n   * Results are cached, and thus may be out of date if the filesystem is\n   * mutated.\n   *\n   * @param cb The callback called with (er, entries).  Note that the `er`\n   * param is somewhat extraneous, as all readdir() errors are handled and\n   * simply result in an empty set of entries being returned.\n   * @param allowZalgo Boolean indicating that immediately known results should\n   * *not* be deferred with `queueMicrotask`. Defaults to `false`. Release\n   * zalgo at your peril, the dark pony lord is devious and unforgiving.\n   */\n  readdirCB(\n    cb: (er: NodeJS.ErrnoException | null, entries: PathBase[]) => any,\n    allowZalgo: boolean = false,\n  ): void {\n    if (!this.canReaddir()) {\n      if (allowZalgo) cb(null, [])\n      else queueMicrotask(() => cb(null, []))\n      return\n    }\n\n    const children = this.children()\n    if (this.calledReaddir()) {\n      const c = children.slice(0, children.provisional)\n      if (allowZalgo) cb(null, c)\n      else queueMicrotask(() => cb(null, c))\n      return\n    }\n\n    // don't have to worry about zalgo at this point.\n    this.#onReaddirCB.push(cb)\n    if (this.#readdirCBInFlight) {\n      return\n    }\n    this.#readdirCBInFlight = true\n\n    // else read the directory, fill up children\n    // de-provisionalize any provisional children.\n    const fullpath = this.fullpath()\n    this.#fs.readdir(fullpath, { withFileTypes: true }, (er, entries) => {\n      if (er) {\n        this.#readdirFail((er as NodeJS.ErrnoException).code)\n        children.provisional = 0\n      } else {\n        // if we didn't get an error, we always get entries.\n        //@ts-ignore\n        for (const e of entries) {\n          this.#readdirAddChild(e, children)\n        }\n        this.#readdirSuccess(children)\n      }\n      this.#callOnReaddirCB(children.slice(0, children.provisional))\n      return\n    })\n  }\n\n  #asyncReaddirInFlight?: Promise<void>\n\n  /**\n   * Return an array of known child entries.\n   *\n   * If the Path cannot or does not contain any children, then an empty array\n   * is returned.\n   *\n   * Results are cached, and thus may be out of date if the filesystem is\n   * mutated.\n   */\n  async readdir(): Promise<PathBase[]> {\n    if (!this.canReaddir()) {\n      return []\n    }\n\n    const children = this.children()\n    if (this.calledReaddir()) {\n      return children.slice(0, children.provisional)\n    }\n\n    // else read the directory, fill up children\n    // de-provisionalize any provisional children.\n    const fullpath = this.fullpath()\n    if (this.#asyncReaddirInFlight) {\n      await this.#asyncReaddirInFlight\n    } else {\n      /* c8 ignore start */\n      let resolve: () => void = () => {}\n      /* c8 ignore stop */\n      this.#asyncReaddirInFlight = new Promise<void>(\n        res => (resolve = res),\n      )\n      try {\n        for (const e of await this.#fs.promises.readdir(fullpath, {\n          withFileTypes: true,\n        })) {\n          this.#readdirAddChild(e, children)\n        }\n        this.#readdirSuccess(children)\n      } catch (er) {\n        this.#readdirFail((er as NodeJS.ErrnoException).code)\n        children.provisional = 0\n      }\n      this.#asyncReaddirInFlight = undefined\n      resolve()\n    }\n    return children.slice(0, children.provisional)\n  }\n\n  /**\n   * synchronous {@link PathBase.readdir}\n   */\n  readdirSync(): PathBase[] {\n    if (!this.canReaddir()) {\n      return []\n    }\n\n    const children = this.children()\n    if (this.calledReaddir()) {\n      return children.slice(0, children.provisional)\n    }\n\n    // else read the directory, fill up children\n    // de-provisionalize any provisional children.\n    const fullpath = this.fullpath()\n    try {\n      for (const e of this.#fs.readdirSync(fullpath, {\n        withFileTypes: true,\n      })) {\n        this.#readdirAddChild(e, children)\n      }\n      this.#readdirSuccess(children)\n    } catch (er) {\n      this.#readdirFail((er as NodeJS.ErrnoException).code)\n      children.provisional = 0\n    }\n    return children.slice(0, children.provisional)\n  }\n\n  canReaddir() {\n    if (this.#type & ENOCHILD) return false\n    const ifmt = IFMT & this.#type\n    // we always set ENOTDIR when setting IFMT, so should be impossible\n    /* c8 ignore start */\n    if (!(ifmt === UNKNOWN || ifmt === IFDIR || ifmt === IFLNK)) {\n      return false\n    }\n    /* c8 ignore stop */\n    return true\n  }\n\n  shouldWalk(\n    dirs: Set<PathBase | undefined>,\n    walkFilter?: (e: PathBase) => boolean,\n  ): boolean {\n    return (\n      (this.#type & IFDIR) === IFDIR &&\n      !(this.#type & ENOCHILD) &&\n      !dirs.has(this) &&\n      (!walkFilter || walkFilter(this))\n    )\n  }\n\n  /**\n   * Return the Path object corresponding to path as resolved\n   * by realpath(3).\n   *\n   * If the realpath call fails for any reason, `undefined` is returned.\n   *\n   * Result is cached, and thus may be outdated if the filesystem is mutated.\n   * On success, returns a Path object.\n   */\n  async realpath(): Promise<PathBase | undefined> {\n    if (this.#realpath) return this.#realpath\n    if ((ENOREALPATH | ENOREADLINK | ENOENT) & this.#type) return undefined\n    try {\n      const rp = await this.#fs.promises.realpath(this.fullpath())\n      return (this.#realpath = this.resolve(rp))\n    } catch (_) {\n      this.#markENOREALPATH()\n    }\n  }\n\n  /**\n   * Synchronous {@link realpath}\n   */\n  realpathSync(): PathBase | undefined {\n    if (this.#realpath) return this.#realpath\n    if ((ENOREALPATH | ENOREADLINK | ENOENT) & this.#type) return undefined\n    try {\n      const rp = this.#fs.realpathSync(this.fullpath())\n      return (this.#realpath = this.resolve(rp))\n    } catch (_) {\n      this.#markENOREALPATH()\n    }\n  }\n\n  /**\n   * Internal method to mark this Path object as the scurry cwd,\n   * called by {@link PathScurry#chdir}\n   *\n   * @internal\n   */\n  [setAsCwd](oldCwd: PathBase): void {\n    if (oldCwd === this) return\n    oldCwd.isCWD = false\n    this.isCWD = true\n\n    const changed = new Set<PathBase>([])\n    let rp = []\n    let p: PathBase = this\n    while (p && p.parent) {\n      changed.add(p)\n      p.#relative = rp.join(this.sep)\n      p.#relativePosix = rp.join('/')\n      p = p.parent\n      rp.push('..')\n    }\n    // now un-memoize parents of old cwd\n    p = oldCwd\n    while (p && p.parent && !changed.has(p)) {\n      p.#relative = undefined\n      p.#relativePosix = undefined\n      p = p.parent\n    }\n  }\n}\n\n/**\n * Path class used on win32 systems\n *\n * Uses `'\\\\'` as the path separator for returned paths, either `'\\\\'` or `'/'`\n * as the path separator for parsing paths.\n */\nexport class PathWin32 extends PathBase {\n  /**\n   * Separator for generating path strings.\n   */\n  sep: '\\\\' = '\\\\'\n  /**\n   * Separator for parsing path strings.\n   */\n  splitSep: RegExp = eitherSep\n\n  /**\n   * Do not create new Path objects directly.  They should always be accessed\n   * via the PathScurry class or other methods on the Path class.\n   *\n   * @internal\n   */\n  constructor(\n    name: string,\n    type: number = UNKNOWN,\n    root: PathBase | undefined,\n    roots: { [k: string]: PathBase },\n    nocase: boolean,\n    children: ChildrenCache,\n    opts: PathOpts,\n  ) {\n    super(name, type, root, roots, nocase, children, opts)\n  }\n\n  /**\n   * @internal\n   */\n  newChild(name: string, type: number = UNKNOWN, opts: PathOpts = {}) {\n    return new PathWin32(\n      name,\n      type,\n      this.root,\n      this.roots,\n      this.nocase,\n      this.childrenCache(),\n      opts,\n    )\n  }\n\n  /**\n   * @internal\n   */\n  getRootString(path: string): string {\n    return win32.parse(path).root\n  }\n\n  /**\n   * @internal\n   */\n  getRoot(rootPath: string): PathBase {\n    rootPath = uncToDrive(rootPath.toUpperCase())\n    if (rootPath === this.root.name) {\n      return this.root\n    }\n    // ok, not that one, check if it matches another we know about\n    for (const [compare, root] of Object.entries(this.roots)) {\n      if (this.sameRoot(rootPath, compare)) {\n        return (this.roots[rootPath] = root)\n      }\n    }\n    // otherwise, have to create a new one.\n    return (this.roots[rootPath] = new PathScurryWin32(\n      rootPath,\n      this,\n    ).root)\n  }\n\n  /**\n   * @internal\n   */\n  sameRoot(rootPath: string, compare: string = this.root.name): boolean {\n    // windows can (rarely) have case-sensitive filesystem, but\n    // UNC and drive letters are always case-insensitive, and canonically\n    // represented uppercase.\n    rootPath = rootPath\n      .toUpperCase()\n      .replace(/\\//g, '\\\\')\n      .replace(uncDriveRegexp, '$1\\\\')\n    return rootPath === compare\n  }\n}\n\n/**\n * Path class used on all posix systems.\n *\n * Uses `'/'` as the path separator.\n */\nexport class PathPosix extends PathBase {\n  /**\n   * separator for parsing path strings\n   */\n  splitSep: '/' = '/'\n  /**\n   * separator for generating path strings\n   */\n  sep: '/' = '/'\n\n  /**\n   * Do not create new Path objects directly.  They should always be accessed\n   * via the PathScurry class or other methods on the Path class.\n   *\n   * @internal\n   */\n  constructor(\n    name: string,\n    type: number = UNKNOWN,\n    root: PathBase | undefined,\n    roots: { [k: string]: PathBase },\n    nocase: boolean,\n    children: ChildrenCache,\n    opts: PathOpts,\n  ) {\n    super(name, type, root, roots, nocase, children, opts)\n  }\n\n  /**\n   * @internal\n   */\n  getRootString(path: string): string {\n    return path.startsWith('/') ? '/' : ''\n  }\n\n  /**\n   * @internal\n   */\n  getRoot(_rootPath: string): PathBase {\n    return this.root\n  }\n\n  /**\n   * @internal\n   */\n  newChild(name: string, type: number = UNKNOWN, opts: PathOpts = {}) {\n    return new PathPosix(\n      name,\n      type,\n      this.root,\n      this.roots,\n      this.nocase,\n      this.childrenCache(),\n      opts,\n    )\n  }\n}\n\n/**\n * Options that may be provided to the PathScurry constructor\n */\nexport interface PathScurryOpts {\n  /**\n   * perform case-insensitive path matching. Default based on platform\n   * subclass.\n   */\n  nocase?: boolean\n  /**\n   * Number of Path entries to keep in the cache of Path child references.\n   *\n   * Setting this higher than 65536 will dramatically increase the data\n   * consumption and construction time overhead of each PathScurry.\n   *\n   * Setting this value to 256 or lower will significantly reduce the data\n   * consumption and construction time overhead, but may also reduce resolve()\n   * and readdir() performance on large filesystems.\n   *\n   * Default `16384`.\n   */\n  childrenCacheSize?: number\n  /**\n   * An object that overrides the built-in functions from the fs and\n   * fs/promises modules.\n   *\n   * See {@link FSOption}\n   */\n  fs?: FSOption\n}\n\n/**\n * The base class for all PathScurry classes, providing the interface for path\n * resolution and filesystem operations.\n *\n * Typically, you should *not* instantiate this class directly, but rather one\n * of the platform-specific classes, or the exported {@link PathScurry} which\n * defaults to the current platform.\n */\nexport abstract class PathScurryBase {\n  /**\n   * The root Path entry for the current working directory of this Scurry\n   */\n  root: PathBase\n  /**\n   * The string path for the root of this Scurry's current working directory\n   */\n  rootPath: string\n  /**\n   * A collection of all roots encountered, referenced by rootPath\n   */\n  roots: { [k: string]: PathBase }\n  /**\n   * The Path entry corresponding to this PathScurry's current working directory.\n   */\n  cwd: PathBase\n  #resolveCache: ResolveCache\n  #resolvePosixCache: ResolveCache\n  #children: ChildrenCache\n  /**\n   * Perform path comparisons case-insensitively.\n   *\n   * Defaults true on Darwin and Windows systems, false elsewhere.\n   */\n  nocase: boolean\n\n  /**\n   * The path separator used for parsing paths\n   *\n   * `'/'` on Posix systems, either `'/'` or `'\\\\'` on Windows\n   */\n  abstract sep: string | RegExp\n\n  #fs: FSValue\n\n  /**\n   * This class should not be instantiated directly.\n   *\n   * Use PathScurryWin32, PathScurryDarwin, PathScurryPosix, or PathScurry\n   *\n   * @internal\n   */\n  constructor(\n    cwd: URL | string = process.cwd(),\n    pathImpl: typeof win32 | typeof posix,\n    sep: string | RegExp,\n    {\n      nocase,\n      childrenCacheSize = 16 * 1024,\n      fs = defaultFS,\n    }: PathScurryOpts = {},\n  ) {\n    this.#fs = fsFromOption(fs)\n    if (cwd instanceof URL || cwd.startsWith('file://')) {\n      cwd = fileURLToPath(cwd)\n    }\n    // resolve and split root, and then add to the store.\n    // this is the only time we call path.resolve()\n    const cwdPath = pathImpl.resolve(cwd)\n    this.roots = Object.create(null)\n    this.rootPath = this.parseRootPath(cwdPath)\n    this.#resolveCache = new ResolveCache()\n    this.#resolvePosixCache = new ResolveCache()\n    this.#children = new ChildrenCache(childrenCacheSize)\n\n    const split = cwdPath.substring(this.rootPath.length).split(sep)\n    // resolve('/') leaves '', splits to [''], we don't want that.\n    if (split.length === 1 && !split[0]) {\n      split.pop()\n    }\n    /* c8 ignore start */\n    if (nocase === undefined) {\n      throw new TypeError(\n        'must provide nocase setting to PathScurryBase ctor',\n      )\n    }\n    /* c8 ignore stop */\n    this.nocase = nocase\n    this.root = this.newRoot(this.#fs)\n    this.roots[this.rootPath] = this.root\n    let prev: PathBase = this.root\n    let len = split.length - 1\n    const joinSep = pathImpl.sep\n    let abs = this.rootPath\n    let sawFirst = false\n    for (const part of split) {\n      const l = len--\n      prev = prev.child(part, {\n        relative: new Array(l).fill('..').join(joinSep),\n        relativePosix: new Array(l).fill('..').join('/'),\n        fullpath: (abs += (sawFirst ? '' : joinSep) + part),\n      })\n      sawFirst = true\n    }\n    this.cwd = prev\n  }\n\n  /**\n   * Get the depth of a provided path, string, or the cwd\n   */\n  depth(path: Path | string = this.cwd): number {\n    if (typeof path === 'string') {\n      path = this.cwd.resolve(path)\n    }\n    return path.depth()\n  }\n\n  /**\n   * Parse the root portion of a path string\n   *\n   * @internal\n   */\n  abstract parseRootPath(dir: string): string\n  /**\n   * create a new Path to use as root during construction.\n   *\n   * @internal\n   */\n  abstract newRoot(fs: FSValue): PathBase\n  /**\n   * Determine whether a given path string is absolute\n   */\n  abstract isAbsolute(p: string): boolean\n\n  /**\n   * Return the cache of child entries.  Exposed so subclasses can create\n   * child Path objects in a platform-specific way.\n   *\n   * @internal\n   */\n  childrenCache() {\n    return this.#children\n  }\n\n  /**\n   * Resolve one or more path strings to a resolved string\n   *\n   * Same interface as require('path').resolve.\n   *\n   * Much faster than path.resolve() when called multiple times for the same\n   * path, because the resolved Path objects are cached.  Much slower\n   * otherwise.\n   */\n  resolve(...paths: string[]): string {\n    // first figure out the minimum number of paths we have to test\n    // we always start at cwd, but any absolutes will bump the start\n    let r = ''\n    for (let i = paths.length - 1; i >= 0; i--) {\n      const p = paths[i]\n      if (!p || p === '.') continue\n      r = r ? `${p}/${r}` : p\n      if (this.isAbsolute(p)) {\n        break\n      }\n    }\n    const cached = this.#resolveCache.get(r)\n    if (cached !== undefined) {\n      return cached\n    }\n    const result = this.cwd.resolve(r).fullpath()\n    this.#resolveCache.set(r, result)\n    return result\n  }\n\n  /**\n   * Resolve one or more path strings to a resolved string, returning\n   * the posix path.  Identical to .resolve() on posix systems, but on\n   * windows will return a forward-slash separated UNC path.\n   *\n   * Same interface as require('path').resolve.\n   *\n   * Much faster than path.resolve() when called multiple times for the same\n   * path, because the resolved Path objects are cached.  Much slower\n   * otherwise.\n   */\n  resolvePosix(...paths: string[]): string {\n    // first figure out the minimum number of paths we have to test\n    // we always start at cwd, but any absolutes will bump the start\n    let r = ''\n    for (let i = paths.length - 1; i >= 0; i--) {\n      const p = paths[i]\n      if (!p || p === '.') continue\n      r = r ? `${p}/${r}` : p\n      if (this.isAbsolute(p)) {\n        break\n      }\n    }\n    const cached = this.#resolvePosixCache.get(r)\n    if (cached !== undefined) {\n      return cached\n    }\n    const result = this.cwd.resolve(r).fullpathPosix()\n    this.#resolvePosixCache.set(r, result)\n    return result\n  }\n\n  /**\n   * find the relative path from the cwd to the supplied path string or entry\n   */\n  relative(entry: PathBase | string = this.cwd): string {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    }\n    return entry.relative()\n  }\n\n  /**\n   * find the relative path from the cwd to the supplied path string or\n   * entry, using / as the path delimiter, even on Windows.\n   */\n  relativePosix(entry: PathBase | string = this.cwd): string {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    }\n    return entry.relativePosix()\n  }\n\n  /**\n   * Return the basename for the provided string or Path object\n   */\n  basename(entry: PathBase | string = this.cwd): string {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    }\n    return entry.name\n  }\n\n  /**\n   * Return the dirname for the provided string or Path object\n   */\n  dirname(entry: PathBase | string = this.cwd): string {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    }\n    return (entry.parent || entry).fullpath()\n  }\n\n  /**\n   * Return an array of known child entries.\n   *\n   * First argument may be either a string, or a Path object.\n   *\n   * If the Path cannot or does not contain any children, then an empty array\n   * is returned.\n   *\n   * Results are cached, and thus may be out of date if the filesystem is\n   * mutated.\n   *\n   * Unlike `fs.readdir()`, the `withFileTypes` option defaults to `true`. Set\n   * `{ withFileTypes: false }` to return strings.\n   */\n\n  readdir(): Promise<PathBase[]>\n  readdir(opts: { withFileTypes: true }): Promise<PathBase[]>\n  readdir(opts: { withFileTypes: false }): Promise<string[]>\n  readdir(opts: { withFileTypes: boolean }): Promise<PathBase[] | string[]>\n  readdir(entry: PathBase | string): Promise<PathBase[]>\n  readdir(\n    entry: PathBase | string,\n    opts: { withFileTypes: true },\n  ): Promise<PathBase[]>\n  readdir(\n    entry: PathBase | string,\n    opts: { withFileTypes: false },\n  ): Promise<string[]>\n  readdir(\n    entry: PathBase | string,\n    opts: { withFileTypes: boolean },\n  ): Promise<PathBase[] | string[]>\n  async readdir(\n    entry: PathBase | string | { withFileTypes: boolean } = this.cwd,\n    opts: { withFileTypes: boolean } = {\n      withFileTypes: true,\n    },\n  ): Promise<PathBase[] | string[]> {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    } else if (!(entry instanceof PathBase)) {\n      opts = entry\n      entry = this.cwd\n    }\n    const { withFileTypes } = opts\n    if (!entry.canReaddir()) {\n      return []\n    } else {\n      const p = await entry.readdir()\n      return withFileTypes ? p : p.map(e => e.name)\n    }\n  }\n\n  /**\n   * synchronous {@link PathScurryBase.readdir}\n   */\n  readdirSync(): PathBase[]\n  readdirSync(opts: { withFileTypes: true }): PathBase[]\n  readdirSync(opts: { withFileTypes: false }): string[]\n  readdirSync(opts: { withFileTypes: boolean }): PathBase[] | string[]\n  readdirSync(entry: PathBase | string): PathBase[]\n  readdirSync(\n    entry: PathBase | string,\n    opts: { withFileTypes: true },\n  ): PathBase[]\n  readdirSync(\n    entry: PathBase | string,\n    opts: { withFileTypes: false },\n  ): string[]\n  readdirSync(\n    entry: PathBase | string,\n    opts: { withFileTypes: boolean },\n  ): PathBase[] | string[]\n  readdirSync(\n    entry: PathBase | string | { withFileTypes: boolean } = this.cwd,\n    opts: { withFileTypes: boolean } = {\n      withFileTypes: true,\n    },\n  ): PathBase[] | string[] {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    } else if (!(entry instanceof PathBase)) {\n      opts = entry\n      entry = this.cwd\n    }\n    const { withFileTypes = true } = opts\n    if (!entry.canReaddir()) {\n      return []\n    } else if (withFileTypes) {\n      return entry.readdirSync()\n    } else {\n      return entry.readdirSync().map(e => e.name)\n    }\n  }\n\n  /**\n   * Call lstat() on the string or Path object, and update all known\n   * information that can be determined.\n   *\n   * Note that unlike `fs.lstat()`, the returned value does not contain some\n   * information, such as `mode`, `dev`, `nlink`, and `ino`.  If that\n   * information is required, you will need to call `fs.lstat` yourself.\n   *\n   * If the Path refers to a nonexistent file, or if the lstat call fails for\n   * any reason, `undefined` is returned.  Otherwise the updated Path object is\n   * returned.\n   *\n   * Results are cached, and thus may be out of date if the filesystem is\n   * mutated.\n   */\n  async lstat(\n    entry: string | PathBase = this.cwd,\n  ): Promise<PathBase | undefined> {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    }\n    return entry.lstat()\n  }\n\n  /**\n   * synchronous {@link PathScurryBase.lstat}\n   */\n  lstatSync(entry: string | PathBase = this.cwd): PathBase | undefined {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    }\n    return entry.lstatSync()\n  }\n\n  /**\n   * Return the Path object or string path corresponding to the target of a\n   * symbolic link.\n   *\n   * If the path is not a symbolic link, or if the readlink call fails for any\n   * reason, `undefined` is returned.\n   *\n   * Result is cached, and thus may be outdated if the filesystem is mutated.\n   *\n   * `{withFileTypes}` option defaults to `false`.\n   *\n   * On success, returns a Path object if `withFileTypes` option is true,\n   * otherwise a string.\n   */\n  readlink(): Promise<string | undefined>\n  readlink(opt: { withFileTypes: false }): Promise<string | undefined>\n  readlink(opt: { withFileTypes: true }): Promise<PathBase | undefined>\n  readlink(opt: {\n    withFileTypes: boolean\n  }): Promise<PathBase | string | undefined>\n  readlink(\n    entry: string | PathBase,\n    opt?: { withFileTypes: false },\n  ): Promise<string | undefined>\n  readlink(\n    entry: string | PathBase,\n    opt: { withFileTypes: true },\n  ): Promise<PathBase | undefined>\n  readlink(\n    entry: string | PathBase,\n    opt: { withFileTypes: boolean },\n  ): Promise<string | PathBase | undefined>\n  async readlink(\n    entry: string | PathBase | { withFileTypes: boolean } = this.cwd,\n    { withFileTypes }: { withFileTypes: boolean } = {\n      withFileTypes: false,\n    },\n  ): Promise<string | PathBase | undefined> {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    } else if (!(entry instanceof PathBase)) {\n      withFileTypes = entry.withFileTypes\n      entry = this.cwd\n    }\n    const e = await entry.readlink()\n    return withFileTypes ? e : e?.fullpath()\n  }\n\n  /**\n   * synchronous {@link PathScurryBase.readlink}\n   */\n  readlinkSync(): string | undefined\n  readlinkSync(opt: { withFileTypes: false }): string | undefined\n  readlinkSync(opt: { withFileTypes: true }): PathBase | undefined\n  readlinkSync(opt: {\n    withFileTypes: boolean\n  }): PathBase | string | undefined\n  readlinkSync(\n    entry: string | PathBase,\n    opt?: { withFileTypes: false },\n  ): string | undefined\n  readlinkSync(\n    entry: string | PathBase,\n    opt: { withFileTypes: true },\n  ): PathBase | undefined\n  readlinkSync(\n    entry: string | PathBase,\n    opt: { withFileTypes: boolean },\n  ): string | PathBase | undefined\n  readlinkSync(\n    entry: string | PathBase | { withFileTypes: boolean } = this.cwd,\n    { withFileTypes }: { withFileTypes: boolean } = {\n      withFileTypes: false,\n    },\n  ): string | PathBase | undefined {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    } else if (!(entry instanceof PathBase)) {\n      withFileTypes = entry.withFileTypes\n      entry = this.cwd\n    }\n    const e = entry.readlinkSync()\n    return withFileTypes ? e : e?.fullpath()\n  }\n\n  /**\n   * Return the Path object or string path corresponding to path as resolved\n   * by realpath(3).\n   *\n   * If the realpath call fails for any reason, `undefined` is returned.\n   *\n   * Result is cached, and thus may be outdated if the filesystem is mutated.\n   *\n   * `{withFileTypes}` option defaults to `false`.\n   *\n   * On success, returns a Path object if `withFileTypes` option is true,\n   * otherwise a string.\n   */\n  realpath(): Promise<string | undefined>\n  realpath(opt: { withFileTypes: false }): Promise<string | undefined>\n  realpath(opt: { withFileTypes: true }): Promise<PathBase | undefined>\n  realpath(opt: {\n    withFileTypes: boolean\n  }): Promise<PathBase | string | undefined>\n  realpath(\n    entry: string | PathBase,\n    opt?: { withFileTypes: false },\n  ): Promise<string | undefined>\n  realpath(\n    entry: string | PathBase,\n    opt: { withFileTypes: true },\n  ): Promise<PathBase | undefined>\n  realpath(\n    entry: string | PathBase,\n    opt: { withFileTypes: boolean },\n  ): Promise<string | PathBase | undefined>\n  async realpath(\n    entry: string | PathBase | { withFileTypes: boolean } = this.cwd,\n    { withFileTypes }: { withFileTypes: boolean } = {\n      withFileTypes: false,\n    },\n  ): Promise<string | PathBase | undefined> {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    } else if (!(entry instanceof PathBase)) {\n      withFileTypes = entry.withFileTypes\n      entry = this.cwd\n    }\n    const e = await entry.realpath()\n    return withFileTypes ? e : e?.fullpath()\n  }\n\n  realpathSync(): string | undefined\n  realpathSync(opt: { withFileTypes: false }): string | undefined\n  realpathSync(opt: { withFileTypes: true }): PathBase | undefined\n  realpathSync(opt: {\n    withFileTypes: boolean\n  }): PathBase | string | undefined\n  realpathSync(\n    entry: string | PathBase,\n    opt?: { withFileTypes: false },\n  ): string | undefined\n  realpathSync(\n    entry: string | PathBase,\n    opt: { withFileTypes: true },\n  ): PathBase | undefined\n  realpathSync(\n    entry: string | PathBase,\n    opt: { withFileTypes: boolean },\n  ): string | PathBase | undefined\n  realpathSync(\n    entry: string | PathBase | { withFileTypes: boolean } = this.cwd,\n    { withFileTypes }: { withFileTypes: boolean } = {\n      withFileTypes: false,\n    },\n  ): string | PathBase | undefined {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    } else if (!(entry instanceof PathBase)) {\n      withFileTypes = entry.withFileTypes\n      entry = this.cwd\n    }\n    const e = entry.realpathSync()\n    return withFileTypes ? e : e?.fullpath()\n  }\n\n  /**\n   * Asynchronously walk the directory tree, returning an array of\n   * all path strings or Path objects found.\n   *\n   * Note that this will be extremely memory-hungry on large filesystems.\n   * In such cases, it may be better to use the stream or async iterator\n   * walk implementation.\n   */\n  walk(): Promise<PathBase[]>\n  walk(\n    opts: WalkOptionsWithFileTypesTrue | WalkOptionsWithFileTypesUnset,\n  ): Promise<PathBase[]>\n  walk(opts: WalkOptionsWithFileTypesFalse): Promise<string[]>\n  walk(opts: WalkOptions): Promise<string[] | PathBase[]>\n  walk(entry: string | PathBase): Promise<PathBase[]>\n  walk(\n    entry: string | PathBase,\n    opts: WalkOptionsWithFileTypesTrue | WalkOptionsWithFileTypesUnset,\n  ): Promise<PathBase[]>\n  walk(\n    entry: string | PathBase,\n    opts: WalkOptionsWithFileTypesFalse,\n  ): Promise<string[]>\n  walk(\n    entry: string | PathBase,\n    opts: WalkOptions,\n  ): Promise<PathBase[] | string[]>\n  async walk(\n    entry: string | PathBase | WalkOptions = this.cwd,\n    opts: WalkOptions = {},\n  ): Promise<PathBase[] | string[]> {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    } else if (!(entry instanceof PathBase)) {\n      opts = entry\n      entry = this.cwd\n    }\n    const {\n      withFileTypes = true,\n      follow = false,\n      filter,\n      walkFilter,\n    } = opts\n    const results: (string | PathBase)[] = []\n    if (!filter || filter(entry)) {\n      results.push(withFileTypes ? entry : entry.fullpath())\n    }\n    const dirs = new Set<PathBase>()\n    const walk = (\n      dir: PathBase,\n      cb: (er?: NodeJS.ErrnoException) => void,\n    ) => {\n      dirs.add(dir)\n      dir.readdirCB((er, entries) => {\n        /* c8 ignore start */\n        if (er) {\n          return cb(er)\n        }\n        /* c8 ignore stop */\n        let len = entries.length\n        if (!len) return cb()\n        const next = () => {\n          if (--len === 0) {\n            cb()\n          }\n        }\n        for (const e of entries) {\n          if (!filter || filter(e)) {\n            results.push(withFileTypes ? e : e.fullpath())\n          }\n          if (follow && e.isSymbolicLink()) {\n            e.realpath()\n              .then(r => (r?.isUnknown() ? r.lstat() : r))\n              .then(r =>\n                r?.shouldWalk(dirs, walkFilter) ? walk(r, next) : next(),\n              )\n          } else {\n            if (e.shouldWalk(dirs, walkFilter)) {\n              walk(e, next)\n            } else {\n              next()\n            }\n          }\n        }\n      }, true) // zalgooooooo\n    }\n\n    const start = entry\n    return new Promise<PathBase[] | string[]>((res, rej) => {\n      walk(start, er => {\n        /* c8 ignore start */\n        if (er) return rej(er)\n        /* c8 ignore stop */\n        res(results as PathBase[] | string[])\n      })\n    })\n  }\n\n  /**\n   * Synchronously walk the directory tree, returning an array of\n   * all path strings or Path objects found.\n   *\n   * Note that this will be extremely memory-hungry on large filesystems.\n   * In such cases, it may be better to use the stream or async iterator\n   * walk implementation.\n   */\n  walkSync(): PathBase[]\n  walkSync(\n    opts: WalkOptionsWithFileTypesTrue | WalkOptionsWithFileTypesUnset,\n  ): PathBase[]\n  walkSync(opts: WalkOptionsWithFileTypesFalse): string[]\n  walkSync(opts: WalkOptions): string[] | PathBase[]\n  walkSync(entry: string | PathBase): PathBase[]\n  walkSync(\n    entry: string | PathBase,\n    opts: WalkOptionsWithFileTypesUnset | WalkOptionsWithFileTypesTrue,\n  ): PathBase[]\n  walkSync(\n    entry: string | PathBase,\n    opts: WalkOptionsWithFileTypesFalse,\n  ): string[]\n  walkSync(\n    entry: string | PathBase,\n    opts: WalkOptions,\n  ): PathBase[] | string[]\n  walkSync(\n    entry: string | PathBase | WalkOptions = this.cwd,\n    opts: WalkOptions = {},\n  ): PathBase[] | string[] {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    } else if (!(entry instanceof PathBase)) {\n      opts = entry\n      entry = this.cwd\n    }\n    const {\n      withFileTypes = true,\n      follow = false,\n      filter,\n      walkFilter,\n    } = opts\n    const results: (string | PathBase)[] = []\n    if (!filter || filter(entry)) {\n      results.push(withFileTypes ? entry : entry.fullpath())\n    }\n    const dirs = new Set<PathBase>([entry])\n    for (const dir of dirs) {\n      const entries = dir.readdirSync()\n      for (const e of entries) {\n        if (!filter || filter(e)) {\n          results.push(withFileTypes ? e : e.fullpath())\n        }\n        let r: PathBase | undefined = e\n        if (e.isSymbolicLink()) {\n          if (!(follow && (r = e.realpathSync()))) continue\n          if (r.isUnknown()) r.lstatSync()\n        }\n        if (r.shouldWalk(dirs, walkFilter)) {\n          dirs.add(r)\n        }\n      }\n    }\n    return results as string[] | PathBase[]\n  }\n\n  /**\n   * Support for `for await`\n   *\n   * Alias for {@link PathScurryBase.iterate}\n   *\n   * Note: As of Node 19, this is very slow, compared to other methods of\n   * walking.  Consider using {@link PathScurryBase.stream} if memory overhead\n   * and backpressure are concerns, or {@link PathScurryBase.walk} if not.\n   */\n  [Symbol.asyncIterator]() {\n    return this.iterate()\n  }\n\n  /**\n   * Async generator form of {@link PathScurryBase.walk}\n   *\n   * Note: As of Node 19, this is very slow, compared to other methods of\n   * walking, especially if most/all of the directory tree has been previously\n   * walked.  Consider using {@link PathScurryBase.stream} if memory overhead\n   * and backpressure are concerns, or {@link PathScurryBase.walk} if not.\n   */\n  iterate(): AsyncGenerator<PathBase, void, void>\n  iterate(\n    opts: WalkOptionsWithFileTypesTrue | WalkOptionsWithFileTypesUnset,\n  ): AsyncGenerator<PathBase, void, void>\n  iterate(\n    opts: WalkOptionsWithFileTypesFalse,\n  ): AsyncGenerator<string, void, void>\n  iterate(opts: WalkOptions): AsyncGenerator<string | PathBase, void, void>\n  iterate(entry: string | PathBase): AsyncGenerator<PathBase, void, void>\n  iterate(\n    entry: string | PathBase,\n    opts: WalkOptionsWithFileTypesTrue | WalkOptionsWithFileTypesUnset,\n  ): AsyncGenerator<PathBase, void, void>\n  iterate(\n    entry: string | PathBase,\n    opts: WalkOptionsWithFileTypesFalse,\n  ): AsyncGenerator<string, void, void>\n  iterate(\n    entry: string | PathBase,\n    opts: WalkOptions,\n  ): AsyncGenerator<PathBase | string, void, void>\n  iterate(\n    entry: string | PathBase | WalkOptions = this.cwd,\n    options: WalkOptions = {},\n  ): AsyncGenerator<PathBase | string, void, void> {\n    // iterating async over the stream is significantly more performant,\n    // especially in the warm-cache scenario, because it buffers up directory\n    // entries in the background instead of waiting for a yield for each one.\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    } else if (!(entry instanceof PathBase)) {\n      options = entry\n      entry = this.cwd\n    }\n    return this.stream(entry, options)[Symbol.asyncIterator]()\n  }\n\n  /**\n   * Iterating over a PathScurry performs a synchronous walk.\n   *\n   * Alias for {@link PathScurryBase.iterateSync}\n   */\n  [Symbol.iterator]() {\n    return this.iterateSync()\n  }\n\n  iterateSync(): Generator<PathBase, void, void>\n  iterateSync(\n    opts: WalkOptionsWithFileTypesTrue | WalkOptionsWithFileTypesUnset,\n  ): Generator<PathBase, void, void>\n  iterateSync(\n    opts: WalkOptionsWithFileTypesFalse,\n  ): Generator<string, void, void>\n  iterateSync(opts: WalkOptions): Generator<string | PathBase, void, void>\n  iterateSync(entry: string | PathBase): Generator<PathBase, void, void>\n  iterateSync(\n    entry: string | PathBase,\n    opts: WalkOptionsWithFileTypesTrue | WalkOptionsWithFileTypesUnset,\n  ): Generator<PathBase, void, void>\n  iterateSync(\n    entry: string | PathBase,\n    opts: WalkOptionsWithFileTypesFalse,\n  ): Generator<string, void, void>\n  iterateSync(\n    entry: string | PathBase,\n    opts: WalkOptions,\n  ): Generator<PathBase | string, void, void>\n  *iterateSync(\n    entry: string | PathBase | WalkOptions = this.cwd,\n    opts: WalkOptions = {},\n  ): Generator<PathBase | string, void, void> {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    } else if (!(entry instanceof PathBase)) {\n      opts = entry\n      entry = this.cwd\n    }\n    const {\n      withFileTypes = true,\n      follow = false,\n      filter,\n      walkFilter,\n    } = opts\n    if (!filter || filter(entry)) {\n      yield withFileTypes ? entry : entry.fullpath()\n    }\n    const dirs = new Set<PathBase>([entry])\n    for (const dir of dirs) {\n      const entries = dir.readdirSync()\n      for (const e of entries) {\n        if (!filter || filter(e)) {\n          yield withFileTypes ? e : e.fullpath()\n        }\n        let r: PathBase | undefined = e\n        if (e.isSymbolicLink()) {\n          if (!(follow && (r = e.realpathSync()))) continue\n          if (r.isUnknown()) r.lstatSync()\n        }\n        if (r.shouldWalk(dirs, walkFilter)) {\n          dirs.add(r)\n        }\n      }\n    }\n  }\n\n  /**\n   * Stream form of {@link PathScurryBase.walk}\n   *\n   * Returns a Minipass stream that emits {@link PathBase} objects by default,\n   * or strings if `{ withFileTypes: false }` is set in the options.\n   */\n  stream(): Minipass<PathBase>\n  stream(\n    opts: WalkOptionsWithFileTypesTrue | WalkOptionsWithFileTypesUnset,\n  ): Minipass<PathBase>\n  stream(opts: WalkOptionsWithFileTypesFalse): Minipass<string>\n  stream(opts: WalkOptions): Minipass<string | PathBase>\n  stream(entry: string | PathBase): Minipass<PathBase>\n  stream(\n    entry: string | PathBase,\n    opts: WalkOptionsWithFileTypesUnset | WalkOptionsWithFileTypesTrue,\n  ): Minipass<PathBase>\n  stream(\n    entry: string | PathBase,\n    opts: WalkOptionsWithFileTypesFalse,\n  ): Minipass<string>\n  stream(\n    entry: string | PathBase,\n    opts: WalkOptions,\n  ): Minipass<string> | Minipass<PathBase>\n  stream(\n    entry: string | PathBase | WalkOptions = this.cwd,\n    opts: WalkOptions = {},\n  ): Minipass<string> | Minipass<PathBase> {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    } else if (!(entry instanceof PathBase)) {\n      opts = entry\n      entry = this.cwd\n    }\n    const {\n      withFileTypes = true,\n      follow = false,\n      filter,\n      walkFilter,\n    } = opts\n    const results = new Minipass<string | PathBase>({ objectMode: true })\n    if (!filter || filter(entry)) {\n      results.write(withFileTypes ? entry : entry.fullpath())\n    }\n    const dirs = new Set<PathBase>()\n    const queue: PathBase[] = [entry]\n    let processing = 0\n    const process = () => {\n      let paused = false\n      while (!paused) {\n        const dir = queue.shift()\n        if (!dir) {\n          if (processing === 0) results.end()\n          return\n        }\n\n        processing++\n        dirs.add(dir)\n\n        const onReaddir = (\n          er: null | NodeJS.ErrnoException,\n          entries: PathBase[],\n          didRealpaths: boolean = false,\n        ) => {\n          /* c8 ignore start */\n          if (er) return results.emit('error', er)\n          /* c8 ignore stop */\n          if (follow && !didRealpaths) {\n            const promises: Promise<PathBase | undefined>[] = []\n            for (const e of entries) {\n              if (e.isSymbolicLink()) {\n                promises.push(\n                  e\n                    .realpath()\n                    .then((r: PathBase | undefined) =>\n                      r?.isUnknown() ? r.lstat() : r,\n                    ),\n                )\n              }\n            }\n            if (promises.length) {\n              Promise.all(promises).then(() =>\n                onReaddir(null, entries, true),\n              )\n              return\n            }\n          }\n\n          for (const e of entries) {\n            if (e && (!filter || filter(e))) {\n              if (!results.write(withFileTypes ? e : e.fullpath())) {\n                paused = true\n              }\n            }\n          }\n\n          processing--\n          for (const e of entries) {\n            const r = e.realpathCached() || e\n            if (r.shouldWalk(dirs, walkFilter)) {\n              queue.push(r)\n            }\n          }\n          if (paused && !results.flowing) {\n            results.once('drain', process)\n          } else if (!sync) {\n            process()\n          }\n        }\n\n        // zalgo containment\n        let sync = true\n        dir.readdirCB(onReaddir, true)\n        sync = false\n      }\n    }\n    process()\n    return results as Minipass<string> | Minipass<PathBase>\n  }\n\n  /**\n   * Synchronous form of {@link PathScurryBase.stream}\n   *\n   * Returns a Minipass stream that emits {@link PathBase} objects by default,\n   * or strings if `{ withFileTypes: false }` is set in the options.\n   *\n   * Will complete the walk in a single tick if the stream is consumed fully.\n   * Otherwise, will pause as needed for stream backpressure.\n   */\n  streamSync(): Minipass<PathBase>\n  streamSync(\n    opts: WalkOptionsWithFileTypesTrue | WalkOptionsWithFileTypesUnset,\n  ): Minipass<PathBase>\n  streamSync(opts: WalkOptionsWithFileTypesFalse): Minipass<string>\n  streamSync(opts: WalkOptions): Minipass<string | PathBase>\n  streamSync(entry: string | PathBase): Minipass<PathBase>\n  streamSync(\n    entry: string | PathBase,\n    opts: WalkOptionsWithFileTypesUnset | WalkOptionsWithFileTypesTrue,\n  ): Minipass<PathBase>\n  streamSync(\n    entry: string | PathBase,\n    opts: WalkOptionsWithFileTypesFalse,\n  ): Minipass<string>\n  streamSync(\n    entry: string | PathBase,\n    opts: WalkOptions,\n  ): Minipass<string> | Minipass<PathBase>\n  streamSync(\n    entry: string | PathBase | WalkOptions = this.cwd,\n    opts: WalkOptions = {},\n  ): Minipass<string> | Minipass<PathBase> {\n    if (typeof entry === 'string') {\n      entry = this.cwd.resolve(entry)\n    } else if (!(entry instanceof PathBase)) {\n      opts = entry\n      entry = this.cwd\n    }\n    const {\n      withFileTypes = true,\n      follow = false,\n      filter,\n      walkFilter,\n    } = opts\n    const results = new Minipass<string | PathBase>({ objectMode: true })\n    const dirs = new Set<PathBase>()\n    if (!filter || filter(entry)) {\n      results.write(withFileTypes ? entry : entry.fullpath())\n    }\n    const queue: PathBase[] = [entry]\n    let processing = 0\n    const process = () => {\n      let paused = false\n      while (!paused) {\n        const dir = queue.shift()\n        if (!dir) {\n          if (processing === 0) results.end()\n          return\n        }\n        processing++\n        dirs.add(dir)\n\n        const entries = dir.readdirSync()\n        for (const e of entries) {\n          if (!filter || filter(e)) {\n            if (!results.write(withFileTypes ? e : e.fullpath())) {\n              paused = true\n            }\n          }\n        }\n        processing--\n        for (const e of entries) {\n          let r: PathBase | undefined = e\n          if (e.isSymbolicLink()) {\n            if (!(follow && (r = e.realpathSync()))) continue\n            if (r.isUnknown()) r.lstatSync()\n          }\n          if (r.shouldWalk(dirs, walkFilter)) {\n            queue.push(r)\n          }\n        }\n      }\n      if (paused && !results.flowing) results.once('drain', process)\n    }\n    process()\n    return results as Minipass<string> | Minipass<PathBase>\n  }\n\n  chdir(path: string | Path = this.cwd) {\n    const oldCwd = this.cwd\n    this.cwd = typeof path === 'string' ? this.cwd.resolve(path) : path\n    this.cwd[setAsCwd](oldCwd)\n  }\n}\n\n/**\n * Options provided to all walk methods.\n */\nexport interface WalkOptions {\n  /**\n   * Return results as {@link PathBase} objects rather than strings.\n   * When set to false, results are fully resolved paths, as returned by\n   * {@link PathBase.fullpath}.\n   * @default true\n   */\n  withFileTypes?: boolean\n\n  /**\n   *  Attempt to read directory entries from symbolic links. Otherwise, only\n   *  actual directories are traversed. Regardless of this setting, a given\n   *  target path will only ever be walked once, meaning that a symbolic link\n   *  to a previously traversed directory will never be followed.\n   *\n   *  Setting this imposes a slight performance penalty, because `readlink`\n   *  must be called on all symbolic links encountered, in order to avoid\n   *  infinite cycles.\n   * @default false\n   */\n  follow?: boolean\n\n  /**\n   * Only return entries where the provided function returns true.\n   *\n   * This will not prevent directories from being traversed, even if they do\n   * not pass the filter, though it will prevent directories themselves from\n   * being included in the result set.  See {@link walkFilter}\n   *\n   * Asynchronous functions are not supported here.\n   *\n   * By default, if no filter is provided, all entries and traversed\n   * directories are included.\n   */\n  filter?: (entry: PathBase) => boolean\n\n  /**\n   * Only traverse directories (and in the case of {@link follow} being set to\n   * true, symbolic links to directories) if the provided function returns\n   * true.\n   *\n   * This will not prevent directories from being included in the result set,\n   * even if they do not pass the supplied filter function.  See {@link filter}\n   * to do that.\n   *\n   * Asynchronous functions are not supported here.\n   */\n  walkFilter?: (entry: PathBase) => boolean\n}\n\nexport type WalkOptionsWithFileTypesUnset = WalkOptions & {\n  withFileTypes?: undefined\n}\nexport type WalkOptionsWithFileTypesTrue = WalkOptions & {\n  withFileTypes: true\n}\nexport type WalkOptionsWithFileTypesFalse = WalkOptions & {\n  withFileTypes: false\n}\n\n/**\n * Windows implementation of {@link PathScurryBase}\n *\n * Defaults to case insensitve, uses `'\\\\'` to generate path strings.  Uses\n * {@link PathWin32} for Path objects.\n */\nexport class PathScurryWin32 extends PathScurryBase {\n  /**\n   * separator for generating path strings\n   */\n  sep: '\\\\' = '\\\\'\n\n  constructor(\n    cwd: URL | string = process.cwd(),\n    opts: PathScurryOpts = {},\n  ) {\n    const { nocase = true } = opts\n    super(cwd, win32, '\\\\', { ...opts, nocase })\n    this.nocase = nocase\n    for (let p: PathBase | undefined = this.cwd; p; p = p.parent) {\n      p.nocase = this.nocase\n    }\n  }\n\n  /**\n   * @internal\n   */\n  parseRootPath(dir: string): string {\n    // if the path starts with a single separator, it's not a UNC, and we'll\n    // just get separator as the root, and driveFromUNC will return \\\n    // In that case, mount \\ on the root from the cwd.\n    return win32.parse(dir).root.toUpperCase()\n  }\n\n  /**\n   * @internal\n   */\n  newRoot(fs: FSValue) {\n    return new PathWin32(\n      this.rootPath,\n      IFDIR,\n      undefined,\n      this.roots,\n      this.nocase,\n      this.childrenCache(),\n      { fs },\n    )\n  }\n\n  /**\n   * Return true if the provided path string is an absolute path\n   */\n  isAbsolute(p: string): boolean {\n    return (\n      p.startsWith('/') || p.startsWith('\\\\') || /^[a-z]:(\\/|\\\\)/i.test(p)\n    )\n  }\n}\n\n/**\n * {@link PathScurryBase} implementation for all posix systems other than Darwin.\n *\n * Defaults to case-sensitive matching, uses `'/'` to generate path strings.\n *\n * Uses {@link PathPosix} for Path objects.\n */\nexport class PathScurryPosix extends PathScurryBase {\n  /**\n   * separator for generating path strings\n   */\n  sep: '/' = '/'\n  constructor(\n    cwd: URL | string = process.cwd(),\n    opts: PathScurryOpts = {},\n  ) {\n    const { nocase = false } = opts\n    super(cwd, posix, '/', { ...opts, nocase })\n    this.nocase = nocase\n  }\n\n  /**\n   * @internal\n   */\n  parseRootPath(_dir: string): string {\n    return '/'\n  }\n\n  /**\n   * @internal\n   */\n  newRoot(fs: FSValue) {\n    return new PathPosix(\n      this.rootPath,\n      IFDIR,\n      undefined,\n      this.roots,\n      this.nocase,\n      this.childrenCache(),\n      { fs },\n    )\n  }\n\n  /**\n   * Return true if the provided path string is an absolute path\n   */\n  isAbsolute(p: string): boolean {\n    return p.startsWith('/')\n  }\n}\n\n/**\n * {@link PathScurryBase} implementation for Darwin (macOS) systems.\n *\n * Defaults to case-insensitive matching, uses `'/'` for generating path\n * strings.\n *\n * Uses {@link PathPosix} for Path objects.\n */\nexport class PathScurryDarwin extends PathScurryPosix {\n  constructor(\n    cwd: URL | string = process.cwd(),\n    opts: PathScurryOpts = {},\n  ) {\n    const { nocase = true } = opts\n    super(cwd, { ...opts, nocase })\n  }\n}\n\n/**\n * Default {@link PathBase} implementation for the current platform.\n *\n * {@link PathWin32} on Windows systems, {@link PathPosix} on all others.\n */\nexport const Path = process.platform === 'win32' ? PathWin32 : PathPosix\nexport type Path = PathBase | InstanceType<typeof Path>\n\n/**\n * Default {@link PathScurryBase} implementation for the current platform.\n *\n * {@link PathScurryWin32} on Windows systems, {@link PathScurryDarwin} on\n * Darwin (macOS) systems, {@link PathScurryPosix} on all others.\n */\nexport const PathScurry:\n  | typeof PathScurryWin32\n  | typeof PathScurryDarwin\n  | typeof PathScurryPosix =\n  process.platform === 'win32' ? PathScurryWin32\n  : process.platform === 'darwin' ? PathScurryDarwin\n  : PathScurryPosix\nexport type PathScurry = PathScurryBase | InstanceType<typeof PathScurry>\n","const proc =\n  typeof process === 'object' && process\n    ? process\n    : {\n        stdout: null,\n        stderr: null,\n      }\nimport { EventEmitter } from 'node:events'\nimport Stream from 'node:stream'\nimport { StringDecoder } from 'node:string_decoder'\n\n/**\n * Same as StringDecoder, but exposing the `lastNeed` flag on the type\n */\ntype SD = StringDecoder & { lastNeed: boolean }\n\nexport type { SD, Pipe, PipeProxyErrors }\n\n/**\n * Return true if the argument is a Minipass stream, Node stream, or something\n * else that Minipass can interact with.\n */\nexport const isStream = (\n  s: any\n): s is Minipass.Readable | Minipass.Writable =>\n  !!s &&\n  typeof s === 'object' &&\n  (s instanceof Minipass ||\n    s instanceof Stream ||\n    isReadable(s) ||\n    isWritable(s))\n\n/**\n * Return true if the argument is a valid {@link Minipass.Readable}\n */\nexport const isReadable = (s: any): s is Minipass.Readable =>\n  !!s &&\n  typeof s === 'object' &&\n  s instanceof EventEmitter &&\n  typeof (s as Minipass.Readable).pipe === 'function' &&\n  // node core Writable streams have a pipe() method, but it throws\n  (s as Minipass.Readable).pipe !== Stream.Writable.prototype.pipe\n\n/**\n * Return true if the argument is a valid {@link Minipass.Writable}\n */\nexport const isWritable = (s: any): s is Minipass.Readable =>\n  !!s &&\n  typeof s === 'object' &&\n  s instanceof EventEmitter &&\n  typeof (s as Minipass.Writable).write === 'function' &&\n  typeof (s as Minipass.Writable).end === 'function'\n\nconst EOF = Symbol('EOF')\nconst MAYBE_EMIT_END = Symbol('maybeEmitEnd')\nconst EMITTED_END = Symbol('emittedEnd')\nconst EMITTING_END = Symbol('emittingEnd')\nconst EMITTED_ERROR = Symbol('emittedError')\nconst CLOSED = Symbol('closed')\nconst READ = Symbol('read')\nconst FLUSH = Symbol('flush')\nconst FLUSHCHUNK = Symbol('flushChunk')\nconst ENCODING = Symbol('encoding')\nconst DECODER = Symbol('decoder')\nconst FLOWING = Symbol('flowing')\nconst PAUSED = Symbol('paused')\nconst RESUME = Symbol('resume')\nconst BUFFER = Symbol('buffer')\nconst PIPES = Symbol('pipes')\nconst BUFFERLENGTH = Symbol('bufferLength')\nconst BUFFERPUSH = Symbol('bufferPush')\nconst BUFFERSHIFT = Symbol('bufferShift')\nconst OBJECTMODE = Symbol('objectMode')\n// internal event when stream is destroyed\nconst DESTROYED = Symbol('destroyed')\n// internal event when stream has an error\nconst ERROR = Symbol('error')\nconst EMITDATA = Symbol('emitData')\nconst EMITEND = Symbol('emitEnd')\nconst EMITEND2 = Symbol('emitEnd2')\nconst ASYNC = Symbol('async')\nconst ABORT = Symbol('abort')\nconst ABORTED = Symbol('aborted')\nconst SIGNAL = Symbol('signal')\nconst DATALISTENERS = Symbol('dataListeners')\nconst DISCARDED = Symbol('discarded')\n\nconst defer = (fn: (...a: any[]) => any) => Promise.resolve().then(fn)\nconst nodefer = (fn: (...a: any[]) => any) => fn()\n\n// events that mean 'the stream is over'\n// these are treated specially, and re-emitted\n// if they are listened for after emitting.\ntype EndishEvent = 'end' | 'finish' | 'prefinish'\nconst isEndish = (ev: any): ev is EndishEvent =>\n  ev === 'end' || ev === 'finish' || ev === 'prefinish'\n\nconst isArrayBufferLike = (b: any): b is ArrayBufferLike =>\n  b instanceof ArrayBuffer ||\n  (!!b &&\n    typeof b === 'object' &&\n    b.constructor &&\n    b.constructor.name === 'ArrayBuffer' &&\n    b.byteLength >= 0)\n\nconst isArrayBufferView = (b: any): b is ArrayBufferView =>\n  !Buffer.isBuffer(b) && ArrayBuffer.isView(b)\n\n/**\n * Options that may be passed to stream.pipe()\n */\nexport interface PipeOptions {\n  /**\n   * end the destination stream when the source stream ends\n   */\n  end?: boolean\n  /**\n   * proxy errors from the source stream to the destination stream\n   */\n  proxyErrors?: boolean\n}\n\n/**\n * Internal class representing a pipe to a destination stream.\n *\n * @internal\n */\nclass Pipe<T extends unknown> {\n  src: Minipass<T>\n  dest: Minipass<any, T>\n  opts: PipeOptions\n  ondrain: () => any\n  constructor(\n    src: Minipass<T>,\n    dest: Minipass.Writable,\n    opts: PipeOptions\n  ) {\n    this.src = src\n    this.dest = dest as Minipass<any, T>\n    this.opts = opts\n    this.ondrain = () => src[RESUME]()\n    this.dest.on('drain', this.ondrain)\n  }\n  unpipe() {\n    this.dest.removeListener('drain', this.ondrain)\n  }\n  // only here for the prototype\n  /* c8 ignore start */\n  proxyErrors(_er: any) {}\n  /* c8 ignore stop */\n  end() {\n    this.unpipe()\n    if (this.opts.end) this.dest.end()\n  }\n}\n\n/**\n * Internal class representing a pipe to a destination stream where\n * errors are proxied.\n *\n * @internal\n */\nclass PipeProxyErrors<T> extends Pipe<T> {\n  unpipe() {\n    this.src.removeListener('error', this.proxyErrors)\n    super.unpipe()\n  }\n  constructor(\n    src: Minipass<T>,\n    dest: Minipass.Writable,\n    opts: PipeOptions\n  ) {\n    super(src, dest, opts)\n    this.proxyErrors = er => dest.emit('error', er)\n    src.on('error', this.proxyErrors)\n  }\n}\n\nexport namespace Minipass {\n  /**\n   * Encoding used to create a stream that outputs strings rather than\n   * Buffer objects.\n   */\n  export type Encoding = BufferEncoding | 'buffer' | null\n\n  /**\n   * Any stream that Minipass can pipe into\n   */\n  export type Writable =\n    | Minipass<any, any, any>\n    | NodeJS.WriteStream\n    | (NodeJS.WriteStream & { fd: number })\n    | (EventEmitter & {\n        end(): any\n        write(chunk: any, ...args: any[]): any\n      })\n\n  /**\n   * Any stream that can be read from\n   */\n  export type Readable =\n    | Minipass<any, any, any>\n    | NodeJS.ReadStream\n    | (NodeJS.ReadStream & { fd: number })\n    | (EventEmitter & {\n        pause(): any\n        resume(): any\n        pipe(...destArgs: any[]): any\n      })\n\n  /**\n   * Utility type that can be iterated sync or async\n   */\n  export type DualIterable<T> = Iterable<T> & AsyncIterable<T>\n\n  type EventArguments = Record<string | symbol, unknown[]>\n\n  /**\n   * The listing of events that a Minipass class can emit.\n   * Extend this when extending the Minipass class, and pass as\n   * the third template argument.  The key is the name of the event,\n   * and the value is the argument list.\n   *\n   * Any undeclared events will still be allowed, but the handler will get\n   * arguments as `unknown[]`.\n   */\n  export interface Events<RType extends any = Buffer>\n    extends EventArguments {\n    readable: []\n    data: [chunk: RType]\n    error: [er: unknown]\n    abort: [reason: unknown]\n    drain: []\n    resume: []\n    end: []\n    finish: []\n    prefinish: []\n    close: []\n    [DESTROYED]: [er?: unknown]\n    [ERROR]: [er: unknown]\n  }\n\n  /**\n   * String or buffer-like data that can be joined and sliced\n   */\n  export type ContiguousData =\n    | Buffer\n    | ArrayBufferLike\n    | ArrayBufferView\n    | string\n  export type BufferOrString = Buffer | string\n\n  /**\n   * Options passed to the Minipass constructor.\n   */\n  export type SharedOptions = {\n    /**\n     * Defer all data emission and other events until the end of the\n     * current tick, similar to Node core streams\n     */\n    async?: boolean\n    /**\n     * A signal which will abort the stream\n     */\n    signal?: AbortSignal\n    /**\n     * Output string encoding. Set to `null` or `'buffer'` (or omit) to\n     * emit Buffer objects rather than strings.\n     *\n     * Conflicts with `objectMode`\n     */\n    encoding?: BufferEncoding | null | 'buffer'\n    /**\n     * Output data exactly as it was written, supporting non-buffer/string\n     * data (such as arbitrary objects, falsey values, etc.)\n     *\n     * Conflicts with `encoding`\n     */\n    objectMode?: boolean\n  }\n\n  /**\n   * Options for a string encoded output\n   */\n  export type EncodingOptions = SharedOptions & {\n    encoding: BufferEncoding\n    objectMode?: false\n  }\n\n  /**\n   * Options for contiguous data buffer output\n   */\n  export type BufferOptions = SharedOptions & {\n    encoding?: null | 'buffer'\n    objectMode?: false\n  }\n\n  /**\n   * Options for objectMode arbitrary output\n   */\n  export type ObjectModeOptions = SharedOptions & {\n    objectMode: true\n    encoding?: null\n  }\n\n  /**\n   * Utility type to determine allowed options based on read type\n   */\n  export type Options<T> =\n    | ObjectModeOptions\n    | (T extends string\n        ? EncodingOptions\n        : T extends Buffer\n        ? BufferOptions\n        : SharedOptions)\n}\n\nconst isObjectModeOptions = (\n  o: Minipass.SharedOptions\n): o is Minipass.ObjectModeOptions => !!o.objectMode\n\nconst isEncodingOptions = (\n  o: Minipass.SharedOptions\n): o is Minipass.EncodingOptions =>\n  !o.objectMode && !!o.encoding && o.encoding !== 'buffer'\n\n/**\n * Main export, the Minipass class\n *\n * `RType` is the type of data emitted, defaults to Buffer\n *\n * `WType` is the type of data to be written, if RType is buffer or string,\n * then any {@link Minipass.ContiguousData} is allowed.\n *\n * `Events` is the set of event handler signatures that this object\n * will emit, see {@link Minipass.Events}\n */\nexport class Minipass<\n    RType extends unknown = Buffer,\n    WType extends unknown = RType extends Minipass.BufferOrString\n      ? Minipass.ContiguousData\n      : RType,\n    Events extends Minipass.Events<RType> = Minipass.Events<RType>\n  >\n  extends EventEmitter\n  implements Minipass.DualIterable<RType>\n{\n  [FLOWING]: boolean = false;\n  [PAUSED]: boolean = false;\n  [PIPES]: Pipe<RType>[] = [];\n  [BUFFER]: RType[] = [];\n  [OBJECTMODE]: boolean;\n  [ENCODING]: BufferEncoding | null;\n  [ASYNC]: boolean;\n  [DECODER]: SD | null;\n  [EOF]: boolean = false;\n  [EMITTED_END]: boolean = false;\n  [EMITTING_END]: boolean = false;\n  [CLOSED]: boolean = false;\n  [EMITTED_ERROR]: unknown = null;\n  [BUFFERLENGTH]: number = 0;\n  [DESTROYED]: boolean = false;\n  [SIGNAL]?: AbortSignal;\n  [ABORTED]: boolean = false;\n  [DATALISTENERS]: number = 0;\n  [DISCARDED]: boolean = false\n\n  /**\n   * true if the stream can be written\n   */\n  writable: boolean = true\n  /**\n   * true if the stream can be read\n   */\n  readable: boolean = true\n\n  /**\n   * If `RType` is Buffer, then options do not need to be provided.\n   * Otherwise, an options object must be provided to specify either\n   * {@link Minipass.SharedOptions.objectMode} or\n   * {@link Minipass.SharedOptions.encoding}, as appropriate.\n   */\n  constructor(\n    ...args:\n      | [Minipass.ObjectModeOptions]\n      | (RType extends Buffer\n          ? [] | [Minipass.Options<RType>]\n          : [Minipass.Options<RType>])\n  ) {\n    const options: Minipass.Options<RType> = (args[0] ||\n      {}) as Minipass.Options<RType>\n    super()\n    if (options.objectMode && typeof options.encoding === 'string') {\n      throw new TypeError(\n        'Encoding and objectMode may not be used together'\n      )\n    }\n    if (isObjectModeOptions(options)) {\n      this[OBJECTMODE] = true\n      this[ENCODING] = null\n    } else if (isEncodingOptions(options)) {\n      this[ENCODING] = options.encoding\n      this[OBJECTMODE] = false\n    } else {\n      this[OBJECTMODE] = false\n      this[ENCODING] = null\n    }\n    this[ASYNC] = !!options.async\n    this[DECODER] = this[ENCODING]\n      ? (new StringDecoder(this[ENCODING]) as SD)\n      : null\n\n    //@ts-ignore - private option for debugging and testing\n    if (options && options.debugExposeBuffer === true) {\n      Object.defineProperty(this, 'buffer', { get: () => this[BUFFER] })\n    }\n    //@ts-ignore - private option for debugging and testing\n    if (options && options.debugExposePipes === true) {\n      Object.defineProperty(this, 'pipes', { get: () => this[PIPES] })\n    }\n\n    const { signal } = options\n    if (signal) {\n      this[SIGNAL] = signal\n      if (signal.aborted) {\n        this[ABORT]()\n      } else {\n        signal.addEventListener('abort', () => this[ABORT]())\n      }\n    }\n  }\n\n  /**\n   * The amount of data stored in the buffer waiting to be read.\n   *\n   * For Buffer strings, this will be the total byte length.\n   * For string encoding streams, this will be the string character length,\n   * according to JavaScript's `string.length` logic.\n   * For objectMode streams, this is a count of the items waiting to be\n   * emitted.\n   */\n  get bufferLength() {\n    return this[BUFFERLENGTH]\n  }\n\n  /**\n   * The `BufferEncoding` currently in use, or `null`\n   */\n  get encoding() {\n    return this[ENCODING]\n  }\n\n  /**\n   * @deprecated - This is a read only property\n   */\n  set encoding(_enc) {\n    throw new Error('Encoding must be set at instantiation time')\n  }\n\n  /**\n   * @deprecated - Encoding may only be set at instantiation time\n   */\n  setEncoding(_enc: Minipass.Encoding) {\n    throw new Error('Encoding must be set at instantiation time')\n  }\n\n  /**\n   * True if this is an objectMode stream\n   */\n  get objectMode() {\n    return this[OBJECTMODE]\n  }\n\n  /**\n   * @deprecated - This is a read-only property\n   */\n  set objectMode(_om) {\n    throw new Error('objectMode must be set at instantiation time')\n  }\n\n  /**\n   * true if this is an async stream\n   */\n  get ['async'](): boolean {\n    return this[ASYNC]\n  }\n  /**\n   * Set to true to make this stream async.\n   *\n   * Once set, it cannot be unset, as this would potentially cause incorrect\n   * behavior.  Ie, a sync stream can be made async, but an async stream\n   * cannot be safely made sync.\n   */\n  set ['async'](a: boolean) {\n    this[ASYNC] = this[ASYNC] || !!a\n  }\n\n  // drop everything and get out of the flow completely\n  [ABORT]() {\n    this[ABORTED] = true\n    this.emit('abort', this[SIGNAL]?.reason)\n    this.destroy(this[SIGNAL]?.reason)\n  }\n\n  /**\n   * True if the stream has been aborted.\n   */\n  get aborted() {\n    return this[ABORTED]\n  }\n  /**\n   * No-op setter. Stream aborted status is set via the AbortSignal provided\n   * in the constructor options.\n   */\n  set aborted(_) {}\n\n  /**\n   * Write data into the stream\n   *\n   * If the chunk written is a string, and encoding is not specified, then\n   * `utf8` will be assumed. If the stream encoding matches the encoding of\n   * a written string, and the state of the string decoder allows it, then\n   * the string will be passed through to either the output or the internal\n   * buffer without any processing. Otherwise, it will be turned into a\n   * Buffer object for processing into the desired encoding.\n   *\n   * If provided, `cb` function is called immediately before return for\n   * sync streams, or on next tick for async streams, because for this\n   * base class, a chunk is considered \"processed\" once it is accepted\n   * and either emitted or buffered. That is, the callback does not indicate\n   * that the chunk has been eventually emitted, though of course child\n   * classes can override this function to do whatever processing is required\n   * and call `super.write(...)` only once processing is completed.\n   */\n  write(chunk: WType, cb?: () => void): boolean\n  write(\n    chunk: WType,\n    encoding?: Minipass.Encoding,\n    cb?: () => void\n  ): boolean\n  write(\n    chunk: WType,\n    encoding?: Minipass.Encoding | (() => void),\n    cb?: () => void\n  ): boolean {\n    if (this[ABORTED]) return false\n    if (this[EOF]) throw new Error('write after end')\n\n    if (this[DESTROYED]) {\n      this.emit(\n        'error',\n        Object.assign(\n          new Error('Cannot call write after a stream was destroyed'),\n          { code: 'ERR_STREAM_DESTROYED' }\n        )\n      )\n      return true\n    }\n\n    if (typeof encoding === 'function') {\n      cb = encoding\n      encoding = 'utf8'\n    }\n\n    if (!encoding) encoding = 'utf8'\n\n    const fn = this[ASYNC] ? defer : nodefer\n\n    // convert array buffers and typed array views into buffers\n    // at some point in the future, we may want to do the opposite!\n    // leave strings and buffers as-is\n    // anything is only allowed if in object mode, so throw\n    if (!this[OBJECTMODE] && !Buffer.isBuffer(chunk)) {\n      if (isArrayBufferView(chunk)) {\n        //@ts-ignore - sinful unsafe type changing\n        chunk = Buffer.from(\n          chunk.buffer,\n          chunk.byteOffset,\n          chunk.byteLength\n        )\n      } else if (isArrayBufferLike(chunk)) {\n        //@ts-ignore - sinful unsafe type changing\n        chunk = Buffer.from(chunk)\n      } else if (typeof chunk !== 'string') {\n        throw new Error(\n          'Non-contiguous data written to non-objectMode stream'\n        )\n      }\n    }\n\n    // handle object mode up front, since it's simpler\n    // this yields better performance, fewer checks later.\n    if (this[OBJECTMODE]) {\n      // maybe impossible?\n      /* c8 ignore start */\n      if (this[FLOWING] && this[BUFFERLENGTH] !== 0) this[FLUSH](true)\n      /* c8 ignore stop */\n\n      if (this[FLOWING]) this.emit('data', chunk as unknown as RType)\n      else this[BUFFERPUSH](chunk as unknown as RType)\n\n      if (this[BUFFERLENGTH] !== 0) this.emit('readable')\n\n      if (cb) fn(cb)\n\n      return this[FLOWING]\n    }\n\n    // at this point the chunk is a buffer or string\n    // don't buffer it up or send it to the decoder\n    if (!(chunk as Minipass.BufferOrString).length) {\n      if (this[BUFFERLENGTH] !== 0) this.emit('readable')\n      if (cb) fn(cb)\n      return this[FLOWING]\n    }\n\n    // fast-path writing strings of same encoding to a stream with\n    // an empty buffer, skipping the buffer/decoder dance\n    if (\n      typeof chunk === 'string' &&\n      // unless it is a string already ready for us to use\n      !(encoding === this[ENCODING] && !this[DECODER]?.lastNeed)\n    ) {\n      //@ts-ignore - sinful unsafe type change\n      chunk = Buffer.from(chunk, encoding)\n    }\n\n    if (Buffer.isBuffer(chunk) && this[ENCODING]) {\n      //@ts-ignore - sinful unsafe type change\n      chunk = this[DECODER].write(chunk)\n    }\n\n    // Note: flushing CAN potentially switch us into not-flowing mode\n    if (this[FLOWING] && this[BUFFERLENGTH] !== 0) this[FLUSH](true)\n\n    if (this[FLOWING]) this.emit('data', chunk as unknown as RType)\n    else this[BUFFERPUSH](chunk as unknown as RType)\n\n    if (this[BUFFERLENGTH] !== 0) this.emit('readable')\n\n    if (cb) fn(cb)\n\n    return this[FLOWING]\n  }\n\n  /**\n   * Low-level explicit read method.\n   *\n   * In objectMode, the argument is ignored, and one item is returned if\n   * available.\n   *\n   * `n` is the number of bytes (or in the case of encoding streams,\n   * characters) to consume. If `n` is not provided, then the entire buffer\n   * is returned, or `null` is returned if no data is available.\n   *\n   * If `n` is greater that the amount of data in the internal buffer,\n   * then `null` is returned.\n   */\n  read(n?: number | null): RType | null {\n    if (this[DESTROYED]) return null\n    this[DISCARDED] = false\n\n    if (\n      this[BUFFERLENGTH] === 0 ||\n      n === 0 ||\n      (n && n > this[BUFFERLENGTH])\n    ) {\n      this[MAYBE_EMIT_END]()\n      return null\n    }\n\n    if (this[OBJECTMODE]) n = null\n\n    if (this[BUFFER].length > 1 && !this[OBJECTMODE]) {\n      // not object mode, so if we have an encoding, then RType is string\n      // otherwise, must be Buffer\n      this[BUFFER] = [\n        (this[ENCODING]\n          ? this[BUFFER].join('')\n          : Buffer.concat(\n              this[BUFFER] as Buffer[],\n              this[BUFFERLENGTH]\n            )) as RType,\n      ]\n    }\n\n    const ret = this[READ](n || null, this[BUFFER][0] as RType)\n    this[MAYBE_EMIT_END]()\n    return ret\n  }\n\n  [READ](n: number | null, chunk: RType) {\n    if (this[OBJECTMODE]) this[BUFFERSHIFT]()\n    else {\n      const c = chunk as Minipass.BufferOrString\n      if (n === c.length || n === null) this[BUFFERSHIFT]()\n      else if (typeof c === 'string') {\n        this[BUFFER][0] = c.slice(n) as RType\n        chunk = c.slice(0, n) as RType\n        this[BUFFERLENGTH] -= n\n      } else {\n        this[BUFFER][0] = c.subarray(n) as RType\n        chunk = c.subarray(0, n) as RType\n        this[BUFFERLENGTH] -= n\n      }\n    }\n\n    this.emit('data', chunk)\n\n    if (!this[BUFFER].length && !this[EOF]) this.emit('drain')\n\n    return chunk\n  }\n\n  /**\n   * End the stream, optionally providing a final write.\n   *\n   * See {@link Minipass#write} for argument descriptions\n   */\n  end(cb?: () => void): this\n  end(chunk: WType, cb?: () => void): this\n  end(chunk: WType, encoding?: Minipass.Encoding, cb?: () => void): this\n  end(\n    chunk?: WType | (() => void),\n    encoding?: Minipass.Encoding | (() => void),\n    cb?: () => void\n  ): this {\n    if (typeof chunk === 'function') {\n      cb = chunk as () => void\n      chunk = undefined\n    }\n    if (typeof encoding === 'function') {\n      cb = encoding\n      encoding = 'utf8'\n    }\n    if (chunk !== undefined) this.write(chunk, encoding)\n    if (cb) this.once('end', cb)\n    this[EOF] = true\n    this.writable = false\n\n    // if we haven't written anything, then go ahead and emit,\n    // even if we're not reading.\n    // we'll re-emit if a new 'end' listener is added anyway.\n    // This makes MP more suitable to write-only use cases.\n    if (this[FLOWING] || !this[PAUSED]) this[MAYBE_EMIT_END]()\n    return this\n  }\n\n  // don't let the internal resume be overwritten\n  [RESUME]() {\n    if (this[DESTROYED]) return\n\n    if (!this[DATALISTENERS] && !this[PIPES].length) {\n      this[DISCARDED] = true\n    }\n    this[PAUSED] = false\n    this[FLOWING] = true\n    this.emit('resume')\n    if (this[BUFFER].length) this[FLUSH]()\n    else if (this[EOF]) this[MAYBE_EMIT_END]()\n    else this.emit('drain')\n  }\n\n  /**\n   * Resume the stream if it is currently in a paused state\n   *\n   * If called when there are no pipe destinations or `data` event listeners,\n   * this will place the stream in a \"discarded\" state, where all data will\n   * be thrown away. The discarded state is removed if a pipe destination or\n   * data handler is added, if pause() is called, or if any synchronous or\n   * asynchronous iteration is started.\n   */\n  resume() {\n    return this[RESUME]()\n  }\n\n  /**\n   * Pause the stream\n   */\n  pause() {\n    this[FLOWING] = false\n    this[PAUSED] = true\n    this[DISCARDED] = false\n  }\n\n  /**\n   * true if the stream has been forcibly destroyed\n   */\n  get destroyed() {\n    return this[DESTROYED]\n  }\n\n  /**\n   * true if the stream is currently in a flowing state, meaning that\n   * any writes will be immediately emitted.\n   */\n  get flowing() {\n    return this[FLOWING]\n  }\n\n  /**\n   * true if the stream is currently in a paused state\n   */\n  get paused() {\n    return this[PAUSED]\n  }\n\n  [BUFFERPUSH](chunk: RType) {\n    if (this[OBJECTMODE]) this[BUFFERLENGTH] += 1\n    else this[BUFFERLENGTH] += (chunk as Minipass.BufferOrString).length\n    this[BUFFER].push(chunk)\n  }\n\n  [BUFFERSHIFT](): RType {\n    if (this[OBJECTMODE]) this[BUFFERLENGTH] -= 1\n    else\n      this[BUFFERLENGTH] -= (\n        this[BUFFER][0] as Minipass.BufferOrString\n      ).length\n    return this[BUFFER].shift() as RType\n  }\n\n  [FLUSH](noDrain: boolean = false) {\n    do {} while (\n      this[FLUSHCHUNK](this[BUFFERSHIFT]()) &&\n      this[BUFFER].length\n    )\n\n    if (!noDrain && !this[BUFFER].length && !this[EOF]) this.emit('drain')\n  }\n\n  [FLUSHCHUNK](chunk: RType) {\n    this.emit('data', chunk)\n    return this[FLOWING]\n  }\n\n  /**\n   * Pipe all data emitted by this stream into the destination provided.\n   *\n   * Triggers the flow of data.\n   */\n  pipe<W extends Minipass.Writable>(dest: W, opts?: PipeOptions): W {\n    if (this[DESTROYED]) return dest\n    this[DISCARDED] = false\n\n    const ended = this[EMITTED_END]\n    opts = opts || {}\n    if (dest === proc.stdout || dest === proc.stderr) opts.end = false\n    else opts.end = opts.end !== false\n    opts.proxyErrors = !!opts.proxyErrors\n\n    // piping an ended stream ends immediately\n    if (ended) {\n      if (opts.end) dest.end()\n    } else {\n      // \"as\" here just ignores the WType, which pipes don't care about,\n      // since they're only consuming from us, and writing to the dest\n      this[PIPES].push(\n        !opts.proxyErrors\n          ? new Pipe<RType>(this as Minipass<RType>, dest, opts)\n          : new PipeProxyErrors<RType>(this as Minipass<RType>, dest, opts)\n      )\n      if (this[ASYNC]) defer(() => this[RESUME]())\n      else this[RESUME]()\n    }\n\n    return dest\n  }\n\n  /**\n   * Fully unhook a piped destination stream.\n   *\n   * If the destination stream was the only consumer of this stream (ie,\n   * there are no other piped destinations or `'data'` event listeners)\n   * then the flow of data will stop until there is another consumer or\n   * {@link Minipass#resume} is explicitly called.\n   */\n  unpipe<W extends Minipass.Writable>(dest: W) {\n    const p = this[PIPES].find(p => p.dest === dest)\n    if (p) {\n      if (this[PIPES].length === 1) {\n        if (this[FLOWING] && this[DATALISTENERS] === 0) {\n          this[FLOWING] = false\n        }\n        this[PIPES] = []\n      } else this[PIPES].splice(this[PIPES].indexOf(p), 1)\n      p.unpipe()\n    }\n  }\n\n  /**\n   * Alias for {@link Minipass#on}\n   */\n  addListener<Event extends keyof Events>(\n    ev: Event,\n    handler: (...args: Events[Event]) => any\n  ): this {\n    return this.on(ev, handler)\n  }\n\n  /**\n   * Mostly identical to `EventEmitter.on`, with the following\n   * behavior differences to prevent data loss and unnecessary hangs:\n   *\n   * - Adding a 'data' event handler will trigger the flow of data\n   *\n   * - Adding a 'readable' event handler when there is data waiting to be read\n   *   will cause 'readable' to be emitted immediately.\n   *\n   * - Adding an 'endish' event handler ('end', 'finish', etc.) which has\n   *   already passed will cause the event to be emitted immediately and all\n   *   handlers removed.\n   *\n   * - Adding an 'error' event handler after an error has been emitted will\n   *   cause the event to be re-emitted immediately with the error previously\n   *   raised.\n   */\n  on<Event extends keyof Events>(\n    ev: Event,\n    handler: (...args: Events[Event]) => any\n  ): this {\n    const ret = super.on(\n      ev as string | symbol,\n      handler as (...a: any[]) => any\n    )\n    if (ev === 'data') {\n      this[DISCARDED] = false\n      this[DATALISTENERS]++\n      if (!this[PIPES].length && !this[FLOWING]) {\n        this[RESUME]()\n      }\n    } else if (ev === 'readable' && this[BUFFERLENGTH] !== 0) {\n      super.emit('readable')\n    } else if (isEndish(ev) && this[EMITTED_END]) {\n      super.emit(ev)\n      this.removeAllListeners(ev)\n    } else if (ev === 'error' && this[EMITTED_ERROR]) {\n      const h = handler as (...a: Events['error']) => any\n      if (this[ASYNC]) defer(() => h.call(this, this[EMITTED_ERROR]))\n      else h.call(this, this[EMITTED_ERROR])\n    }\n    return ret\n  }\n\n  /**\n   * Alias for {@link Minipass#off}\n   */\n  removeListener<Event extends keyof Events>(\n    ev: Event,\n    handler: (...args: Events[Event]) => any\n  ) {\n    return this.off(ev, handler)\n  }\n\n  /**\n   * Mostly identical to `EventEmitter.off`\n   *\n   * If a 'data' event handler is removed, and it was the last consumer\n   * (ie, there are no pipe destinations or other 'data' event listeners),\n   * then the flow of data will stop until there is another consumer or\n   * {@link Minipass#resume} is explicitly called.\n   */\n  off<Event extends keyof Events>(\n    ev: Event,\n    handler: (...args: Events[Event]) => any\n  ) {\n    const ret = super.off(\n      ev as string | symbol,\n      handler as (...a: any[]) => any\n    )\n    // if we previously had listeners, and now we don't, and we don't\n    // have any pipes, then stop the flow, unless it's been explicitly\n    // put in a discarded flowing state via stream.resume().\n    if (ev === 'data') {\n      this[DATALISTENERS] = this.listeners('data').length\n      if (\n        this[DATALISTENERS] === 0 &&\n        !this[DISCARDED] &&\n        !this[PIPES].length\n      ) {\n        this[FLOWING] = false\n      }\n    }\n    return ret\n  }\n\n  /**\n   * Mostly identical to `EventEmitter.removeAllListeners`\n   *\n   * If all 'data' event handlers are removed, and they were the last consumer\n   * (ie, there are no pipe destinations), then the flow of data will stop\n   * until there is another consumer or {@link Minipass#resume} is explicitly\n   * called.\n   */\n  removeAllListeners<Event extends keyof Events>(ev?: Event) {\n    const ret = super.removeAllListeners(ev as string | symbol | undefined)\n    if (ev === 'data' || ev === undefined) {\n      this[DATALISTENERS] = 0\n      if (!this[DISCARDED] && !this[PIPES].length) {\n        this[FLOWING] = false\n      }\n    }\n    return ret\n  }\n\n  /**\n   * true if the 'end' event has been emitted\n   */\n  get emittedEnd() {\n    return this[EMITTED_END]\n  }\n\n  [MAYBE_EMIT_END]() {\n    if (\n      !this[EMITTING_END] &&\n      !this[EMITTED_END] &&\n      !this[DESTROYED] &&\n      this[BUFFER].length === 0 &&\n      this[EOF]\n    ) {\n      this[EMITTING_END] = true\n      this.emit('end')\n      this.emit('prefinish')\n      this.emit('finish')\n      if (this[CLOSED]) this.emit('close')\n      this[EMITTING_END] = false\n    }\n  }\n\n  /**\n   * Mostly identical to `EventEmitter.emit`, with the following\n   * behavior differences to prevent data loss and unnecessary hangs:\n   *\n   * If the stream has been destroyed, and the event is something other\n   * than 'close' or 'error', then `false` is returned and no handlers\n   * are called.\n   *\n   * If the event is 'end', and has already been emitted, then the event\n   * is ignored. If the stream is in a paused or non-flowing state, then\n   * the event will be deferred until data flow resumes. If the stream is\n   * async, then handlers will be called on the next tick rather than\n   * immediately.\n   *\n   * If the event is 'close', and 'end' has not yet been emitted, then\n   * the event will be deferred until after 'end' is emitted.\n   *\n   * If the event is 'error', and an AbortSignal was provided for the stream,\n   * and there are no listeners, then the event is ignored, matching the\n   * behavior of node core streams in the presense of an AbortSignal.\n   *\n   * If the event is 'finish' or 'prefinish', then all listeners will be\n   * removed after emitting the event, to prevent double-firing.\n   */\n  emit<Event extends keyof Events>(\n    ev: Event,\n    ...args: Events[Event]\n  ): boolean {\n    const data = args[0]\n    // error and close are only events allowed after calling destroy()\n    if (\n      ev !== 'error' &&\n      ev !== 'close' &&\n      ev !== DESTROYED &&\n      this[DESTROYED]\n    ) {\n      return false\n    } else if (ev === 'data') {\n      return !this[OBJECTMODE] && !data\n        ? false\n        : this[ASYNC]\n        ? (defer(() => this[EMITDATA](data as RType)), true)\n        : this[EMITDATA](data as RType)\n    } else if (ev === 'end') {\n      return this[EMITEND]()\n    } else if (ev === 'close') {\n      this[CLOSED] = true\n      // don't emit close before 'end' and 'finish'\n      if (!this[EMITTED_END] && !this[DESTROYED]) return false\n      const ret = super.emit('close')\n      this.removeAllListeners('close')\n      return ret\n    } else if (ev === 'error') {\n      this[EMITTED_ERROR] = data\n      super.emit(ERROR, data)\n      const ret =\n        !this[SIGNAL] || this.listeners('error').length\n          ? super.emit('error', data)\n          : false\n      this[MAYBE_EMIT_END]()\n      return ret\n    } else if (ev === 'resume') {\n      const ret = super.emit('resume')\n      this[MAYBE_EMIT_END]()\n      return ret\n    } else if (ev === 'finish' || ev === 'prefinish') {\n      const ret = super.emit(ev)\n      this.removeAllListeners(ev)\n      return ret\n    }\n\n    // Some other unknown event\n    const ret = super.emit(ev as string, ...args)\n    this[MAYBE_EMIT_END]()\n    return ret\n  }\n\n  [EMITDATA](data: RType) {\n    for (const p of this[PIPES]) {\n      if (p.dest.write(data as RType) === false) this.pause()\n    }\n    const ret = this[DISCARDED] ? false : super.emit('data', data)\n    this[MAYBE_EMIT_END]()\n    return ret\n  }\n\n  [EMITEND]() {\n    if (this[EMITTED_END]) return false\n\n    this[EMITTED_END] = true\n    this.readable = false\n    return this[ASYNC]\n      ? (defer(() => this[EMITEND2]()), true)\n      : this[EMITEND2]()\n  }\n\n  [EMITEND2]() {\n    if (this[DECODER]) {\n      const data = this[DECODER].end()\n      if (data) {\n        for (const p of this[PIPES]) {\n          p.dest.write(data as RType)\n        }\n        if (!this[DISCARDED]) super.emit('data', data)\n      }\n    }\n\n    for (const p of this[PIPES]) {\n      p.end()\n    }\n    const ret = super.emit('end')\n    this.removeAllListeners('end')\n    return ret\n  }\n\n  /**\n   * Return a Promise that resolves to an array of all emitted data once\n   * the stream ends.\n   */\n  async collect(): Promise<RType[] & { dataLength: number }> {\n    const buf: RType[] & { dataLength: number } = Object.assign([], {\n      dataLength: 0,\n    })\n    if (!this[OBJECTMODE]) buf.dataLength = 0\n    // set the promise first, in case an error is raised\n    // by triggering the flow here.\n    const p = this.promise()\n    this.on('data', c => {\n      buf.push(c)\n      if (!this[OBJECTMODE])\n        buf.dataLength += (c as Minipass.BufferOrString).length\n    })\n    await p\n    return buf\n  }\n\n  /**\n   * Return a Promise that resolves to the concatenation of all emitted data\n   * once the stream ends.\n   *\n   * Not allowed on objectMode streams.\n   */\n  async concat(): Promise<RType> {\n    if (this[OBJECTMODE]) {\n      throw new Error('cannot concat in objectMode')\n    }\n    const buf = await this.collect()\n    return (\n      this[ENCODING]\n        ? buf.join('')\n        : Buffer.concat(buf as Buffer[], buf.dataLength)\n    ) as RType\n  }\n\n  /**\n   * Return a void Promise that resolves once the stream ends.\n   */\n  async promise(): Promise<void> {\n    return new Promise<void>((resolve, reject) => {\n      this.on(DESTROYED, () => reject(new Error('stream destroyed')))\n      this.on('error', er => reject(er))\n      this.on('end', () => resolve())\n    })\n  }\n\n  /**\n   * Asynchronous `for await of` iteration.\n   *\n   * This will continue emitting all chunks until the stream terminates.\n   */\n  [Symbol.asyncIterator](): AsyncGenerator<RType, void, void> {\n    // set this up front, in case the consumer doesn't call next()\n    // right away.\n    this[DISCARDED] = false\n    let stopped = false\n    const stop = async (): Promise<IteratorReturnResult<void>> => {\n      this.pause()\n      stopped = true\n      return { value: undefined, done: true }\n    }\n    const next = (): Promise<IteratorResult<RType, void>> => {\n      if (stopped) return stop()\n      const res = this.read()\n      if (res !== null) return Promise.resolve({ done: false, value: res })\n\n      if (this[EOF]) return stop()\n\n      let resolve!: (res: IteratorResult<RType>) => void\n      let reject!: (er: unknown) => void\n      const onerr = (er: unknown) => {\n        this.off('data', ondata)\n        this.off('end', onend)\n        this.off(DESTROYED, ondestroy)\n        stop()\n        reject(er)\n      }\n      const ondata = (value: RType) => {\n        this.off('error', onerr)\n        this.off('end', onend)\n        this.off(DESTROYED, ondestroy)\n        this.pause()\n        resolve({ value, done: !!this[EOF] })\n      }\n      const onend = () => {\n        this.off('error', onerr)\n        this.off('data', ondata)\n        this.off(DESTROYED, ondestroy)\n        stop()\n        resolve({ done: true, value: undefined })\n      }\n      const ondestroy = () => onerr(new Error('stream destroyed'))\n      return new Promise<IteratorResult<RType>>((res, rej) => {\n        reject = rej\n        resolve = res\n        this.once(DESTROYED, ondestroy)\n        this.once('error', onerr)\n        this.once('end', onend)\n        this.once('data', ondata)\n      })\n    }\n\n    return {\n      next,\n      throw: stop,\n      return: stop,\n      [Symbol.asyncIterator]() {\n        return this\n      },\n    }\n  }\n\n  /**\n   * Synchronous `for of` iteration.\n   *\n   * The iteration will terminate when the internal buffer runs out, even\n   * if the stream has not yet terminated.\n   */\n  [Symbol.iterator](): Generator<RType, void, void> {\n    // set this up front, in case the consumer doesn't call next()\n    // right away.\n    this[DISCARDED] = false\n    let stopped = false\n    const stop = (): IteratorReturnResult<void> => {\n      this.pause()\n      this.off(ERROR, stop)\n      this.off(DESTROYED, stop)\n      this.off('end', stop)\n      stopped = true\n      return { done: true, value: undefined }\n    }\n\n    const next = (): IteratorResult<RType, void> => {\n      if (stopped) return stop()\n      const value = this.read()\n      return value === null ? stop() : { done: false, value }\n    }\n\n    this.once('end', stop)\n    this.once(ERROR, stop)\n    this.once(DESTROYED, stop)\n\n    return {\n      next,\n      throw: stop,\n      return: stop,\n      [Symbol.iterator]() {\n        return this\n      },\n    }\n  }\n\n  /**\n   * Destroy a stream, preventing it from being used for any further purpose.\n   *\n   * If the stream has a `close()` method, then it will be called on\n   * destruction.\n   *\n   * After destruction, any attempt to write data, read data, or emit most\n   * events will be ignored.\n   *\n   * If an error argument is provided, then it will be emitted in an\n   * 'error' event.\n   */\n  destroy(er?: unknown) {\n    if (this[DESTROYED]) {\n      if (er) this.emit('error', er)\n      else this.emit(DESTROYED)\n      return this\n    }\n\n    this[DESTROYED] = true\n    this[DISCARDED] = true\n\n    // throw away all buffered data, it's never coming out\n    this[BUFFER].length = 0\n    this[BUFFERLENGTH] = 0\n\n    const wc = this as Minipass<RType, WType, Events> & {\n      close?: () => void\n    }\n    if (typeof wc.close === 'function' && !this[CLOSED]) wc.close()\n\n    if (er) this.emit('error', er)\n    // if no error to emit, still reject pending promises\n    else this.emit(DESTROYED)\n\n    return this\n  }\n\n  /**\n   * Alias for {@link isStream}\n   *\n   * Former export location, maintained for backwards compatibility.\n   *\n   * @deprecated\n   */\n  static get isStream() {\n    return isStream\n  }\n}\n","import { Minimatch, MinimatchOptions } from 'minimatch'\nimport { Minipass } from 'minipass'\nimport {\n  FSOption,\n  Path,\n  PathScurry,\n  PathScurryDarwin,\n  PathScurryPosix,\n  PathScurryWin32,\n} from 'path-scurry'\nimport { fileURLToPath } from 'url'\nimport { IgnoreLike } from './ignore.js'\nimport { Pattern } from './pattern.js'\nimport { GlobStream, GlobWalker } from './walker.js'\n\nexport type MatchSet = Minimatch['set']\nexport type GlobParts = Exclude<Minimatch['globParts'], undefined>\n\n// if no process global, just call it linux.\n// so we default to case-sensitive, / separators\nconst defaultPlatform: NodeJS.Platform =\n  typeof process === 'object' &&\n  process &&\n  typeof process.platform === 'string'\n    ? process.platform\n    : 'linux'\n\n/**\n * A `GlobOptions` object may be provided to any of the exported methods, and\n * must be provided to the `Glob` constructor.\n *\n * All options are optional, boolean, and false by default, unless otherwise\n * noted.\n *\n * All resolved options are added to the Glob object as properties.\n *\n * If you are running many `glob` operations, you can pass a Glob object as the\n * `options` argument to a subsequent operation to share the previously loaded\n * cache.\n */\nexport interface GlobOptions {\n  /**\n   * Set to `true` to always receive absolute paths for\n   * matched files. Set to `false` to always return relative paths.\n   *\n   * When this option is not set, absolute paths are returned for patterns\n   * that are absolute, and otherwise paths are returned that are relative\n   * to the `cwd` setting.\n   *\n   * This does _not_ make an extra system call to get\n   * the realpath, it only does string path resolution.\n   *\n   * Conflicts with {@link withFileTypes}\n   */\n  absolute?: boolean\n\n  /**\n   * Set to false to enable {@link windowsPathsNoEscape}\n   *\n   * @deprecated\n   */\n  allowWindowsEscape?: boolean\n\n  /**\n   * The current working directory in which to search. Defaults to\n   * `process.cwd()`.\n   *\n   * May be eiher a string path or a `file://` URL object or string.\n   */\n  cwd?: string | URL\n\n  /**\n   * Include `.dot` files in normal matches and `globstar`\n   * matches. Note that an explicit dot in a portion of the pattern\n   * will always match dot files.\n   */\n  dot?: boolean\n\n  /**\n   * Prepend all relative path strings with `./` (or `.\\` on Windows).\n   *\n   * Without this option, returned relative paths are \"bare\", so instead of\n   * returning `'./foo/bar'`, they are returned as `'foo/bar'`.\n   *\n   * Relative patterns starting with `'../'` are not prepended with `./`, even\n   * if this option is set.\n   */\n  dotRelative?: boolean\n\n  /**\n   * Follow symlinked directories when expanding `**`\n   * patterns. This can result in a lot of duplicate references in\n   * the presence of cyclic links, and make performance quite bad.\n   *\n   * By default, a `**` in a pattern will follow 1 symbolic link if\n   * it is not the first item in the pattern, or none if it is the\n   * first item in the pattern, following the same behavior as Bash.\n   */\n  follow?: boolean\n\n  /**\n   * string or string[], or an object with `ignore` and `ignoreChildren`\n   * methods.\n   *\n   * If a string or string[] is provided, then this is treated as a glob\n   * pattern or array of glob patterns to exclude from matches. To ignore all\n   * children within a directory, as well as the entry itself, append `'/**'`\n   * to the ignore pattern.\n   *\n   * **Note** `ignore` patterns are _always_ in `dot:true` mode, regardless of\n   * any other settings.\n   *\n   * If an object is provided that has `ignored(path)` and/or\n   * `childrenIgnored(path)` methods, then these methods will be called to\n   * determine whether any Path is a match or if its children should be\n   * traversed, respectively.\n   */\n  ignore?: string | string[] | IgnoreLike\n\n  /**\n   * Treat brace expansion like `{a,b}` as a \"magic\" pattern. Has no\n   * effect if {@link nobrace} is set.\n   *\n   * Only has effect on the {@link hasMagic} function.\n   */\n  magicalBraces?: boolean\n\n  /**\n   * Add a `/` character to directory matches. Note that this requires\n   * additional stat calls in some cases.\n   */\n  mark?: boolean\n\n  /**\n   * Perform a basename-only match if the pattern does not contain any slash\n   * characters. That is, `*.js` would be treated as equivalent to\n   * `**\\/*.js`, matching all js files in all directories.\n   */\n  matchBase?: boolean\n\n  /**\n   * Limit the directory traversal to a given depth below the cwd.\n   * Note that this does NOT prevent traversal to sibling folders,\n   * root patterns, and so on. It only limits the maximum folder depth\n   * that the walk will descend, relative to the cwd.\n   */\n  maxDepth?: number\n\n  /**\n   * Do not expand `{a,b}` and `{1..3}` brace sets.\n   */\n  nobrace?: boolean\n\n  /**\n   * Perform a case-insensitive match. This defaults to `true` on macOS and\n   * Windows systems, and `false` on all others.\n   *\n   * **Note** `nocase` should only be explicitly set when it is\n   * known that the filesystem's case sensitivity differs from the\n   * platform default. If set `true` on case-sensitive file\n   * systems, or `false` on case-insensitive file systems, then the\n   * walk may return more or less results than expected.\n   */\n  nocase?: boolean\n\n  /**\n   * Do not match directories, only files. (Note: to match\n   * _only_ directories, put a `/` at the end of the pattern.)\n   */\n  nodir?: boolean\n\n  /**\n   * Do not match \"extglob\" patterns such as `+(a|b)`.\n   */\n  noext?: boolean\n\n  /**\n   * Do not match `**` against multiple filenames. (Ie, treat it as a normal\n   * `*` instead.)\n   *\n   * Conflicts with {@link matchBase}\n   */\n  noglobstar?: boolean\n\n  /**\n   * Defaults to value of `process.platform` if available, or `'linux'` if\n   * not. Setting `platform:'win32'` on non-Windows systems may cause strange\n   * behavior.\n   */\n  platform?: NodeJS.Platform\n\n  /**\n   * Set to true to call `fs.realpath` on all of the\n   * results. In the case of an entry that cannot be resolved, the\n   * entry is omitted. This incurs a slight performance penalty, of\n   * course, because of the added system calls.\n   */\n  realpath?: boolean\n\n  /**\n   *\n   * A string path resolved against the `cwd` option, which\n   * is used as the starting point for absolute patterns that start\n   * with `/`, (but not drive letters or UNC paths on Windows).\n   *\n   * Note that this _doesn't_ necessarily limit the walk to the\n   * `root` directory, and doesn't affect the cwd starting point for\n   * non-absolute patterns. A pattern containing `..` will still be\n   * able to traverse out of the root directory, if it is not an\n   * actual root directory on the filesystem, and any non-absolute\n   * patterns will be matched in the `cwd`. For example, the\n   * pattern `/../*` with `{root:'/some/path'}` will return all\n   * files in `/some`, not all files in `/some/path`. The pattern\n   * `*` with `{root:'/some/path'}` will return all the entries in\n   * the cwd, not the entries in `/some/path`.\n   *\n   * To start absolute and non-absolute patterns in the same\n   * path, you can use `{root:''}`. However, be aware that on\n   * Windows systems, a pattern like `x:/*` or `//host/share/*` will\n   * _always_ start in the `x:/` or `//host/share` directory,\n   * regardless of the `root` setting.\n   */\n  root?: string\n\n  /**\n   * A [PathScurry](http://npm.im/path-scurry) object used\n   * to traverse the file system. If the `nocase` option is set\n   * explicitly, then any provided `scurry` object must match this\n   * setting.\n   */\n  scurry?: PathScurry\n\n  /**\n   * Call `lstat()` on all entries, whether required or not to determine\n   * if it's a valid match. When used with {@link withFileTypes}, this means\n   * that matches will include data such as modified time, permissions, and\n   * so on.  Note that this will incur a performance cost due to the added\n   * system calls.\n   */\n  stat?: boolean\n\n  /**\n   * An AbortSignal which will cancel the Glob walk when\n   * triggered.\n   */\n  signal?: AbortSignal\n\n  /**\n   * Use `\\\\` as a path separator _only_, and\n   *  _never_ as an escape character. If set, all `\\\\` characters are\n   *  replaced with `/` in the pattern.\n   *\n   *  Note that this makes it **impossible** to match against paths\n   *  containing literal glob pattern characters, but allows matching\n   *  with patterns constructed using `path.join()` and\n   *  `path.resolve()` on Windows platforms, mimicking the (buggy!)\n   *  behavior of Glob v7 and before on Windows. Please use with\n   *  caution, and be mindful of [the caveat below about Windows\n   *  paths](#windows). (For legacy reasons, this is also set if\n   *  `allowWindowsEscape` is set to the exact value `false`.)\n   */\n  windowsPathsNoEscape?: boolean\n\n  /**\n   * Return [PathScurry](http://npm.im/path-scurry)\n   * `Path` objects instead of strings. These are similar to a\n   * NodeJS `Dirent` object, but with additional methods and\n   * properties.\n   *\n   * Conflicts with {@link absolute}\n   */\n  withFileTypes?: boolean\n\n  /**\n   * An fs implementation to override some or all of the defaults.  See\n   * http://npm.im/path-scurry for details about what can be overridden.\n   */\n  fs?: FSOption\n\n  /**\n   * Just passed along to Minimatch.  Note that this makes all pattern\n   * matching operations slower and *extremely* noisy.\n   */\n  debug?: boolean\n\n  /**\n   * Return `/` delimited paths, even on Windows.\n   *\n   * On posix systems, this has no effect.  But, on Windows, it means that\n   * paths will be `/` delimited, and absolute paths will be their full\n   * resolved UNC forms, eg instead of `'C:\\\\foo\\\\bar'`, it would return\n   * `'//?/C:/foo/bar'`\n   */\n  posix?: boolean\n}\n\nexport type GlobOptionsWithFileTypesTrue = GlobOptions & {\n  withFileTypes: true\n  // string options not relevant if returning Path objects.\n  absolute?: undefined\n  mark?: undefined\n  posix?: undefined\n}\n\nexport type GlobOptionsWithFileTypesFalse = GlobOptions & {\n  withFileTypes?: false\n}\n\nexport type GlobOptionsWithFileTypesUnset = GlobOptions & {\n  withFileTypes?: undefined\n}\n\nexport type Result<Opts> = Opts extends GlobOptionsWithFileTypesTrue\n  ? Path\n  : Opts extends GlobOptionsWithFileTypesFalse\n  ? string\n  : Opts extends GlobOptionsWithFileTypesUnset\n  ? string\n  : string | Path\nexport type Results<Opts> = Result<Opts>[]\n\nexport type FileTypes<Opts> = Opts extends GlobOptionsWithFileTypesTrue\n  ? true\n  : Opts extends GlobOptionsWithFileTypesFalse\n  ? false\n  : Opts extends GlobOptionsWithFileTypesUnset\n  ? false\n  : boolean\n\n/**\n * An object that can perform glob pattern traversals.\n */\nexport class Glob<Opts extends GlobOptions> implements GlobOptions {\n  absolute?: boolean\n  cwd: string\n  root?: string\n  dot: boolean\n  dotRelative: boolean\n  follow: boolean\n  ignore?: string | string[] | IgnoreLike\n  magicalBraces: boolean\n  mark?: boolean\n  matchBase: boolean\n  maxDepth: number\n  nobrace: boolean\n  nocase: boolean\n  nodir: boolean\n  noext: boolean\n  noglobstar: boolean\n  pattern: string[]\n  platform: NodeJS.Platform\n  realpath: boolean\n  scurry: PathScurry\n  stat: boolean\n  signal?: AbortSignal\n  windowsPathsNoEscape: boolean\n  withFileTypes: FileTypes<Opts>\n\n  /**\n   * The options provided to the constructor.\n   */\n  opts: Opts\n\n  /**\n   * An array of parsed immutable {@link Pattern} objects.\n   */\n  patterns: Pattern[]\n\n  /**\n   * All options are stored as properties on the `Glob` object.\n   *\n   * See {@link GlobOptions} for full options descriptions.\n   *\n   * Note that a previous `Glob` object can be passed as the\n   * `GlobOptions` to another `Glob` instantiation to re-use settings\n   * and caches with a new pattern.\n   *\n   * Traversal functions can be called multiple times to run the walk\n   * again.\n   */\n  constructor(pattern: string | string[], opts: Opts) {\n    this.withFileTypes = !!opts.withFileTypes as FileTypes<Opts>\n    this.signal = opts.signal\n    this.follow = !!opts.follow\n    this.dot = !!opts.dot\n    this.dotRelative = !!opts.dotRelative\n    this.nodir = !!opts.nodir\n    this.mark = !!opts.mark\n    if (!opts.cwd) {\n      this.cwd = ''\n    } else if (opts.cwd instanceof URL || opts.cwd.startsWith('file://')) {\n      opts.cwd = fileURLToPath(opts.cwd)\n    }\n    this.cwd = opts.cwd || ''\n    this.root = opts.root\n    this.magicalBraces = !!opts.magicalBraces\n    this.nobrace = !!opts.nobrace\n    this.noext = !!opts.noext\n    this.realpath = !!opts.realpath\n    this.absolute = opts.absolute\n\n    this.noglobstar = !!opts.noglobstar\n    this.matchBase = !!opts.matchBase\n    this.maxDepth =\n      typeof opts.maxDepth === 'number' ? opts.maxDepth : Infinity\n    this.stat = !!opts.stat\n    this.ignore = opts.ignore\n\n    if (this.withFileTypes && this.absolute !== undefined) {\n      throw new Error('cannot set absolute and withFileTypes:true')\n    }\n\n    if (typeof pattern === 'string') {\n      pattern = [pattern]\n    }\n\n    this.windowsPathsNoEscape =\n      !!opts.windowsPathsNoEscape ||\n      (opts as GlobOptions).allowWindowsEscape === false\n\n    if (this.windowsPathsNoEscape) {\n      pattern = pattern.map(p => p.replace(/\\\\/g, '/'))\n    }\n\n    if (this.matchBase) {\n      if (opts.noglobstar) {\n        throw new TypeError('base matching requires globstar')\n      }\n      pattern = pattern.map(p => (p.includes('/') ? p : `./**/${p}`))\n    }\n\n    this.pattern = pattern\n\n    this.platform = opts.platform || defaultPlatform\n    this.opts = { ...opts, platform: this.platform }\n    if (opts.scurry) {\n      this.scurry = opts.scurry\n      if (\n        opts.nocase !== undefined &&\n        opts.nocase !== opts.scurry.nocase\n      ) {\n        throw new Error('nocase option contradicts provided scurry option')\n      }\n    } else {\n      const Scurry =\n        opts.platform === 'win32'\n          ? PathScurryWin32\n          : opts.platform === 'darwin'\n          ? PathScurryDarwin\n          : opts.platform\n          ? PathScurryPosix\n          : PathScurry\n      this.scurry = new Scurry(this.cwd, {\n        nocase: opts.nocase,\n        fs: opts.fs,\n      })\n    }\n    this.nocase = this.scurry.nocase\n\n    // If you do nocase:true on a case-sensitive file system, then\n    // we need to use regexps instead of strings for non-magic\n    // path portions, because statting `aBc` won't return results\n    // for the file `AbC` for example.\n    const nocaseMagicOnly =\n      this.platform === 'darwin' || this.platform === 'win32'\n\n    const mmo: MinimatchOptions = {\n      // default nocase based on platform\n      ...opts,\n      dot: this.dot,\n      matchBase: this.matchBase,\n      nobrace: this.nobrace,\n      nocase: this.nocase,\n      nocaseMagicOnly,\n      nocomment: true,\n      noext: this.noext,\n      nonegate: true,\n      optimizationLevel: 2,\n      platform: this.platform,\n      windowsPathsNoEscape: this.windowsPathsNoEscape,\n      debug: !!this.opts.debug,\n    }\n\n    const mms = this.pattern.map(p => new Minimatch(p, mmo))\n    const [matchSet, globParts] = mms.reduce(\n      (set: [MatchSet, GlobParts], m) => {\n        set[0].push(...m.set)\n        set[1].push(...m.globParts)\n        return set\n      },\n      [[], []]\n    )\n    this.patterns = matchSet.map((set, i) => {\n      return new Pattern(set, globParts[i], 0, this.platform)\n    })\n  }\n\n  /**\n   * Returns a Promise that resolves to the results array.\n   */\n  async walk(): Promise<Results<Opts>>\n  async walk(): Promise<(string | Path)[]> {\n    // Walkers always return array of Path objects, so we just have to\n    // coerce them into the right shape.  It will have already called\n    // realpath() if the option was set to do so, so we know that's cached.\n    // start out knowing the cwd, at least\n    return [\n      ...(await new GlobWalker(this.patterns, this.scurry.cwd, {\n        ...this.opts,\n        maxDepth:\n          this.maxDepth !== Infinity\n            ? this.maxDepth + this.scurry.cwd.depth()\n            : Infinity,\n        platform: this.platform,\n        nocase: this.nocase,\n      }).walk()),\n    ]\n  }\n\n  /**\n   * synchronous {@link Glob.walk}\n   */\n  walkSync(): Results<Opts>\n  walkSync(): (string | Path)[] {\n    return [\n      ...new GlobWalker(this.patterns, this.scurry.cwd, {\n        ...this.opts,\n        maxDepth:\n          this.maxDepth !== Infinity\n            ? this.maxDepth + this.scurry.cwd.depth()\n            : Infinity,\n        platform: this.platform,\n        nocase: this.nocase,\n      }).walkSync(),\n    ]\n  }\n\n  /**\n   * Stream results asynchronously.\n   */\n  stream(): Minipass<Result<Opts>, Result<Opts>>\n  stream(): Minipass<string | Path, string | Path> {\n    return new GlobStream(this.patterns, this.scurry.cwd, {\n      ...this.opts,\n      maxDepth:\n        this.maxDepth !== Infinity\n          ? this.maxDepth + this.scurry.cwd.depth()\n          : Infinity,\n      platform: this.platform,\n      nocase: this.nocase,\n    }).stream()\n  }\n\n  /**\n   * Stream results synchronously.\n   */\n  streamSync(): Minipass<Result<Opts>, Result<Opts>>\n  streamSync(): Minipass<string | Path, string | Path> {\n    return new GlobStream(this.patterns, this.scurry.cwd, {\n      ...this.opts,\n      maxDepth:\n        this.maxDepth !== Infinity\n          ? this.maxDepth + this.scurry.cwd.depth()\n          : Infinity,\n      platform: this.platform,\n      nocase: this.nocase,\n    }).streamSync()\n  }\n\n  /**\n   * Default sync iteration function. Returns a Generator that\n   * iterates over the results.\n   */\n  iterateSync(): Generator<Result<Opts>, void, void> {\n    return this.streamSync()[Symbol.iterator]()\n  }\n  [Symbol.iterator]() {\n    return this.iterateSync()\n  }\n\n  /**\n   * Default async iteration function. Returns an AsyncGenerator that\n   * iterates over the results.\n   */\n  iterate(): AsyncGenerator<Result<Opts>, void, void> {\n    return this.stream()[Symbol.asyncIterator]()\n  }\n  [Symbol.asyncIterator]() {\n    return this.iterate()\n  }\n}\n","// this is just a very light wrapper around 2 arrays with an offset index\n\nimport { GLOBSTAR } from 'minimatch'\nexport type MMPattern = string | RegExp | typeof GLOBSTAR\n\n// an array of length >= 1\nexport type PatternList = [p: MMPattern, ...rest: MMPattern[]]\nexport type UNCPatternList = [\n  p0: '',\n  p1: '',\n  p2: string,\n  p3: string,\n  ...rest: MMPattern[]\n]\nexport type DrivePatternList = [p0: string, ...rest: MMPattern[]]\nexport type AbsolutePatternList = [p0: '', ...rest: MMPattern[]]\nexport type GlobList = [p: string, ...rest: string[]]\n\nconst isPatternList = (pl: MMPattern[]): pl is PatternList =>\n  pl.length >= 1\nconst isGlobList = (gl: string[]): gl is GlobList => gl.length >= 1\n\n/**\n * An immutable-ish view on an array of glob parts and their parsed\n * results\n */\nexport class Pattern {\n  readonly #patternList: PatternList\n  readonly #globList: GlobList\n  readonly #index: number\n  readonly length: number\n  readonly #platform: NodeJS.Platform\n  #rest?: Pattern | null\n  #globString?: string\n  #isDrive?: boolean\n  #isUNC?: boolean\n  #isAbsolute?: boolean\n  #followGlobstar: boolean = true\n\n  constructor(\n    patternList: MMPattern[],\n    globList: string[],\n    index: number,\n    platform: NodeJS.Platform\n  ) {\n    if (!isPatternList(patternList)) {\n      throw new TypeError('empty pattern list')\n    }\n    if (!isGlobList(globList)) {\n      throw new TypeError('empty glob list')\n    }\n    if (globList.length !== patternList.length) {\n      throw new TypeError('mismatched pattern list and glob list lengths')\n    }\n    this.length = patternList.length\n    if (index < 0 || index >= this.length) {\n      throw new TypeError('index out of range')\n    }\n    this.#patternList = patternList\n    this.#globList = globList\n    this.#index = index\n    this.#platform = platform\n\n    // normalize root entries of absolute patterns on initial creation.\n    if (this.#index === 0) {\n      // c: => ['c:/']\n      // C:/ => ['C:/']\n      // C:/x => ['C:/', 'x']\n      // //host/share => ['//host/share/']\n      // //host/share/ => ['//host/share/']\n      // //host/share/x => ['//host/share/', 'x']\n      // /etc => ['/', 'etc']\n      // / => ['/']\n      if (this.isUNC()) {\n        // '' / '' / 'host' / 'share'\n        const [p0, p1, p2, p3, ...prest] = this.#patternList\n        const [g0, g1, g2, g3, ...grest] = this.#globList\n        if (prest[0] === '') {\n          // ends in /\n          prest.shift()\n          grest.shift()\n        }\n        const p = [p0, p1, p2, p3, ''].join('/')\n        const g = [g0, g1, g2, g3, ''].join('/')\n        this.#patternList = [p, ...prest]\n        this.#globList = [g, ...grest]\n        this.length = this.#patternList.length\n      } else if (this.isDrive() || this.isAbsolute()) {\n        const [p1, ...prest] = this.#patternList\n        const [g1, ...grest] = this.#globList\n        if (prest[0] === '') {\n          // ends in /\n          prest.shift()\n          grest.shift()\n        }\n        const p = (p1 as string) + '/'\n        const g = g1 + '/'\n        this.#patternList = [p, ...prest]\n        this.#globList = [g, ...grest]\n        this.length = this.#patternList.length\n      }\n    }\n  }\n\n  /**\n   * The first entry in the parsed list of patterns\n   */\n  pattern(): MMPattern {\n    return this.#patternList[this.#index]\n  }\n\n  /**\n   * true of if pattern() returns a string\n   */\n  isString(): boolean {\n    return typeof this.#patternList[this.#index] === 'string'\n  }\n  /**\n   * true of if pattern() returns GLOBSTAR\n   */\n  isGlobstar(): boolean {\n    return this.#patternList[this.#index] === GLOBSTAR\n  }\n  /**\n   * true if pattern() returns a regexp\n   */\n  isRegExp(): boolean {\n    return this.#patternList[this.#index] instanceof RegExp\n  }\n\n  /**\n   * The /-joined set of glob parts that make up this pattern\n   */\n  globString(): string {\n    return (this.#globString =\n      this.#globString ||\n      (this.#index === 0\n        ? this.isAbsolute()\n          ? this.#globList[0] + this.#globList.slice(1).join('/')\n          : this.#globList.join('/')\n        : this.#globList.slice(this.#index).join('/')))\n  }\n\n  /**\n   * true if there are more pattern parts after this one\n   */\n  hasMore(): boolean {\n    return this.length > this.#index + 1\n  }\n\n  /**\n   * The rest of the pattern after this part, or null if this is the end\n   */\n  rest(): Pattern | null {\n    if (this.#rest !== undefined) return this.#rest\n    if (!this.hasMore()) return (this.#rest = null)\n    this.#rest = new Pattern(\n      this.#patternList,\n      this.#globList,\n      this.#index + 1,\n      this.#platform\n    )\n    this.#rest.#isAbsolute = this.#isAbsolute\n    this.#rest.#isUNC = this.#isUNC\n    this.#rest.#isDrive = this.#isDrive\n    return this.#rest\n  }\n\n  /**\n   * true if the pattern represents a //unc/path/ on windows\n   */\n  isUNC(): boolean {\n    const pl = this.#patternList\n    return this.#isUNC !== undefined\n      ? this.#isUNC\n      : (this.#isUNC =\n          this.#platform === 'win32' &&\n          this.#index === 0 &&\n          pl[0] === '' &&\n          pl[1] === '' &&\n          typeof pl[2] === 'string' &&\n          !!pl[2] &&\n          typeof pl[3] === 'string' &&\n          !!pl[3])\n  }\n\n  // pattern like C:/...\n  // split = ['C:', ...]\n  // XXX: would be nice to handle patterns like `c:*` to test the cwd\n  // in c: for *, but I don't know of a way to even figure out what that\n  // cwd is without actually chdir'ing into it?\n  /**\n   * True if the pattern starts with a drive letter on Windows\n   */\n  isDrive(): boolean {\n    const pl = this.#patternList\n    return this.#isDrive !== undefined\n      ? this.#isDrive\n      : (this.#isDrive =\n          this.#platform === 'win32' &&\n          this.#index === 0 &&\n          this.length > 1 &&\n          typeof pl[0] === 'string' &&\n          /^[a-z]:$/i.test(pl[0]))\n  }\n\n  // pattern = '/' or '/...' or '/x/...'\n  // split = ['', ''] or ['', ...] or ['', 'x', ...]\n  // Drive and UNC both considered absolute on windows\n  /**\n   * True if the pattern is rooted on an absolute path\n   */\n  isAbsolute(): boolean {\n    const pl = this.#patternList\n    return this.#isAbsolute !== undefined\n      ? this.#isAbsolute\n      : (this.#isAbsolute =\n          (pl[0] === '' && pl.length > 1) ||\n          this.isDrive() ||\n          this.isUNC())\n  }\n\n  /**\n   * consume the root of the pattern, and return it\n   */\n  root(): string {\n    const p = this.#patternList[0]\n    return typeof p === 'string' && this.isAbsolute() && this.#index === 0\n      ? p\n      : ''\n  }\n\n  /**\n   * Check to see if the current globstar pattern is allowed to follow\n   * a symbolic link.\n   */\n  checkFollowGlobstar(): boolean {\n    return !(\n      this.#index === 0 ||\n      !this.isGlobstar() ||\n      !this.#followGlobstar\n    )\n  }\n\n  /**\n   * Mark that the current globstar pattern is following a symbolic link\n   */\n  markFollowGlobstar(): boolean {\n    if (this.#index === 0 || !this.isGlobstar() || !this.#followGlobstar)\n      return false\n    this.#followGlobstar = false\n    return true\n  }\n}\n","'use strict'\nconst proc =\n  typeof process === 'object' && process\n    ? process\n    : {\n        stdout: null,\n        stderr: null,\n      }\nimport EE from 'events'\nimport Stream from 'stream'\nimport stringdecoder from 'string_decoder'\nconst SD = stringdecoder.StringDecoder\n\nconst EOF = Symbol('EOF')\nconst MAYBE_EMIT_END = Symbol('maybeEmitEnd')\nconst EMITTED_END = Symbol('emittedEnd')\nconst EMITTING_END = Symbol('emittingEnd')\nconst EMITTED_ERROR = Symbol('emittedError')\nconst CLOSED = Symbol('closed')\nconst READ = Symbol('read')\nconst FLUSH = Symbol('flush')\nconst FLUSHCHUNK = Symbol('flushChunk')\nconst ENCODING = Symbol('encoding')\nconst DECODER = Symbol('decoder')\nconst FLOWING = Symbol('flowing')\nconst PAUSED = Symbol('paused')\nconst RESUME = Symbol('resume')\nconst BUFFER = Symbol('buffer')\nconst PIPES = Symbol('pipes')\nconst BUFFERLENGTH = Symbol('bufferLength')\nconst BUFFERPUSH = Symbol('bufferPush')\nconst BUFFERSHIFT = Symbol('bufferShift')\nconst OBJECTMODE = Symbol('objectMode')\n// internal event when stream is destroyed\nconst DESTROYED = Symbol('destroyed')\n// internal event when stream has an error\nconst ERROR = Symbol('error')\nconst EMITDATA = Symbol('emitData')\nconst EMITEND = Symbol('emitEnd')\nconst EMITEND2 = Symbol('emitEnd2')\nconst ASYNC = Symbol('async')\nconst ABORT = Symbol('abort')\nconst ABORTED = Symbol('aborted')\nconst SIGNAL = Symbol('signal')\n\nconst defer = fn => Promise.resolve().then(fn)\n\n// TODO remove when Node v8 support drops\nconst doIter = global._MP_NO_ITERATOR_SYMBOLS_ !== '1'\nconst ASYNCITERATOR =\n  (doIter && Symbol.asyncIterator) || Symbol('asyncIterator not implemented')\nconst ITERATOR =\n  (doIter && Symbol.iterator) || Symbol('iterator not implemented')\n\n// events that mean 'the stream is over'\n// these are treated specially, and re-emitted\n// if they are listened for after emitting.\nconst isEndish = ev => ev === 'end' || ev === 'finish' || ev === 'prefinish'\n\nconst isArrayBuffer = b =>\n  b instanceof ArrayBuffer ||\n  (typeof b === 'object' &&\n    b.constructor &&\n    b.constructor.name === 'ArrayBuffer' &&\n    b.byteLength >= 0)\n\nconst isArrayBufferView = b => !Buffer.isBuffer(b) && ArrayBuffer.isView(b)\n\nclass Pipe {\n  constructor(src, dest, opts) {\n    this.src = src\n    this.dest = dest\n    this.opts = opts\n    this.ondrain = () => src[RESUME]()\n    dest.on('drain', this.ondrain)\n  }\n  unpipe() {\n    this.dest.removeListener('drain', this.ondrain)\n  }\n  // istanbul ignore next - only here for the prototype\n  proxyErrors() {}\n  end() {\n    this.unpipe()\n    if (this.opts.end) this.dest.end()\n  }\n}\n\nclass PipeProxyErrors extends Pipe {\n  unpipe() {\n    this.src.removeListener('error', this.proxyErrors)\n    super.unpipe()\n  }\n  constructor(src, dest, opts) {\n    super(src, dest, opts)\n    this.proxyErrors = er => dest.emit('error', er)\n    src.on('error', this.proxyErrors)\n  }\n}\n\nexport class Minipass extends Stream {\n  constructor(options) {\n    super()\n    this[FLOWING] = false\n    // whether we're explicitly paused\n    this[PAUSED] = false\n    this[PIPES] = []\n    this[BUFFER] = []\n    this[OBJECTMODE] = (options && options.objectMode) || false\n    if (this[OBJECTMODE]) this[ENCODING] = null\n    else this[ENCODING] = (options && options.encoding) || null\n    if (this[ENCODING] === 'buffer') this[ENCODING] = null\n    this[ASYNC] = (options && !!options.async) || false\n    this[DECODER] = this[ENCODING] ? new SD(this[ENCODING]) : null\n    this[EOF] = false\n    this[EMITTED_END] = false\n    this[EMITTING_END] = false\n    this[CLOSED] = false\n    this[EMITTED_ERROR] = null\n    this.writable = true\n    this.readable = true\n    this[BUFFERLENGTH] = 0\n    this[DESTROYED] = false\n    if (options && options.debugExposeBuffer === true) {\n      Object.defineProperty(this, 'buffer', { get: () => this[BUFFER] })\n    }\n    if (options && options.debugExposePipes === true) {\n      Object.defineProperty(this, 'pipes', { get: () => this[PIPES] })\n    }\n    this[SIGNAL] = options && options.signal\n    this[ABORTED] = false\n    if (this[SIGNAL]) {\n      this[SIGNAL].addEventListener('abort', () => this[ABORT]())\n      if (this[SIGNAL].aborted) {\n        this[ABORT]()\n      }\n    }\n  }\n\n  get bufferLength() {\n    return this[BUFFERLENGTH]\n  }\n\n  get encoding() {\n    return this[ENCODING]\n  }\n  set encoding(enc) {\n    if (this[OBJECTMODE]) throw new Error('cannot set encoding in objectMode')\n\n    if (\n      this[ENCODING] &&\n      enc !== this[ENCODING] &&\n      ((this[DECODER] && this[DECODER].lastNeed) || this[BUFFERLENGTH])\n    )\n      throw new Error('cannot change encoding')\n\n    if (this[ENCODING] !== enc) {\n      this[DECODER] = enc ? new SD(enc) : null\n      if (this[BUFFER].length)\n        this[BUFFER] = this[BUFFER].map(chunk => this[DECODER].write(chunk))\n    }\n\n    this[ENCODING] = enc\n  }\n\n  setEncoding(enc) {\n    this.encoding = enc\n  }\n\n  get objectMode() {\n    return this[OBJECTMODE]\n  }\n  set objectMode(om) {\n    this[OBJECTMODE] = this[OBJECTMODE] || !!om\n  }\n\n  get ['async']() {\n    return this[ASYNC]\n  }\n  set ['async'](a) {\n    this[ASYNC] = this[ASYNC] || !!a\n  }\n\n  // drop everything and get out of the flow completely\n  [ABORT]() {\n    this[ABORTED] = true\n    this.emit('abort', this[SIGNAL].reason)\n    this.destroy(this[SIGNAL].reason)\n  }\n\n  get aborted() {\n    return this[ABORTED]\n  }\n  set aborted(_) {}\n\n  write(chunk, encoding, cb) {\n    if (this[ABORTED]) return false\n    if (this[EOF]) throw new Error('write after end')\n\n    if (this[DESTROYED]) {\n      this.emit(\n        'error',\n        Object.assign(\n          new Error('Cannot call write after a stream was destroyed'),\n          { code: 'ERR_STREAM_DESTROYED' }\n        )\n      )\n      return true\n    }\n\n    if (typeof encoding === 'function') (cb = encoding), (encoding = 'utf8')\n\n    if (!encoding) encoding = 'utf8'\n\n    const fn = this[ASYNC] ? defer : f => f()\n\n    // convert array buffers and typed array views into buffers\n    // at some point in the future, we may want to do the opposite!\n    // leave strings and buffers as-is\n    // anything else switches us into object mode\n    if (!this[OBJECTMODE] && !Buffer.isBuffer(chunk)) {\n      if (isArrayBufferView(chunk))\n        chunk = Buffer.from(chunk.buffer, chunk.byteOffset, chunk.byteLength)\n      else if (isArrayBuffer(chunk)) chunk = Buffer.from(chunk)\n      else if (typeof chunk !== 'string')\n        // use the setter so we throw if we have encoding set\n        this.objectMode = true\n    }\n\n    // handle object mode up front, since it's simpler\n    // this yields better performance, fewer checks later.\n    if (this[OBJECTMODE]) {\n      /* istanbul ignore if - maybe impossible? */\n      if (this.flowing && this[BUFFERLENGTH] !== 0) this[FLUSH](true)\n\n      if (this.flowing) this.emit('data', chunk)\n      else this[BUFFERPUSH](chunk)\n\n      if (this[BUFFERLENGTH] !== 0) this.emit('readable')\n\n      if (cb) fn(cb)\n\n      return this.flowing\n    }\n\n    // at this point the chunk is a buffer or string\n    // don't buffer it up or send it to the decoder\n    if (!chunk.length) {\n      if (this[BUFFERLENGTH] !== 0) this.emit('readable')\n      if (cb) fn(cb)\n      return this.flowing\n    }\n\n    // fast-path writing strings of same encoding to a stream with\n    // an empty buffer, skipping the buffer/decoder dance\n    if (\n      typeof chunk === 'string' &&\n      // unless it is a string already ready for us to use\n      !(encoding === this[ENCODING] && !this[DECODER].lastNeed)\n    ) {\n      chunk = Buffer.from(chunk, encoding)\n    }\n\n    if (Buffer.isBuffer(chunk) && this[ENCODING])\n      chunk = this[DECODER].write(chunk)\n\n    // Note: flushing CAN potentially switch us into not-flowing mode\n    if (this.flowing && this[BUFFERLENGTH] !== 0) this[FLUSH](true)\n\n    if (this.flowing) this.emit('data', chunk)\n    else this[BUFFERPUSH](chunk)\n\n    if (this[BUFFERLENGTH] !== 0) this.emit('readable')\n\n    if (cb) fn(cb)\n\n    return this.flowing\n  }\n\n  read(n) {\n    if (this[DESTROYED]) return null\n\n    if (this[BUFFERLENGTH] === 0 || n === 0 || n > this[BUFFERLENGTH]) {\n      this[MAYBE_EMIT_END]()\n      return null\n    }\n\n    if (this[OBJECTMODE]) n = null\n\n    if (this[BUFFER].length > 1 && !this[OBJECTMODE]) {\n      if (this.encoding) this[BUFFER] = [this[BUFFER].join('')]\n      else this[BUFFER] = [Buffer.concat(this[BUFFER], this[BUFFERLENGTH])]\n    }\n\n    const ret = this[READ](n || null, this[BUFFER][0])\n    this[MAYBE_EMIT_END]()\n    return ret\n  }\n\n  [READ](n, chunk) {\n    if (n === chunk.length || n === null) this[BUFFERSHIFT]()\n    else {\n      this[BUFFER][0] = chunk.slice(n)\n      chunk = chunk.slice(0, n)\n      this[BUFFERLENGTH] -= n\n    }\n\n    this.emit('data', chunk)\n\n    if (!this[BUFFER].length && !this[EOF]) this.emit('drain')\n\n    return chunk\n  }\n\n  end(chunk, encoding, cb) {\n    if (typeof chunk === 'function') (cb = chunk), (chunk = null)\n    if (typeof encoding === 'function') (cb = encoding), (encoding = 'utf8')\n    if (chunk) this.write(chunk, encoding)\n    if (cb) this.once('end', cb)\n    this[EOF] = true\n    this.writable = false\n\n    // if we haven't written anything, then go ahead and emit,\n    // even if we're not reading.\n    // we'll re-emit if a new 'end' listener is added anyway.\n    // This makes MP more suitable to write-only use cases.\n    if (this.flowing || !this[PAUSED]) this[MAYBE_EMIT_END]()\n    return this\n  }\n\n  // don't let the internal resume be overwritten\n  [RESUME]() {\n    if (this[DESTROYED]) return\n\n    this[PAUSED] = false\n    this[FLOWING] = true\n    this.emit('resume')\n    if (this[BUFFER].length) this[FLUSH]()\n    else if (this[EOF]) this[MAYBE_EMIT_END]()\n    else this.emit('drain')\n  }\n\n  resume() {\n    return this[RESUME]()\n  }\n\n  pause() {\n    this[FLOWING] = false\n    this[PAUSED] = true\n  }\n\n  get destroyed() {\n    return this[DESTROYED]\n  }\n\n  get flowing() {\n    return this[FLOWING]\n  }\n\n  get paused() {\n    return this[PAUSED]\n  }\n\n  [BUFFERPUSH](chunk) {\n    if (this[OBJECTMODE]) this[BUFFERLENGTH] += 1\n    else this[BUFFERLENGTH] += chunk.length\n    this[BUFFER].push(chunk)\n  }\n\n  [BUFFERSHIFT]() {\n    if (this[OBJECTMODE]) this[BUFFERLENGTH] -= 1\n    else this[BUFFERLENGTH] -= this[BUFFER][0].length\n    return this[BUFFER].shift()\n  }\n\n  [FLUSH](noDrain) {\n    do {} while (this[FLUSHCHUNK](this[BUFFERSHIFT]()) && this[BUFFER].length)\n\n    if (!noDrain && !this[BUFFER].length && !this[EOF]) this.emit('drain')\n  }\n\n  [FLUSHCHUNK](chunk) {\n    this.emit('data', chunk)\n    return this.flowing\n  }\n\n  pipe(dest, opts) {\n    if (this[DESTROYED]) return\n\n    const ended = this[EMITTED_END]\n    opts = opts || {}\n    if (dest === proc.stdout || dest === proc.stderr) opts.end = false\n    else opts.end = opts.end !== false\n    opts.proxyErrors = !!opts.proxyErrors\n\n    // piping an ended stream ends immediately\n    if (ended) {\n      if (opts.end) dest.end()\n    } else {\n      this[PIPES].push(\n        !opts.proxyErrors\n          ? new Pipe(this, dest, opts)\n          : new PipeProxyErrors(this, dest, opts)\n      )\n      if (this[ASYNC]) defer(() => this[RESUME]())\n      else this[RESUME]()\n    }\n\n    return dest\n  }\n\n  unpipe(dest) {\n    const p = this[PIPES].find(p => p.dest === dest)\n    if (p) {\n      this[PIPES].splice(this[PIPES].indexOf(p), 1)\n      p.unpipe()\n    }\n  }\n\n  addListener(ev, fn) {\n    return this.on(ev, fn)\n  }\n\n  on(ev, fn) {\n    const ret = super.on(ev, fn)\n    if (ev === 'data' && !this[PIPES].length && !this.flowing) this[RESUME]()\n    else if (ev === 'readable' && this[BUFFERLENGTH] !== 0)\n      super.emit('readable')\n    else if (isEndish(ev) && this[EMITTED_END]) {\n      super.emit(ev)\n      this.removeAllListeners(ev)\n    } else if (ev === 'error' && this[EMITTED_ERROR]) {\n      if (this[ASYNC]) defer(() => fn.call(this, this[EMITTED_ERROR]))\n      else fn.call(this, this[EMITTED_ERROR])\n    }\n    return ret\n  }\n\n  get emittedEnd() {\n    return this[EMITTED_END]\n  }\n\n  [MAYBE_EMIT_END]() {\n    if (\n      !this[EMITTING_END] &&\n      !this[EMITTED_END] &&\n      !this[DESTROYED] &&\n      this[BUFFER].length === 0 &&\n      this[EOF]\n    ) {\n      this[EMITTING_END] = true\n      this.emit('end')\n      this.emit('prefinish')\n      this.emit('finish')\n      if (this[CLOSED]) this.emit('close')\n      this[EMITTING_END] = false\n    }\n  }\n\n  emit(ev, data, ...extra) {\n    // error and close are only events allowed after calling destroy()\n    if (ev !== 'error' && ev !== 'close' && ev !== DESTROYED && this[DESTROYED])\n      return\n    else if (ev === 'data') {\n      return !this[OBJECTMODE] && !data\n        ? false\n        : this[ASYNC]\n        ? defer(() => this[EMITDATA](data))\n        : this[EMITDATA](data)\n    } else if (ev === 'end') {\n      return this[EMITEND]()\n    } else if (ev === 'close') {\n      this[CLOSED] = true\n      // don't emit close before 'end' and 'finish'\n      if (!this[EMITTED_END] && !this[DESTROYED]) return\n      const ret = super.emit('close')\n      this.removeAllListeners('close')\n      return ret\n    } else if (ev === 'error') {\n      this[EMITTED_ERROR] = data\n      super.emit(ERROR, data)\n      const ret =\n        !this[SIGNAL] || this.listeners('error').length\n          ? super.emit('error', data)\n          : false\n      this[MAYBE_EMIT_END]()\n      return ret\n    } else if (ev === 'resume') {\n      const ret = super.emit('resume')\n      this[MAYBE_EMIT_END]()\n      return ret\n    } else if (ev === 'finish' || ev === 'prefinish') {\n      const ret = super.emit(ev)\n      this.removeAllListeners(ev)\n      return ret\n    }\n\n    // Some other unknown event\n    const ret = super.emit(ev, data, ...extra)\n    this[MAYBE_EMIT_END]()\n    return ret\n  }\n\n  [EMITDATA](data) {\n    for (const p of this[PIPES]) {\n      if (p.dest.write(data) === false) this.pause()\n    }\n    const ret = super.emit('data', data)\n    this[MAYBE_EMIT_END]()\n    return ret\n  }\n\n  [EMITEND]() {\n    if (this[EMITTED_END]) return\n\n    this[EMITTED_END] = true\n    this.readable = false\n    if (this[ASYNC]) defer(() => this[EMITEND2]())\n    else this[EMITEND2]()\n  }\n\n  [EMITEND2]() {\n    if (this[DECODER]) {\n      const data = this[DECODER].end()\n      if (data) {\n        for (const p of this[PIPES]) {\n          p.dest.write(data)\n        }\n        super.emit('data', data)\n      }\n    }\n\n    for (const p of this[PIPES]) {\n      p.end()\n    }\n    const ret = super.emit('end')\n    this.removeAllListeners('end')\n    return ret\n  }\n\n  // const all = await stream.collect()\n  collect() {\n    const buf = []\n    if (!this[OBJECTMODE]) buf.dataLength = 0\n    // set the promise first, in case an error is raised\n    // by triggering the flow here.\n    const p = this.promise()\n    this.on('data', c => {\n      buf.push(c)\n      if (!this[OBJECTMODE]) buf.dataLength += c.length\n    })\n    return p.then(() => buf)\n  }\n\n  // const data = await stream.concat()\n  concat() {\n    return this[OBJECTMODE]\n      ? Promise.reject(new Error('cannot concat in objectMode'))\n      : this.collect().then(buf =>\n          this[OBJECTMODE]\n            ? Promise.reject(new Error('cannot concat in objectMode'))\n            : this[ENCODING]\n            ? buf.join('')\n            : Buffer.concat(buf, buf.dataLength)\n        )\n  }\n\n  // stream.promise().then(() => done, er => emitted error)\n  promise() {\n    return new Promise((resolve, reject) => {\n      this.on(DESTROYED, () => reject(new Error('stream destroyed')))\n      this.on('error', er => reject(er))\n      this.on('end', () => resolve())\n    })\n  }\n\n  // for await (let chunk of stream)\n  [ASYNCITERATOR]() {\n    let stopped = false\n    const stop = () => {\n      this.pause()\n      stopped = true\n      return Promise.resolve({ done: true })\n    }\n    const next = () => {\n      if (stopped) return stop()\n      const res = this.read()\n      if (res !== null) return Promise.resolve({ done: false, value: res })\n\n      if (this[EOF]) return stop()\n\n      let resolve = null\n      let reject = null\n      const onerr = er => {\n        this.removeListener('data', ondata)\n        this.removeListener('end', onend)\n        this.removeListener(DESTROYED, ondestroy)\n        stop()\n        reject(er)\n      }\n      const ondata = value => {\n        this.removeListener('error', onerr)\n        this.removeListener('end', onend)\n        this.removeListener(DESTROYED, ondestroy)\n        this.pause()\n        resolve({ value: value, done: !!this[EOF] })\n      }\n      const onend = () => {\n        this.removeListener('error', onerr)\n        this.removeListener('data', ondata)\n        this.removeListener(DESTROYED, ondestroy)\n        stop()\n        resolve({ done: true })\n      }\n      const ondestroy = () => onerr(new Error('stream destroyed'))\n      return new Promise((res, rej) => {\n        reject = rej\n        resolve = res\n        this.once(DESTROYED, ondestroy)\n        this.once('error', onerr)\n        this.once('end', onend)\n        this.once('data', ondata)\n      })\n    }\n\n    return {\n      next,\n      throw: stop,\n      return: stop,\n      [ASYNCITERATOR]() {\n        return this\n      },\n    }\n  }\n\n  // for (let chunk of stream)\n  [ITERATOR]() {\n    let stopped = false\n    const stop = () => {\n      this.pause()\n      this.removeListener(ERROR, stop)\n      this.removeListener(DESTROYED, stop)\n      this.removeListener('end', stop)\n      stopped = true\n      return { done: true }\n    }\n\n    const next = () => {\n      if (stopped) return stop()\n      const value = this.read()\n      return value === null ? stop() : { value }\n    }\n    this.once('end', stop)\n    this.once(ERROR, stop)\n    this.once(DESTROYED, stop)\n\n    return {\n      next,\n      throw: stop,\n      return: stop,\n      [ITERATOR]() {\n        return this\n      },\n    }\n  }\n\n  destroy(er) {\n    if (this[DESTROYED]) {\n      if (er) this.emit('error', er)\n      else this.emit(DESTROYED)\n      return this\n    }\n\n    this[DESTROYED] = true\n\n    // throw away all buffered data, it's never coming out\n    this[BUFFER].length = 0\n    this[BUFFERLENGTH] = 0\n\n    if (typeof this.close === 'function' && !this[CLOSED]) this.close()\n\n    if (er) this.emit('error', er)\n    // if no error to emit, still reject pending promises\n    else this.emit(DESTROYED)\n\n    return this\n  }\n\n  static isStream(s) {\n    return (\n      !!s &&\n      (s instanceof Minipass ||\n        s instanceof Stream ||\n        (s instanceof EE &&\n          // readable\n          (typeof s.pipe === 'function' ||\n            // writable\n            (typeof s.write === 'function' && typeof s.end === 'function'))))\n    )\n  }\n}\n\n\n","// give it a pattern, and it'll be able to tell you if\n// a given path should be ignored.\n// Ignoring a path ignores its children if the pattern ends in /**\n// Ignores are always parsed in dot:true mode\n\nimport { Minimatch } from 'minimatch'\nimport { Path } from 'path-scurry'\nimport { Pattern } from './pattern.js'\nimport { GlobWalkerOpts } from './walker.js'\n\nexport interface IgnoreLike {\n  ignored?: (p: Path) => boolean\n  childrenIgnored?: (p: Path) => boolean\n}\n\nconst defaultPlatform: NodeJS.Platform =\n  typeof process === 'object' &&\n  process &&\n  typeof process.platform === 'string'\n    ? process.platform\n    : 'linux'\n\n/**\n * Class used to process ignored patterns\n */\nexport class Ignore implements IgnoreLike {\n  relative: Minimatch[]\n  relativeChildren: Minimatch[]\n  absolute: Minimatch[]\n  absoluteChildren: Minimatch[]\n\n  constructor(\n    ignored: string[],\n    {\n      nobrace,\n      nocase,\n      noext,\n      noglobstar,\n      platform = defaultPlatform,\n    }: GlobWalkerOpts\n  ) {\n    this.relative = []\n    this.absolute = []\n    this.relativeChildren = []\n    this.absoluteChildren = []\n    const mmopts = {\n      dot: true,\n      nobrace,\n      nocase,\n      noext,\n      noglobstar,\n      optimizationLevel: 2,\n      platform,\n      nocomment: true,\n      nonegate: true,\n    }\n\n    // this is a little weird, but it gives us a clean set of optimized\n    // minimatch matchers, without getting tripped up if one of them\n    // ends in /** inside a brace section, and it's only inefficient at\n    // the start of the walk, not along it.\n    // It'd be nice if the Pattern class just had a .test() method, but\n    // handling globstars is a bit of a pita, and that code already lives\n    // in minimatch anyway.\n    // Another way would be if maybe Minimatch could take its set/globParts\n    // as an option, and then we could at least just use Pattern to test\n    // for absolute-ness.\n    // Yet another way, Minimatch could take an array of glob strings, and\n    // a cwd option, and do the right thing.\n    for (const ign of ignored) {\n      const mm = new Minimatch(ign, mmopts)\n      for (let i = 0; i < mm.set.length; i++) {\n        const parsed = mm.set[i]\n        const globParts = mm.globParts[i]\n        const p = new Pattern(parsed, globParts, 0, platform)\n        const m = new Minimatch(p.globString(), mmopts)\n        const children = globParts[globParts.length - 1] === '**'\n        const absolute = p.isAbsolute()\n        if (absolute) this.absolute.push(m)\n        else this.relative.push(m)\n        if (children) {\n          if (absolute) this.absoluteChildren.push(m)\n          else this.relativeChildren.push(m)\n        }\n      }\n    }\n  }\n\n  ignored(p: Path): boolean {\n    const fullpath = p.fullpath()\n    const fullpaths = `${fullpath}/`\n    const relative = p.relative() || '.'\n    const relatives = `${relative}/`\n    for (const m of this.relative) {\n      if (m.match(relative) || m.match(relatives)) return true\n    }\n    for (const m of this.absolute) {\n      if (m.match(fullpath) || m.match(fullpaths)) return true\n    }\n    return false\n  }\n\n  childrenIgnored(p: Path): boolean {\n    const fullpath = p.fullpath() + '/'\n    const relative = (p.relative() || '.') + '/'\n    for (const m of this.relativeChildren) {\n      if (m.match(relative)) return true\n    }\n    for (const m of this.absoluteChildren) {\n      if (m.match(fullpath)) true\n    }\n    return false\n  }\n}\n","// synchronous utility for filtering entries and calculating subwalks\n\nimport { GLOBSTAR, MMRegExp } from 'minimatch'\nimport { Path } from 'path-scurry'\nimport { MMPattern, Pattern } from './pattern.js'\nimport { GlobWalkerOpts } from './walker.js'\n\n/**\n * A cache of which patterns have been processed for a given Path\n */\nexport class HasWalkedCache {\n  store: Map<string, Set<string>>\n  constructor(store: Map<string, Set<string>> = new Map()) {\n    this.store = store\n  }\n  copy() {\n    return new HasWalkedCache(new Map(this.store))\n  }\n  hasWalked(target: Path, pattern: Pattern) {\n    return this.store.get(target.fullpath())?.has(pattern.globString())\n  }\n  storeWalked(target: Path, pattern: Pattern) {\n    const fullpath = target.fullpath()\n    const cached = this.store.get(fullpath)\n    if (cached) cached.add(pattern.globString())\n    else this.store.set(fullpath, new Set([pattern.globString()]))\n  }\n}\n\n/**\n * A record of which paths have been matched in a given walk step,\n * and whether they only are considered a match if they are a directory,\n * and whether their absolute or relative path should be returned.\n */\nexport class MatchRecord {\n  store: Map<Path, number> = new Map()\n  add(target: Path, absolute: boolean, ifDir: boolean) {\n    const n = (absolute ? 2 : 0) | (ifDir ? 1 : 0)\n    const current = this.store.get(target)\n    this.store.set(target, current === undefined ? n : n & current)\n  }\n  // match, absolute, ifdir\n  entries(): [Path, boolean, boolean][] {\n    return [...this.store.entries()].map(([path, n]) => [\n      path,\n      !!(n & 2),\n      !!(n & 1),\n    ])\n  }\n}\n\n/**\n * A collection of patterns that must be processed in a subsequent step\n * for a given path.\n */\nexport class SubWalks {\n  store: Map<Path, Pattern[]> = new Map()\n  add(target: Path, pattern: Pattern) {\n    if (!target.canReaddir()) {\n      return\n    }\n    const subs = this.store.get(target)\n    if (subs) {\n      if (!subs.find(p => p.globString() === pattern.globString())) {\n        subs.push(pattern)\n      }\n    } else this.store.set(target, [pattern])\n  }\n  get(target: Path): Pattern[] {\n    const subs = this.store.get(target)\n    /* c8 ignore start */\n    if (!subs) {\n      throw new Error('attempting to walk unknown path')\n    }\n    /* c8 ignore stop */\n    return subs\n  }\n  entries(): [Path, Pattern[]][] {\n    return this.keys().map(k => [k, this.store.get(k) as Pattern[]])\n  }\n  keys(): Path[] {\n    return [...this.store.keys()].filter(t => t.canReaddir())\n  }\n}\n\n/**\n * The class that processes patterns for a given path.\n *\n * Handles child entry filtering, and determining whether a path's\n * directory contents must be read.\n */\nexport class Processor {\n  hasWalkedCache: HasWalkedCache\n  matches = new MatchRecord()\n  subwalks = new SubWalks()\n  patterns?: Pattern[]\n  follow: boolean\n  dot: boolean\n  opts: GlobWalkerOpts\n\n  constructor(opts: GlobWalkerOpts, hasWalkedCache?: HasWalkedCache) {\n    this.opts = opts\n    this.follow = !!opts.follow\n    this.dot = !!opts.dot\n    this.hasWalkedCache = hasWalkedCache\n      ? hasWalkedCache.copy()\n      : new HasWalkedCache()\n  }\n\n  processPatterns(target: Path, patterns: Pattern[]) {\n    this.patterns = patterns\n    const processingSet: [Path, Pattern][] = patterns.map(p => [target, p])\n\n    // map of paths to the magic-starting subwalks they need to walk\n    // first item in patterns is the filter\n\n    for (let [t, pattern] of processingSet) {\n      this.hasWalkedCache.storeWalked(t, pattern)\n\n      const root = pattern.root()\n      const absolute = pattern.isAbsolute() && this.opts.absolute !== false\n\n      // start absolute patterns at root\n      if (root) {\n        t = t.resolve(\n          root === '/' && this.opts.root !== undefined\n            ? this.opts.root\n            : root\n        )\n        const rest = pattern.rest()\n        if (!rest) {\n          this.matches.add(t, true, false)\n          continue\n        } else {\n          pattern = rest\n        }\n      }\n\n      if (t.isENOENT()) continue\n\n      let p: MMPattern\n      let rest: Pattern | null\n      let changed = false\n      while (\n        typeof (p = pattern.pattern()) === 'string' &&\n        (rest = pattern.rest())\n      ) {\n        const c = t.resolve(p)\n        // we can be reasonably sure that .. is a readable dir\n        if (c.isUnknown() && p !== '..') break\n        t = c\n        pattern = rest\n        changed = true\n      }\n      p = pattern.pattern()\n      rest = pattern.rest()\n      if (changed) {\n        if (this.hasWalkedCache.hasWalked(t, pattern)) continue\n        this.hasWalkedCache.storeWalked(t, pattern)\n      }\n\n      // now we have either a final string for a known entry,\n      // more strings for an unknown entry,\n      // or a pattern starting with magic, mounted on t.\n      if (typeof p === 'string') {\n        // must be final entry\n        if (!rest) {\n          const ifDir = p === '..' || p === '' || p === '.'\n          this.matches.add(t.resolve(p), absolute, ifDir)\n        } else {\n          this.subwalks.add(t, pattern)\n        }\n        continue\n      } else if (p === GLOBSTAR) {\n        // if no rest, match and subwalk pattern\n        // if rest, process rest and subwalk pattern\n        // if it's a symlink, but we didn't get here by way of a\n        // globstar match (meaning it's the first time THIS globstar\n        // has traversed a symlink), then we follow it. Otherwise, stop.\n        if (\n          !t.isSymbolicLink() ||\n          this.follow ||\n          pattern.checkFollowGlobstar()\n        ) {\n          this.subwalks.add(t, pattern)\n        }\n        const rp = rest?.pattern()\n        const rrest = rest?.rest()\n        if (!rest || ((rp === '' || rp === '.') && !rrest)) {\n          // only HAS to be a dir if it ends in **/ or **/.\n          // but ending in ** will match files as well.\n          this.matches.add(t, absolute, rp === '' || rp === '.')\n        } else {\n          if (rp === '..') {\n            // this would mean you're matching **/.. at the fs root,\n            // and no thanks, I'm not gonna test that specific case.\n            /* c8 ignore start */\n            const tp = t.parent || t\n            /* c8 ignore stop */\n            if (!rrest) this.matches.add(tp, absolute, true)\n            else if (!this.hasWalkedCache.hasWalked(tp, rrest)) {\n              this.subwalks.add(tp, rrest)\n            }\n          }\n        }\n      } else if (p instanceof RegExp) {\n        this.subwalks.add(t, pattern)\n      }\n    }\n\n    return this\n  }\n\n  subwalkTargets(): Path[] {\n    return this.subwalks.keys()\n  }\n\n  child() {\n    return new Processor(this.opts, this.hasWalkedCache)\n  }\n\n  // return a new Processor containing the subwalks for each\n  // child entry, and a set of matches, and\n  // a hasWalkedCache that's a copy of this one\n  // then we're going to call\n  filterEntries(parent: Path, entries: Path[]): Processor {\n    const patterns = this.subwalks.get(parent)\n    // put matches and entry walks into the results processor\n    const results = this.child()\n    for (const e of entries) {\n      for (const pattern of patterns) {\n        const absolute = pattern.isAbsolute()\n        const p = pattern.pattern()\n        const rest = pattern.rest()\n        if (p === GLOBSTAR) {\n          results.testGlobstar(e, pattern, rest, absolute)\n        } else if (p instanceof RegExp) {\n          results.testRegExp(e, p, rest, absolute)\n        } else {\n          results.testString(e, p, rest, absolute)\n        }\n      }\n    }\n    return results\n  }\n\n  testGlobstar(\n    e: Path,\n    pattern: Pattern,\n    rest: Pattern | null,\n    absolute: boolean\n  ) {\n    if (this.dot || !e.name.startsWith('.')) {\n      if (!pattern.hasMore()) {\n        this.matches.add(e, absolute, false)\n      }\n      if (e.canReaddir()) {\n        // if we're in follow mode or it's not a symlink, just keep\n        // testing the same pattern. If there's more after the globstar,\n        // then this symlink consumes the globstar. If not, then we can\n        // follow at most ONE symlink along the way, so we mark it, which\n        // also checks to ensure that it wasn't already marked.\n        if (this.follow || !e.isSymbolicLink()) {\n          this.subwalks.add(e, pattern)\n        } else if (e.isSymbolicLink()) {\n          if (rest && pattern.checkFollowGlobstar()) {\n            this.subwalks.add(e, rest)\n          } else if (pattern.markFollowGlobstar()) {\n            this.subwalks.add(e, pattern)\n          }\n        }\n      }\n    }\n    // if the NEXT thing matches this entry, then also add\n    // the rest.\n    if (rest) {\n      const rp = rest.pattern()\n      if (\n        typeof rp === 'string' &&\n        // dots and empty were handled already\n        rp !== '..' &&\n        rp !== '' &&\n        rp !== '.'\n      ) {\n        this.testString(e, rp, rest.rest(), absolute)\n      } else if (rp === '..') {\n        /* c8 ignore start */\n        const ep = e.parent || e\n        /* c8 ignore stop */\n        this.subwalks.add(ep, rest)\n      } else if (rp instanceof RegExp) {\n        this.testRegExp(e, rp, rest.rest(), absolute)\n      }\n    }\n  }\n\n  testRegExp(\n    e: Path,\n    p: MMRegExp,\n    rest: Pattern | null,\n    absolute: boolean\n  ) {\n    if (!p.test(e.name)) return\n    if (!rest) {\n      this.matches.add(e, absolute, false)\n    } else {\n      this.subwalks.add(e, rest)\n    }\n  }\n\n  testString(e: Path, p: string, rest: Pattern | null, absolute: boolean) {\n    // should never happen?\n    if (!e.isNamed(p)) return\n    if (!rest) {\n      this.matches.add(e, absolute, false)\n    } else {\n      this.subwalks.add(e, rest)\n    }\n  }\n}\n","/**\n * Single-use utility classes to provide functionality to the {@link Glob}\n * methods.\n *\n * @module\n */\nimport { Minipass } from 'minipass'\nimport { Path } from 'path-scurry'\nimport { Ignore, IgnoreLike } from './ignore.js'\n\n// XXX can we somehow make it so that it NEVER processes a given path more than\n// once, enough that the match set tracking is no longer needed?  that'd speed\n// things up a lot.  Or maybe bring back nounique, and skip it in that case?\n\n// a single minimatch set entry with 1 or more parts\nimport { Pattern } from './pattern.js'\nimport { Processor } from './processor.js'\n\nexport interface GlobWalkerOpts {\n  absolute?: boolean\n  allowWindowsEscape?: boolean\n  cwd?: string | URL\n  dot?: boolean\n  dotRelative?: boolean\n  follow?: boolean\n  ignore?: string | string[] | IgnoreLike\n  mark?: boolean\n  matchBase?: boolean\n  // Note: maxDepth here means \"maximum actual Path.depth()\",\n  // not \"maximum depth beyond cwd\"\n  maxDepth?: number\n  nobrace?: boolean\n  nocase?: boolean\n  nodir?: boolean\n  noext?: boolean\n  noglobstar?: boolean\n  platform?: NodeJS.Platform\n  posix?: boolean\n  realpath?: boolean\n  root?: string\n  stat?: boolean\n  signal?: AbortSignal\n  windowsPathsNoEscape?: boolean\n  withFileTypes?: boolean\n}\n\nexport type GWOFileTypesTrue = GlobWalkerOpts & {\n  withFileTypes: true\n}\nexport type GWOFileTypesFalse = GlobWalkerOpts & {\n  withFileTypes: false\n}\nexport type GWOFileTypesUnset = GlobWalkerOpts & {\n  withFileTypes?: undefined\n}\n\nexport type Result<O extends GlobWalkerOpts> = O extends GWOFileTypesTrue\n  ? Path\n  : O extends GWOFileTypesFalse\n  ? string\n  : O extends GWOFileTypesUnset\n  ? string\n  : Path | string\n\nexport type Matches<O extends GlobWalkerOpts> = O extends GWOFileTypesTrue\n  ? Set<Path>\n  : O extends GWOFileTypesFalse\n  ? Set<string>\n  : O extends GWOFileTypesUnset\n  ? Set<string>\n  : Set<Path | string>\n\nexport type MatchStream<O extends GlobWalkerOpts> =\n  O extends GWOFileTypesTrue\n    ? Minipass<Path, Path>\n    : O extends GWOFileTypesFalse\n    ? Minipass<string, string>\n    : O extends GWOFileTypesUnset\n    ? Minipass<string, string>\n    : Minipass<Path | string, Path | string>\n\nconst makeIgnore = (\n  ignore: string | string[] | IgnoreLike,\n  opts: GlobWalkerOpts\n): IgnoreLike =>\n  typeof ignore === 'string'\n    ? new Ignore([ignore], opts)\n    : Array.isArray(ignore)\n    ? new Ignore(ignore, opts)\n    : ignore\n\n/**\n * basic walking utilities that all the glob walker types use\n */\nexport abstract class GlobUtil<O extends GlobWalkerOpts = GlobWalkerOpts> {\n  path: Path\n  patterns: Pattern[]\n  opts: O\n  seen: Set<Path> = new Set<Path>()\n  paused: boolean = false\n  aborted: boolean = false\n  #onResume: (() => any)[] = []\n  #ignore?: IgnoreLike\n  #sep: '\\\\' | '/'\n  signal?: AbortSignal\n  maxDepth: number\n\n  constructor(patterns: Pattern[], path: Path, opts: O)\n  constructor(patterns: Pattern[], path: Path, opts: O) {\n    this.patterns = patterns\n    this.path = path\n    this.opts = opts\n    this.#sep = !opts.posix && opts.platform === 'win32' ? '\\\\' : '/'\n    if (opts.ignore) {\n      this.#ignore = makeIgnore(opts.ignore, opts)\n    }\n    // ignore, always set with maxDepth, but it's optional on the\n    // GlobOptions type\n    /* c8 ignore start */\n    this.maxDepth = opts.maxDepth || Infinity\n    /* c8 ignore stop */\n    if (opts.signal) {\n      this.signal = opts.signal\n      this.signal.addEventListener('abort', () => {\n        this.#onResume.length = 0\n      })\n    }\n  }\n\n  #ignored(path: Path): boolean {\n    return this.seen.has(path) || !!this.#ignore?.ignored?.(path)\n  }\n  #childrenIgnored(path: Path): boolean {\n    return !!this.#ignore?.childrenIgnored?.(path)\n  }\n\n  // backpressure mechanism\n  pause() {\n    this.paused = true\n  }\n  resume() {\n    /* c8 ignore start */\n    if (this.signal?.aborted) return\n    /* c8 ignore stop */\n    this.paused = false\n    let fn: (() => any) | undefined = undefined\n    while (!this.paused && (fn = this.#onResume.shift())) {\n      fn()\n    }\n  }\n  onResume(fn: () => any) {\n    if (this.signal?.aborted) return\n    /* c8 ignore start */\n    if (!this.paused) {\n      fn()\n    } else {\n      /* c8 ignore stop */\n      this.#onResume.push(fn)\n    }\n  }\n\n  // do the requisite realpath/stat checking, and return the path\n  // to add or undefined to filter it out.\n  async matchCheck(e: Path, ifDir: boolean): Promise<Path | undefined> {\n    if (ifDir && this.opts.nodir) return undefined\n    let rpc: Path | undefined\n    if (this.opts.realpath) {\n      rpc = e.realpathCached() || (await e.realpath())\n      if (!rpc) return undefined\n      e = rpc\n    }\n    const needStat = e.isUnknown() || this.opts.stat\n    return this.matchCheckTest(needStat ? await e.lstat() : e, ifDir)\n  }\n\n  matchCheckTest(e: Path | undefined, ifDir: boolean): Path | undefined {\n    return e &&\n      (this.maxDepth === Infinity || e.depth() <= this.maxDepth) &&\n      (!ifDir || e.canReaddir()) &&\n      (!this.opts.nodir || !e.isDirectory()) &&\n      !this.#ignored(e)\n      ? e\n      : undefined\n  }\n\n  matchCheckSync(e: Path, ifDir: boolean): Path | undefined {\n    if (ifDir && this.opts.nodir) return undefined\n    let rpc: Path | undefined\n    if (this.opts.realpath) {\n      rpc = e.realpathCached() || e.realpathSync()\n      if (!rpc) return undefined\n      e = rpc\n    }\n    const needStat = e.isUnknown() || this.opts.stat\n    return this.matchCheckTest(needStat ? e.lstatSync() : e, ifDir)\n  }\n\n  abstract matchEmit(p: Result<O>): void\n  abstract matchEmit(p: string | Path): void\n\n  matchFinish(e: Path, absolute: boolean) {\n    if (this.#ignored(e)) return\n    const abs =\n      this.opts.absolute === undefined ? absolute : this.opts.absolute\n    this.seen.add(e)\n    const mark = this.opts.mark && e.isDirectory() ? this.#sep : ''\n    // ok, we have what we need!\n    if (this.opts.withFileTypes) {\n      this.matchEmit(e)\n    } else if (abs) {\n      const abs = this.opts.posix ? e.fullpathPosix() : e.fullpath()\n      this.matchEmit(abs + mark)\n    } else {\n      const rel = this.opts.posix ? e.relativePosix() : e.relative()\n      const pre =\n        this.opts.dotRelative && !rel.startsWith('..' + this.#sep)\n          ? '.' + this.#sep\n          : ''\n      this.matchEmit(!rel ? '.' + mark : pre + rel + mark)\n    }\n  }\n\n  async match(e: Path, absolute: boolean, ifDir: boolean): Promise<void> {\n    const p = await this.matchCheck(e, ifDir)\n    if (p) this.matchFinish(p, absolute)\n  }\n\n  matchSync(e: Path, absolute: boolean, ifDir: boolean): void {\n    const p = this.matchCheckSync(e, ifDir)\n    if (p) this.matchFinish(p, absolute)\n  }\n\n  walkCB(target: Path, patterns: Pattern[], cb: () => any) {\n    /* c8 ignore start */\n    if (this.signal?.aborted) cb()\n    /* c8 ignore stop */\n    this.walkCB2(target, patterns, new Processor(this.opts), cb)\n  }\n\n  walkCB2(\n    target: Path,\n    patterns: Pattern[],\n    processor: Processor,\n    cb: () => any\n  ) {\n    if (this.#childrenIgnored(target)) return cb()\n    if (this.signal?.aborted) cb()\n    if (this.paused) {\n      this.onResume(() => this.walkCB2(target, patterns, processor, cb))\n      return\n    }\n    processor.processPatterns(target, patterns)\n\n    // done processing.  all of the above is sync, can be abstracted out.\n    // subwalks is a map of paths to the entry filters they need\n    // matches is a map of paths to [absolute, ifDir] tuples.\n    let tasks = 1\n    const next = () => {\n      if (--tasks === 0) cb()\n    }\n\n    for (const [m, absolute, ifDir] of processor.matches.entries()) {\n      if (this.#ignored(m)) continue\n      tasks++\n      this.match(m, absolute, ifDir).then(() => next())\n    }\n\n    for (const t of processor.subwalkTargets()) {\n      if (this.maxDepth !== Infinity && t.depth() >= this.maxDepth) {\n        continue\n      }\n      tasks++\n      const childrenCached = t.readdirCached()\n      if (t.calledReaddir())\n        this.walkCB3(t, childrenCached, processor, next)\n      else {\n        t.readdirCB(\n          (_, entries) => this.walkCB3(t, entries, processor, next),\n          true\n        )\n      }\n    }\n\n    next()\n  }\n\n  walkCB3(\n    target: Path,\n    entries: Path[],\n    processor: Processor,\n    cb: () => any\n  ) {\n    processor = processor.filterEntries(target, entries)\n\n    let tasks = 1\n    const next = () => {\n      if (--tasks === 0) cb()\n    }\n\n    for (const [m, absolute, ifDir] of processor.matches.entries()) {\n      if (this.#ignored(m)) continue\n      tasks++\n      this.match(m, absolute, ifDir).then(() => next())\n    }\n    for (const [target, patterns] of processor.subwalks.entries()) {\n      tasks++\n      this.walkCB2(target, patterns, processor.child(), next)\n    }\n\n    next()\n  }\n\n  walkCBSync(target: Path, patterns: Pattern[], cb: () => any) {\n    /* c8 ignore start */\n    if (this.signal?.aborted) cb()\n    /* c8 ignore stop */\n    this.walkCB2Sync(target, patterns, new Processor(this.opts), cb)\n  }\n\n  walkCB2Sync(\n    target: Path,\n    patterns: Pattern[],\n    processor: Processor,\n    cb: () => any\n  ) {\n    if (this.#childrenIgnored(target)) return cb()\n    if (this.signal?.aborted) cb()\n    if (this.paused) {\n      this.onResume(() =>\n        this.walkCB2Sync(target, patterns, processor, cb)\n      )\n      return\n    }\n    processor.processPatterns(target, patterns)\n\n    // done processing.  all of the above is sync, can be abstracted out.\n    // subwalks is a map of paths to the entry filters they need\n    // matches is a map of paths to [absolute, ifDir] tuples.\n    let tasks = 1\n    const next = () => {\n      if (--tasks === 0) cb()\n    }\n\n    for (const [m, absolute, ifDir] of processor.matches.entries()) {\n      if (this.#ignored(m)) continue\n      this.matchSync(m, absolute, ifDir)\n    }\n\n    for (const t of processor.subwalkTargets()) {\n      if (this.maxDepth !== Infinity && t.depth() >= this.maxDepth) {\n        continue\n      }\n      tasks++\n      const children = t.readdirSync()\n      this.walkCB3Sync(t, children, processor, next)\n    }\n\n    next()\n  }\n\n  walkCB3Sync(\n    target: Path,\n    entries: Path[],\n    processor: Processor,\n    cb: () => any\n  ) {\n    processor = processor.filterEntries(target, entries)\n\n    let tasks = 1\n    const next = () => {\n      if (--tasks === 0) cb()\n    }\n\n    for (const [m, absolute, ifDir] of processor.matches.entries()) {\n      if (this.#ignored(m)) continue\n      this.matchSync(m, absolute, ifDir)\n    }\n    for (const [target, patterns] of processor.subwalks.entries()) {\n      tasks++\n      this.walkCB2Sync(target, patterns, processor.child(), next)\n    }\n\n    next()\n  }\n}\n\nexport class GlobWalker<\n  O extends GlobWalkerOpts = GlobWalkerOpts\n> extends GlobUtil<O> {\n  matches: O extends GWOFileTypesTrue\n    ? Set<Path>\n    : O extends GWOFileTypesFalse\n    ? Set<string>\n    : O extends GWOFileTypesUnset\n    ? Set<string>\n    : Set<Path | string>\n\n  constructor(patterns: Pattern[], path: Path, opts: O) {\n    super(patterns, path, opts)\n    this.matches = new Set() as Matches<O>\n  }\n\n  matchEmit(e: Result<O>): void\n  matchEmit(e: Path | string): void {\n    this.matches.add(e)\n  }\n\n  async walk(): Promise<Matches<O>> {\n    if (this.signal?.aborted) throw this.signal.reason\n    if (this.path.isUnknown()) {\n      await this.path.lstat()\n    }\n    await new Promise((res, rej) => {\n      this.walkCB(this.path, this.patterns, () => {\n        if (this.signal?.aborted) {\n          rej(this.signal.reason)\n        } else {\n          res(this.matches)\n        }\n      })\n    })\n    return this.matches\n  }\n\n  walkSync(): Matches<O> {\n    if (this.signal?.aborted) throw this.signal.reason\n    if (this.path.isUnknown()) {\n      this.path.lstatSync()\n    }\n    // nothing for the callback to do, because this never pauses\n    this.walkCBSync(this.path, this.patterns, () => {\n      if (this.signal?.aborted) throw this.signal.reason\n    })\n    return this.matches\n  }\n}\n\nexport class GlobStream<\n  O extends GlobWalkerOpts = GlobWalkerOpts\n> extends GlobUtil<O> {\n  results: O extends GWOFileTypesTrue\n    ? Minipass<Path, Path>\n    : O extends GWOFileTypesFalse\n    ? Minipass<string, string>\n    : O extends GWOFileTypesUnset\n    ? Minipass<string, string>\n    : Minipass<Path | string, Path | string>\n\n  constructor(patterns: Pattern[], path: Path, opts: O) {\n    super(patterns, path, opts)\n    this.results = new Minipass({\n      signal: this.signal,\n      objectMode: true,\n    }) as MatchStream<O>\n    this.results.on('drain', () => this.resume())\n    this.results.on('resume', () => this.resume())\n  }\n\n  matchEmit(e: Result<O>): void\n  matchEmit(e: Path | string): void {\n    this.results.write(e)\n    if (!this.results.flowing) this.pause()\n  }\n\n  stream(): MatchStream<O> {\n    const target = this.path\n    if (target.isUnknown()) {\n      target.lstat().then(() => {\n        this.walkCB(target, this.patterns, () => this.results.end())\n      })\n    } else {\n      this.walkCB(target, this.patterns, () => this.results.end())\n    }\n    return this.results\n  }\n\n  streamSync(): MatchStream<O> {\n    if (this.path.isUnknown()) {\n      this.path.lstatSync()\n    }\n    this.walkCBSync(this.path, this.patterns, () => this.results.end())\n    return this.results\n  }\n}\n","import { Minimatch } from 'minimatch'\nimport { GlobOptions } from './glob.js'\n\n/**\n * Return true if the patterns provided contain any magic glob characters,\n * given the options provided.\n *\n * Brace expansion is not considered \"magic\" unless the `magicalBraces` option\n * is set, as brace expansion just turns one string into an array of strings.\n * So a pattern like `'x{a,b}y'` would return `false`, because `'xay'` and\n * `'xby'` both do not contain any magic glob characters, and it's treated the\n * same as if you had called it on `['xay', 'xby']`. When `magicalBraces:true`\n * is in the options, brace expansion _is_ treated as a pattern having magic.\n */\nexport const hasMagic = (\n  pattern: string | string[],\n  options: GlobOptions = {}\n): boolean => {\n  if (!Array.isArray(pattern)) {\n    pattern = [pattern]\n  }\n  for (const p of pattern) {\n    if (new Minimatch(p, options).hasMagic()) return true\n  }\n  return false\n}\n","import { escape, unescape } from 'minimatch'\nimport { Minipass } from 'minipass'\nimport { Path } from 'path-scurry'\nimport type {\n  GlobOptions,\n  GlobOptionsWithFileTypesFalse,\n  GlobOptionsWithFileTypesTrue,\n  GlobOptionsWithFileTypesUnset,\n} from './glob.js'\nimport { Glob } from './glob.js'\nimport { hasMagic } from './has-magic.js'\n\n/**\n * Syncronous form of {@link globStream}. Will read all the matches as fast as\n * you consume them, even all in a single tick if you consume them immediately,\n * but will still respond to backpressure if they're not consumed immediately.\n */\nexport function globStreamSync(\n  pattern: string | string[],\n  options: GlobOptionsWithFileTypesTrue\n): Minipass<Path, Path>\nexport function globStreamSync(\n  pattern: string | string[],\n  options: GlobOptionsWithFileTypesFalse\n): Minipass<string, string>\nexport function globStreamSync(\n  pattern: string | string[],\n  options: GlobOptionsWithFileTypesUnset\n): Minipass<string, string>\nexport function globStreamSync(\n  pattern: string | string[],\n  options: GlobOptions\n): Minipass<Path, Path> | Minipass<string, string>\nexport function globStreamSync(\n  pattern: string | string[],\n  options: GlobOptions = {}\n) {\n  return new Glob(pattern, options).streamSync()\n}\n\n/**\n * Return a stream that emits all the strings or `Path` objects and\n * then emits `end` when completed.\n */\nexport function globStream(\n  pattern: string | string[],\n  options: GlobOptionsWithFileTypesFalse\n): Minipass<string, string>\nexport function globStream(\n  pattern: string | string[],\n  options: GlobOptionsWithFileTypesTrue\n): Minipass<Path, Path>\nexport function globStream(\n  pattern: string | string[],\n  options?: GlobOptionsWithFileTypesUnset | undefined\n): Minipass<string, string>\nexport function globStream(\n  pattern: string | string[],\n  options: GlobOptions\n): Minipass<Path, Path> | Minipass<string, string>\nexport function globStream(\n  pattern: string | string[],\n  options: GlobOptions = {}\n) {\n  return new Glob(pattern, options).stream()\n}\n\n/**\n * Synchronous form of {@link glob}\n */\nexport function globSync(\n  pattern: string | string[],\n  options: GlobOptionsWithFileTypesFalse\n): string[]\nexport function globSync(\n  pattern: string | string[],\n  options: GlobOptionsWithFileTypesTrue\n): Path[]\nexport function globSync(\n  pattern: string | string[],\n  options?: GlobOptionsWithFileTypesUnset | undefined\n): string[]\nexport function globSync(\n  pattern: string | string[],\n  options: GlobOptions\n): Path[] | string[]\nexport function globSync(\n  pattern: string | string[],\n  options: GlobOptions = {}\n) {\n  return new Glob(pattern, options).walkSync()\n}\n\n/**\n * Perform an asynchronous glob search for the pattern(s) specified. Returns\n * [Path](https://isaacs.github.io/path-scurry/classes/PathBase) objects if the\n * {@link withFileTypes} option is set to `true`. See {@link GlobOptions} for\n * full option descriptions.\n */\nasync function glob_(\n  pattern: string | string[],\n  options?: GlobOptionsWithFileTypesUnset | undefined\n): Promise<string[]>\nasync function glob_(\n  pattern: string | string[],\n  options: GlobOptionsWithFileTypesTrue\n): Promise<Path[]>\nasync function glob_(\n  pattern: string | string[],\n  options: GlobOptionsWithFileTypesFalse\n): Promise<string[]>\nasync function glob_(\n  pattern: string | string[],\n  options: GlobOptions\n): Promise<Path[] | string[]>\nasync function glob_(\n  pattern: string | string[],\n  options: GlobOptions = {}\n) {\n  return new Glob(pattern, options).walk()\n}\n\n/**\n * Return a sync iterator for walking glob pattern matches.\n */\nexport function globIterateSync(\n  pattern: string | string[],\n  options?: GlobOptionsWithFileTypesUnset | undefined\n): Generator<string, void, void>\nexport function globIterateSync(\n  pattern: string | string[],\n  options: GlobOptionsWithFileTypesTrue\n): Generator<Path, void, void>\nexport function globIterateSync(\n  pattern: string | string[],\n  options: GlobOptionsWithFileTypesFalse\n): Generator<string, void, void>\nexport function globIterateSync(\n  pattern: string | string[],\n  options: GlobOptions\n): Generator<Path, void, void> | Generator<string, void, void>\nexport function globIterateSync(\n  pattern: string | string[],\n  options: GlobOptions = {}\n) {\n  return new Glob(pattern, options).iterateSync()\n}\n\n/**\n * Return an async iterator for walking glob pattern matches.\n */\nexport function globIterate(\n  pattern: string | string[],\n  options?: GlobOptionsWithFileTypesUnset | undefined\n): AsyncGenerator<string, void, void>\nexport function globIterate(\n  pattern: string | string[],\n  options: GlobOptionsWithFileTypesTrue\n): AsyncGenerator<Path, void, void>\nexport function globIterate(\n  pattern: string | string[],\n  options: GlobOptionsWithFileTypesFalse\n): AsyncGenerator<string, void, void>\nexport function globIterate(\n  pattern: string | string[],\n  options: GlobOptions\n): AsyncGenerator<Path, void, void> | AsyncGenerator<string, void, void>\nexport function globIterate(\n  pattern: string | string[],\n  options: GlobOptions = {}\n) {\n  return new Glob(pattern, options).iterate()\n}\n\n// aliases: glob.sync.stream() glob.stream.sync() glob.sync() etc\nexport const streamSync = globStreamSync\nexport const stream = Object.assign(globStream, { sync: globStreamSync })\nexport const iterateSync = globIterateSync\nexport const iterate = Object.assign(globIterate, {\n  sync: globIterateSync,\n})\nexport const sync = Object.assign(globSync, {\n  stream: globStreamSync,\n  iterate: globIterateSync,\n})\n\n/* c8 ignore start */\nexport { escape, unescape } from 'minimatch'\nexport { Glob } from './glob.js'\nexport type {\n  GlobOptions,\n  GlobOptionsWithFileTypesFalse,\n  GlobOptionsWithFileTypesTrue,\n  GlobOptionsWithFileTypesUnset,\n} from './glob.js'\nexport { hasMagic } from './has-magic.js'\nexport type { IgnoreLike } from './ignore.js'\nexport type { MatchStream } from './walker.js'\n/* c8 ignore stop */\n\nexport const glob = Object.assign(glob_, {\n  glob: glob_,\n  globSync,\n  sync,\n  globStream,\n  stream,\n  globStreamSync,\n  streamSync,\n  globIterate,\n  iterate,\n  globIterateSync,\n  iterateSync,\n  Glob,\n  hasMagic,\n  escape,\n  unescape,\n})\nglob.glob = glob\n","import { glob } from 'glob';\nimport ignore from 'ignore';\nimport fs from 'fs/promises';\nimport path from 'path';\nimport { ScanOptions } from './types.js';\nimport { LienConfig, FrameworkInstance } from '../config/schema.js';\n\n/**\n * Scan codebase using framework-aware configuration\n * @param rootDir - Project root directory\n * @param config - Lien configuration with frameworks\n * @returns Array of file paths relative to rootDir\n */\nexport async function scanCodebaseWithFrameworks(\n  rootDir: string,\n  config: LienConfig\n): Promise<string[]> {\n  const allFiles: string[] = [];\n  \n  // Scan each framework\n  for (const framework of config.frameworks) {\n    if (!framework.enabled) {\n      continue;\n    }\n    \n    const frameworkFiles = await scanFramework(rootDir, framework);\n    allFiles.push(...frameworkFiles);\n  }\n  \n  // Deduplicate files across frameworks to prevent double-indexing\n  // This handles overlapping framework paths (e.g., root \".\" and \"packages/cli\")\n  return Array.from(new Set(allFiles));\n}\n\n/**\n * Scan files for a specific framework instance\n */\nasync function scanFramework(\n  rootDir: string,\n  framework: FrameworkInstance\n): Promise<string[]> {\n  const frameworkPath = path.join(rootDir, framework.path);\n  \n  // Load .gitignore from framework path\n  const gitignorePath = path.join(frameworkPath, '.gitignore');\n  let ig = ignore();\n  \n  try {\n    const gitignoreContent = await fs.readFile(gitignorePath, 'utf-8');\n    ig = ignore().add(gitignoreContent);\n  } catch (e) {\n    // No .gitignore in framework path, try root\n    const rootGitignorePath = path.join(rootDir, '.gitignore');\n    try {\n      const gitignoreContent = await fs.readFile(rootGitignorePath, 'utf-8');\n      ig = ignore().add(gitignoreContent);\n    } catch (e) {\n      // No .gitignore at all, that's fine\n    }\n  }\n  \n  // Add framework-specific exclusions\n  ig.add([\n    ...framework.config.exclude,\n    '.lien/**',\n  ]);\n  \n  // Find all files matching framework patterns\n  const allFiles: string[] = [];\n  \n  for (const pattern of framework.config.include) {\n    const files = await glob(pattern, {\n      cwd: frameworkPath,\n      absolute: false, // Get paths relative to framework path\n      nodir: true,\n      ignore: framework.config.exclude,\n    });\n    allFiles.push(...files);\n  }\n  \n  // Remove duplicates\n  const uniqueFiles = Array.from(new Set(allFiles));\n  \n  // Filter using ignore patterns and prefix with framework path\n  return uniqueFiles\n    .filter(file => !ig.ignores(file))\n    .map(file => {\n      // Return path relative to root: framework.path/file\n      return framework.path === '.' \n        ? file \n        : path.join(framework.path, file);\n    });\n}\n\n/**\n * Legacy scan function for backwards compatibility\n * @deprecated Use scanCodebaseWithFrameworks instead\n */\nexport async function scanCodebase(options: ScanOptions): Promise<string[]> {\n  const { rootDir, includePatterns = [], excludePatterns = [] } = options;\n  \n  // Load .gitignore\n  const gitignorePath = path.join(rootDir, '.gitignore');\n  let ig = ignore();\n  \n  try {\n    const gitignoreContent = await fs.readFile(gitignorePath, 'utf-8');\n    ig = ignore().add(gitignoreContent);\n  } catch (e) {\n    // No .gitignore, that's fine\n  }\n  \n  // Add default exclusions\n  ig.add([\n    'node_modules/**',\n    '.git/**',\n    'dist/**',\n    'build/**',\n    '*.min.js',\n    '*.min.css',\n    '.lien/**',\n    ...excludePatterns,\n  ]);\n  \n  // Determine patterns to search for\n  const patterns = includePatterns.length > 0 \n    ? includePatterns \n    : ['**/*.{ts,tsx,js,jsx,py,php,go,rs,java,cpp,c,cs,h,md,mdx}'];\n  \n  // Find all code files\n  const allFiles: string[] = [];\n  \n  for (const pattern of patterns) {\n    const files = await glob(pattern, {\n      cwd: rootDir,\n      absolute: true,\n      nodir: true,\n      ignore: ['node_modules/**', '.git/**'],\n    });\n    allFiles.push(...files);\n  }\n  \n  // Remove duplicates\n  const uniqueFiles = Array.from(new Set(allFiles));\n  \n  // Filter using ignore patterns\n  return uniqueFiles.filter(file => {\n    const relativePath = path.relative(rootDir, file);\n    return !ig.ignores(relativePath);\n  });\n}\n\nexport function detectLanguage(filepath: string): string {\n  const ext = path.extname(filepath).toLowerCase();\n  \n  const languageMap: Record<string, string> = {\n    '.ts': 'typescript',\n    '.tsx': 'typescript',\n    '.js': 'javascript',\n    '.jsx': 'javascript',\n    '.mjs': 'javascript',\n    '.cjs': 'javascript',\n    '.vue': 'vue',\n    '.py': 'python',\n    '.go': 'go',\n    '.rs': 'rust',\n    '.java': 'java',\n    '.cpp': 'cpp',\n    '.cc': 'cpp',\n    '.cxx': 'cpp',\n    '.c': 'c',\n    '.h': 'c',\n    '.hpp': 'cpp',\n    '.php': 'php',\n    '.rb': 'ruby',\n    '.swift': 'swift',\n    '.kt': 'kotlin',\n    '.cs': 'csharp',\n    '.scala': 'scala',\n    '.liquid': 'liquid',\n    '.md': 'markdown',\n    '.mdx': 'markdown',\n    '.markdown': 'markdown',\n  };\n  \n  return languageMap[ext] || 'unknown';\n}\n\n","/**\n * Symbol extraction utilities for different programming languages.\n * Extracts function, class, and interface names from code chunks for better indexing.\n */\n\nexport interface ExtractedSymbols {\n  functions: string[];\n  classes: string[];\n  interfaces: string[];\n}\n\n/**\n * Extract symbols (functions, classes, interfaces) from code content.\n * \n * @param content - The code content to extract symbols from\n * @param language - The programming language of the content\n * @returns Extracted symbols organized by type\n */\nexport function extractSymbols(\n  content: string,\n  language: string\n): ExtractedSymbols {\n  const symbols: ExtractedSymbols = {\n    functions: [],\n    classes: [],\n    interfaces: [],\n  };\n  \n  const normalizedLang = language.toLowerCase();\n  \n  switch (normalizedLang) {\n    case 'typescript':\n    case 'tsx':\n      symbols.functions = extractTSFunctions(content);\n      symbols.classes = extractTSClasses(content);\n      symbols.interfaces = extractTSInterfaces(content);\n      break;\n    \n    case 'javascript':\n    case 'jsx':\n      symbols.functions = extractJSFunctions(content);\n      symbols.classes = extractJSClasses(content);\n      break;\n    \n    case 'python':\n    case 'py':\n      symbols.functions = extractPythonFunctions(content);\n      symbols.classes = extractPythonClasses(content);\n      break;\n    \n    case 'php':\n      symbols.functions = extractPHPFunctions(content);\n      symbols.classes = extractPHPClasses(content);\n      symbols.interfaces = extractPHPInterfaces(content);\n      break;\n    \n    case 'vue':\n      // Extract from <script> blocks (handles both Options API and Composition API)\n      symbols.functions = extractVueFunctions(content);\n      symbols.classes = extractVueComponents(content);\n      break;\n    \n    case 'go':\n      symbols.functions = extractGoFunctions(content);\n      symbols.interfaces = extractGoInterfaces(content);\n      break;\n    \n    case 'java':\n      symbols.functions = extractJavaFunctions(content);\n      symbols.classes = extractJavaClasses(content);\n      symbols.interfaces = extractJavaInterfaces(content);\n      break;\n    \n    case 'csharp':\n    case 'cs':\n      symbols.functions = extractCSharpFunctions(content);\n      symbols.classes = extractCSharpClasses(content);\n      symbols.interfaces = extractCSharpInterfaces(content);\n      break;\n    \n    case 'ruby':\n    case 'rb':\n      symbols.functions = extractRubyFunctions(content);\n      symbols.classes = extractRubyClasses(content);\n      break;\n    \n    case 'rust':\n    case 'rs':\n      symbols.functions = extractRustFunctions(content);\n      break;\n  }\n  \n  return symbols;\n}\n\n// TypeScript / JavaScript Functions\nfunction extractTSFunctions(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Regular functions: function name(...) or async function name(...)\n  const functionMatches = content.matchAll(/(?:async\\s+)?function\\s+(\\w+)\\s*\\(/g);\n  for (const match of functionMatches) {\n    names.add(match[1]);\n  }\n  \n  // Arrow functions: const/let/var name = (...) =>\n  const arrowMatches = content.matchAll(/(?:const|let|var)\\s+(\\w+)\\s*=\\s*(?:async\\s*)?\\([^)]*\\)\\s*=>/g);\n  for (const match of arrowMatches) {\n    names.add(match[1]);\n  }\n  \n  // Method definitions: name(...) { or async name(...) {\n  const methodMatches = content.matchAll(/(?:async\\s+)?(\\w+)\\s*\\([^)]*\\)\\s*[:{]/g);\n  for (const match of methodMatches) {\n    // Exclude common keywords\n    if (!['if', 'for', 'while', 'switch', 'catch'].includes(match[1])) {\n      names.add(match[1]);\n    }\n  }\n  \n  // Export function\n  const exportMatches = content.matchAll(/export\\s+(?:async\\s+)?function\\s+(\\w+)\\s*\\(/g);\n  for (const match of exportMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\nfunction extractJSFunctions(content: string): string[] {\n  return extractTSFunctions(content); // Same patterns\n}\n\nfunction extractTSClasses(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Class declarations: class Name or export class Name\n  const classMatches = content.matchAll(/(?:export\\s+)?(?:abstract\\s+)?class\\s+(\\w+)/g);\n  for (const match of classMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\nfunction extractJSClasses(content: string): string[] {\n  return extractTSClasses(content); // Same patterns\n}\n\nfunction extractTSInterfaces(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Interface declarations: interface Name or export interface Name\n  const interfaceMatches = content.matchAll(/(?:export\\s+)?interface\\s+(\\w+)/g);\n  for (const match of interfaceMatches) {\n    names.add(match[1]);\n  }\n  \n  // Type aliases: type Name = or export type Name =\n  const typeMatches = content.matchAll(/(?:export\\s+)?type\\s+(\\w+)\\s*=/g);\n  for (const match of typeMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\n// Python Functions\nfunction extractPythonFunctions(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Function definitions: def name(...):\n  const functionMatches = content.matchAll(/def\\s+(\\w+)\\s*\\(/g);\n  for (const match of functionMatches) {\n    names.add(match[1]);\n  }\n  \n  // Async functions: async def name(...):\n  const asyncMatches = content.matchAll(/async\\s+def\\s+(\\w+)\\s*\\(/g);\n  for (const match of asyncMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\nfunction extractPythonClasses(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Class definitions: class Name or class Name(Base):\n  const classMatches = content.matchAll(/class\\s+(\\w+)(?:\\s*\\(|:)/g);\n  for (const match of classMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\n// PHP Functions\nfunction extractPHPFunctions(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Function definitions: function name(...) or public function name(...)\n  const functionMatches = content.matchAll(/(?:public|private|protected)?\\s*function\\s+(\\w+)\\s*\\(/g);\n  for (const match of functionMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\nfunction extractPHPClasses(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Class definitions: class Name or abstract class Name\n  const classMatches = content.matchAll(/(?:abstract\\s+)?class\\s+(\\w+)/g);\n  for (const match of classMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\nfunction extractPHPInterfaces(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Interface definitions: interface Name\n  const interfaceMatches = content.matchAll(/interface\\s+(\\w+)/g);\n  for (const match of interfaceMatches) {\n    names.add(match[1]);\n  }\n  \n  // Trait definitions: trait Name\n  const traitMatches = content.matchAll(/trait\\s+(\\w+)/g);\n  for (const match of traitMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\n// Go Functions\nfunction extractGoFunctions(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Function definitions: func Name(...) or func (r *Receiver) Name(...)\n  const functionMatches = content.matchAll(/func\\s+(?:\\(\\w+\\s+\\*?\\w+\\)\\s+)?(\\w+)\\s*\\(/g);\n  for (const match of functionMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\nfunction extractGoInterfaces(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Interface definitions: type Name interface {\n  const interfaceMatches = content.matchAll(/type\\s+(\\w+)\\s+interface\\s*\\{/g);\n  for (const match of interfaceMatches) {\n    names.add(match[1]);\n  }\n  \n  // Struct definitions: type Name struct {\n  const structMatches = content.matchAll(/type\\s+(\\w+)\\s+struct\\s*\\{/g);\n  for (const match of structMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\n// Java Functions\nfunction extractJavaFunctions(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Method definitions: public/private/protected return_type name(...)\n  const methodMatches = content.matchAll(/(?:public|private|protected)\\s+(?:static\\s+)?(?:\\w+(?:<[^>]+>)?)\\s+(\\w+)\\s*\\(/g);\n  for (const match of methodMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\nfunction extractJavaClasses(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Class definitions: public class Name or abstract class Name\n  const classMatches = content.matchAll(/(?:public\\s+)?(?:abstract\\s+)?class\\s+(\\w+)/g);\n  for (const match of classMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\nfunction extractJavaInterfaces(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Interface definitions: public interface Name\n  const interfaceMatches = content.matchAll(/(?:public\\s+)?interface\\s+(\\w+)/g);\n  for (const match of interfaceMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\n// C# Functions\nfunction extractCSharpFunctions(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Method definitions: public/private/protected return_type Name(...)\n  const methodMatches = content.matchAll(/(?:public|private|protected|internal)\\s+(?:static\\s+)?(?:async\\s+)?(?:\\w+(?:<[^>]+>)?)\\s+(\\w+)\\s*\\(/g);\n  for (const match of methodMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\nfunction extractCSharpClasses(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Class definitions: public class Name or abstract class Name\n  const classMatches = content.matchAll(/(?:public|internal)?\\s*(?:abstract\\s+)?class\\s+(\\w+)/g);\n  for (const match of classMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\nfunction extractCSharpInterfaces(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Interface definitions: public interface Name\n  const interfaceMatches = content.matchAll(/(?:public|internal)?\\s*interface\\s+(\\w+)/g);\n  for (const match of interfaceMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\n// Ruby Functions\nfunction extractRubyFunctions(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Method definitions: def name or def self.name\n  const methodMatches = content.matchAll(/def\\s+(?:self\\.)?(\\w+)/g);\n  for (const match of methodMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\nfunction extractRubyClasses(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Class definitions: class Name or class Name < Base\n  const classMatches = content.matchAll(/class\\s+(\\w+)/g);\n  for (const match of classMatches) {\n    names.add(match[1]);\n  }\n  \n  // Module definitions: module Name\n  const moduleMatches = content.matchAll(/module\\s+(\\w+)/g);\n  for (const match of moduleMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\n// Rust Functions\nfunction extractRustFunctions(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Function definitions: fn name(...) or pub fn name(...)\n  const functionMatches = content.matchAll(/(?:pub\\s+)?fn\\s+(\\w+)\\s*\\(/g);\n  for (const match of functionMatches) {\n    names.add(match[1]);\n  }\n  \n  // Struct definitions: struct Name {\n  const structMatches = content.matchAll(/(?:pub\\s+)?struct\\s+(\\w+)/g);\n  for (const match of structMatches) {\n    names.add(match[1]);\n  }\n  \n  // Trait definitions: trait Name {\n  const traitMatches = content.matchAll(/(?:pub\\s+)?trait\\s+(\\w+)/g);\n  for (const match of traitMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\n// Vue Functions\nfunction extractVueFunctions(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Extract script content from Vue SFC\n  const scriptMatch = content.match(/<script[^>]*>([\\s\\S]*?)<\\/script>/);\n  if (!scriptMatch) return [];\n  \n  const scriptContent = scriptMatch[1];\n  \n  // Composition API: const/function name = ...\n  const compositionMatches = scriptContent.matchAll(/(?:const|function)\\s+(\\w+)\\s*=/g);\n  for (const match of compositionMatches) {\n    names.add(match[1]);\n  }\n  \n  // Options API methods\n  const methodMatches = scriptContent.matchAll(/(\\w+)\\s*\\([^)]*\\)\\s*{/g);\n  for (const match of methodMatches) {\n    names.add(match[1]);\n  }\n  \n  return Array.from(names);\n}\n\n// Vue Components\nfunction extractVueComponents(content: string): string[] {\n  const names = new Set<string>();\n  \n  // Extract component name from filename convention or export\n  const scriptMatch = content.match(/<script[^>]*>([\\s\\S]*?)<\\/script>/);\n  if (!scriptMatch) return [];\n  \n  const scriptContent = scriptMatch[1];\n  \n  // export default { name: 'ComponentName' }\n  const nameMatch = scriptContent.match(/name:\\s*['\"](\\w+)['\"]/);\n  if (nameMatch) {\n    names.add(nameMatch[1]);\n  }\n  \n  // defineComponent or <script setup> components\n  const defineComponentMatch = scriptContent.match(/defineComponent\\s*\\(/);\n  if (defineComponentMatch) {\n    names.add('VueComponent');\n  }\n  \n  return Array.from(names);\n}\n\n","import Parser from 'tree-sitter';\nimport TypeScript from 'tree-sitter-typescript';\nimport JavaScript from 'tree-sitter-javascript';\nimport PHPParser from 'tree-sitter-php';\nimport Python from 'tree-sitter-python';\nimport { extname } from 'path';\nimport type { ASTParseResult, SupportedLanguage } from './types.js';\n\n/**\n * Cache for parser instances to avoid recreating them\n */\nconst parserCache = new Map<SupportedLanguage, Parser>();\n\n/**\n * Tree-sitter language grammar type\n * Using any here due to type incompatibility between parser packages and tree-sitter core\n */\ntype TreeSitterLanguage = any;\n\n/**\n * Language configuration mapping\n */\nconst languageConfig: Record<SupportedLanguage, TreeSitterLanguage> = {\n  typescript: TypeScript.typescript,\n  javascript: JavaScript,\n  php: PHPParser.php, // Note: tree-sitter-php exports both 'php' (mixed HTML/PHP) and 'php_only'\n  python: Python,\n};\n\n/**\n * Get or create a cached parser instance for a language\n */\nfunction getParser(language: SupportedLanguage): Parser {\n  if (!parserCache.has(language)) {\n    const parser = new Parser();\n    const grammar = languageConfig[language];\n    \n    if (!grammar) {\n      throw new Error(`No grammar available for language: ${language}`);\n    }\n    \n    parser.setLanguage(grammar);\n    parserCache.set(language, parser);\n  }\n  \n  return parserCache.get(language)!;\n}\n\n/**\n * Detect language from file extension\n * Uses path.extname() to handle edge cases like multiple dots in filenames\n */\nexport function detectLanguage(filePath: string): SupportedLanguage | null {\n  // extname returns extension with leading dot (e.g., '.ts')\n  // Remove the dot and convert to lowercase\n  const ext = extname(filePath).slice(1).toLowerCase();\n  \n  switch (ext) {\n    case 'ts':\n    case 'tsx':\n      return 'typescript';\n    case 'js':\n    case 'jsx':\n    case 'mjs':\n    case 'cjs':\n      return 'javascript';\n    case 'php':\n      return 'php';\n    case 'py':\n      return 'python';\n    default:\n      return null;\n  }\n}\n\n/**\n * Check if a file is supported for AST parsing\n */\nexport function isASTSupported(filePath: string): boolean {\n  return detectLanguage(filePath) !== null;\n}\n\n/**\n * Parse source code into an AST using Tree-sitter\n * \n * **Known Limitation:** Tree-sitter may throw \"Invalid argument\" errors on very large files\n * (1000+ lines). This is a limitation of Tree-sitter's internal buffer handling. When this\n * occurs, callers should fall back to line-based chunking (handled automatically by chunker.ts).\n * \n * @param content - Source code to parse\n * @param language - Programming language\n * @returns Parse result with tree or error\n */\nexport function parseAST(content: string, language: SupportedLanguage): ASTParseResult {\n  try {\n    const parser = getParser(language);\n    const tree = parser.parse(content);\n    \n    // Check for parse errors (hasError is a property, not a method)\n    if (tree.rootNode.hasError) {\n      return {\n        tree,\n        error: 'Parse completed with errors',\n      };\n    }\n    \n    return { tree };\n  } catch (error) {\n    return {\n      tree: null,\n      error: error instanceof Error ? error.message : 'Unknown parse error',\n    };\n  }\n}\n\n/**\n * Clear parser cache (useful for testing)\n */\nexport function clearParserCache(): void {\n  parserCache.clear();\n}\n\n","import type Parser from 'tree-sitter';\n\n/**\n * Decision point node types for cyclomatic complexity calculation.\n * \n * These AST node types represent branch points in code flow.\n */\nconst DECISION_POINTS = [\n  // Common across languages (TypeScript/JavaScript/Python/PHP)\n  'if_statement',          // if conditions\n  'while_statement',       // while loops\n  'for_statement',         // for loops\n  'switch_case',           // switch/case statements\n  'catch_clause',          // try/catch error handling\n  'ternary_expression',    // Ternary operator (a ? b : c)\n  'binary_expression',     // For && and || logical operators\n  \n  // TypeScript/JavaScript specific\n  'do_statement',          // do...while loops\n  'for_in_statement',      // for...in loops\n  'for_of_statement',      // for...of loops\n  \n  // PHP specific\n  'foreach_statement',     // PHP foreach loops\n  \n  // Python specific\n  'elif_clause',           // Python elif (adds decision point)\n  // Note: 'else_clause' is NOT a decision point (it's the default path)\n  'except_clause',         // Python except (try/except)\n  'conditional_expression', // Python ternary (x if cond else y)\n];\n\n/**\n * Calculate cyclomatic complexity of a function\n * \n * Complexity = 1 (base) + number of decision points\n * Decision points: if, while, do...while, for, for...in, for...of, foreach, case, catch, &&, ||, ?:\n * \n * @param node - AST node to analyze (typically a function/method)\n * @returns Cyclomatic complexity score (minimum 1)\n */\nexport function calculateComplexity(node: Parser.SyntaxNode): number {\n  let complexity = 1; // Base complexity\n  \n  function traverse(n: Parser.SyntaxNode) {\n    if (DECISION_POINTS.includes(n.type)) {\n      // For binary expressions, only count && and ||\n      if (n.type === 'binary_expression') {\n        const operator = n.childForFieldName('operator');\n        if (operator && (operator.text === '&&' || operator.text === '||')) {\n          complexity++;\n        }\n      } else {\n        complexity++;\n      }\n    }\n    \n    // Traverse children\n    for (let i = 0; i < n.namedChildCount; i++) {\n      const child = n.namedChild(i);\n      if (child) traverse(child);\n    }\n  }\n  \n  traverse(node);\n  return complexity;\n}\n","import type Parser from 'tree-sitter';\n\n// Node types that increase complexity AND increment nesting for children\nconst NESTING_TYPES = new Set([\n  'if_statement', 'for_statement', 'while_statement', 'switch_statement',\n  'catch_clause', 'except_clause', 'do_statement', 'for_in_statement',\n  'for_of_statement', 'foreach_statement', 'match_statement',\n]);\n\n// Types that add complexity but DON'T nest (hybrid increments)\nconst NON_NESTING_TYPES = new Set([\n  'else_clause', 'elif_clause', 'ternary_expression', 'conditional_expression',\n]);\n\n// Lambda types that add complexity when nested\nconst LAMBDA_TYPES = new Set(['arrow_function', 'function_expression', 'lambda']);\n\n/** Traversal context passed to handlers */\ninterface TraversalContext {\n  traverse: (n: Parser.SyntaxNode, level: number, lastOp: string | null) => void;\n}\n\n/**\n * Check if node is a logical operator and return normalized form\n */\nfunction getLogicalOperator(node: Parser.SyntaxNode): string | null {\n  if (node.type !== 'binary_expression' && node.type !== 'boolean_operator') {\n    return null;\n  }\n  const operator = node.childForFieldName('operator');\n  const opText = operator?.text;\n  \n  if (opText === '&&' || opText === 'and') return '&&';\n  if (opText === '||' || opText === 'or') return '||';\n  return null;\n}\n\n/**\n * Determine nesting level for a child node based on SonarSource spec.\n */\nfunction getChildNestingLevel(\n  parent: Parser.SyntaxNode,\n  child: Parser.SyntaxNode,\n  currentLevel: number\n): number {\n  const isCondition = parent.childForFieldName('condition') === child;\n  const isElseClause = NON_NESTING_TYPES.has(child.type);\n  return (!isCondition && !isElseClause) ? currentLevel + 1 : currentLevel;\n}\n\n/**\n * Get complexity increment for nested lambda (only adds if already nested)\n */\nfunction getNestedLambdaIncrement(nodeType: string, nestingLevel: number): number {\n  return (LAMBDA_TYPES.has(nodeType) && nestingLevel > 0) ? 1 : 0;\n}\n\n/** Traverse logical operator children, passing the operator type */\nfunction traverseLogicalChildren(\n  n: Parser.SyntaxNode,\n  level: number,\n  op: string,\n  ctx: TraversalContext\n): void {\n  const operator = n.childForFieldName('operator');\n  for (let i = 0; i < n.namedChildCount; i++) {\n    const child = n.namedChild(i);\n    if (child && child !== operator) ctx.traverse(child, level, op);\n  }\n}\n\n/** Traverse nesting type children with proper nesting level adjustment */\nfunction traverseNestingChildren(\n  n: Parser.SyntaxNode,\n  level: number,\n  ctx: TraversalContext\n): void {\n  for (let i = 0; i < n.namedChildCount; i++) {\n    const child = n.namedChild(i);\n    if (child) ctx.traverse(child, getChildNestingLevel(n, child, level), null);\n  }\n}\n\n/** Traverse all children at specified level */\nfunction traverseAllChildren(\n  n: Parser.SyntaxNode,\n  level: number,\n  ctx: TraversalContext\n): void {\n  for (let i = 0; i < n.namedChildCount; i++) {\n    const child = n.namedChild(i);\n    if (child) ctx.traverse(child, level, null);\n  }\n}\n\n/**\n * Calculate cognitive complexity of a function\n * \n * Based on SonarSource's Cognitive Complexity specification:\n * - +1 for each break from linear flow (if, for, while, catch, etc.)\n * - +1 for each nesting level when inside a control structure\n * - +1 for each logical operator sequence break (a && b || c)\n * \n * @see https://www.sonarsource.com/docs/CognitiveComplexity.pdf\n * \n * @param node - AST node to analyze (typically a function/method)\n * @returns Cognitive complexity score (minimum 0)\n */\nexport function calculateCognitiveComplexity(node: Parser.SyntaxNode): number {\n  let complexity = 0;\n  const ctx: TraversalContext = { traverse };\n  \n  function traverse(n: Parser.SyntaxNode, nestingLevel: number, lastLogicalOp: string | null): void {\n    const logicalOp = getLogicalOperator(n);\n    \n    if (logicalOp) {\n      complexity += (lastLogicalOp !== logicalOp) ? 1 : 0;\n      traverseLogicalChildren(n, nestingLevel, logicalOp, ctx);\n      return;\n    }\n    \n    if (NESTING_TYPES.has(n.type)) {\n      complexity += 1 + nestingLevel;\n      traverseNestingChildren(n, nestingLevel, ctx);\n      return;\n    }\n    \n    if (NON_NESTING_TYPES.has(n.type)) {\n      complexity += 1;\n      traverseAllChildren(n, nestingLevel + 1, ctx);\n      return;\n    }\n    \n    complexity += getNestedLambdaIncrement(n.type, nestingLevel);\n    traverseAllChildren(n, nestingLevel, ctx);\n  }\n  \n  traverse(node, 0, null);\n  return complexity;\n}\n","import type Parser from 'tree-sitter';\n\n/** Raw Halstead counts from AST */\nexport interface HalsteadCounts {\n  n1: number;  // distinct operators\n  n2: number;  // distinct operands\n  N1: number;  // total operators\n  N2: number;  // total operands\n  operators: Map<string, number>;  // operator -> count\n  operands: Map<string, number>;   // operand -> count\n}\n\n/** Calculated Halstead metrics */\nexport interface HalsteadMetrics {\n  vocabulary: number;   // n = n1 + n2\n  length: number;       // N = N1 + N2\n  volume: number;       // V = N √ó log‚ÇÇ(n)\n  difficulty: number;   // D = (n1/2) √ó (N2/n2)\n  effort: number;       // E = D √ó V\n  time: number;         // T = E / 18 (seconds to understand)\n  bugs: number;         // B = V / 3000 (estimated delivered bugs)\n}\n\n/** \n * Language-specific operator symbols.\n * These are the actual text values we match against.\n */\nconst OPERATOR_SYMBOLS: Record<string, Set<string>> = {\n  typescript: new Set([\n    // Arithmetic\n    '+', '-', '*', '/', '%', '**',\n    // Comparison\n    '==', '===', '!=', '!==', '<', '>', '<=', '>=',\n    // Logical\n    '&&', '||', '!', '??',\n    // Assignment\n    '=', '+=', '-=', '*=', '/=', '%=', '**=', '&&=', '||=', '??=',\n    // Bitwise\n    '&', '|', '^', '~', '<<', '>>', '>>>',\n    '&=', '|=', '^=', '<<=', '>>=', '>>>=',\n    // Other\n    '?', ':', '.', '?.', '++', '--', '...', '=>',\n    // Brackets/parens (counted as operators)\n    '(', ')', '[', ']', '{', '}',\n  ]),\n  python: new Set([\n    // Arithmetic\n    '+', '-', '*', '/', '%', '**', '//',\n    // Comparison\n    '==', '!=', '<', '>', '<=', '>=',\n    // Logical (handled via keywords below)\n    // Assignment\n    '=', '+=', '-=', '*=', '/=', '%=', '**=', '//=',\n    '&=', '|=', '^=', '<<=', '>>=',\n    // Bitwise\n    '&', '|', '^', '~', '<<', '>>',\n    // Other\n    '.', ':', '->', '@',\n    '(', ')', '[', ']', '{', '}',\n  ]),\n  php: new Set([\n    // Arithmetic\n    '+', '-', '*', '/', '%', '**',\n    // Comparison\n    '==', '===', '!=', '!==', '<>', '<', '>', '<=', '>=', '<=>',\n    // Logical\n    '&&', '||', '!', 'and', 'or', 'xor',\n    // Assignment\n    '=', '+=', '-=', '*=', '/=', '%=', '**=', '.=',\n    '&=', '|=', '^=', '<<=', '>>=', '??=',\n    // Bitwise\n    '&', '|', '^', '~', '<<', '>>',\n    // String\n    '.',\n    // Other\n    '?', ':', '::', '->', '=>', '??', '@',\n    '(', ')', '[', ']', '{', '}',\n  ]),\n};\n\n/** \n * Language-specific operator keywords.\n * These are keywords that act as operators.\n */\nconst OPERATOR_KEYWORDS: Record<string, Set<string>> = {\n  typescript: new Set([\n    'if', 'else', 'for', 'while', 'do', 'switch', 'case', 'default',\n    'return', 'throw', 'try', 'catch', 'finally',\n    'new', 'delete', 'typeof', 'instanceof', 'in', 'of',\n    'await', 'yield', 'break', 'continue',\n    'const', 'let', 'var', 'function', 'class', 'extends', 'implements',\n    'import', 'export', 'from', 'as',\n  ]),\n  python: new Set([\n    'if', 'elif', 'else', 'for', 'while', 'match', 'case',\n    'return', 'raise', 'try', 'except', 'finally',\n    'and', 'or', 'not', 'is', 'in',\n    'await', 'yield', 'break', 'continue', 'pass',\n    'def', 'class', 'lambda', 'async',\n    'import', 'from', 'as', 'with',\n    'global', 'nonlocal', 'del', 'assert',\n  ]),\n  php: new Set([\n    'if', 'elseif', 'else', 'for', 'foreach', 'while', 'do', 'switch', 'case', 'default', 'match',\n    'return', 'throw', 'try', 'catch', 'finally',\n    'new', 'clone', 'instanceof',\n    'yield', 'break', 'continue',\n    'function', 'class', 'extends', 'implements', 'trait', 'interface',\n    'use', 'namespace', 'as',\n    'echo', 'print', 'include', 'require', 'include_once', 'require_once',\n    'global', 'static', 'const', 'public', 'private', 'protected', 'readonly',\n  ]),\n};\n\n/** \n * AST node types that represent operators (language-agnostic).\n * These are the tree-sitter node types, not the text content.\n */\nconst OPERATOR_NODE_TYPES = new Set([\n  // Expression operators\n  'binary_expression',\n  'unary_expression',\n  'update_expression',\n  'assignment_expression',\n  'augmented_assignment_expression',\n  'ternary_expression',\n  'conditional_expression',\n  \n  // Call/access operators\n  'call_expression',\n  'method_call',\n  'member_expression',\n  'subscript_expression',\n  'attribute',\n  \n  // Object/array literals ([] and {} are operators)\n  'array',\n  'object',\n  'dictionary',\n  'list',\n]);\n\n/**\n * AST node types that represent operands.\n */\nconst OPERAND_NODE_TYPES = new Set([\n  // Identifiers\n  'identifier',\n  'property_identifier',\n  'shorthand_property_identifier',\n  'variable_name',\n  'name',\n  \n  // Literals\n  'number',\n  'integer',\n  'float',\n  'string',\n  'string_fragment',\n  'template_string',\n  'true',\n  'false',\n  'null',\n  'undefined',\n  'none',\n  \n  // Special\n  'this',\n  'self',\n  'super',\n]);\n\n/**\n * Get the operator set for a language (with fallback to typescript)\n */\nfunction getOperatorSymbols(language: string): Set<string> {\n  return OPERATOR_SYMBOLS[language] || OPERATOR_SYMBOLS.typescript;\n}\n\n/**\n * Get the keyword set for a language (with fallback to typescript)\n */\nfunction getOperatorKeywords(language: string): Set<string> {\n  return OPERATOR_KEYWORDS[language] || OPERATOR_KEYWORDS.typescript;\n}\n\n/**\n * Check if a node represents an operator\n */\nfunction isOperator(node: Parser.SyntaxNode, language: string): boolean {\n  const nodeType = node.type;\n  const nodeText = node.text;\n  \n  // Check if it's an operator node type\n  if (OPERATOR_NODE_TYPES.has(nodeType)) {\n    return true;\n  }\n  \n  // Check if it's an operator symbol or keyword\n  const symbols = getOperatorSymbols(language);\n  const keywords = getOperatorKeywords(language);\n  \n  return symbols.has(nodeText) || keywords.has(nodeText);\n}\n\n/**\n * Check if a node represents an operand\n */\nfunction isOperand(node: Parser.SyntaxNode): boolean {\n  return OPERAND_NODE_TYPES.has(node.type);\n}\n\n/**\n * Get the canonical key for an operator (for counting distinct operators)\n */\nfunction getOperatorKey(node: Parser.SyntaxNode): string {\n  // For complex expressions, use the operator type\n  if (OPERATOR_NODE_TYPES.has(node.type)) {\n    // For binary/unary expressions, extract the actual operator\n    const operator = node.childForFieldName('operator');\n    if (operator) {\n      return operator.text;\n    }\n    return node.type;\n  }\n  return node.text;\n}\n\n/**\n * Get the canonical key for an operand (for counting distinct operands)\n */\nfunction getOperandKey(node: Parser.SyntaxNode): string {\n  return node.text;\n}\n\n/**\n * Sum all values in a map\n */\nfunction sumValues(map: Map<string, number>): number {\n  let sum = 0;\n  for (const count of map.values()) {\n    sum += count;\n  }\n  return sum;\n}\n\n/**\n * Count operators and operands in an AST node\n * \n * @param node - AST node to analyze (typically a function/method)\n * @param language - Programming language for language-specific handling\n * @returns HalsteadCounts with raw operator/operand counts\n */\nexport function countHalstead(node: Parser.SyntaxNode, language: string): HalsteadCounts {\n  const operators = new Map<string, number>();\n  const operands = new Map<string, number>();\n  \n  function traverse(n: Parser.SyntaxNode): void {\n    // Check if this is an operator\n    if (isOperator(n, language)) {\n      const key = getOperatorKey(n);\n      operators.set(key, (operators.get(key) || 0) + 1);\n    }\n    \n    // Check if this is an operand\n    if (isOperand(n)) {\n      const key = getOperandKey(n);\n      operands.set(key, (operands.get(key) || 0) + 1);\n    }\n    \n    // Recurse into children\n    for (const child of n.children) {\n      traverse(child);\n    }\n  }\n  \n  traverse(node);\n  \n  return {\n    n1: operators.size,\n    n2: operands.size,\n    N1: sumValues(operators),\n    N2: sumValues(operands),\n    operators,\n    operands,\n  };\n}\n\n/**\n * Calculate derived Halstead metrics from raw counts\n * \n * Formulas based on Maurice Halstead's \"Elements of Software Science\" (1977):\n * - Vocabulary (n) = n1 + n2\n * - Length (N) = N1 + N2\n * - Volume (V) = N √ó log‚ÇÇ(n) - size of implementation\n * - Difficulty (D) = (n1/2) √ó (N2/n2) - error-proneness\n * - Effort (E) = D √ó V - mental effort required\n * - Time (T) = E / 18 - seconds to understand (Stroud number)\n * - Bugs (B) = V / 3000 - estimated delivered bugs\n * \n * @param counts - Raw Halstead counts from countHalstead()\n * @returns Calculated HalsteadMetrics\n */\nexport function calculateHalsteadMetrics(counts: HalsteadCounts): HalsteadMetrics {\n  const { n1, n2, N1, N2 } = counts;\n  \n  const vocabulary = n1 + n2;\n  const length = N1 + N2;\n  \n  // Avoid log(0) and division by zero\n  const volume = vocabulary > 0 ? length * Math.log2(vocabulary) : 0;\n  const difficulty = n2 > 0 ? (n1 / 2) * (N2 / n2) : 0;\n  const effort = difficulty * volume;\n  const time = effort / 18;  // Stroud number (18 mental discriminations per second)\n  const bugs = volume / 3000;\n  \n  return {\n    vocabulary: Math.round(vocabulary),\n    length: Math.round(length),\n    volume: Math.round(volume * 100) / 100,\n    difficulty: Math.round(difficulty * 100) / 100,\n    effort: Math.round(effort),\n    time: Math.round(time),\n    bugs: Math.round(bugs * 1000) / 1000,\n  };\n}\n\n/**\n * Calculate Halstead metrics for an AST node in one call\n * \n * Convenience function that combines countHalstead and calculateHalsteadMetrics.\n * \n * @param node - AST node to analyze\n * @param language - Programming language\n * @returns Calculated HalsteadMetrics\n */\nexport function calculateHalstead(node: Parser.SyntaxNode, language: string): HalsteadMetrics {\n  const counts = countHalstead(node, language);\n  return calculateHalsteadMetrics(counts);\n}\n","import type Parser from 'tree-sitter';\nimport type { SymbolInfo } from './types.js';\nimport { calculateComplexity } from './complexity/index.js';\n\n/**\n * Type for symbol extractor functions\n */\ntype SymbolExtractor = (\n  node: Parser.SyntaxNode,\n  content: string,\n  parentClass?: string\n) => SymbolInfo | null;\n\n/**\n * Extract function declaration info (function_declaration, function)\n */\nfunction extractFunctionInfo(\n  node: Parser.SyntaxNode,\n  content: string,\n  parentClass?: string\n): SymbolInfo | null {\n    const nameNode = node.childForFieldName('name');\n    if (!nameNode) return null;\n    \n    return {\n      name: nameNode.text,\n      type: parentClass ? 'method' : 'function',\n      startLine: node.startPosition.row + 1,\n      endLine: node.endPosition.row + 1,\n      parentClass,\n      signature: extractSignature(node, content),\n      parameters: extractParameters(node, content),\n      returnType: extractReturnType(node, content),\n      complexity: calculateComplexity(node),\n    };\n  }\n  \n/**\n * Extract arrow function or function expression info\n */\nfunction extractArrowFunctionInfo(\n  node: Parser.SyntaxNode,\n  content: string,\n  parentClass?: string\n): SymbolInfo | null {\n    // Try to find variable name for arrow functions\n    const parent = node.parent;\n    let name = 'anonymous';\n    \n    if (parent?.type === 'variable_declarator') {\n      const nameNode = parent.childForFieldName('name');\n      name = nameNode?.text || 'anonymous';\n    }\n    \n    return {\n      name,\n      type: parentClass ? 'method' : 'function',\n      startLine: node.startPosition.row + 1,\n      endLine: node.endPosition.row + 1,\n      parentClass,\n      signature: extractSignature(node, content),\n      parameters: extractParameters(node, content),\n      complexity: calculateComplexity(node),\n    };\n  }\n  \n/**\n * Extract method definition info\n */\nfunction extractMethodInfo(\n  node: Parser.SyntaxNode,\n  content: string,\n  parentClass?: string\n): SymbolInfo | null {\n    const nameNode = node.childForFieldName('name');\n    if (!nameNode) return null;\n    \n    return {\n      name: nameNode.text,\n      type: 'method',\n      startLine: node.startPosition.row + 1,\n      endLine: node.endPosition.row + 1,\n      parentClass,\n      signature: extractSignature(node, content),\n      parameters: extractParameters(node, content),\n      returnType: extractReturnType(node, content),\n      complexity: calculateComplexity(node),\n    };\n  }\n  \n/**\n * Extract class declaration info\n */\nfunction extractClassInfo(\n  node: Parser.SyntaxNode,\n  _content: string,\n  _parentClass?: string\n): SymbolInfo | null {\n    const nameNode = node.childForFieldName('name');\n    if (!nameNode) return null;\n    \n    return {\n      name: nameNode.text,\n      type: 'class',\n      startLine: node.startPosition.row + 1,\n      endLine: node.endPosition.row + 1,\n      signature: `class ${nameNode.text}`,\n    };\n  }\n  \n/**\n * Extract interface declaration info (TypeScript)\n */\nfunction extractInterfaceInfo(\n  node: Parser.SyntaxNode,\n  _content: string,\n  _parentClass?: string\n): SymbolInfo | null {\n    const nameNode = node.childForFieldName('name');\n    if (!nameNode) return null;\n    \n    return {\n      name: nameNode.text,\n      type: 'interface',\n      startLine: node.startPosition.row + 1,\n      endLine: node.endPosition.row + 1,\n      signature: `interface ${nameNode.text}`,\n    };\n  }\n\n/**\n * Extract Python function info (def and async def)\n */\nfunction extractPythonFunctionInfo(\n  node: Parser.SyntaxNode,\n  content: string,\n  parentClass?: string\n): SymbolInfo | null {\n    const nameNode = node.childForFieldName('name');\n    if (!nameNode) return null;\n    \n    return {\n      name: nameNode.text,\n      type: parentClass ? 'method' : 'function',\n      startLine: node.startPosition.row + 1,\n      endLine: node.endPosition.row + 1,\n      parentClass,\n      signature: extractSignature(node, content),\n      parameters: extractParameters(node, content),\n      complexity: calculateComplexity(node),\n    };\n  }\n\n/**\n * Extract Python class info\n */\nfunction extractPythonClassInfo(\n  node: Parser.SyntaxNode,\n  _content: string,\n  _parentClass?: string\n): SymbolInfo | null {\n    const nameNode = node.childForFieldName('name');\n    if (!nameNode) return null;\n    \n    return {\n      name: nameNode.text,\n      type: 'class',\n      startLine: node.startPosition.row + 1,\n      endLine: node.endPosition.row + 1,\n      signature: `class ${nameNode.text}`,\n    };\n  }\n  \n/**\n * Map of AST node types to their specialized extractors\n * \n * Note: There is intentional overlap in node type names across languages:\n * - 'function_definition': Used by both PHP and Python\n * - 'class_declaration': Used by TypeScript/JavaScript\n * - 'class_definition': Used by Python\n * \n * This is handled correctly because each file is parsed with its specific language parser.\n */\nconst symbolExtractors: Record<string, SymbolExtractor> = {\n  // TypeScript/JavaScript\n  'function_declaration': extractFunctionInfo,\n  'function': extractFunctionInfo,\n  'arrow_function': extractArrowFunctionInfo,\n  'function_expression': extractArrowFunctionInfo,\n  'method_definition': extractMethodInfo,\n  'class_declaration': extractClassInfo,\n  'interface_declaration': extractInterfaceInfo,\n  \n  // PHP\n  'function_definition': extractFunctionInfo,   // PHP functions (Python handled via language check in extractSymbolInfo)\n  'method_declaration': extractMethodInfo,       // PHP methods\n  \n  // Python\n  'async_function_definition': extractPythonFunctionInfo,  // Python async functions\n  'class_definition': extractPythonClassInfo,              // Python classes\n  // Note: Python regular functions use 'function_definition' (same as PHP)\n  // They are dispatched to extractPythonFunctionInfo via language check in extractSymbolInfo()\n};\n\n/**\n * Extract symbol information from an AST node using specialized extractors\n * \n * @param node - AST node to extract info from\n * @param content - Source code content\n * @param parentClass - Parent class name if this is a method\n * @param language - Programming language (for disambiguating shared node types)\n * @returns Symbol information or null\n */\nexport function extractSymbolInfo(\n  node: Parser.SyntaxNode,\n  content: string,\n  parentClass?: string,\n  language?: string\n): SymbolInfo | null {\n  // Handle ambiguous node types that are shared between languages\n  // PHP and Python both use 'function_definition', but need different extractors\n  if (node.type === 'function_definition' && language === 'python') {\n    return extractPythonFunctionInfo(node, content, parentClass);\n  }\n  \n  const extractor = symbolExtractors[node.type];\n  return extractor ? extractor(node, content, parentClass) : null;\n}\n\n/**\n * Extract function/method signature\n */\nfunction extractSignature(node: Parser.SyntaxNode, content: string): string {\n  // Get the first line of the function (up to opening brace or arrow)\n  const startLine = node.startPosition.row;\n  const lines = content.split('\\n');\n  let signature = lines[startLine] || '';\n  \n  // If signature spans multiple lines, try to get up to the opening brace\n  let currentLine = startLine;\n  while (currentLine < node.endPosition.row && !signature.includes('{') && !signature.includes('=>')) {\n    currentLine++;\n    signature += ' ' + (lines[currentLine] || '');\n  }\n  \n  // Clean up signature\n  signature = signature.split('{')[0].split('=>')[0].trim();\n  \n  // Limit length\n  if (signature.length > 200) {\n    signature = signature.substring(0, 197) + '...';\n  }\n  \n  return signature;\n}\n\n/**\n * Extract parameter list from function node\n * \n * Note: The `_content` parameter is unused in this function, but is kept for API consistency\n * with other extract functions (e.g., extractSignature).\n */\nfunction extractParameters(node: Parser.SyntaxNode, _content: string): string[] {\n  const parameters: string[] = [];\n  \n  // Find parameters node\n  const paramsNode = node.childForFieldName('parameters');\n  if (!paramsNode) return parameters;\n  \n  // Traverse parameter nodes\n  for (let i = 0; i < paramsNode.namedChildCount; i++) {\n    const param = paramsNode.namedChild(i);\n    if (param) {\n      parameters.push(param.text);\n    }\n  }\n  \n  return parameters;\n}\n\n/**\n * Extract return type from function node (TypeScript)\n * \n * Note: The `_content` parameter is unused in this function, but is kept for API consistency\n * with other extract functions (e.g., extractSignature).\n */\nfunction extractReturnType(node: Parser.SyntaxNode, _content: string): string | undefined {\n  const returnTypeNode = node.childForFieldName('return_type');\n  if (!returnTypeNode) return undefined;\n  \n  return returnTypeNode.text;\n}\n\n/**\n * Extract import statements from a file\n */\nexport function extractImports(rootNode: Parser.SyntaxNode): string[] {\n  const imports: string[] = [];\n  \n  function traverse(node: Parser.SyntaxNode) {\n    // Handle import statements (shared node type between languages)\n    if (node.type === 'import_statement') {\n      // TypeScript/JavaScript: Extract just the module path from 'source' field\n      const sourceNode = node.childForFieldName('source');\n      if (sourceNode) {\n        // TS/JS import with source field\n        const importPath = sourceNode.text.replace(/['\"]/g, '');\n        imports.push(importPath);\n      } else {\n        // Python import without source field (e.g., \"import os\")\n        const importText = node.text.split('\\n')[0];\n        imports.push(importText);\n      }\n    }\n    // Python-specific: from...import statements\n    else if (node.type === 'import_from_statement') {\n      // Python: Get the entire import line (first line only)\n      const importText = node.text.split('\\n')[0];\n      imports.push(importText);\n    }\n    \n    // Only traverse top-level nodes for imports\n    if (node === rootNode) {\n      for (let i = 0; i < node.namedChildCount; i++) {\n        const child = node.namedChild(i);\n        if (child) traverse(child);\n      }\n    }\n  }\n  \n  traverse(rootNode);\n  return imports;\n}\n","import type Parser from 'tree-sitter';\nimport type { LanguageTraverser, DeclarationFunctionInfo } from './types.js';\n\n/**\n * TypeScript/JavaScript AST traverser\n * \n * Handles TypeScript and JavaScript AST node types and traversal patterns.\n * Both languages share the same AST structure (via tree-sitter-typescript).\n */\nexport class TypeScriptTraverser implements LanguageTraverser {\n  targetNodeTypes = [\n    'function_declaration',\n    'function',\n    'interface_declaration',\n    'method_definition',\n    'lexical_declaration',    // For const/let with arrow functions\n    'variable_declaration',   // For var with functions\n  ];\n  \n  containerTypes = [\n    'class_declaration',      // We extract methods, not the class itself\n  ];\n  \n  declarationTypes = [\n    'lexical_declaration',    // const/let\n    'variable_declaration',   // var\n  ];\n  \n  functionTypes = [\n    'arrow_function',\n    'function_expression',\n    'function',\n  ];\n  \n  shouldExtractChildren(node: Parser.SyntaxNode): boolean {\n    return this.containerTypes.includes(node.type);\n  }\n  \n  isDeclarationWithFunction(node: Parser.SyntaxNode): boolean {\n    return this.declarationTypes.includes(node.type);\n  }\n  \n  getContainerBody(node: Parser.SyntaxNode): Parser.SyntaxNode | null {\n    if (node.type === 'class_declaration') {\n      return node.childForFieldName('body');\n    }\n    return null;\n  }\n  \n  shouldTraverseChildren(node: Parser.SyntaxNode): boolean {\n    return node.type === 'program' || \n           node.type === 'export_statement' ||\n           node.type === 'class_body';\n  }\n  \n  findParentContainerName(node: Parser.SyntaxNode): string | undefined {\n    let current = node.parent;\n    while (current) {\n      if (current.type === 'class_declaration') {\n        const nameNode = current.childForFieldName('name');\n        return nameNode?.text;\n      }\n      current = current.parent;\n    }\n    return undefined;\n  }\n  \n  /**\n   * Check if a declaration node contains a function (arrow, function expression, etc.)\n   */\n  findFunctionInDeclaration(node: Parser.SyntaxNode): DeclarationFunctionInfo {\n    const search = (n: Parser.SyntaxNode, depth: number): Parser.SyntaxNode | null => {\n      if (depth > 3) return null; // Don't search too deep\n      \n      if (this.functionTypes.includes(n.type)) {\n        return n;\n      }\n      \n      for (let i = 0; i < n.childCount; i++) {\n        const child = n.child(i);\n        if (child) {\n          const result = search(child, depth + 1);\n          if (result) return result;\n        }\n      }\n      \n      return null;\n    };\n    \n    const functionNode = search(node, 0);\n    return {\n      hasFunction: functionNode !== null,\n      functionNode,\n    };\n  }\n}\n\n/**\n * JavaScript uses the same traverser as TypeScript\n */\nexport class JavaScriptTraverser extends TypeScriptTraverser {}\n\n","import type Parser from 'tree-sitter';\nimport type { LanguageTraverser, DeclarationFunctionInfo } from './types.js';\n\n/**\n * PHP AST traverser\n * \n * Handles PHP AST node types and traversal patterns.\n * PHP uses tree-sitter-php grammar.\n */\nexport class PHPTraverser implements LanguageTraverser {\n  targetNodeTypes = [\n    'function_definition',      // function foo() {}\n    'method_declaration',       // public function bar() {}\n  ];\n  \n  containerTypes = [\n    'class_declaration',        // We extract methods, not the class itself\n    'trait_declaration',        // PHP traits\n    'interface_declaration',    // PHP interfaces (for interface methods)\n  ];\n  \n  declarationTypes = [\n    // PHP doesn't have arrow functions or const/let like JS\n    // Functions are always defined with 'function' keyword\n  ];\n  \n  functionTypes = [\n    'function_definition',\n    'method_declaration',\n  ];\n  \n  shouldExtractChildren(node: Parser.SyntaxNode): boolean {\n    return this.containerTypes.includes(node.type);\n  }\n  \n  isDeclarationWithFunction(_node: Parser.SyntaxNode): boolean {\n    // PHP doesn't have variable declarations with functions like JS/TS\n    // Functions are always defined with 'function' keyword\n    return false;\n  }\n  \n  getContainerBody(node: Parser.SyntaxNode): Parser.SyntaxNode | null {\n    if (node.type === 'class_declaration' || \n        node.type === 'trait_declaration' ||\n        node.type === 'interface_declaration') {\n      // In PHP, the body is called 'declaration_list'\n      return node.childForFieldName('body');\n    }\n    return null;\n  }\n  \n  shouldTraverseChildren(node: Parser.SyntaxNode): boolean {\n    return node.type === 'program' ||           // Top-level PHP file\n           node.type === 'php' ||               // PHP block\n           node.type === 'declaration_list';    // Body of class/trait/interface\n  }\n  \n  findParentContainerName(node: Parser.SyntaxNode): string | undefined {\n    let current = node.parent;\n    while (current) {\n      if (current.type === 'class_declaration' || \n          current.type === 'trait_declaration') {\n        const nameNode = current.childForFieldName('name');\n        return nameNode?.text;\n      }\n      current = current.parent;\n    }\n    return undefined;\n  }\n  \n  findFunctionInDeclaration(_node: Parser.SyntaxNode): DeclarationFunctionInfo {\n    // PHP doesn't have this pattern\n    return {\n      hasFunction: false,\n      functionNode: null,\n    };\n  }\n}\n\n","import type Parser from 'tree-sitter';\nimport type { LanguageTraverser, DeclarationFunctionInfo } from './types.js';\n\n/**\n * Python AST traverser\n * \n * Handles Python AST node types and traversal patterns.\n * Python has a simpler structure than TypeScript/JavaScript:\n * - Functions are defined with 'def' or 'async def'\n * - No variable declarations with functions (unlike JS const x = () => {})\n * - Classes contain methods (which are just functions)\n */\nexport class PythonTraverser implements LanguageTraverser {\n  targetNodeTypes = [\n    'function_definition',\n    'async_function_definition',\n  ];\n  \n  containerTypes = [\n    'class_definition',  // We extract methods, not the class itself\n  ];\n  \n  declarationTypes = [\n    // Python doesn't have const/let/var declarations like JS/TS\n    // Functions are always defined with 'def' or 'async def'\n  ];\n  \n  functionTypes = [\n    'function_definition',\n    'async_function_definition',\n  ];\n  \n  shouldExtractChildren(node: Parser.SyntaxNode): boolean {\n    return this.containerTypes.includes(node.type);\n  }\n  \n  isDeclarationWithFunction(_node: Parser.SyntaxNode): boolean {\n    // Python doesn't have variable declarations with functions like JS/TS\n    // Functions are always defined with 'def' or 'async def'\n    return false;\n  }\n  \n  getContainerBody(node: Parser.SyntaxNode): Parser.SyntaxNode | null {\n    if (node.type === 'class_definition') {\n      // In Python, the class body is called 'block'\n      return node.childForFieldName('body');\n    }\n    return null;\n  }\n  \n  shouldTraverseChildren(node: Parser.SyntaxNode): boolean {\n    return node.type === 'module' ||  // Top-level Python file\n           node.type === 'block';     // Body of class/function\n  }\n  \n  findParentContainerName(node: Parser.SyntaxNode): string | undefined {\n    let current = node.parent;\n    while (current) {\n      if (current.type === 'class_definition') {\n        const nameNode = current.childForFieldName('name');\n        return nameNode?.text;\n      }\n      current = current.parent;\n    }\n    return undefined;\n  }\n  \n  /**\n   * Python doesn't have this pattern (const x = () => {})\n   * Functions are always defined with 'def' or 'async def'\n   */\n  findFunctionInDeclaration(_node: Parser.SyntaxNode): DeclarationFunctionInfo {\n    return {\n      hasFunction: false,\n      functionNode: null,\n    };\n  }\n}\n\n","import type { SupportedLanguage } from '../types.js';\nimport type { LanguageTraverser } from './types.js';\nimport { TypeScriptTraverser, JavaScriptTraverser } from './typescript.js';\nimport { PHPTraverser } from './php.js';\nimport { PythonTraverser } from './python.js';\n\nexport type { LanguageTraverser, DeclarationFunctionInfo } from './types.js';\n\n/**\n * Registry of language traversers\n * \n * Maps each supported language to its traverser implementation.\n * When adding a new language:\n * 1. Create a new traverser class implementing LanguageTraverser\n * 2. Add it to this registry\n * 3. Update SupportedLanguage type in ../types.ts\n */\nconst traverserRegistry: Record<SupportedLanguage, LanguageTraverser> = {\n  typescript: new TypeScriptTraverser(),\n  javascript: new JavaScriptTraverser(),\n  php: new PHPTraverser(),\n  python: new PythonTraverser(),\n};\n\n/**\n * Get the traverser for a specific language\n * \n * @param language - Programming language\n * @returns Language-specific traverser\n * @throws Error if language is not supported\n */\nexport function getTraverser(language: SupportedLanguage): LanguageTraverser {\n  const traverser = traverserRegistry[language];\n  \n  if (!traverser) {\n    throw new Error(`No traverser available for language: ${language}`);\n  }\n  \n  return traverser;\n}\n\n/**\n * Check if a language has a traverser implementation\n * \n * @param language - Programming language\n * @returns True if traverser exists\n */\nexport function hasTraverser(language: SupportedLanguage): boolean {\n  return language in traverserRegistry;\n}\n\n","import type Parser from 'tree-sitter';\nimport type { ASTChunk } from './types.js';\nimport { parseAST, detectLanguage, isASTSupported } from './parser.js';\nimport { extractSymbolInfo, extractImports } from './symbols.js';\nimport { calculateCognitiveComplexity, calculateHalstead } from './complexity/index.js';\nimport { getTraverser } from './traversers/index.js';\n\nexport interface ASTChunkOptions {\n  maxChunkSize?: number; // Reserved for future use (smart splitting of large functions)\n  minChunkSize?: number;\n}\n\n/**\n * Chunk a file using AST-based semantic boundaries\n * \n * Uses Tree-sitter to parse code into an AST and extract semantic chunks\n * (functions, classes, methods) that respect code structure.\n * \n * **Known Limitations:**\n * - Tree-sitter may fail with \"Invalid argument\" error on very large files (1000+ lines)\n * - When this occurs, Lien automatically falls back to line-based chunking\n * - Configure fallback behavior via `chunking.astFallback` ('line-based' or 'error')\n * \n * @param filepath - Path to the file\n * @param content - File content\n * @param options - Chunking options\n * @returns Array of AST-aware chunks\n * @throws Error if AST parsing fails and astFallback is 'error'\n */\nexport function chunkByAST(\n  filepath: string,\n  content: string,\n  options: ASTChunkOptions = {}\n): ASTChunk[] {\n  const { minChunkSize = 5 } = options;\n  \n  // Check if AST is supported for this file\n  const language = detectLanguage(filepath);\n  if (!language) {\n    throw new Error(`Unsupported language for file: ${filepath}`);\n  }\n  \n  // Parse the file\n  const parseResult = parseAST(content, language);\n  \n  // If parsing failed, throw error (caller should fallback to line-based)\n  if (!parseResult.tree) {\n    throw new Error(`Failed to parse ${filepath}: ${parseResult.error}`);\n  }\n  \n  const chunks: ASTChunk[] = [];\n  const lines = content.split('\\n');\n  const rootNode = parseResult.tree.rootNode;\n  \n  // Get language-specific traverser\n  const traverser = getTraverser(language);\n  \n  // Extract file-level imports once\n  const fileImports = extractImports(rootNode);\n  \n  // Find all top-level function and class declarations\n  const topLevelNodes = findTopLevelNodes(rootNode, traverser);\n  \n  for (const node of topLevelNodes) {\n    // For variable declarations, try to find the function inside\n    let actualNode = node;\n    if (traverser.isDeclarationWithFunction(node)) {\n      const declInfo = traverser.findFunctionInDeclaration(node);\n      if (declInfo.functionNode) {\n        actualNode = declInfo.functionNode;\n      }\n    }\n    \n    // For methods, find the parent container name (e.g., class name)\n    const parentClassName = traverser.findParentContainerName(actualNode);\n    \n    const symbolInfo = extractSymbolInfo(actualNode, content, parentClassName, language);\n    \n    // Extract the code for this node (use original node for full declaration)\n    const nodeContent = getNodeContent(node, lines);\n    \n    // Create a chunk for this semantic unit\n    // Note: Large functions are kept as single chunks (may exceed maxChunkSize)\n    // This preserves semantic boundaries - better than splitting mid-function\n    chunks.push(createChunk(filepath, node, nodeContent, symbolInfo, fileImports, language));\n  }\n  \n  // Handle remaining code (imports, exports, top-level statements)\n  const coveredRanges = topLevelNodes.map(n => ({\n    start: n.startPosition.row,\n    end: n.endPosition.row,\n  }));\n  \n  const uncoveredChunks = extractUncoveredCode(\n    lines,\n    coveredRanges,\n    filepath,\n    minChunkSize,\n    fileImports,\n    language\n  );\n  \n  chunks.push(...uncoveredChunks);\n  \n  // Sort chunks by line number\n  chunks.sort((a, b) => a.metadata.startLine - b.metadata.startLine);\n  \n  return chunks;\n}\n\n/** Check if node is a function-containing declaration at top level */\nfunction isFunctionDeclaration(\n  node: Parser.SyntaxNode,\n  depth: number,\n  traverser: ReturnType<typeof getTraverser>\n): boolean {\n  if (depth !== 0 || !traverser.isDeclarationWithFunction(node)) return false;\n  return traverser.findFunctionInDeclaration(node).hasFunction;\n}\n\n/** Check if node is a target type at valid depth */\nfunction isTargetNode(\n  node: Parser.SyntaxNode,\n  depth: number,\n  traverser: ReturnType<typeof getTraverser>\n): boolean {\n  return depth <= 1 && traverser.targetNodeTypes.includes(node.type);\n}\n\n/**\n * Find all top-level nodes that should become chunks\n * \n * Uses a language-specific traverser to handle different AST structures.\n * This function is now language-agnostic - all language-specific logic\n * is delegated to the traverser.\n * \n * @param rootNode - Root AST node\n * @param traverser - Language-specific traverser\n * @returns Array of nodes to extract as chunks\n */\nfunction findTopLevelNodes(\n  rootNode: Parser.SyntaxNode,\n  traverser: ReturnType<typeof getTraverser>\n): Parser.SyntaxNode[] {\n  const nodes: Parser.SyntaxNode[] = [];\n  \n  function traverse(node: Parser.SyntaxNode, depth: number): void {\n    // Capture function declarations and target nodes\n    if (isFunctionDeclaration(node, depth, traverser) || isTargetNode(node, depth, traverser)) {\n      nodes.push(node);\n      return;\n    }\n    \n    // Handle containers - traverse body at increased depth\n    if (traverser.shouldExtractChildren(node)) {\n      const body = traverser.getContainerBody(node);\n      if (body) traverse(body, depth + 1);\n      return;\n    }\n    \n    // Traverse children of traversable nodes\n    if (!traverser.shouldTraverseChildren(node)) return;\n    for (let i = 0; i < node.namedChildCount; i++) {\n      const child = node.namedChild(i);\n      if (child) traverse(child, depth);\n    }\n  }\n  \n  traverse(rootNode, 0);\n  return nodes;\n}\n\n/**\n * Extract content for a specific AST node\n */\nfunction getNodeContent(node: Parser.SyntaxNode, lines: string[]): string {\n  const startLine = node.startPosition.row;\n  const endLine = node.endPosition.row;\n  \n  return lines.slice(startLine, endLine + 1).join('\\n');\n}\n\n/** Maps symbol types to legacy symbol array keys */\nconst SYMBOL_TYPE_TO_ARRAY: Record<string, 'functions' | 'classes' | 'interfaces'> = {\n  function: 'functions',\n  method: 'functions',\n  class: 'classes',\n  interface: 'interfaces',\n};\n\n/** Symbol types that have meaningful complexity metrics */\nconst COMPLEXITY_SYMBOL_TYPES = new Set(['function', 'method']);\n\n/**\n * Build legacy symbols object for backward compatibility\n */\nfunction buildLegacySymbols(symbolInfo: ReturnType<typeof extractSymbolInfo>): {\n  functions: string[];\n  classes: string[];\n  interfaces: string[];\n} {\n  const symbols = { functions: [] as string[], classes: [] as string[], interfaces: [] as string[] };\n  \n  if (symbolInfo?.name && symbolInfo.type) {\n    const arrayKey = SYMBOL_TYPE_TO_ARRAY[symbolInfo.type];\n    if (arrayKey) symbols[arrayKey].push(symbolInfo.name);\n  }\n  \n  return symbols;\n}\n\n/**\n * Determine chunk type from symbol info\n */\nfunction getChunkType(symbolInfo: ReturnType<typeof extractSymbolInfo>): 'block' | 'class' | 'function' {\n  if (!symbolInfo) return 'block';\n  return symbolInfo.type === 'class' ? 'class' : 'function';\n}\n\n/**\n * Create a chunk from an AST node\n */\nfunction createChunk(\n  filepath: string,\n  node: Parser.SyntaxNode,\n  content: string,\n  symbolInfo: ReturnType<typeof extractSymbolInfo>,\n  imports: string[],\n  language: string\n): ASTChunk {\n  const symbols = buildLegacySymbols(symbolInfo);\n  const shouldCalcComplexity = symbolInfo?.type && COMPLEXITY_SYMBOL_TYPES.has(symbolInfo.type);\n  \n  // Calculate complexity metrics only for functions and methods\n  const cognitiveComplexity = shouldCalcComplexity\n    ? calculateCognitiveComplexity(node)\n    : undefined;\n  \n  // Calculate Halstead metrics only for functions and methods\n  const halstead = shouldCalcComplexity\n    ? calculateHalstead(node, language)\n    : undefined;\n  \n  return {\n    content,\n    metadata: {\n      file: filepath,\n      startLine: node.startPosition.row + 1,\n      endLine: node.endPosition.row + 1,\n      type: getChunkType(symbolInfo),\n      language,\n      symbols,\n      symbolName: symbolInfo?.name,\n      symbolType: symbolInfo?.type,\n      parentClass: symbolInfo?.parentClass,\n      complexity: symbolInfo?.complexity,\n      cognitiveComplexity,\n      parameters: symbolInfo?.parameters,\n      signature: symbolInfo?.signature,\n      imports,\n      // Halstead metrics\n      halsteadVolume: halstead?.volume,\n      halsteadDifficulty: halstead?.difficulty,\n      halsteadEffort: halstead?.effort,\n      halsteadBugs: halstead?.bugs,\n    },\n  };\n}\n\n/**\n * Represents a range of lines in a file\n */\ninterface LineRange {\n  start: number;\n  end: number;\n}\n\n/**\n * Find gaps between covered ranges (uncovered code)\n */\nfunction findUncoveredRanges(\n  coveredRanges: LineRange[],\n  totalLines: number\n): LineRange[] {\n  const uncoveredRanges: LineRange[] = [];\n  let currentStart = 0;\n  \n  // Sort covered ranges\n  const sortedRanges = [...coveredRanges].sort((a, b) => a.start - b.start);\n  \n  for (const range of sortedRanges) {\n    if (currentStart < range.start) {\n      // There's a gap before this range\n      uncoveredRanges.push({\n        start: currentStart,\n        end: range.start - 1,\n      });\n    }\n    currentStart = range.end + 1;\n  }\n  \n  // Handle remaining code after last covered range\n  if (currentStart < totalLines) {\n    uncoveredRanges.push({\n      start: currentStart,\n      end: totalLines - 1,\n    });\n  }\n  \n  return uncoveredRanges;\n}\n\n/**\n * Create a chunk from a line range\n */\nfunction createChunkFromRange(\n  range: LineRange,\n  lines: string[],\n  filepath: string,\n  language: string,\n  imports: string[]\n): ASTChunk {\n  const uncoveredLines = lines.slice(range.start, range.end + 1);\n  const content = uncoveredLines.join('\\n').trim();\n  \n  return {\n    content,\n    metadata: {\n      file: filepath,\n      startLine: range.start + 1,\n      endLine: range.end + 1,\n      type: 'block',\n      language,\n      // Empty symbols for uncovered code (imports, exports, etc.)\n      symbols: { functions: [], classes: [], interfaces: [] },\n      imports,\n    },\n  };\n}\n\n/**\n * Validate that a chunk meets the minimum size requirements\n */\nfunction isValidChunk(chunk: ASTChunk, minChunkSize: number): boolean {\n  const lineCount = chunk.metadata.endLine - chunk.metadata.startLine + 1;\n  return chunk.content.length > 0 && lineCount >= minChunkSize;\n}\n\n/**\n * Extract code that wasn't covered by function/class chunks\n * (imports, exports, top-level statements)\n */\nfunction extractUncoveredCode(\n  lines: string[],\n  coveredRanges: Array<{ start: number; end: number }>,\n  filepath: string,\n  minChunkSize: number,\n  imports: string[],\n  language: string\n): ASTChunk[] {\n  const uncoveredRanges = findUncoveredRanges(coveredRanges, lines.length);\n  \n  return uncoveredRanges\n    .map(range => createChunkFromRange(range, lines, filepath, language, imports))\n    .filter(chunk => isValidChunk(chunk, minChunkSize));\n}\n\n/**\n * Check if AST chunking should be used for a file\n */\nexport function shouldUseAST(filepath: string): boolean {\n  return isASTSupported(filepath);\n}\n\n","import type { CodeChunk } from './types.js';\n\n/**\n * Liquid-specific chunking for Shopify themes\n * \n * Uses regex to identify special Liquid blocks (schema, style, javascript)\n * and keeps them as single semantic units\n */\n\ninterface LiquidBlock {\n  type: 'schema' | 'style' | 'javascript';\n  startLine: number;\n  endLine: number;\n  content: string;\n}\n\n/**\n * Extract schema name from JSON content\n * \n * Extracts the \"name\" field from Shopify schema JSON.\n * Uses JSON.parse to properly handle escaped quotes and other JSON edge cases.\n * \n * Example:\n * {% schema %}\n * {\n *   \"name\": \"My \\\"Special\\\" Section\",\n *   \"settings\": []\n * }\n * {% endschema %}\n * \n * Returns: 'My \"Special\" Section' (with literal quotes, unescaped)\n */\nfunction extractSchemaName(schemaContent: string): string | undefined {\n  try {\n    // Remove Liquid tags to isolate JSON content\n    // Replace {% schema %} and {% endschema %} (with optional whitespace control)\n    let jsonContent = schemaContent\n      .replace(/\\{%-?\\s*schema\\s*-?%\\}/g, '')\n      .replace(/\\{%-?\\s*endschema\\s*-?%\\}/g, '')\n      .trim();\n    \n    // Parse the JSON\n    const schema = JSON.parse(jsonContent);\n    // Ensure name is a string before returning\n    return typeof schema.name === 'string' ? schema.name : undefined;\n  } catch (error) {\n    // Invalid JSON - return undefined\n    // This is acceptable: schema blocks with invalid JSON won't have names extracted\n  }\n  return undefined;\n}\n\n/**\n * Remove Liquid comment blocks from content to avoid extracting tags from comments\n * \n * Example:\n * {% comment %}Don't use {% render 'old-snippet' %}{% endcomment %}\n * ‚Üí (removed)\n */\nfunction removeComments(content: string): string {\n  // Remove {% comment %}...{% endcomment %} blocks (with optional whitespace control)\n  return content.replace(/\\{%-?\\s*comment\\s*-?%\\}[\\s\\S]*?\\{%-?\\s*endcomment\\s*-?%\\}/g, '');\n}\n\n/**\n * Extract dependencies from {% render %}, {% include %}, and {% section %} tags\n * \n * Examples:\n * - {% render 'product-card' %} ‚Üí 'product-card'\n * - {% render \"cart-item\", product: product %} ‚Üí 'cart-item'\n * - {% include 'snippets/header' %} ‚Üí 'snippets/header'\n * - {% section 'announcement-bar' %} ‚Üí 'announcement-bar'\n * \n * Limitations:\n * - Does not handle escaped quotes in snippet names (e.g., {% render 'name\\'s' %})\n * - This is acceptable because Shopify snippet names map to filenames, and\n *   filesystem restrictions prevent quotes in filenames (snippets/name's.liquid is invalid)\n * - In practice, Shopify snippet names use only alphanumeric, dash, and underscore\n * \n * Note: Expects content with comments already removed for performance\n * \n * @param contentWithoutComments - Content with Liquid comments already removed\n */\nfunction extractRenderTags(contentWithoutComments: string): string[] {\n  const dependencies = new Set<string>();\n  \n  // Match {% render 'snippet-name' %} or {% render \"snippet-name\" %}\n  // Note: Does not handle escaped quotes - see function docs for rationale\n  const renderPattern = /\\{%-?\\s*render\\s+['\"]([^'\"]+)['\"]/g;\n  let match;\n  \n  while ((match = renderPattern.exec(contentWithoutComments)) !== null) {\n    dependencies.add(match[1]);\n  }\n  \n  // Match {% include 'snippet-name' %} or {% include \"snippet-name\" %}\n  const includePattern = /\\{%-?\\s*include\\s+['\"]([^'\"]+)['\"]/g;\n  \n  while ((match = includePattern.exec(contentWithoutComments)) !== null) {\n    dependencies.add(match[1]);\n  }\n  \n  // Match {% section 'section-name' %} or {% section \"section-name\" %}\n  const sectionPattern = /\\{%-?\\s*section\\s+['\"]([^'\"]+)['\"]/g;\n  \n  while ((match = sectionPattern.exec(contentWithoutComments)) !== null) {\n    dependencies.add(match[1]);\n  }\n  \n  return Array.from(dependencies);\n}\n\n/**\n * Find all special Liquid blocks in the template\n * \n * Limitation: Does not support nested blocks of the same type.\n * - Matches first start tag with first end tag\n * - This is acceptable because Shopify Liquid does not allow nested blocks\n * - Example invalid: {% schema %}...{% schema %}...{% endschema %} (Shopify rejects this)\n * - If malformed input contains nested blocks, only outermost block is extracted\n */\nfunction findLiquidBlocks(content: string): LiquidBlock[] {\n  const lines = content.split('\\n');\n  const blocks: LiquidBlock[] = [];\n  \n  // Regex patterns for Liquid blocks\n  // Note: Matches first start ‚Üí first end (no nesting support, which is correct for Shopify)\n  const blockPatterns = [\n    { type: 'schema' as const, start: /\\{%-?\\s*schema\\s*-?%\\}/, end: /\\{%-?\\s*endschema\\s*-?%\\}/ },\n    { type: 'style' as const, start: /\\{%-?\\s*style\\s*-?%\\}/, end: /\\{%-?\\s*endstyle\\s*-?%\\}/ },\n    { type: 'javascript' as const, start: /\\{%-?\\s*javascript\\s*-?%\\}/, end: /\\{%-?\\s*endjavascript\\s*-?%\\}/ },\n  ];\n  \n  for (const pattern of blockPatterns) {\n    let searchStart = 0;\n    \n    while (searchStart < lines.length) {\n      // Find start tag\n      const startIdx = lines.findIndex((line, idx) => \n        idx >= searchStart && pattern.start.test(line)\n      );\n      \n      if (startIdx === -1) break;\n      \n      // Find end tag (allow same line for single-line blocks)\n      const endIdx = lines.findIndex((line, idx) => \n        idx >= startIdx && pattern.end.test(line)\n      );\n      \n      if (endIdx === -1) {\n        // No end tag found, treat rest as template\n        break;\n      }\n      \n      // Extract block content\n      const blockContent = lines.slice(startIdx, endIdx + 1).join('\\n');\n      \n      blocks.push({\n        type: pattern.type,\n        startLine: startIdx,\n        endLine: endIdx,\n        content: blockContent,\n      });\n      \n      searchStart = endIdx + 1;\n    }\n  }\n  \n  return blocks.sort((a, b) => a.startLine - b.startLine);\n}\n\n/** Parameters for chunking operations */\ninterface ChunkParams {\n  filepath: string;\n  chunkSize: number;\n  chunkOverlap: number;\n}\n\n/** Context for processing a file - computed once and reused */\ninterface ChunkContext {\n  lines: string[];\n  linesWithoutComments: string[];\n  params: ChunkParams;\n}\n\n/**\n * Create a CodeChunk with consistent structure\n */\nfunction createCodeChunk(\n  content: string,\n  startLine: number,\n  endLine: number,\n  filepath: string,\n  type: 'block' | 'template',\n  options: {\n    symbolName?: string;\n    symbolType?: LiquidBlock['type'];\n    imports?: string[];\n  } = {}\n): CodeChunk {\n  return {\n    content,\n    metadata: {\n      file: filepath,\n      startLine,\n      endLine,\n      language: 'liquid',\n      type,\n      symbolName: options.symbolName,\n      symbolType: options.symbolType,\n      imports: options.imports?.length ? options.imports : undefined,\n    },\n  };\n}\n\n/**\n * Split a large block into multiple chunks with overlap\n */\nfunction splitLargeBlock(\n  block: LiquidBlock,\n  ctx: ChunkContext,\n  symbolName: string | undefined,\n  imports: string[]\n): CodeChunk[] {\n  const chunks: CodeChunk[] = [];\n  const blockLines = block.content.split('\\n');\n  const { chunkSize, chunkOverlap, filepath } = ctx.params;\n\n  for (let offset = 0; offset < blockLines.length; offset += chunkSize - chunkOverlap) {\n    const endOffset = Math.min(offset + chunkSize, blockLines.length);\n    const chunkContent = blockLines.slice(offset, endOffset).join('\\n');\n\n    if (chunkContent.trim().length > 0) {\n      chunks.push(createCodeChunk(\n        chunkContent,\n        block.startLine + offset + 1,\n        block.startLine + endOffset,\n        filepath,\n        'block',\n        { symbolName, symbolType: block.type, imports }\n      ));\n    }\n\n    if (endOffset >= blockLines.length) break;\n  }\n\n  return chunks;\n}\n\n/**\n * Create chunks from a special Liquid block (schema, style, javascript)\n * Returns the chunks and marks covered lines\n */\nfunction processSpecialBlock(\n  block: LiquidBlock,\n  ctx: ChunkContext,\n  coveredLines: Set<number>\n): CodeChunk[] {\n  // Mark lines as covered\n  for (let i = block.startLine; i <= block.endLine; i++) {\n    coveredLines.add(i);\n  }\n\n  // Extract metadata\n  const symbolName = block.type === 'schema' ? extractSchemaName(block.content) : undefined;\n\n  // Extract imports from cleaned content\n  const blockContentWithoutComments = ctx.linesWithoutComments\n    .slice(block.startLine, block.endLine + 1)\n    .join('\\n');\n  const imports = extractRenderTags(blockContentWithoutComments);\n\n  const blockLineCount = block.endLine - block.startLine + 1;\n  const maxBlockSize = ctx.params.chunkSize * 3;\n\n  // Keep small blocks as single chunk, split large ones\n  if (blockLineCount <= maxBlockSize) {\n    return [createCodeChunk(\n      block.content,\n      block.startLine + 1,\n      block.endLine + 1,\n      ctx.params.filepath,\n      'block',\n      { symbolName, symbolType: block.type, imports }\n    )];\n  }\n\n  return splitLargeBlock(block, ctx, symbolName, imports);\n}\n\n/**\n * Create a template chunk from accumulated lines\n */\nfunction flushTemplateChunk(\n  currentChunk: string[],\n  chunkStartLine: number,\n  endLine: number,\n  ctx: ChunkContext\n): CodeChunk | null {\n  if (currentChunk.length === 0) return null;\n\n  const chunkContent = currentChunk.join('\\n');\n  if (chunkContent.trim().length === 0) return null;\n\n  const cleanedChunk = ctx.linesWithoutComments.slice(chunkStartLine, endLine).join('\\n');\n  const imports = extractRenderTags(cleanedChunk);\n\n  return createCodeChunk(\n    chunkContent,\n    chunkStartLine + 1,\n    endLine,\n    ctx.params.filepath,\n    'template',\n    { imports }\n  );\n}\n\n/**\n * Process uncovered template content into chunks\n */\nfunction processTemplateContent(\n  ctx: ChunkContext,\n  coveredLines: Set<number>\n): CodeChunk[] {\n  const chunks: CodeChunk[] = [];\n  const { lines, params } = ctx;\n  const { chunkSize, chunkOverlap } = params;\n\n  let currentChunk: string[] = [];\n  let chunkStartLine = 0;\n\n  for (let i = 0; i < lines.length; i++) {\n    // Skip lines covered by special blocks\n    if (coveredLines.has(i)) {\n      const chunk = flushTemplateChunk(currentChunk, chunkStartLine, i, ctx);\n      if (chunk) chunks.push(chunk);\n      currentChunk = [];\n      continue;\n    }\n\n    // Start new chunk if needed\n    if (currentChunk.length === 0) {\n      chunkStartLine = i;\n    }\n\n    currentChunk.push(lines[i]);\n\n    // Flush if chunk is full\n    if (currentChunk.length >= chunkSize) {\n      const chunk = flushTemplateChunk(currentChunk, chunkStartLine, i + 1, ctx);\n      if (chunk) chunks.push(chunk);\n\n      // Add overlap for next chunk\n      currentChunk = currentChunk.slice(-chunkOverlap);\n      chunkStartLine = Math.max(0, i + 1 - chunkOverlap);\n    }\n  }\n\n  // Flush remaining chunk\n  const finalChunk = flushTemplateChunk(currentChunk, chunkStartLine, lines.length, ctx);\n  if (finalChunk) chunks.push(finalChunk);\n\n  return chunks;\n}\n\n/**\n * Chunk a Liquid template file\n * \n * Special handling for:\n * - {% schema %} blocks (kept together, extract section name)\n * - {% style %} blocks (kept together)  \n * - {% javascript %} blocks (kept together)\n * - {% render %}, {% include %}, and {% section %} tags (tracked as imports)\n * - Regular template content (chunked by lines)\n */\nexport function chunkLiquidFile(\n  filepath: string,\n  content: string,\n  chunkSize: number = 75,\n  chunkOverlap: number = 10\n): CodeChunk[] {\n  // Build context once for reuse across helpers\n  const contentWithoutComments = removeComments(content);\n  const ctx: ChunkContext = {\n    lines: content.split('\\n'),\n    linesWithoutComments: contentWithoutComments.split('\\n'),\n    params: { filepath, chunkSize, chunkOverlap },\n  };\n\n  // Find special blocks and track covered lines\n  const blocks = findLiquidBlocks(content);\n  const coveredLines = new Set<number>();\n\n  // Process special blocks\n  const blockChunks = blocks.flatMap(block => processSpecialBlock(block, ctx, coveredLines));\n\n  // Process uncovered template content\n  const templateChunks = processTemplateContent(ctx, coveredLines);\n\n  // Combine and sort by line number\n  return [...blockChunks, ...templateChunks].sort((a, b) => a.metadata.startLine - b.metadata.startLine);\n}\n\n","import type { CodeChunk } from './types.js';\n\n/**\n * Shopify JSON template chunking\n * \n * JSON template files define which sections appear on a template page.\n * We extract section references to track dependencies.\n * \n * Example structure:\n * {\n *   \"sections\": {\n *     \"main\": { \"type\": \"main-product\", \"settings\": {...} },\n *     \"recommendations\": { \"type\": \"product-recommendations\", \"settings\": {...} }\n *   },\n *   \"order\": [\"main\", \"recommendations\"]\n * }\n */\n\n/**\n * Extract section types from a Shopify JSON template\n * \n * These are the actual section file names (e.g., \"main-product\" ‚Üí sections/main-product.liquid)\n */\nfunction extractSectionReferences(jsonContent: string): string[] {\n  try {\n    const template = JSON.parse(jsonContent);\n    const sectionTypes = new Set<string>();\n    \n    // Extract from sections object\n    if (template.sections && typeof template.sections === 'object') {\n      for (const section of Object.values(template.sections)) {\n        if (\n          typeof section === 'object' && \n          section !== null && \n          'type' in section && \n          typeof section.type === 'string'\n        ) {\n          sectionTypes.add(section.type);\n        }\n      }\n    }\n    \n    return Array.from(sectionTypes);\n  } catch (error) {\n    // Invalid JSON - return empty array\n    console.warn(`[Lien] Failed to parse JSON template: ${error instanceof Error ? error.message : String(error)}`);\n    return [];\n  }\n}\n\n/**\n * Extract the template name from the filepath\n * \n * templates/customers/account.json ‚Üí \"customers/account\"\n * templates/product.json ‚Üí \"product\"\n */\nfunction extractTemplateName(filepath: string): string | undefined {\n  // Match everything after templates/ up to .json\n  const match = filepath.match(/templates\\/(.+)\\.json$/);\n  return match ? match[1] : undefined;\n}\n\n/**\n * Chunk a Shopify JSON template file\n * \n * JSON templates are typically small (define section layout),\n * so we keep them as a single chunk and extract section references.\n */\nexport function chunkJSONTemplate(\n  filepath: string,\n  content: string\n): CodeChunk[] {\n  // Skip empty files\n  if (content.trim().length === 0) {\n    return [];\n  }\n  \n  const lines = content.split('\\n');\n  const templateName = extractTemplateName(filepath);\n  const sectionReferences = extractSectionReferences(content);\n  \n  return [{\n    content,\n    metadata: {\n      file: filepath,\n      startLine: 1,\n      endLine: lines.length,\n      language: 'json',\n      type: 'template',\n      symbolName: templateName,\n      symbolType: 'template',\n      imports: sectionReferences.length > 0 ? sectionReferences : undefined,\n    },\n  }];\n}\n\n","import { CodeChunk } from './types.js';\nimport { detectLanguage } from './scanner.js';\nimport { extractSymbols } from './symbol-extractor.js';\nimport { shouldUseAST, chunkByAST } from './ast/chunker.js';\nimport { chunkLiquidFile } from './liquid-chunker.js';\nimport { chunkJSONTemplate } from './json-template-chunker.js';\n\nexport interface ChunkOptions {\n  chunkSize?: number;\n  chunkOverlap?: number;\n  useAST?: boolean; // Flag to enable AST-based chunking\n  astFallback?: 'line-based' | 'error'; // How to handle AST parsing errors\n}\n\nexport function chunkFile(\n  filepath: string,\n  content: string,\n  options: ChunkOptions = {}\n): CodeChunk[] {\n  const { chunkSize = 75, chunkOverlap = 10, useAST = true, astFallback = 'line-based' } = options;\n  \n  // Special handling for Liquid files\n  if (filepath.endsWith('.liquid')) {\n    return chunkLiquidFile(filepath, content, chunkSize, chunkOverlap);\n  }\n  \n  // Special handling for Shopify JSON template files (templates/**/*.json)\n  // Use regex to ensure 'templates/' is a path segment, not part of another name\n  // Matches: templates/product.json OR some-path/templates/customers/account.json\n  // Rejects: my-templates/config.json OR node_modules/pkg/templates/file.json (filtered by scanner)\n  if (filepath.endsWith('.json') && /(?:^|\\/)templates\\//.test(filepath)) {\n    return chunkJSONTemplate(filepath, content);\n  }\n  \n  // Try AST-based chunking for supported languages\n  if (useAST && shouldUseAST(filepath)) {\n    try {\n      return chunkByAST(filepath, content, {\n        minChunkSize: Math.floor(chunkSize / 10),\n      });\n    } catch (error) {\n      // Handle AST errors based on configuration\n      if (astFallback === 'error') {\n        // Throw error if user wants strict AST-only behavior\n        throw new Error(`AST chunking failed for ${filepath}: ${error instanceof Error ? error.message : String(error)}`);\n      }\n      // Otherwise fallback to line-based chunking\n      console.warn(`AST chunking failed for ${filepath}, falling back to line-based:`, error);\n    }\n  }\n  \n  // Line-based chunking (original implementation)\n  return chunkByLines(filepath, content, chunkSize, chunkOverlap);\n}\n\n/**\n * Original line-based chunking implementation\n */\nfunction chunkByLines(\n  filepath: string,\n  content: string,\n  chunkSize: number,\n  chunkOverlap: number\n): CodeChunk[] {\n  const lines = content.split('\\n');\n  const chunks: CodeChunk[] = [];\n  const language = detectLanguage(filepath);\n  \n  // Handle empty files\n  if (lines.length === 0 || (lines.length === 1 && lines[0].trim() === '')) {\n    return chunks;\n  }\n  \n  // Chunk by lines with overlap\n  for (let i = 0; i < lines.length; i += chunkSize - chunkOverlap) {\n    const endLine = Math.min(i + chunkSize, lines.length);\n    const chunkLines = lines.slice(i, endLine);\n    const chunkContent = chunkLines.join('\\n');\n    \n    // Skip empty chunks\n    if (chunkContent.trim().length === 0) {\n      continue;\n    }\n    \n    // Extract symbols from the chunk\n    const symbols = extractSymbols(chunkContent, language);\n    \n    chunks.push({\n      content: chunkContent,\n      metadata: {\n        file: filepath,\n        startLine: i + 1,\n        endLine: endLine,\n        type: 'block', // MVP: all chunks are 'block' type\n        language,\n        symbols,\n      },\n    });\n    \n    // If we've reached the end, break\n    if (endLine >= lines.length) {\n      break;\n    }\n  }\n  \n  return chunks;\n}\n\nexport function chunkText(text: string, options: ChunkOptions = {}): string[] {\n  const { chunkSize = 75, chunkOverlap = 10 } = options;\n  \n  const lines = text.split('\\n');\n  const chunks: string[] = [];\n  \n  for (let i = 0; i < lines.length; i += chunkSize - chunkOverlap) {\n    const endLine = Math.min(i + chunkSize, lines.length);\n    const chunkLines = lines.slice(i, endLine);\n    const chunkContent = chunkLines.join('\\n');\n    \n    if (chunkContent.trim().length > 0) {\n      chunks.push(chunkContent);\n    }\n    \n    if (endLine >= lines.length) {\n      break;\n    }\n  }\n  \n  return chunks;\n}\n\n","import { pipeline, env, type FeatureExtractionPipeline } from '@xenova/transformers';\nimport { EmbeddingService } from './types.js';\nimport { EmbeddingError, wrapError } from '../errors/index.js';\nimport { DEFAULT_EMBEDDING_MODEL } from '../constants.js';\n\n// Configure transformers.js to cache models locally\nenv.allowRemoteModels = true;\nenv.allowLocalModels = true;\n\nexport class LocalEmbeddings implements EmbeddingService {\n  private extractor: FeatureExtractionPipeline | null = null;\n  private readonly modelName = DEFAULT_EMBEDDING_MODEL;\n  private initPromise: Promise<void> | null = null;\n  \n  async initialize(): Promise<void> {\n    // Prevent multiple simultaneous initializations\n    if (this.initPromise) {\n      return this.initPromise;\n    }\n    \n    if (this.extractor) {\n      return;\n    }\n    \n    this.initPromise = (async () => {\n      try {\n        // This downloads ~100MB on first run, then caches in ~/.cache/huggingface\n        this.extractor = await pipeline('feature-extraction', this.modelName) as FeatureExtractionPipeline;\n      } catch (error: unknown) {\n        this.initPromise = null;\n        throw wrapError(error, 'Failed to initialize embedding model');\n      }\n    })();\n    \n    return this.initPromise;\n  }\n  \n  async embed(text: string): Promise<Float32Array> {\n    await this.initialize();\n    \n    if (!this.extractor) {\n      throw new EmbeddingError('Embedding model not initialized');\n    }\n    \n    try {\n      const output = await this.extractor(text, {\n        pooling: 'mean',\n        normalize: true,\n      });\n      \n      return output.data as Float32Array;\n    } catch (error: unknown) {\n      throw wrapError(error, 'Failed to generate embedding', { textLength: text.length });\n    }\n  }\n  \n  async embedBatch(texts: string[]): Promise<Float32Array[]> {\n    await this.initialize();\n    \n    if (!this.extractor) {\n      throw new EmbeddingError('Embedding model not initialized');\n    }\n    \n    try {\n      // Process embeddings with Promise.all for concurrent execution\n      // Each call is sequential but Promise.all allows task interleaving\n      const results = await Promise.all(\n        texts.map(text => this.embed(text))\n      );\n      return results;\n    } catch (error: unknown) {\n      throw wrapError(error, 'Failed to generate batch embeddings', { batchSize: texts.length });\n    }\n  }\n}\n\n","/**\n * Error codes for all Lien-specific errors.\n * Used to identify error types programmatically.\n */\nexport enum LienErrorCode {\n  // Configuration\n  CONFIG_NOT_FOUND = 'CONFIG_NOT_FOUND',\n  CONFIG_INVALID = 'CONFIG_INVALID',\n  \n  // Index\n  INDEX_NOT_FOUND = 'INDEX_NOT_FOUND',\n  INDEX_CORRUPTED = 'INDEX_CORRUPTED',\n  \n  // Embeddings\n  EMBEDDING_MODEL_FAILED = 'EMBEDDING_MODEL_FAILED',\n  EMBEDDING_GENERATION_FAILED = 'EMBEDDING_GENERATION_FAILED',\n  \n  // File System\n  FILE_NOT_FOUND = 'FILE_NOT_FOUND',\n  FILE_NOT_READABLE = 'FILE_NOT_READABLE',\n  INVALID_PATH = 'INVALID_PATH',\n  \n  // Tool Input\n  INVALID_INPUT = 'INVALID_INPUT',\n  \n  // System\n  INTERNAL_ERROR = 'INTERNAL_ERROR',\n}\n\n","import { LienErrorCode } from './codes.js';\n\n// Re-export for consumers\nexport { LienErrorCode } from './codes.js';\n\n/**\n * Severity levels for errors\n */\nexport type ErrorSeverity = 'low' | 'medium' | 'high' | 'critical';\n\n/**\n * Base error class for all Lien-specific errors\n */\nexport class LienError extends Error {\n  constructor(\n    message: string,\n    public readonly code: LienErrorCode,\n    public readonly context?: Record<string, unknown>,\n    public readonly severity: ErrorSeverity = 'medium',\n    public readonly recoverable: boolean = true,\n    public readonly retryable: boolean = false\n  ) {\n    super(message);\n    this.name = 'LienError';\n    \n    // Maintains proper stack trace for where our error was thrown (only available on V8)\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n  }\n  \n  /**\n   * Serialize error to JSON for MCP responses\n   */\n  toJSON() {\n    return {\n      error: this.message,\n      code: this.code,\n      severity: this.severity,\n      recoverable: this.recoverable,\n      context: this.context,\n    };\n  }\n  \n  /**\n   * Check if this error is retryable\n   */\n  isRetryable(): boolean {\n    return this.retryable;\n  }\n  \n  /**\n   * Check if this error is recoverable\n   */\n  isRecoverable(): boolean {\n    return this.recoverable;\n  }\n}\n\n/**\n * Configuration-related errors (loading, parsing, migration)\n */\nexport class ConfigError extends LienError {\n  constructor(message: string, context?: Record<string, unknown>) {\n    super(message, LienErrorCode.CONFIG_INVALID, context, 'medium', true, false);\n    this.name = 'ConfigError';\n  }\n}\n\n/**\n * Indexing-related errors (file processing, chunking)\n */\nexport class IndexingError extends LienError {\n  constructor(\n    message: string,\n    public readonly file?: string,\n    context?: Record<string, unknown>\n  ) {\n    super(message, LienErrorCode.INTERNAL_ERROR, { ...context, file }, 'medium', true, false);\n    this.name = 'IndexingError';\n  }\n}\n\n/**\n * Embedding generation errors\n */\nexport class EmbeddingError extends LienError {\n  constructor(message: string, context?: Record<string, unknown>) {\n    super(message, LienErrorCode.EMBEDDING_GENERATION_FAILED, context, 'high', true, true);\n    this.name = 'EmbeddingError';\n  }\n}\n\n/**\n * Vector database errors (connection, query, storage)\n */\nexport class DatabaseError extends LienError {\n  constructor(message: string, context?: Record<string, unknown>) {\n    super(message, LienErrorCode.INTERNAL_ERROR, context, 'high', true, true);\n    this.name = 'DatabaseError';\n  }\n}\n\n/**\n * Helper function to wrap unknown errors with context\n * @param error - Unknown error object to wrap\n * @param context - Context message describing what operation failed\n * @param additionalContext - Optional additional context data\n * @returns LienError with proper message and context\n */\nexport function wrapError(\n  error: unknown,\n  context: string,\n  additionalContext?: Record<string, unknown>\n): LienError {\n  const message = error instanceof Error ? error.message : String(error);\n  const stack = error instanceof Error ? error.stack : undefined;\n  \n  const wrappedError = new LienError(\n    `${context}: ${message}`,\n    LienErrorCode.INTERNAL_ERROR,\n    additionalContext\n  );\n  \n  // Preserve original stack trace if available\n  if (stack) {\n    wrappedError.stack = `${wrappedError.stack}\\n\\nCaused by:\\n${stack}`;\n  }\n  \n  return wrappedError;\n}\n\n/**\n * Type guard to check if an error is a LienError\n */\nexport function isLienError(error: unknown): error is LienError {\n  return error instanceof LienError;\n}\n\n/**\n * Extract error message from unknown error type\n * @param error - Unknown error object\n * @returns Error message string\n */\nexport function getErrorMessage(error: unknown): string {\n  if (error instanceof Error) {\n    return error.message;\n  }\n  return String(error);\n}\n\n/**\n * Extract stack trace from unknown error type\n * @param error - Unknown error object\n * @returns Stack trace string or undefined\n */\nexport function getErrorStack(error: unknown): string | undefined {\n  if (error instanceof Error) {\n    return error.stack;\n  }\n  return undefined;\n}\n\n","/**\n * Centralized constants for @liendev/core.\n * This file contains all magic numbers and configuration defaults.\n */\n\n// Chunking settings\nexport const DEFAULT_CHUNK_SIZE = 75;\nexport const DEFAULT_CHUNK_OVERLAP = 10;\n\n// Concurrency and batching\nexport const DEFAULT_CONCURRENCY = 4;\nexport const DEFAULT_EMBEDDING_BATCH_SIZE = 50;\n\n// Micro-batching for event loop yielding\n// Process N embeddings at a time, then yield to event loop\n// This prevents UI freezing during CPU-intensive embedding generation\nexport const EMBEDDING_MICRO_BATCH_SIZE = 10;\n\n// Vector database batch size limits\n// Maximum batch size before splitting (prevents LanceDB errors on very large batches)\nexport const VECTOR_DB_MAX_BATCH_SIZE = 1000;\n// Minimum batch size for retry logic (stop splitting below this size)\nexport const VECTOR_DB_MIN_BATCH_SIZE = 10;\n\n// Embedding model configuration\nexport const EMBEDDING_DIMENSIONS = 384; // all-MiniLM-L6-v2\nexport const DEFAULT_EMBEDDING_MODEL = 'Xenova/all-MiniLM-L6-v2';\n\n// MCP server configuration\nexport const DEFAULT_PORT = 7133; // LIEN in leetspeak\nexport const VERSION_CHECK_INTERVAL_MS = 2000;\n\n// Git detection\nexport const DEFAULT_GIT_POLL_INTERVAL_MS = 10000; // Check every 10 seconds\n\n// File watching\nexport const DEFAULT_DEBOUNCE_MS = 1000;\n\n// Configuration version - matches the CLI/core release version\n// Core and CLI are always released together with matching versions\nexport const CURRENT_CONFIG_VERSION = '0.19.5';\n\n// Index format version - bump on ANY breaking change to indexing\n// Examples that require version bump:\n// - Chunking algorithm changes\n// - Embedding model changes (e.g., switch from all-MiniLM-L6-v2 to another model)\n// - Vector DB schema changes (new metadata fields)\n// - Metadata structure changes\n// v2: AST-based chunking + enhanced metadata (symbolName, complexity, etc.)\n// v3: Added cognitiveComplexity field to schema\n// v4: Added Halstead metrics (volume, difficulty, effort, bugs)\nexport const INDEX_FORMAT_VERSION = 4;\n","import * as lancedb from '@lancedb/lancedb';\nimport path from 'path';\nimport os from 'os';\nimport crypto from 'crypto';\nimport { SearchResult, VectorDBInterface } from './types.js';\nimport { ChunkMetadata } from '../indexer/types.js';\nimport { EMBEDDING_DIMENSION } from '../embeddings/types.js';\nimport { readVersionFile } from './version.js';\nimport { DatabaseError, wrapError } from '../errors/index.js';\nimport * as queryOps from './query.js';\nimport * as batchOps from './batch-insert.js';\nimport * as maintenanceOps from './maintenance.js';\n\ntype LanceDBConnection = Awaited<ReturnType<typeof lancedb.connect>>;\ntype LanceDBTable = Awaited<ReturnType<LanceDBConnection['openTable']>>;\n\nexport class VectorDB implements VectorDBInterface {\n  private db: LanceDBConnection | null = null;\n  private table: LanceDBTable | null = null;\n  public readonly dbPath: string;\n  private readonly tableName = 'code_chunks';\n  private lastVersionCheck: number = 0;\n  private currentVersion: number = 0;\n  \n  constructor(projectRoot: string) {\n    // Store in user's home directory under ~/.lien/indices/{projectName-hash}\n    const projectName = path.basename(projectRoot);\n    \n    // Create unique identifier from full path to prevent collisions\n    const pathHash = crypto\n      .createHash('md5')\n      .update(projectRoot)\n      .digest('hex')\n      .substring(0, 8);\n    \n    this.dbPath = path.join(\n      os.homedir(),\n      '.lien',\n      'indices',\n      `${projectName}-${pathHash}`\n    );\n  }\n  \n  async initialize(): Promise<void> {\n    try {\n      this.db = await lancedb.connect(this.dbPath);\n      \n      try {\n        this.table = await this.db.openTable(this.tableName);\n      } catch {\n        // Table doesn't exist yet - will be created on first insert\n        this.table = null;\n      }\n      \n      // Read and cache the current version\n      try {\n        this.currentVersion = await readVersionFile(this.dbPath);\n      } catch {\n        // Version file doesn't exist yet, will be created on first index\n        this.currentVersion = 0;\n      }\n    } catch (error: unknown) {\n      throw wrapError(error, 'Failed to initialize vector database', { dbPath: this.dbPath });\n    }\n  }\n  \n  async insertBatch(\n    vectors: Float32Array[],\n    metadatas: ChunkMetadata[],\n    contents: string[]\n  ): Promise<void> {\n    if (!this.db) {\n      throw new DatabaseError('Vector database not initialized');\n    }\n    // Note: insertBatch may return null for empty batches when table is null\n    // This is correct behavior - empty batches are no-ops and don't create tables\n    this.table = await batchOps.insertBatch(\n      this.db,\n      this.table,\n      this.tableName,\n      vectors,\n      metadatas,\n      contents\n    );\n  }\n  \n  async search(\n    queryVector: Float32Array,\n    limit: number = 5,\n    query?: string\n  ): Promise<SearchResult[]> {\n    if (!this.table) {\n      throw new DatabaseError('Vector database not initialized');\n    }\n    \n    try {\n      return await queryOps.search(this.table, queryVector, limit, query);\n    } catch (error) {\n      const errorMsg = String(error);\n      \n      // Detect corrupted index or missing data files\n      if (errorMsg.includes('Not found:') || errorMsg.includes('.lance')) {\n        // Attempt to reconnect - index may have been rebuilt\n        try {\n          await this.initialize();\n          if (!this.table) {\n            throw new DatabaseError('Vector database not initialized after reconnection');\n          }\n          return await queryOps.search(this.table, queryVector, limit, query);\n        } catch (retryError: unknown) {\n          throw new DatabaseError(\n            `Index appears corrupted or outdated. Please restart the MCP server or run 'lien reindex' in the project directory.`,\n            { originalError: retryError }\n          );\n        }\n      }\n      \n      throw error;\n    }\n  }\n  \n  async scanWithFilter(options: {\n    language?: string;\n    pattern?: string;\n    limit?: number;\n  }): Promise<SearchResult[]> {\n    if (!this.table) {\n      throw new DatabaseError('Vector database not initialized');\n    }\n    return queryOps.scanWithFilter(this.table, options);\n  }\n  \n  /**\n   * Scan all chunks in the database\n   * Fetches total count first, then retrieves all chunks in a single optimized query\n   * @param options - Filter options (language, pattern)\n   * @returns All matching chunks\n   */\n  async scanAll(options: {\n    language?: string;\n    pattern?: string;\n  } = {}): Promise<SearchResult[]> {\n    if (!this.table) {\n      throw new DatabaseError('Vector database not initialized');\n    }\n    return queryOps.scanAll(this.table, options);\n  }\n  \n  async querySymbols(options: {\n    language?: string;\n    pattern?: string;\n    symbolType?: 'function' | 'class' | 'interface';\n    limit?: number;\n  }): Promise<SearchResult[]> {\n    if (!this.table) {\n      throw new DatabaseError('Vector database not initialized');\n    }\n    return queryOps.querySymbols(this.table, options);\n  }\n  \n  async clear(): Promise<void> {\n    if (!this.db) {\n      throw new DatabaseError('Vector database not initialized');\n    }\n    // Close connections first to release file handles\n    this.table = null;\n    await maintenanceOps.clear(this.db, null, this.tableName, this.dbPath);\n  }\n  \n  async deleteByFile(filepath: string): Promise<void> {\n    if (!this.table) {\n      throw new DatabaseError('Vector database not initialized');\n    }\n    await maintenanceOps.deleteByFile(this.table, filepath);\n  }\n  \n  async updateFile(\n    filepath: string,\n    vectors: Float32Array[],\n    metadatas: ChunkMetadata[],\n    contents: string[]\n  ): Promise<void> {\n    if (!this.db) {\n      throw new DatabaseError('Vector database connection not initialized');\n    }\n    if (!this.table) {\n      throw new DatabaseError('Vector database table not initialized');\n    }\n    this.table = await maintenanceOps.updateFile(\n      this.db,\n      this.table,\n      this.tableName,\n      this.dbPath,\n      filepath,\n      vectors,\n      metadatas,\n      contents\n    );\n  }\n  \n  async checkVersion(): Promise<boolean> {\n    const now = Date.now();\n    \n    // Cache version checks for 1 second to minimize I/O\n    if (now - this.lastVersionCheck < 1000) {\n      return false;\n    }\n    \n    this.lastVersionCheck = now;\n    \n    try {\n      const version = await readVersionFile(this.dbPath);\n      \n      if (version > this.currentVersion) {\n        this.currentVersion = version;\n        return true;\n      }\n      \n      return false;\n    } catch (error) {\n      // If we can't read version file, don't reconnect\n      return false;\n    }\n  }\n  \n  async reconnect(): Promise<void> {\n    try {\n      // Close existing connections to force reload from disk\n      this.table = null;\n      this.db = null;\n      \n      // Reinitialize with fresh connection\n      await this.initialize();\n    } catch (error) {\n      throw wrapError(error, 'Failed to reconnect to vector database');\n    }\n  }\n  \n  getCurrentVersion(): number {\n    return this.currentVersion;\n  }\n  \n  getVersionDate(): string {\n    if (this.currentVersion === 0) {\n      return 'Unknown';\n    }\n    return new Date(this.currentVersion).toLocaleString();\n  }\n  \n  async hasData(): Promise<boolean> {\n    if (!this.table) {\n      return false;\n    }\n    \n    try {\n      const count = await this.table.countRows();\n      \n      if (count === 0) {\n        return false;\n      }\n      \n      // Sample a few rows to verify they contain real data\n      const sample = await this.table\n        .search(Array(EMBEDDING_DIMENSION).fill(0))\n        .limit(Math.min(count, 5))\n        .toArray();\n      \n      const hasRealData = (sample as unknown as any[]).some((r: any) => \n        r.content && \n        r.content.trim().length > 0\n      );\n      \n      return hasRealData;\n    } catch {\n      // If any error occurs, assume no data\n      return false;\n    }\n  }\n  \n  static async load(projectRoot: string): Promise<VectorDB> {\n    const db = new VectorDB(projectRoot);\n    await db.initialize();\n    return db;\n  }\n}\n","import { EMBEDDING_DIMENSIONS } from '../constants.js';\n\nexport interface EmbeddingService {\n  initialize(): Promise<void>;\n  embed(text: string): Promise<Float32Array>;\n  embedBatch(texts: string[]): Promise<Float32Array[]>;\n}\n\nexport const EMBEDDING_DIMENSION = EMBEDDING_DIMENSIONS;\n\n// Re-export for convenience\nexport { EMBEDDING_DIMENSIONS };\n\n","import fs from 'fs/promises';\nimport path from 'path';\n\nconst VERSION_FILE = '.lien-index-version';\n\n/**\n * Writes a version timestamp file to mark when the index was last updated.\n * This file is used by the MCP server to detect when it needs to reconnect.\n * \n * @param indexPath - Path to the index directory\n */\nexport async function writeVersionFile(indexPath: string): Promise<void> {\n  try {\n    const versionFilePath = path.join(indexPath, VERSION_FILE);\n    const timestamp = Date.now().toString();\n    await fs.writeFile(versionFilePath, timestamp, 'utf-8');\n  } catch (error) {\n    // Don't throw - version file is a convenience feature, not critical\n    console.error(`Warning: Failed to write version file: ${error}`);\n  }\n}\n\n/**\n * Reads the version timestamp from the index directory.\n * Returns 0 if the file doesn't exist (e.g., old index).\n * \n * @param indexPath - Path to the index directory\n * @returns Version timestamp, or 0 if not found\n */\nexport async function readVersionFile(indexPath: string): Promise<number> {\n  try {\n    const versionFilePath = path.join(indexPath, VERSION_FILE);\n    const content = await fs.readFile(versionFilePath, 'utf-8');\n    const timestamp = parseInt(content.trim(), 10);\n    return isNaN(timestamp) ? 0 : timestamp;\n  } catch (error) {\n    // File doesn't exist or can't be read - treat as version 0\n    return 0;\n  }\n}\n\n","/**\n * Relevance category based on semantic similarity score\n */\nexport type RelevanceCategory = 'highly_relevant' | 'relevant' | 'loosely_related' | 'not_relevant';\n\n/**\n * Calculate relevance category from cosine distance score.\n * \n * Lower scores indicate higher similarity (closer in vector space).\n * Thresholds based on observed score distributions from dogfooding.\n * \n * @param score - Cosine distance score from vector search\n * @returns Human-readable relevance category\n */\nexport function calculateRelevance(score: number): RelevanceCategory {\n  if (score < 1.0) return 'highly_relevant';\n  if (score < 1.3) return 'relevant';\n  if (score < 1.5) return 'loosely_related';\n  return 'not_relevant';\n}\n\n","/**\n * Query Intent Classification\n * \n * Classifies user search queries into three categories to apply\n * appropriate relevance boosting strategies:\n * \n * - LOCATION: \"Where is X?\" - User wants to find specific files/code\n * - CONCEPTUAL: \"How does X work?\" - User wants to understand concepts\n * - IMPLEMENTATION: \"How is X implemented?\" - User wants implementation details\n * \n * Examples:\n * - \"where is the auth handler\" ‚Üí LOCATION\n * - \"how does authentication work\" ‚Üí CONCEPTUAL\n * - \"how is authentication implemented\" ‚Üí IMPLEMENTATION\n */\n\n/**\n * Query intent types for semantic search\n */\nexport enum QueryIntent {\n  /** User wants to locate specific files or code (e.g., \"where is X\") */\n  LOCATION = 'location',\n  \n  /** User wants to understand concepts/processes (e.g., \"how does X work\") */\n  CONCEPTUAL = 'conceptual',\n  \n  /** User wants implementation details (e.g., \"how is X implemented\") */\n  IMPLEMENTATION = 'implementation',\n}\n\n/**\n * Intent classification rule with patterns and priority\n */\nexport interface IntentRule {\n  intent: QueryIntent;\n  patterns: RegExp[];\n  priority: number;\n}\n\n/**\n * Intent classification rules.\n * Rules are checked in priority order (higher priority first).\n */\nconst INTENT_RULES: IntentRule[] = [\n  // LOCATION intent (highest priority - most specific)\n  {\n    intent: QueryIntent.LOCATION,\n    priority: 3,\n    patterns: [\n      /where\\s+(is|are|does|can\\s+i\\s+find)/,\n      /find\\s+the\\s+/,\n      /locate\\s+/,\n    ],\n  },\n  \n  // CONCEPTUAL intent (medium priority)\n  {\n    intent: QueryIntent.CONCEPTUAL,\n    priority: 2,\n    patterns: [\n      /how\\s+does\\s+.*\\s+work/,\n      /what\\s+(is|are|does)/,\n      /explain\\s+/,\n      /understand\\s+/,\n      /\\b(process|workflow|architecture)\\b/,\n    ],\n  },\n  \n  // IMPLEMENTATION intent (low priority - catches \"how is X implemented\")\n  {\n    intent: QueryIntent.IMPLEMENTATION,\n    priority: 1,\n    patterns: [\n      /how\\s+(is|are)\\s+.*\\s+(implemented|built|coded)/,\n      /implementation\\s+of/,\n      /source\\s+code\\s+for/,\n    ],\n  },\n];\n\n/**\n * Capture the initial number of built-in rules.\n * This is used by resetIntentRules() to distinguish built-in rules from custom rules.\n */\nconst INITIAL_RULE_COUNT = INTENT_RULES.length;\n\n/**\n * Cached sorted rules to avoid re-sorting on every query.\n * Invalidated when rules are modified via addIntentRule() or resetIntentRules().\n */\nlet cachedSortedRules: IntentRule[] | null = null;\n\n/**\n * Get sorted rules (cached).\n * Lazy-computes and caches the sorted array on first access.\n */\nfunction getSortedRules(): IntentRule[] {\n  if (cachedSortedRules === null) {\n    cachedSortedRules = [...INTENT_RULES].sort((a, b) => b.priority - a.priority);\n  }\n  return cachedSortedRules;\n}\n\n/**\n * Invalidate the sorted rules cache.\n * Called when rules are modified.\n */\nfunction invalidateSortedRulesCache(): void {\n  cachedSortedRules = null;\n}\n\n/**\n * Classifies a search query into one of three intent categories.\n * \n * Uses data-driven pattern matching to detect query intent.\n * Rules are checked in priority order, with the first match winning.\n * \n * @param query - The search query string\n * @returns The detected query intent (defaults to IMPLEMENTATION)\n * \n * @example\n * classifyQueryIntent(\"where is the user controller\") // ‚Üí LOCATION\n * classifyQueryIntent(\"how does authentication work\") // ‚Üí CONCEPTUAL\n * classifyQueryIntent(\"how is the API implemented\") // ‚Üí IMPLEMENTATION\n */\nexport function classifyQueryIntent(query: string): QueryIntent {\n  const lower = query.toLowerCase().trim();\n  \n  // Use cached sorted rules to avoid re-sorting on every query\n  const sortedRules = getSortedRules();\n  \n  for (const rule of sortedRules) {\n    if (rule.patterns.some(pattern => pattern.test(lower))) {\n      return rule.intent;\n    }\n  }\n  \n  // Default to IMPLEMENTATION for ambiguous queries\n  // This is the most common use case for code search\n  return QueryIntent.IMPLEMENTATION;\n}\n\n/**\n * Add a custom intent rule (useful for testing or extensions).\n * \n * Returns a cleanup function that removes the added rule.\n * This prevents test pollution and allows proper cleanup.\n * \n * @param rule - The intent rule to add\n * @returns A cleanup function that removes the added rule\n * \n * @example\n * const cleanup = addIntentRule({\n *   intent: QueryIntent.LOCATION,\n *   priority: 4,\n *   patterns: [/custom pattern/]\n * });\n * // ... use the rule ...\n * cleanup(); // removes the rule\n */\nexport function addIntentRule(rule: IntentRule): () => void {\n  INTENT_RULES.push(rule);\n  \n  // Invalidate cache since rules have changed\n  invalidateSortedRulesCache();\n  \n  // Return cleanup function to remove the rule\n  return () => {\n    const idx = INTENT_RULES.indexOf(rule);\n    if (idx !== -1) {\n      INTENT_RULES.splice(idx, 1);\n      // Invalidate cache since rules have changed\n      invalidateSortedRulesCache();\n    }\n  };\n}\n\n/**\n * Get all patterns for a specific intent (useful for debugging).\n * \n * @param intent - The intent to get patterns for\n * @returns Array of regex patterns for the intent\n * \n * @example\n * const locationPatterns = getPatternsForIntent(QueryIntent.LOCATION);\n */\nexport function getPatternsForIntent(intent: QueryIntent): RegExp[] {\n  return INTENT_RULES\n    .filter(rule => rule.intent === intent)\n    .flatMap(rule => rule.patterns);\n}\n\n/**\n * Get all intent rules (useful for testing/debugging).\n * \n * @returns A copy of the current intent rules\n */\nexport function getIntentRules(): IntentRule[] {\n  return [...INTENT_RULES];\n}\n\n/**\n * Reset intent rules to initial state.\n * \n * WARNING: This function is intended for testing only.\n * It removes all custom rules added via addIntentRule().\n * The original built-in rules are preserved.\n * \n * @example\n * // In test cleanup\n * afterEach(() => {\n *   resetIntentRules();\n * });\n */\nexport function resetIntentRules(): void {\n  // Remove all custom rules, preserving only the original built-in rules\n  INTENT_RULES.splice(INITIAL_RULE_COUNT);\n  \n  // Invalidate cache since rules have changed\n  invalidateSortedRulesCache();\n}\n\n","import type { BoostingStrategy } from './types.js';\nimport path from 'path';\nimport { QueryIntent } from '../intent-classifier.js';\n\n/**\n * File type detection helpers\n */\n\nfunction isDocumentationFile(filepath: string): boolean {\n  const lower = filepath.toLowerCase();\n  const filename = path.basename(filepath).toLowerCase();\n  \n  if (filename.startsWith('readme')) return true;\n  if (filename.startsWith('changelog')) return true;\n  if (filename.endsWith('.md') || filename.endsWith('.mdx') || filename.endsWith('.markdown')) {\n    return true;\n  }\n  if (\n    lower.includes('/docs/') ||\n    lower.includes('/documentation/') ||\n    lower.includes('/wiki/') ||\n    lower.includes('/.github/')\n  ) {\n    return true;\n  }\n  if (\n    lower.includes('architecture') ||\n    lower.includes('workflow') ||\n    lower.includes('/flow/')\n  ) {\n    return true;\n  }\n  \n  return false;\n}\n\nfunction isTestFile(filepath: string): boolean {\n  const lower = filepath.toLowerCase();\n  \n  if (\n    lower.includes('/test/') ||\n    lower.includes('/tests/') ||\n    lower.includes('/__tests__/')\n  ) {\n    return true;\n  }\n  \n  if (\n    lower.includes('.test.') ||\n    lower.includes('.spec.') ||\n    lower.includes('_test.') ||\n    lower.includes('_spec.')\n  ) {\n    return true;\n  }\n  \n  return false;\n}\n\nfunction isUtilityFile(filepath: string): boolean {\n  const lower = filepath.toLowerCase();\n  \n  if (\n    lower.includes('/utils/') ||\n    lower.includes('/utilities/') ||\n    lower.includes('/helpers/') ||\n    lower.includes('/lib/')\n  ) {\n    return true;\n  }\n  \n  if (\n    lower.includes('.util.') ||\n    lower.includes('.helper.') ||\n    lower.includes('-util.') ||\n    lower.includes('-helper.')\n  ) {\n    return true;\n  }\n  \n  return false;\n}\n\n/**\n * Boosting Strategies\n */\n\n/**\n * Boosts relevance based on path segment matching.\n * Files with query tokens in their path are boosted.\n */\nexport class PathBoostingStrategy implements BoostingStrategy {\n  name = 'path-matching';\n  \n  apply(query: string, filepath: string, baseScore: number): number {\n    const queryTokens = query.toLowerCase().split(/\\s+/);\n    const pathSegments = filepath.toLowerCase().split('/');\n    \n    let boostFactor = 1.0;\n    \n    for (const token of queryTokens) {\n      if (token.length <= 2) continue;\n      if (pathSegments.some(seg => seg.includes(token))) {\n        boostFactor *= 0.9; // Reduce distance = increase relevance\n      }\n    }\n    \n    return baseScore * boostFactor;\n  }\n}\n\n/**\n * Boosts relevance based on filename matching.\n * Files with query tokens in their filename are strongly boosted.\n */\nexport class FilenameBoostingStrategy implements BoostingStrategy {\n  name = 'filename-matching';\n  \n  apply(query: string, filepath: string, baseScore: number): number {\n    const filename = path.basename(filepath, path.extname(filepath)).toLowerCase();\n    const queryTokens = query.toLowerCase().split(/\\s+/);\n    \n    let boostFactor = 1.0;\n    \n    for (const token of queryTokens) {\n      if (token.length <= 2) continue;\n      \n      if (filename === token) {\n        boostFactor *= 0.70; // Strong boost for exact match\n      } else if (filename.includes(token)) {\n        boostFactor *= 0.80; // Moderate boost for partial match\n      }\n    }\n    \n    return baseScore * boostFactor;\n  }\n}\n\n/**\n * Boosts relevance based on file type and query intent.\n * Different file types are boosted for different query intents.\n * \n * Note: This strategy focuses on file-type-specific boosting (test files,\n * documentation files, utility files, etc.). Path and filename boosting\n * are handled separately by PathBoostingStrategy and FilenameBoostingStrategy\n * in the BoostingComposer to avoid double-boosting.\n */\nexport class FileTypeBoostingStrategy implements BoostingStrategy {\n  name = 'file-type';\n  \n  constructor(private intent: QueryIntent) {}\n  \n  apply(query: string, filepath: string, baseScore: number): number {\n    switch (this.intent) {\n      case QueryIntent.LOCATION:\n        return this.applyLocationBoosting(query, filepath, baseScore);\n      \n      case QueryIntent.CONCEPTUAL:\n        return this.applyConceptualBoosting(query, filepath, baseScore);\n      \n      case QueryIntent.IMPLEMENTATION:\n        return this.applyImplementationBoosting(query, filepath, baseScore);\n      \n      default:\n        return baseScore;\n    }\n  }\n  \n  private applyLocationBoosting(_query: string, filepath: string, score: number): number {\n    // Note: Path and filename boosting are handled by PathBoostingStrategy and\n    // FilenameBoostingStrategy in the composer. This method only handles\n    // file-type-specific boosting for location queries.\n    \n    // Slightly deprioritize test files (users want implementation location, not tests)\n    if (isTestFile(filepath)) {\n      score *= 1.10;\n    }\n    \n    return score;\n  }\n  \n  private applyConceptualBoosting(_query: string, filepath: string, score: number): number {\n    // Note: Path and filename boosting are handled by PathBoostingStrategy and\n    // FilenameBoostingStrategy in the composer. This method only handles\n    // file-type-specific boosting for conceptual queries.\n    \n    // Strong boost for documentation files\n    if (isDocumentationFile(filepath)) {\n      score *= 0.65;\n      \n      const lower = filepath.toLowerCase();\n      if (\n        lower.includes('architecture') ||\n        lower.includes('workflow') ||\n        lower.includes('flow')\n      ) {\n        score *= 0.90; // Extra boost for architectural docs\n      }\n    }\n    \n    // Slight boost for utility files (often contain reusable logic)\n    if (isUtilityFile(filepath)) {\n      score *= 0.95;\n    }\n    \n    return score;\n  }\n  \n  private applyImplementationBoosting(_query: string, filepath: string, score: number): number {\n    // Note: Path and filename boosting are handled by PathBoostingStrategy and\n    // FilenameBoostingStrategy in the composer. This method only handles\n    // file-type-specific boosting for implementation queries.\n    \n    // Slightly deprioritize test files (user wants implementation, not tests)\n    if (isTestFile(filepath)) {\n      score *= 1.10;\n    }\n    \n    return score;\n  }\n}\n\n","import type { BoostingStrategy } from './types.js';\n\n/**\n * Composes multiple boosting strategies into a single pipeline.\n * \n * Strategies are applied sequentially, with each strategy\n * receiving the output of the previous strategy as input.\n * \n * @example\n * ```typescript\n * const composer = new BoostingComposer()\n *   .addStrategy(new PathBoostingStrategy())\n *   .addStrategy(new FilenameBoostingStrategy())\n *   .addStrategy(new FileTypeBoostingStrategy(intent));\n * \n * const boostedScore = composer.apply(query, filepath, baseScore);\n * ```\n */\nexport class BoostingComposer {\n  private strategies: BoostingStrategy[] = [];\n  \n  /**\n   * Add a boosting strategy to the pipeline.\n   * Strategies are applied in the order they are added.\n   * \n   * @param strategy - The strategy to add\n   * @returns This composer for chaining\n   */\n  addStrategy(strategy: BoostingStrategy): this {\n    this.strategies.push(strategy);\n    return this;\n  }\n  \n  /**\n   * Apply all strategies to a base score.\n   * \n   * @param query - The search query\n   * @param filepath - The file path being scored\n   * @param baseScore - The initial score from vector similarity\n   * @returns The final boosted score after all strategies\n   */\n  apply(query: string, filepath: string, baseScore: number): number {\n    let score = baseScore;\n    \n    for (const strategy of this.strategies) {\n      score = strategy.apply(query, filepath, score);\n    }\n    \n    return score;\n  }\n  \n  /**\n   * Get the names of all strategies in this composer.\n   * Useful for debugging and logging.\n   */\n  getStrategyNames(): string[] {\n    return this.strategies.map(s => s.name);\n  }\n  \n  /**\n   * Get the number of strategies in this composer.\n   */\n  getStrategyCount(): number {\n    return this.strategies.length;\n  }\n  \n  /**\n   * Clear all strategies from this composer.\n   */\n  clear(): void {\n    this.strategies = [];\n  }\n}\n\n","import { SearchResult } from './types.js';\nimport { EMBEDDING_DIMENSION } from '../embeddings/types.js';\nimport { DatabaseError, wrapError } from '../errors/index.js';\nimport { calculateRelevance } from './relevance.js';\nimport { classifyQueryIntent, QueryIntent } from './intent-classifier.js';\nimport { BoostingComposer, PathBoostingStrategy, FilenameBoostingStrategy, FileTypeBoostingStrategy } from './boosting/index.js';\n\n// TODO: Replace with proper type from lancedb-types.ts\n// Currently using 'any' because tests use incomplete mocks that don't satisfy full LanceDB interface\n// See: https://github.com/getlien/lien/issues/XXX\ntype LanceDBTable = any;\n\n/**\n * Cached strategy instances to avoid repeated instantiation overhead.\n * These strategies are stateless and can be safely reused across queries.\n */\nconst PATH_STRATEGY = new PathBoostingStrategy();\nconst FILENAME_STRATEGY = new FilenameBoostingStrategy();\n\n/**\n * Cached FileTypeBoostingStrategy instances for each intent.\n * Since there are only three possible intents, we can cache all three.\n */\nconst FILE_TYPE_STRATEGIES = {\n  [QueryIntent.LOCATION]: new FileTypeBoostingStrategy(QueryIntent.LOCATION),\n  [QueryIntent.CONCEPTUAL]: new FileTypeBoostingStrategy(QueryIntent.CONCEPTUAL),\n  [QueryIntent.IMPLEMENTATION]: new FileTypeBoostingStrategy(QueryIntent.IMPLEMENTATION),\n};\n\n/**\n * Cached BoostingComposer instances for each intent.\n * Pre-configured with the appropriate strategy pipeline for each intent type.\n * This avoids creating a new composer instance on every search result.\n */\nconst BOOSTING_COMPOSERS = {\n  [QueryIntent.LOCATION]: new BoostingComposer()\n    .addStrategy(PATH_STRATEGY)\n    .addStrategy(FILENAME_STRATEGY)\n    .addStrategy(FILE_TYPE_STRATEGIES[QueryIntent.LOCATION]),\n  [QueryIntent.CONCEPTUAL]: new BoostingComposer()\n    .addStrategy(PATH_STRATEGY)\n    .addStrategy(FILENAME_STRATEGY)\n    .addStrategy(FILE_TYPE_STRATEGIES[QueryIntent.CONCEPTUAL]),\n  [QueryIntent.IMPLEMENTATION]: new BoostingComposer()\n    .addStrategy(PATH_STRATEGY)\n    .addStrategy(FILENAME_STRATEGY)\n    .addStrategy(FILE_TYPE_STRATEGIES[QueryIntent.IMPLEMENTATION]),\n};\n\n/**\n * Database record structure as stored in LanceDB\n */\ninterface DBRecord {\n  vector: number[];\n  content: string;\n  file: string;\n  startLine: number;\n  endLine: number;\n  type: string;\n  language: string;\n  functionNames: string[];\n  classNames: string[];\n  interfaceNames: string[];\n  // AST-derived metadata (v0.13.0)\n  symbolName?: string;\n  symbolType?: string;\n  parentClass?: string;\n  complexity?: number;\n  cognitiveComplexity?: number;\n  parameters?: string[];\n  signature?: string;\n  imports?: string[];\n  // Halstead metrics (v0.19.0)\n  halsteadVolume?: number;\n  halsteadDifficulty?: number;\n  halsteadEffort?: number;\n  halsteadBugs?: number;\n  _distance?: number; // Added by LanceDB for search results\n}\n\n/**\n * Check if a DB record has valid content and file path.\n * Used to filter out empty/invalid records from query results.\n */\nfunction isValidRecord(r: DBRecord): boolean {\n  return Boolean(\n    r.content && \n    r.content.trim().length > 0 &&\n    r.file && \n    r.file.length > 0\n  );\n}\n\n/**\n * Check if an array field has valid (non-empty) entries.\n * LanceDB stores empty arrays as [''] which we need to filter out.\n */\nfunction hasValidArrayEntries(arr: string[] | undefined): boolean {\n  return Boolean(arr && arr.length > 0 && arr[0] !== '');\n}\n\n/**\n * Get symbols for a specific type from a DB record.\n * Consolidates the symbol extraction logic used across query functions.\n */\nfunction getSymbolsForType(\n  r: DBRecord, \n  symbolType?: 'function' | 'class' | 'interface'\n): string[] {\n  if (symbolType === 'function') return r.functionNames || [];\n  if (symbolType === 'class') return r.classNames || [];\n  if (symbolType === 'interface') return r.interfaceNames || [];\n  return [\n    ...(r.functionNames || []),\n    ...(r.classNames || []),\n    ...(r.interfaceNames || []),\n  ];\n}\n\n/**\n * Convert a DB record to base SearchResult metadata.\n * Shared between all query functions to avoid duplication.\n */\nfunction buildSearchResultMetadata(r: DBRecord): SearchResult['metadata'] {\n  return {\n    file: r.file,\n    startLine: r.startLine,\n    endLine: r.endLine,\n    type: r.type as 'function' | 'class' | 'block',\n    language: r.language,\n    symbolName: r.symbolName || undefined,\n    symbolType: r.symbolType as 'function' | 'method' | 'class' | 'interface' | undefined,\n    parentClass: r.parentClass || undefined,\n    complexity: r.complexity || undefined,\n    cognitiveComplexity: r.cognitiveComplexity || undefined,\n    parameters: hasValidArrayEntries(r.parameters) ? r.parameters : undefined,\n    signature: r.signature || undefined,\n    imports: hasValidArrayEntries(r.imports) ? r.imports : undefined,\n    // Halstead metrics (v0.19.0) - use explicit null check to preserve valid 0 values\n    halsteadVolume: r.halsteadVolume != null ? r.halsteadVolume : undefined,\n    halsteadDifficulty: r.halsteadDifficulty != null ? r.halsteadDifficulty : undefined,\n    halsteadEffort: r.halsteadEffort != null ? r.halsteadEffort : undefined,\n    halsteadBugs: r.halsteadBugs != null ? r.halsteadBugs : undefined,\n  };\n}\n\n/**\n * Apply relevance boosting strategies to a search score.\n * \n * Uses composable boosting strategies based on query intent:\n * - Path matching: Boost files with query tokens in path\n * - Filename matching: Boost files with query tokens in filename\n * - File type boosting: Intent-specific boosting (docs for conceptual, etc.)\n */\nfunction applyRelevanceBoosting(\n  query: string | undefined,\n  filepath: string,\n  baseScore: number\n): number {\n  if (!query) {\n    return baseScore;\n  }\n  \n  const intent = classifyQueryIntent(query);\n  \n  // Use cached composer instance configured for this intent\n  return BOOSTING_COMPOSERS[intent].apply(query, filepath, baseScore);\n}\n\n/**\n * Convert a DBRecord to a SearchResult\n */\nfunction dbRecordToSearchResult(\n  r: DBRecord,\n  query?: string\n): SearchResult {\n  const baseScore = r._distance ?? 0;\n  const boostedScore = applyRelevanceBoosting(query, r.file, baseScore);\n  \n  return {\n    content: r.content,\n    metadata: buildSearchResultMetadata(r),\n    score: boostedScore,\n    relevance: calculateRelevance(boostedScore),\n  };\n}\n\n/**\n * Search the vector database\n */\nexport async function search(\n  table: LanceDBTable,\n  queryVector: Float32Array,\n  limit: number = 5,\n  query?: string\n): Promise<SearchResult[]> {\n  if (!table) {\n    throw new DatabaseError('Vector database not initialized');\n  }\n  \n  try {\n    const results = await table\n      .search(Array.from(queryVector))\n      .limit(limit + 20)\n      .toArray();\n    \n    const filtered = (results as unknown as DBRecord[])\n      .filter(isValidRecord)\n      .map((r: DBRecord) => dbRecordToSearchResult(r, query))\n      .sort((a, b) => a.score - b.score)\n      .slice(0, limit);\n    \n    return filtered;\n  } catch (error) {\n    const errorMsg = String(error);\n    \n    // Detect corrupted index\n    if (errorMsg.includes('Not found:') || errorMsg.includes('.lance')) {\n      throw new DatabaseError(\n        `Index appears corrupted or outdated. Please restart the MCP server or run 'lien reindex' in the project directory.`,\n        { originalError: error }\n      );\n    }\n    \n    throw wrapError(error, 'Failed to search vector database');\n  }\n}\n\n/**\n * Scan the database with filters\n */\nexport async function scanWithFilter(\n  table: LanceDBTable,\n  options: {\n    language?: string;\n    pattern?: string;\n    limit?: number;\n  }\n): Promise<SearchResult[]> {\n  if (!table) {\n    throw new DatabaseError('Vector database not initialized');\n  }\n  \n  const { language, pattern, limit = 100 } = options;\n  \n  try {\n    const zeroVector = Array(EMBEDDING_DIMENSION).fill(0);\n    const query = table.search(zeroVector)\n      .where('file != \"\"')\n      .limit(Math.max(limit * 5, 200));\n    \n    const results = await query.toArray();\n    \n    let filtered = (results as unknown as DBRecord[]).filter(isValidRecord);\n    \n    if (language) {\n      filtered = filtered.filter((r: DBRecord) => \n        r.language && r.language.toLowerCase() === language.toLowerCase()\n      );\n    }\n    \n    if (pattern) {\n      const regex = new RegExp(pattern, 'i');\n      filtered = filtered.filter((r: DBRecord) =>\n        regex.test(r.content) || regex.test(r.file)\n      );\n    }\n    \n    return filtered.slice(0, limit).map((r: DBRecord) => ({\n      content: r.content,\n      metadata: buildSearchResultMetadata(r),\n      score: 0,\n      relevance: calculateRelevance(0),\n    }));\n  } catch (error) {\n    throw wrapError(error, 'Failed to scan with filter');\n  }\n}\n\n/**\n * Helper to check if a record matches the requested symbol type\n */\n/** Maps query symbolType to acceptable AST symbolType values */\nconst SYMBOL_TYPE_MATCHES: Record<string, Set<string>> = {\n  function: new Set(['function', 'method']),\n  class: new Set(['class']),\n  interface: new Set(['interface']),\n};\n\nfunction matchesSymbolType(\n  record: DBRecord,\n  symbolType: 'function' | 'class' | 'interface',\n  symbols: string[]\n): boolean {\n  // If AST-based symbolType exists, use lookup table\n  if (record.symbolType) {\n    return SYMBOL_TYPE_MATCHES[symbolType]?.has(record.symbolType) ?? false;\n  }\n\n  // Fallback: check if pre-AST symbols array has valid entries\n  return symbols.length > 0 && symbols.some((s: string) => s.length > 0 && s !== '');\n}\n\ninterface SymbolQueryOptions {\n  language?: string;\n  pattern?: string;\n  symbolType?: 'function' | 'class' | 'interface';\n}\n\n/**\n * Check if a record matches the symbol query filters.\n * Extracted to reduce complexity of querySymbols.\n */\nfunction matchesSymbolFilter(\n  r: DBRecord, \n  { language, pattern, symbolType }: SymbolQueryOptions\n): boolean {\n  // Language filter\n  if (language && (!r.language || r.language.toLowerCase() !== language.toLowerCase())) {\n    return false;\n  }\n  \n  const symbols = getSymbolsForType(r, symbolType);\n  const astSymbolName = r.symbolName || '';\n  \n  // Must have at least one symbol (legacy or AST-based)\n  if (symbols.length === 0 && !astSymbolName) {\n    return false;\n  }\n  \n  // Pattern filter (if provided)\n  if (pattern) {\n    const regex = new RegExp(pattern, 'i');\n    const nameMatches = symbols.some((s: string) => regex.test(s)) || regex.test(astSymbolName);\n    if (!nameMatches) return false;\n  }\n  \n  // Symbol type filter (if provided)\n  if (symbolType) {\n    return matchesSymbolType(r, symbolType, symbols);\n  }\n  \n  return true;\n}\n\n/**\n * Build legacy symbols object for backwards compatibility.\n */\nfunction buildLegacySymbols(r: DBRecord) {\n  return {\n    functions: hasValidArrayEntries(r.functionNames) ? r.functionNames : [],\n    classes: hasValidArrayEntries(r.classNames) ? r.classNames : [],\n    interfaces: hasValidArrayEntries(r.interfaceNames) ? r.interfaceNames : [],\n  };\n}\n\n/**\n * Query symbols (functions, classes, interfaces)\n */\nexport async function querySymbols(\n  table: LanceDBTable,\n  options: {\n    language?: string;\n    pattern?: string;\n    symbolType?: 'function' | 'class' | 'interface';\n    limit?: number;\n  }\n): Promise<SearchResult[]> {\n  if (!table) {\n    throw new DatabaseError('Vector database not initialized');\n  }\n  \n  const { language, pattern, symbolType, limit = 50 } = options;\n  const filterOpts: SymbolQueryOptions = { language, pattern, symbolType };\n  \n  try {\n    const zeroVector = Array(EMBEDDING_DIMENSION).fill(0);\n    const query = table.search(zeroVector)\n      .where('file != \"\"')\n      .limit(Math.max(limit * 10, 500));\n    \n    const results = await query.toArray();\n    \n    const filtered = (results as unknown as DBRecord[])\n      .filter((r) => isValidRecord(r) && matchesSymbolFilter(r, filterOpts));\n    \n    return filtered.slice(0, limit).map((r: DBRecord) => ({\n      content: r.content,\n      metadata: {\n        ...buildSearchResultMetadata(r),\n        symbols: buildLegacySymbols(r),\n      },\n      score: 0,\n      relevance: calculateRelevance(0),\n    }));\n  } catch (error) {\n    throw wrapError(error, 'Failed to query symbols');\n  }\n}\n\n/**\n * Scan all chunks in the database\n * First gets the total count, then fetches all with a single query\n * This is more efficient than pagination for local/embedded databases like LanceDB\n */\nexport async function scanAll(\n  table: LanceDBTable,\n  options: {\n    language?: string;\n    pattern?: string;\n  } = {}\n): Promise<SearchResult[]> {\n  if (!table) {\n    throw new DatabaseError('Vector database not initialized');\n  }\n  \n  try {\n    // Get total row count to determine limit\n    const totalRows = await table.countRows();\n    \n    // Fetch all rows in one query (LanceDB is local, this is efficient)\n    // Note: scanWithFilter internally fetches 5x the limit to handle filtering overhead,\n    // then caps output to 'limit'. We pass totalRows so we get all rows back after\n    // filtering. The 5x overfetch is acceptable overhead for local DBs.\n    const MIN_SCAN_LIMIT = 1000;\n    const results = await scanWithFilter(table, {\n      ...options,\n      limit: Math.max(totalRows, MIN_SCAN_LIMIT),\n    });\n    \n    return results;\n  } catch (error) {\n    throw wrapError(error, 'Failed to scan all chunks');\n  }\n}\n","import { ChunkMetadata } from '../indexer/types.js';\nimport { DatabaseError } from '../errors/index.js';\nimport { VECTOR_DB_MAX_BATCH_SIZE, VECTOR_DB_MIN_BATCH_SIZE } from '../constants.js';\n\n// TODO: Replace with proper types from lancedb-types.ts\n// Currently using 'any' because tests use incomplete mocks that don't satisfy full LanceDB interface\n// Proper types: Awaited<ReturnType<typeof lancedb.connect>> and Awaited<ReturnType<Connection['openTable']>>\ntype LanceDBConnection = any;\ntype LanceDBTable = any;\n\n/**\n * Batch of data to be inserted into the vector database\n */\ninterface BatchToProcess {\n  vectors: Float32Array[];\n  metadatas: ChunkMetadata[];\n  contents: string[];\n}\n\n/**\n * Database record format for LanceDB storage\n */\ninterface DatabaseRecord {\n  vector: number[];\n  content: string;\n  file: string;\n  startLine: number;\n  endLine: number;\n  type: string;\n  language: string;\n  functionNames: string[];\n  classNames: string[];\n  interfaceNames: string[];\n  symbolName: string;\n  symbolType: string;\n  parentClass: string;\n  complexity: number;\n  cognitiveComplexity: number;\n  parameters: string[];\n  signature: string;\n  imports: string[];\n  // Halstead metrics (v0.19.0)\n  halsteadVolume: number;\n  halsteadDifficulty: number;\n  halsteadEffort: number;\n  halsteadBugs: number;\n}\n\n/**\n * Transform a chunk's data into a database record.\n * Handles missing/empty metadata by providing defaults for Arrow type inference.\n */\nfunction transformChunkToRecord(\n  vector: Float32Array,\n  content: string,\n  metadata: ChunkMetadata\n): DatabaseRecord {\n  return {\n    vector: Array.from(vector),\n    content,\n    file: metadata.file,\n    startLine: metadata.startLine,\n    endLine: metadata.endLine,\n    type: metadata.type,\n    language: metadata.language,\n    // Ensure arrays have at least empty string for Arrow type inference\n    functionNames: getNonEmptyArray(metadata.symbols?.functions),\n    classNames: getNonEmptyArray(metadata.symbols?.classes),\n    interfaceNames: getNonEmptyArray(metadata.symbols?.interfaces),\n    // AST-derived metadata (v0.13.0)\n    symbolName: metadata.symbolName || '',\n    symbolType: metadata.symbolType || '',\n    parentClass: metadata.parentClass || '',\n    complexity: metadata.complexity || 0,\n    cognitiveComplexity: metadata.cognitiveComplexity || 0,\n    parameters: getNonEmptyArray(metadata.parameters),\n    signature: metadata.signature || '',\n    imports: getNonEmptyArray(metadata.imports),\n    // Halstead metrics (v0.19.0)\n    halsteadVolume: metadata.halsteadVolume || 0,\n    halsteadDifficulty: metadata.halsteadDifficulty || 0,\n    halsteadEffort: metadata.halsteadEffort || 0,\n    halsteadBugs: metadata.halsteadBugs || 0,\n  };\n}\n\n/**\n * Returns the array if non-empty, otherwise returns [''] for Arrow type inference\n */\nfunction getNonEmptyArray(arr: string[] | undefined): string[] {\n  return arr && arr.length > 0 ? arr : [''];\n}\n\n/**\n * Split a batch in half for retry logic\n */\nfunction splitBatchInHalf(batch: BatchToProcess): [BatchToProcess, BatchToProcess] {\n  const half = Math.floor(batch.vectors.length / 2);\n  return [\n    {\n      vectors: batch.vectors.slice(0, half),\n      metadatas: batch.metadatas.slice(0, half),\n      contents: batch.contents.slice(0, half),\n    },\n    {\n      vectors: batch.vectors.slice(half),\n      metadatas: batch.metadatas.slice(half),\n      contents: batch.contents.slice(half),\n    },\n  ];\n}\n\n/**\n * Transform all chunks in a batch to database records\n */\nfunction transformBatchToRecords(batch: BatchToProcess): DatabaseRecord[] {\n  return batch.vectors.map((vector, i) =>\n    transformChunkToRecord(vector, batch.contents[i], batch.metadatas[i])\n  );\n}\n\n/**\n * Insert a batch of vectors into the database\n * \n * @returns The table instance after insertion, or null only when:\n *          - vectors.length === 0 AND table === null (no-op case)\n *          For non-empty batches, always returns a valid table or throws.\n * @throws {DatabaseError} If database not initialized or insertion fails\n */\nexport async function insertBatch(\n  db: LanceDBConnection,\n  table: LanceDBTable | null,\n  tableName: string,\n  vectors: Float32Array[],\n  metadatas: ChunkMetadata[],\n  contents: string[]\n): Promise<LanceDBTable | null> {\n  if (!db) {\n    throw new DatabaseError('Vector database not initialized');\n  }\n  \n  if (vectors.length !== metadatas.length || vectors.length !== contents.length) {\n    throw new DatabaseError('Vectors, metadatas, and contents arrays must have the same length', {\n      vectorsLength: vectors.length,\n      metadatasLength: metadatas.length,\n      contentsLength: contents.length,\n    });\n  }\n  \n  // Handle empty batch gracefully - return table as-is (could be null)\n  if (vectors.length === 0) {\n    return table;\n  }\n  \n  // Split large batches into smaller chunks\n  if (vectors.length > VECTOR_DB_MAX_BATCH_SIZE) {\n    let currentTable = table;\n    for (let i = 0; i < vectors.length; i += VECTOR_DB_MAX_BATCH_SIZE) {\n      const batchVectors = vectors.slice(i, Math.min(i + VECTOR_DB_MAX_BATCH_SIZE, vectors.length));\n      const batchMetadata = metadatas.slice(i, Math.min(i + VECTOR_DB_MAX_BATCH_SIZE, vectors.length));\n      const batchContents = contents.slice(i, Math.min(i + VECTOR_DB_MAX_BATCH_SIZE, vectors.length));\n      \n      currentTable = await insertBatchInternal(db, currentTable, tableName, batchVectors, batchMetadata, batchContents);\n    }\n    if (!currentTable) {\n      throw new DatabaseError('Failed to create table during batch insert');\n    }\n    return currentTable;\n  } else {\n    return insertBatchInternal(db, table, tableName, vectors, metadatas, contents);\n  }\n}\n\n/**\n * Internal method to insert a single batch with iterative retry logic.\n * Uses a queue-based approach to handle batch splitting on failure.\n * \n * @returns Always returns a valid LanceDBTable or throws DatabaseError\n */\nasync function insertBatchInternal(\n  db: LanceDBConnection,\n  table: LanceDBTable | null,\n  tableName: string,\n  vectors: Float32Array[],\n  metadatas: ChunkMetadata[],\n  contents: string[]\n): Promise<LanceDBTable> {\n  const queue: BatchToProcess[] = [{ vectors, metadatas, contents }];\n  const failedBatches: BatchToProcess[] = [];\n  let currentTable = table;\n  let lastError: Error | undefined;\n  \n  while (queue.length > 0) {\n    const batch = queue.shift()!;\n    const insertResult = await tryInsertBatch(db, currentTable, tableName, batch);\n    \n    if (insertResult.success) {\n      currentTable = insertResult.table;\n    } else {\n      lastError = insertResult.error;\n      handleBatchFailure(batch, queue, failedBatches);\n    }\n  }\n  \n  throwIfBatchesFailed(failedBatches, lastError);\n  \n  if (!currentTable) {\n    throw new DatabaseError('Failed to create table during batch insert');\n  }\n  \n  return currentTable;\n}\n\n/**\n * Result of attempting to insert a batch\n */\ninterface InsertResult {\n  success: boolean;\n  table: LanceDBTable | null;\n  error?: Error;\n}\n\n/**\n * Attempt to insert a batch of records into the database.\n * Errors are captured and returned (not thrown) to support retry logic.\n */\nasync function tryInsertBatch(\n  db: LanceDBConnection,\n  currentTable: LanceDBTable | null,\n  tableName: string,\n  batch: BatchToProcess\n): Promise<InsertResult> {\n  try {\n    const records = transformBatchToRecords(batch);\n    \n    if (!currentTable) {\n      const newTable = await db.createTable(tableName, records);\n      return { success: true, table: newTable };\n    } else {\n      await currentTable.add(records);\n      return { success: true, table: currentTable };\n    }\n  } catch (error) {\n    // Error is captured for retry logic - will be included in final error if all retries fail\n    return { success: false, table: currentTable, error: error as Error };\n  }\n}\n\n/**\n * Handle a failed batch insertion by either splitting and retrying or marking as failed\n */\nfunction handleBatchFailure(\n  batch: BatchToProcess,\n  queue: BatchToProcess[],\n  failedBatches: BatchToProcess[]\n): void {\n  if (batch.vectors.length > VECTOR_DB_MIN_BATCH_SIZE) {\n    // Split and retry\n    const [firstHalf, secondHalf] = splitBatchInHalf(batch);\n    queue.push(firstHalf, secondHalf);\n  } else {\n    // Can't split further, mark as failed\n    failedBatches.push(batch);\n  }\n}\n\n/**\n * Throw an error if any batches failed after all retry attempts.\n * Includes the last error encountered for debugging.\n */\nfunction throwIfBatchesFailed(failedBatches: BatchToProcess[], lastError?: Error): void {\n  if (failedBatches.length === 0) return;\n  \n  const totalFailed = failedBatches.reduce((sum, batch) => sum + batch.vectors.length, 0);\n  throw new DatabaseError(\n    `Failed to insert ${totalFailed} record(s) after retry attempts`,\n    {\n      failedBatches: failedBatches.length,\n      totalRecords: totalFailed,\n      sampleFile: failedBatches[0].metadatas[0].file,\n      lastError: lastError?.message,\n    }\n  );\n}\n","import fs from 'fs/promises';\nimport path from 'path';\nimport { ChunkMetadata } from '../indexer/types.js';\nimport { DatabaseError, wrapError } from '../errors/index.js';\nimport { writeVersionFile } from './version.js';\nimport { insertBatch } from './batch-insert.js';\n\n// TODO: Replace with proper types from lancedb-types.ts\n// Currently using 'any' because tests use incomplete mocks that don't satisfy full LanceDB interface\n// Proper types: Awaited<ReturnType<typeof lancedb.connect>> and Awaited<ReturnType<Connection['openTable']>>\ntype LanceDBConnection = any;\ntype LanceDBTable = any;\n\n/**\n * Clear all data from the vector database.\n * Drops the table AND cleans up the .lance directory to prevent corrupted state.\n */\nexport async function clear(\n  db: LanceDBConnection,\n  table: LanceDBTable | null,\n  tableName: string,\n  dbPath?: string\n): Promise<void> {\n  if (!db) {\n    throw new DatabaseError('Vector database not initialized');\n  }\n  \n  try {\n    // Clean up the .lance directory directly\n    // This is more reliable than dropTable which can have locking issues\n    if (dbPath) {\n      const lanceDir = path.join(dbPath, `${tableName}.lance`);\n      try {\n        await fs.rm(lanceDir, { recursive: true, force: true });\n      } catch (err: any) {\n        // If deletion fails, try dropping the table first\n        if (err?.code === 'ENOTEMPTY' || err?.message?.includes('not empty')) {\n          try {\n            await db.dropTable(tableName);\n            // Try deletion again after dropping\n            await fs.rm(lanceDir, { recursive: true, force: true });\n          } catch {\n            // Ignore - best effort cleanup\n          }\n        }\n      }\n    } else {\n      // No dbPath provided, just drop the table\n      if (table) {\n        await db.dropTable(tableName);\n      }\n    }\n  } catch (error) {\n    throw wrapError(error, 'Failed to clear vector database');\n  }\n}\n\n/**\n * Delete all chunks from a specific file\n */\nexport async function deleteByFile(\n  table: LanceDBTable,\n  filepath: string\n): Promise<void> {\n  if (!table) {\n    throw new DatabaseError('Vector database not initialized');\n  }\n  \n  try {\n    await table.delete(`file = \"${filepath}\"`);\n  } catch (error) {\n    throw wrapError(error, 'Failed to delete file from vector database');\n  }\n}\n\n/**\n * Update a file in the index by atomically deleting old chunks and inserting new ones\n */\nexport async function updateFile(\n  db: LanceDBConnection,\n  table: LanceDBTable | null,\n  tableName: string,\n  dbPath: string,\n  filepath: string,\n  vectors: Float32Array[],\n  metadatas: ChunkMetadata[],\n  contents: string[]\n): Promise<LanceDBTable> {\n  if (!table) {\n    throw new DatabaseError('Vector database not initialized');\n  }\n  \n  try {\n    // 1. Delete old chunks from this file\n    await deleteByFile(table, filepath);\n    \n    // 2. Insert new chunks (if any)\n    let updatedTable = table;\n    if (vectors.length > 0) {\n      updatedTable = await insertBatch(db, table, tableName, vectors, metadatas, contents);\n      if (!updatedTable) {\n        throw new DatabaseError('insertBatch unexpectedly returned null');\n      }\n    }\n    \n    // 3. Update version file to trigger MCP reconnection\n    await writeVersionFile(dbPath);\n    \n    return updatedTable;\n  } catch (error) {\n    throw wrapError(error, 'Failed to update file in vector database');\n  }\n}\n\n","import fs from 'fs/promises';\nimport path from 'path';\nimport { LienConfig, LegacyLienConfig, defaultConfig, isLegacyConfig, isModernConfig } from './schema.js';\nimport { deepMergeConfig } from './merge.js';\nimport { needsMigration as checkNeedsMigration, migrateConfig as performMigration } from './migration.js';\nimport { ConfigError, wrapError } from '../errors/index.js';\n\n/**\n * Validation result with errors and warnings\n */\nexport interface ValidationResult {\n  valid: boolean;\n  errors: string[];\n  warnings: string[];\n}\n\n/**\n * Migration result with status and config\n */\nexport interface MigrationResult {\n  migrated: boolean;\n  backupPath?: string;\n  config: LienConfig;\n}\n\n/**\n * ConfigService encapsulates all configuration operations including\n * loading, saving, migration, and validation.\n * \n * This service provides a single point of truth for config management\n * with comprehensive error handling and validation.\n */\nexport class ConfigService {\n  private static readonly CONFIG_FILENAME = '.lien.config.json';\n  \n  /**\n   * Load configuration from the specified directory.\n   * Automatically handles migration if needed.\n   * \n   * @param rootDir - Root directory containing the config file\n   * @returns Loaded and validated configuration\n   * @throws {ConfigError} If config is invalid or cannot be loaded\n   */\n  async load(rootDir: string = process.cwd()): Promise<LienConfig> {\n    const configPath = this.getConfigPath(rootDir);\n    \n    try {\n      const configContent = await fs.readFile(configPath, 'utf-8');\n      const userConfig = JSON.parse(configContent);\n      \n      // Check if migration is needed\n      if (this.needsMigration(userConfig)) {\n        console.log('üîÑ Migrating config from v0.2.0 to v0.3.0...');\n        \n        const result = await this.migrate(rootDir);\n        \n        if (result.migrated && result.backupPath) {\n          const backupFilename = path.basename(result.backupPath);\n          console.log(`‚úÖ Migration complete! Backup saved as ${backupFilename}`);\n          console.log('üìù Your config now uses the framework-based structure.');\n        }\n        \n        return result.config;\n      }\n      \n      // Merge with defaults first\n      const mergedConfig = deepMergeConfig(defaultConfig, userConfig as Partial<LienConfig>);\n      \n      // Then validate the merged config\n      const validation = this.validate(mergedConfig);\n      if (!validation.valid) {\n        throw new ConfigError(\n          `Invalid configuration:\\n${validation.errors.join('\\n')}`,\n          { errors: validation.errors, warnings: validation.warnings }\n        );\n      }\n      \n      // Show warnings if any\n      if (validation.warnings.length > 0) {\n        console.warn('‚ö†Ô∏è  Configuration warnings:');\n        validation.warnings.forEach(warning => console.warn(`   ${warning}`));\n      }\n      \n      return mergedConfig;\n    } catch (error) {\n      if ((error as NodeJS.ErrnoException).code === 'ENOENT') {\n        // Config doesn't exist, return defaults\n        return defaultConfig;\n      }\n      \n      if (error instanceof ConfigError) {\n        throw error;\n      }\n      \n      if (error instanceof SyntaxError) {\n        throw new ConfigError(\n          'Failed to parse config file: Invalid JSON syntax',\n          { path: configPath, originalError: error.message }\n        );\n      }\n      \n      throw wrapError(error, 'Failed to load configuration', { path: configPath });\n    }\n  }\n  \n  /**\n   * Save configuration to the specified directory.\n   * Validates the config before saving.\n   * \n   * @param rootDir - Root directory to save the config file\n   * @param config - Configuration to save\n   * @throws {ConfigError} If config is invalid or cannot be saved\n   */\n  async save(rootDir: string, config: LienConfig): Promise<void> {\n    const configPath = this.getConfigPath(rootDir);\n    \n    // Validate before saving\n    const validation = this.validate(config);\n    if (!validation.valid) {\n      throw new ConfigError(\n        `Cannot save invalid configuration:\\n${validation.errors.join('\\n')}`,\n        { errors: validation.errors }\n      );\n    }\n    \n    try {\n      const configJson = JSON.stringify(config, null, 2) + '\\n';\n      await fs.writeFile(configPath, configJson, 'utf-8');\n    } catch (error) {\n      throw wrapError(error, 'Failed to save configuration', { path: configPath });\n    }\n  }\n  \n  /**\n   * Check if a configuration file exists in the specified directory.\n   * \n   * @param rootDir - Root directory to check\n   * @returns True if config file exists\n   */\n  async exists(rootDir: string = process.cwd()): Promise<boolean> {\n    const configPath = this.getConfigPath(rootDir);\n    try {\n      await fs.access(configPath);\n      return true;\n    } catch {\n      return false;\n    }\n  }\n  \n  /**\n   * Migrate configuration from v0.2.0 to v0.3.0 format.\n   * Creates a backup of the original config file.\n   * \n   * @param rootDir - Root directory containing the config file\n   * @returns Migration result with status and new config\n   * @throws {ConfigError} If migration fails\n   */\n  async migrate(rootDir: string = process.cwd()): Promise<MigrationResult> {\n    const configPath = this.getConfigPath(rootDir);\n    \n    try {\n      // Read existing config\n      const configContent = await fs.readFile(configPath, 'utf-8');\n      const oldConfig = JSON.parse(configContent);\n      \n      // Check if migration is needed\n      if (!this.needsMigration(oldConfig)) {\n        return {\n          migrated: false,\n          config: oldConfig as LienConfig,\n        };\n      }\n      \n      // Perform migration\n      const newConfig = performMigration(oldConfig);\n      \n      // Validate migrated config\n      const validation = this.validate(newConfig);\n      if (!validation.valid) {\n        throw new ConfigError(\n          `Migration produced invalid configuration:\\n${validation.errors.join('\\n')}`,\n          { errors: validation.errors }\n        );\n      }\n      \n      // Create backup\n      const backupPath = `${configPath}.v0.2.0.backup`;\n      await fs.copyFile(configPath, backupPath);\n      \n      // Write migrated config\n      await this.save(rootDir, newConfig);\n      \n      return {\n        migrated: true,\n        backupPath,\n        config: newConfig,\n      };\n    } catch (error) {\n      if ((error as NodeJS.ErrnoException).code === 'ENOENT') {\n        return {\n          migrated: false,\n          config: defaultConfig,\n        };\n      }\n      \n      if (error instanceof ConfigError) {\n        throw error;\n      }\n      \n      throw wrapError(error, 'Configuration migration failed', { path: configPath });\n    }\n  }\n  \n  /**\n   * Check if a config object needs migration from v0.2.0 to v0.3.0.\n   * \n   * @param config - Config object to check\n   * @returns True if migration is needed\n   */\n  needsMigration(config: unknown): boolean {\n    return checkNeedsMigration(config);\n  }\n  \n  /**\n   * Validate a configuration object.\n   * Checks all constraints and returns detailed validation results.\n   * \n   * @param config - Configuration to validate\n   * @returns Validation result with errors and warnings\n   */\n  validate(config: unknown): ValidationResult {\n    const errors: string[] = [];\n    const warnings: string[] = [];\n    \n    // Type check\n    if (!config || typeof config !== 'object') {\n      return {\n        valid: false,\n        errors: ['Configuration must be an object'],\n        warnings: [],\n      };\n    }\n    \n    const cfg = config as Partial<LienConfig>;\n    \n    // Check for required top-level fields\n    if (!cfg.version) {\n      errors.push('Missing required field: version');\n    }\n    \n    // Validate based on config type\n    if (isModernConfig(cfg as LienConfig | LegacyLienConfig)) {\n      this.validateModernConfig(cfg as LienConfig, errors, warnings);\n    } else if (isLegacyConfig(cfg as LienConfig | LegacyLienConfig)) {\n      this.validateLegacyConfig(cfg as LegacyLienConfig, errors, warnings);\n    } else {\n      errors.push('Configuration format not recognized. Must have either \"frameworks\" or \"indexing\" field');\n    }\n    \n    return {\n      valid: errors.length === 0,\n      errors,\n      warnings,\n    };\n  }\n  \n  /**\n   * Validate a partial configuration object.\n   * Useful for validating user input before merging with defaults.\n   * \n   * @param config - Partial configuration to validate\n   * @returns Validation result with errors and warnings\n   */\n  validatePartial(config: Partial<LienConfig>): ValidationResult {\n    const errors: string[] = [];\n    const warnings: string[] = [];\n    \n    // Validate core settings if present\n    if (config.core) {\n      this.validateCoreConfig(config.core, errors, warnings);\n    }\n    \n    // Validate MCP settings if present\n    if (config.mcp) {\n      this.validateMCPConfig(config.mcp, errors, warnings);\n    }\n    \n    // Validate git detection settings if present\n    if (config.gitDetection) {\n      this.validateGitDetectionConfig(config.gitDetection, errors, warnings);\n    }\n    \n    // Validate file watching settings if present\n    if (config.fileWatching) {\n      this.validateFileWatchingConfig(config.fileWatching, errors, warnings);\n    }\n    \n    // Validate frameworks if present\n    if (config.frameworks) {\n      this.validateFrameworks(config.frameworks, errors, warnings);\n    }\n    \n    return {\n      valid: errors.length === 0,\n      errors,\n      warnings,\n    };\n  }\n  \n  /**\n   * Get the full path to the config file\n   */\n  private getConfigPath(rootDir: string): string {\n    return path.join(rootDir, ConfigService.CONFIG_FILENAME);\n  }\n  \n  /**\n   * Validate modern (v0.3.0+) configuration\n   */\n  private validateModernConfig(\n    config: LienConfig,\n    errors: string[],\n    warnings: string[]\n  ): void {\n    // Validate core settings\n    if (!config.core) {\n      errors.push('Missing required field: core');\n      return;\n    }\n    this.validateCoreConfig(config.core, errors, warnings);\n    \n    // Validate MCP settings\n    if (!config.mcp) {\n      errors.push('Missing required field: mcp');\n      return;\n    }\n    this.validateMCPConfig(config.mcp, errors, warnings);\n    \n    // Validate git detection settings\n    if (!config.gitDetection) {\n      errors.push('Missing required field: gitDetection');\n      return;\n    }\n    this.validateGitDetectionConfig(config.gitDetection, errors, warnings);\n    \n    // Validate file watching settings\n    if (!config.fileWatching) {\n      errors.push('Missing required field: fileWatching');\n      return;\n    }\n    this.validateFileWatchingConfig(config.fileWatching, errors, warnings);\n    \n    // Validate frameworks\n    if (!config.frameworks) {\n      errors.push('Missing required field: frameworks');\n      return;\n    }\n    this.validateFrameworks(config.frameworks, errors, warnings);\n  }\n  \n  /**\n   * Validate legacy (v0.2.0) configuration\n   */\n  private validateLegacyConfig(\n    config: LegacyLienConfig,\n    errors: string[],\n    warnings: string[]\n  ): void {\n    warnings.push('Using legacy configuration format. Consider running \"lien init\" to migrate to v0.3.0');\n    \n    // Validate indexing settings\n    if (!config.indexing) {\n      errors.push('Missing required field: indexing');\n      return;\n    }\n    \n    const { indexing } = config;\n    \n    if (typeof indexing.chunkSize !== 'number' || indexing.chunkSize <= 0) {\n      errors.push('indexing.chunkSize must be a positive number');\n    }\n    \n    if (typeof indexing.chunkOverlap !== 'number' || indexing.chunkOverlap < 0) {\n      errors.push('indexing.chunkOverlap must be a non-negative number');\n    }\n    \n    if (typeof indexing.concurrency !== 'number' || indexing.concurrency < 1 || indexing.concurrency > 16) {\n      errors.push('indexing.concurrency must be between 1 and 16');\n    }\n    \n    if (typeof indexing.embeddingBatchSize !== 'number' || indexing.embeddingBatchSize <= 0) {\n      errors.push('indexing.embeddingBatchSize must be a positive number');\n    }\n    \n    // Validate MCP settings (same for both)\n    if (config.mcp) {\n      this.validateMCPConfig(config.mcp, errors, warnings);\n    }\n  }\n  \n  /**\n   * Validate core configuration settings\n   */\n  private validateCoreConfig(\n    core: Partial<LienConfig['core']>,\n    errors: string[],\n    warnings: string[]\n  ): void {\n    if (core.chunkSize !== undefined) {\n      if (typeof core.chunkSize !== 'number' || core.chunkSize <= 0) {\n        errors.push('core.chunkSize must be a positive number');\n      } else if (core.chunkSize < 50) {\n        warnings.push('core.chunkSize is very small (<50 lines). This may result in poor search quality');\n      } else if (core.chunkSize > 500) {\n        warnings.push('core.chunkSize is very large (>500 lines). This may impact performance');\n      }\n    }\n    \n    if (core.chunkOverlap !== undefined) {\n      if (typeof core.chunkOverlap !== 'number' || core.chunkOverlap < 0) {\n        errors.push('core.chunkOverlap must be a non-negative number');\n      }\n    }\n    \n    if (core.concurrency !== undefined) {\n      if (typeof core.concurrency !== 'number' || core.concurrency < 1 || core.concurrency > 16) {\n        errors.push('core.concurrency must be between 1 and 16');\n      }\n    }\n    \n    if (core.embeddingBatchSize !== undefined) {\n      if (typeof core.embeddingBatchSize !== 'number' || core.embeddingBatchSize <= 0) {\n        errors.push('core.embeddingBatchSize must be a positive number');\n      } else if (core.embeddingBatchSize > 100) {\n        warnings.push('core.embeddingBatchSize is very large (>100). This may cause memory issues');\n      }\n    }\n  }\n  \n  /**\n   * Validate MCP configuration settings\n   */\n  private validateMCPConfig(\n    mcp: Partial<LienConfig['mcp']>,\n    errors: string[],\n    _warnings: string[]\n  ): void {\n    if (mcp.port !== undefined) {\n      if (typeof mcp.port !== 'number' || mcp.port < 1024 || mcp.port > 65535) {\n        errors.push('mcp.port must be between 1024 and 65535');\n      }\n    }\n    \n    if (mcp.transport !== undefined) {\n      if (mcp.transport !== 'stdio' && mcp.transport !== 'socket') {\n        errors.push('mcp.transport must be either \"stdio\" or \"socket\"');\n      }\n    }\n    \n    if (mcp.autoIndexOnFirstRun !== undefined) {\n      if (typeof mcp.autoIndexOnFirstRun !== 'boolean') {\n        errors.push('mcp.autoIndexOnFirstRun must be a boolean');\n      }\n    }\n  }\n  \n  /**\n   * Validate git detection configuration settings\n   */\n  private validateGitDetectionConfig(\n    gitDetection: Partial<LienConfig['gitDetection']>,\n    errors: string[],\n    _warnings: string[]\n  ): void {\n    if (gitDetection.enabled !== undefined) {\n      if (typeof gitDetection.enabled !== 'boolean') {\n        errors.push('gitDetection.enabled must be a boolean');\n      }\n    }\n    \n    if (gitDetection.pollIntervalMs !== undefined) {\n      if (typeof gitDetection.pollIntervalMs !== 'number' || gitDetection.pollIntervalMs < 100) {\n        errors.push('gitDetection.pollIntervalMs must be at least 100ms');\n      } else if (gitDetection.pollIntervalMs < 1000) {\n        _warnings.push('gitDetection.pollIntervalMs is very short (<1s). This may impact performance');\n      }\n    }\n  }\n  \n  /**\n   * Validate file watching configuration settings\n   */\n  private validateFileWatchingConfig(\n    fileWatching: Partial<LienConfig['fileWatching']>,\n    errors: string[],\n    warnings: string[]\n  ): void {\n    if (fileWatching.enabled !== undefined) {\n      if (typeof fileWatching.enabled !== 'boolean') {\n        errors.push('fileWatching.enabled must be a boolean');\n      }\n    }\n    \n    if (fileWatching.debounceMs !== undefined) {\n      if (typeof fileWatching.debounceMs !== 'number' || fileWatching.debounceMs < 0) {\n        errors.push('fileWatching.debounceMs must be a non-negative number');\n      } else if (fileWatching.debounceMs < 100) {\n        warnings.push('fileWatching.debounceMs is very short (<100ms). This may cause excessive reindexing');\n      }\n    }\n  }\n  \n  /**\n   * Validate frameworks configuration\n   */\n  private validateFrameworks(\n    frameworks: unknown[],\n    errors: string[],\n    warnings: string[]\n  ): void {\n    if (!Array.isArray(frameworks)) {\n      errors.push('frameworks must be an array');\n      return;\n    }\n    \n    frameworks.forEach((framework, index) => {\n      if (!framework || typeof framework !== 'object') {\n        errors.push(`frameworks[${index}] must be an object`);\n        return;\n      }\n      \n      const fw = framework as Partial<any>;\n      \n      // Validate required fields\n      if (!fw.name) {\n        errors.push(`frameworks[${index}] missing required field: name`);\n      }\n      \n      if (fw.path === undefined) {\n        errors.push(`frameworks[${index}] missing required field: path`);\n      } else if (typeof fw.path !== 'string') {\n        errors.push(`frameworks[${index}].path must be a string`);\n      } else if (path.isAbsolute(fw.path)) {\n        errors.push(`frameworks[${index}].path must be relative, got: ${fw.path}`);\n      }\n      \n      if (fw.enabled === undefined) {\n        errors.push(`frameworks[${index}] missing required field: enabled`);\n      } else if (typeof fw.enabled !== 'boolean') {\n        errors.push(`frameworks[${index}].enabled must be a boolean`);\n      }\n      \n      if (!fw.config) {\n        errors.push(`frameworks[${index}] missing required field: config`);\n      } else {\n        this.validateFrameworkConfig(fw.config, `frameworks[${index}].config`, errors, warnings);\n      }\n    });\n  }\n  \n  /**\n   * Validate framework-specific configuration\n   */\n  private validateFrameworkConfig(\n    config: any,\n    prefix: string,\n    errors: string[],\n    _warnings: string[]\n  ): void {\n    if (!config || typeof config !== 'object') {\n      errors.push(`${prefix} must be an object`);\n      return;\n    }\n    \n    // Validate include patterns\n    if (!Array.isArray(config.include)) {\n      errors.push(`${prefix}.include must be an array`);\n    } else {\n      config.include.forEach((pattern: unknown, i: number) => {\n        if (typeof pattern !== 'string') {\n          errors.push(`${prefix}.include[${i}] must be a string`);\n        }\n      });\n    }\n    \n    // Validate exclude patterns\n    if (!Array.isArray(config.exclude)) {\n      errors.push(`${prefix}.exclude must be an array`);\n    } else {\n      config.exclude.forEach((pattern: unknown, i: number) => {\n        if (typeof pattern !== 'string') {\n          errors.push(`${prefix}.exclude[${i}] must be a string`);\n        }\n      });\n    }\n  }\n}\n\n// Export a singleton instance for convenience\nexport const configService = new ConfigService();\n\n","import {\n  DEFAULT_CHUNK_SIZE,\n  DEFAULT_CHUNK_OVERLAP,\n  DEFAULT_CONCURRENCY,\n  DEFAULT_EMBEDDING_BATCH_SIZE,\n  DEFAULT_PORT,\n  DEFAULT_GIT_POLL_INTERVAL_MS,\n  DEFAULT_DEBOUNCE_MS,\n  CURRENT_CONFIG_VERSION,\n} from '../constants.js';\n\n/**\n * Framework-specific configuration\n */\nexport interface FrameworkConfig {\n  include: string[];     // File patterns relative to framework path\n  exclude: string[];     // Exclude patterns relative to framework path\n}\n\n/**\n * Framework instance in a monorepo\n */\nexport interface FrameworkInstance {\n  name: string;          // 'nodejs', 'laravel'\n  path: string;          // '.', 'cognito-backend', 'packages/cli'\n  enabled: boolean;\n  config: FrameworkConfig;\n}\n\n/**\n * Main Lien configuration supporting monorepo setups\n */\nexport interface LienConfig {\n  version: string;\n  core: {\n    chunkSize: number;\n    chunkOverlap: number;\n    concurrency: number;\n    embeddingBatchSize: number;\n  };\n  chunking: {\n    useAST: boolean;          // Enable AST-based chunking (v0.13.0)\n    astFallback: 'line-based' | 'error';  // Fallback strategy on AST errors\n  };\n  mcp: {\n    port: number;\n    transport: 'stdio' | 'socket';\n    autoIndexOnFirstRun: boolean;\n  };\n  gitDetection: {\n    enabled: boolean;\n    pollIntervalMs: number;\n  };\n  fileWatching: {\n    enabled: boolean;\n    debounceMs: number;\n  };\n  complexity?: {\n    enabled: boolean;\n    thresholds: {\n      testPaths: number;             // üîÄ Max test paths per function (default: 15)\n      mentalLoad: number;            // üß† Max mental load score (default: 15)\n      timeToUnderstandMinutes?: number;  // ‚è±Ô∏è Max minutes to understand (default: 60)\n      estimatedBugs?: number;            // üêõ Max estimated bugs (default: 1.5)\n    };\n    // Severity multipliers are hardcoded: warning = 1x threshold, error = 2x threshold\n  };\n  frameworks: FrameworkInstance[];\n}\n\n/**\n * Legacy config format for backwards compatibility\n * @deprecated Use LienConfig with frameworks array instead\n */\nexport interface LegacyLienConfig {\n  version: string;\n  indexing: {\n    exclude: string[];\n    include: string[];\n    chunkSize: number;\n    chunkOverlap: number;\n    concurrency: number;\n    embeddingBatchSize: number;\n  };\n  mcp: {\n    port: number;\n    transport: 'stdio' | 'socket';\n    autoIndexOnFirstRun: boolean;\n  };\n  gitDetection: {\n    enabled: boolean;\n    pollIntervalMs: number;\n  };\n  fileWatching: {\n    enabled: boolean;\n    debounceMs: number;\n  };\n}\n\n/**\n * Type guard to check if a config is the legacy format\n * @param config - Config object to check\n * @returns True if config is LegacyLienConfig\n */\nexport function isLegacyConfig(\n  config: LienConfig | LegacyLienConfig\n): config is LegacyLienConfig {\n  return 'indexing' in config && !('frameworks' in config);\n}\n\n/**\n * Type guard to check if a config is the modern format\n * @param config - Config object to check\n * @returns True if config is LienConfig\n */\nexport function isModernConfig(\n  config: LienConfig | LegacyLienConfig\n): config is LienConfig {\n  return 'frameworks' in config;\n}\n\n/**\n * Default configuration with empty frameworks array\n * Frameworks should be detected and added via lien init\n */\nexport const defaultConfig: LienConfig = {\n  version: CURRENT_CONFIG_VERSION,\n  core: {\n    chunkSize: DEFAULT_CHUNK_SIZE,\n    chunkOverlap: DEFAULT_CHUNK_OVERLAP,\n    concurrency: DEFAULT_CONCURRENCY,\n    embeddingBatchSize: DEFAULT_EMBEDDING_BATCH_SIZE,\n  },\n  chunking: {\n    useAST: true,              // AST-based chunking enabled by default (v0.13.0)\n    astFallback: 'line-based', // Fallback to line-based on errors\n  },\n  mcp: {\n    port: DEFAULT_PORT,\n    transport: 'stdio',\n    autoIndexOnFirstRun: true,\n  },\n  gitDetection: {\n    enabled: true,\n    pollIntervalMs: DEFAULT_GIT_POLL_INTERVAL_MS,\n  },\n  fileWatching: {\n    enabled: true, // Enabled by default (fast with incremental indexing!)\n    debounceMs: DEFAULT_DEBOUNCE_MS,\n  },\n  complexity: {\n    enabled: true,\n    thresholds: {\n      testPaths: 15,            // üîÄ Max test paths per function\n      mentalLoad: 15,           // üß† Max mental load score\n      timeToUnderstandMinutes: 60,  // ‚è±Ô∏è Functions taking >1 hour to understand\n      estimatedBugs: 1.5,           // üêõ Functions estimated to have >1.5 bugs\n    },\n  },\n  frameworks: [], // Will be populated by lien init via framework detection\n};\n\n","import { LienConfig } from './schema.js';\n\n/**\n * Deep merges user config with defaults, preserving user customizations.\n * User values always take precedence over defaults.\n * \n * @param defaults - The default configuration\n * @param user - The user's partial configuration\n * @returns Complete merged configuration\n */\nexport function deepMergeConfig(defaults: LienConfig, user: Partial<LienConfig>): LienConfig {\n  return {\n    version: user.version ?? defaults.version,\n    core: {\n      ...defaults.core,\n      ...user.core,\n    },\n    chunking: {\n      ...defaults.chunking,\n      ...user.chunking,\n    },\n    mcp: {\n      ...defaults.mcp,\n      ...user.mcp,\n    },\n    gitDetection: {\n      ...defaults.gitDetection,\n      ...user.gitDetection,\n    },\n    fileWatching: {\n      ...defaults.fileWatching,\n      ...user.fileWatching,\n    },\n    complexity: user.complexity ? {\n      enabled: user.complexity.enabled ?? defaults.complexity?.enabled ?? true,\n      thresholds: {\n        ...defaults.complexity?.thresholds,\n        ...(user.complexity.thresholds || {}),\n      },\n    } : defaults.complexity,\n    frameworks: user.frameworks ?? defaults.frameworks,\n  };\n}\n\n/**\n * Detects new fields that exist in the 'after' config but not in the 'before' config.\n * Returns a list of human-readable field paths.\n * \n * @param before - The existing config (potentially missing fields)\n * @param after - The complete config with all fields\n * @returns Array of new field paths (e.g., [\"mcp.autoIndexOnFirstRun\", \"gitDetection\"])\n */\nexport function detectNewFields(before: Record<string, any>, after: Record<string, any>): string[] {\n  const newFields: string[] = [];\n\n  // Check top-level sections\n  for (const key of Object.keys(after)) {\n    if (!(key in before)) {\n      newFields.push(key);\n      continue;\n    }\n\n    // Check nested fields for object sections\n    if (typeof after[key] === 'object' && after[key] !== null && !Array.isArray(after[key])) {\n      const beforeSection = (before[key] as Record<string, any>) || {};\n      const afterSection = after[key] as Record<string, any>;\n\n      for (const nestedKey of Object.keys(afterSection)) {\n        if (!(nestedKey in beforeSection)) {\n          newFields.push(`${key}.${nestedKey}`);\n        }\n      }\n    }\n  }\n\n  return newFields;\n}\n\n","import fs from 'fs/promises';\nimport path from 'path';\nimport { LienConfig, LegacyLienConfig, FrameworkInstance, defaultConfig } from './schema.js';\nimport { CURRENT_CONFIG_VERSION } from '../constants.js';\n\n/**\n * Checks if a config object needs migration from v0.2.0 to v0.3.0\n */\nexport function needsMigration(config: any): boolean {\n  // Check if config uses old structure:\n  // - Has 'indexing' field instead of 'core' and 'frameworks'\n  // - Or has no 'frameworks' field at all\n  // - Or version is explicitly set to something < 0.3.0\n  // - Or missing 'chunking' field (v0.13.0)\n  if (!config) {\n    return false;\n  }\n\n  // If missing chunking config, needs migration to v0.13.0\n  if (config.frameworks !== undefined && !config.chunking) {\n    return true;\n  }\n\n  // If it has frameworks array and chunking, it's already in new format\n  if (config.frameworks !== undefined && config.chunking !== undefined) {\n    return false;\n  }\n\n  // If it has 'indexing' field, it's the old format\n  if (config.indexing !== undefined) {\n    return true;\n  }\n\n  // If version is explicitly < 0.3.0\n  if (config.version && config.version.startsWith('0.2')) {\n    return true;\n  }\n\n  return false;\n}\n\n/**\n * Migrates a v0.2.0 config to v0.3.0+ format\n * @param oldConfig - The old config to migrate\n * @param targetVersion - The version to set in the migrated config (defaults to CURRENT_CONFIG_VERSION)\n */\nexport function migrateConfig(oldConfig: Partial<LegacyLienConfig | LienConfig>, targetVersion?: string): LienConfig {\n  // Start with default config structure\n  const newConfig: LienConfig = {\n    version: targetVersion ?? CURRENT_CONFIG_VERSION,\n    core: {\n      chunkSize: (oldConfig as any).indexing?.chunkSize ?? (oldConfig as any).core?.chunkSize ?? defaultConfig.core.chunkSize,\n      chunkOverlap: (oldConfig as any).indexing?.chunkOverlap ?? (oldConfig as any).core?.chunkOverlap ?? defaultConfig.core.chunkOverlap,\n      concurrency: (oldConfig as any).indexing?.concurrency ?? (oldConfig as any).core?.concurrency ?? defaultConfig.core.concurrency,\n      embeddingBatchSize: (oldConfig as any).indexing?.embeddingBatchSize ?? (oldConfig as any).core?.embeddingBatchSize ?? defaultConfig.core.embeddingBatchSize,\n    },\n    chunking: {\n      useAST: (oldConfig as any).chunking?.useAST ?? defaultConfig.chunking.useAST,\n      astFallback: (oldConfig as any).chunking?.astFallback ?? defaultConfig.chunking.astFallback,\n    },\n    mcp: {\n      port: oldConfig.mcp?.port ?? defaultConfig.mcp.port,\n      transport: oldConfig.mcp?.transport ?? defaultConfig.mcp.transport,\n      autoIndexOnFirstRun: oldConfig.mcp?.autoIndexOnFirstRun ?? defaultConfig.mcp.autoIndexOnFirstRun,\n    },\n    gitDetection: {\n      enabled: oldConfig.gitDetection?.enabled ?? defaultConfig.gitDetection.enabled,\n      pollIntervalMs: oldConfig.gitDetection?.pollIntervalMs ?? defaultConfig.gitDetection.pollIntervalMs,\n    },\n    fileWatching: {\n      enabled: oldConfig.fileWatching?.enabled ?? defaultConfig.fileWatching.enabled,\n      debounceMs: oldConfig.fileWatching?.debounceMs ?? defaultConfig.fileWatching.debounceMs,\n    },\n    frameworks: (oldConfig as any).frameworks ?? [],\n  };\n\n  // Convert old indexing config to a single \"generic\" framework (only for legacy configs)\n  if ((oldConfig as any).indexing && newConfig.frameworks.length === 0) {\n    const genericFramework: FrameworkInstance = {\n      name: 'generic',\n      path: '.',\n      enabled: true,\n      config: {\n        include: (oldConfig as any).indexing.include ?? ['**/*.{ts,tsx,js,jsx,py,php,go,rs,java,c,cpp,cs}'],\n        exclude: (oldConfig as any).indexing.exclude ?? [\n          '**/node_modules/**',\n          '**/dist/**',\n          '**/build/**',\n          '**/.git/**',\n          '**/coverage/**',\n          '**/.next/**',\n          '**/.nuxt/**',\n          '**/vendor/**',\n        ],\n      },\n    };\n\n    newConfig.frameworks.push(genericFramework);\n  } else if (newConfig.frameworks.length === 0) {\n    // No indexing config and no frameworks present, use defaults for generic framework\n    const genericFramework: FrameworkInstance = {\n      name: 'generic',\n      path: '.',\n      enabled: true,\n      config: {\n        include: ['**/*.{ts,tsx,js,jsx,py,php,go,rs,java,c,cpp,cs}'],\n        exclude: [\n          '**/node_modules/**',\n          '**/dist/**',\n          '**/build/**',\n          '**/.git/**',\n          '**/coverage/**',\n          '**/.next/**',\n          '**/.nuxt/**',\n          '**/vendor/**',\n        ],\n      },\n    };\n\n    newConfig.frameworks.push(genericFramework);\n  }\n\n  return newConfig;\n}\n\n/**\n * Migrates config file and creates backup\n */\nexport async function migrateConfigFile(rootDir: string = process.cwd()): Promise<{\n  migrated: boolean;\n  backupPath?: string;\n  config: LienConfig;\n}> {\n  const configPath = path.join(rootDir, '.lien.config.json');\n\n  try {\n    // Read existing config\n    const configContent = await fs.readFile(configPath, 'utf-8');\n    const oldConfig = JSON.parse(configContent);\n\n    // Check if migration is needed\n    if (!needsMigration(oldConfig)) {\n      return {\n        migrated: false,\n        config: oldConfig as LienConfig,\n      };\n    }\n\n    // Perform migration\n    const newConfig = migrateConfig(oldConfig);\n\n    // Create backup\n    const backupPath = `${configPath}.v0.2.0.backup`;\n    await fs.copyFile(configPath, backupPath);\n\n    // Write migrated config\n    await fs.writeFile(configPath, JSON.stringify(newConfig, null, 2) + '\\n', 'utf-8');\n\n    return {\n      migrated: true,\n      backupPath,\n      config: newConfig,\n    };\n  } catch (error) {\n    // If config doesn't exist, return default\n    if ((error as NodeJS.ErrnoException).code === 'ENOENT') {\n      return {\n        migrated: false,\n        config: defaultConfig,\n      };\n    }\n    throw error;\n  }\n}\n\n","import fs from 'fs/promises';\nimport path from 'path';\nimport { INDEX_FORMAT_VERSION } from '../constants.js';\nimport { GitState } from '../git/tracker.js';\nimport { getPackageVersion } from '../utils/version.js';\n\nconst MANIFEST_FILE = 'manifest.json';\n\n/**\n * Represents a single file in the index manifest\n */\nexport interface FileEntry {\n  filepath: string;\n  lastModified: number;\n  chunkCount: number;\n}\n\n/**\n * Index manifest tracking all indexed files and version information\n */\nexport interface IndexManifest {\n  formatVersion: number;      // Index format version for compatibility checking\n  lienVersion: string;         // Lien package version (for reference)\n  lastIndexed: number;         // Timestamp of last indexing operation\n  gitState?: GitState;         // Last known git state\n  files: Record<string, FileEntry>;  // Map of filepath -> FileEntry (stored as object for JSON)\n}\n\n/**\n * Manages the index manifest file, tracking which files are indexed\n * and their metadata for incremental indexing support.\n * \n * The manifest includes version checking to invalidate indices when\n * Lien's indexing format changes (e.g., new chunking algorithm,\n * different embedding model, schema changes).\n */\nexport class ManifestManager {\n  private manifestPath: string;\n  private indexPath: string;\n  \n  /**\n   * Promise-based lock to prevent race conditions during concurrent updates.\n   * Ensures read-modify-write operations are atomic.\n   */\n  private updateLock = Promise.resolve();\n  \n  /**\n   * Creates a new ManifestManager\n   * @param indexPath - Path to the index directory (same as VectorDB path)\n   */\n  constructor(indexPath: string) {\n    this.indexPath = indexPath;\n    this.manifestPath = path.join(indexPath, MANIFEST_FILE);\n  }\n  \n  /**\n   * Loads the manifest from disk.\n   * Returns null if:\n   * - Manifest doesn't exist (first run)\n   * - Manifest is corrupt\n   * - Format version is incompatible (triggers full reindex)\n   * \n   * @returns Loaded manifest or null\n   */\n  async load(): Promise<IndexManifest | null> {\n    try {\n      const content = await fs.readFile(this.manifestPath, 'utf-8');\n      const manifest = JSON.parse(content) as IndexManifest;\n      \n      // VERSION CHECK: Invalidate if format version doesn't match\n      if (manifest.formatVersion !== INDEX_FORMAT_VERSION) {\n        console.error(\n          `[Lien] Index format v${manifest.formatVersion} is incompatible with current v${INDEX_FORMAT_VERSION}`\n        );\n        console.error(`[Lien] Full reindex required after Lien upgrade`);\n        \n        // Clear old manifest and return null (triggers full reindex)\n        await this.clear();\n        return null;\n      }\n      \n      return manifest;\n    } catch (error) {\n      // File doesn't exist or is invalid - return null for first run\n      if ((error as NodeJS.ErrnoException).code === 'ENOENT') {\n        return null;\n      }\n      \n      // Corrupt manifest - log warning and return null\n      console.error(`[Lien] Warning: Failed to load manifest: ${error}`);\n      return null;\n    }\n  }\n  \n  /**\n   * Saves the manifest to disk.\n   * Always saves with current format and package versions.\n   * \n   * @param manifest - Manifest to save\n   */\n  async save(manifest: IndexManifest): Promise<void> {\n    try {\n      // Ensure index directory exists\n      await fs.mkdir(this.indexPath, { recursive: true });\n      \n      // Always save with current versions\n      const manifestToSave: IndexManifest = {\n        ...manifest,\n        formatVersion: INDEX_FORMAT_VERSION,\n        lienVersion: getPackageVersion(),\n        lastIndexed: Date.now(),\n      };\n      \n      const content = JSON.stringify(manifestToSave, null, 2);\n      await fs.writeFile(this.manifestPath, content, 'utf-8');\n    } catch (error) {\n      // Don't throw - manifest is best-effort\n      console.error(`[Lien] Warning: Failed to save manifest: ${error}`);\n    }\n  }\n  \n  /**\n   * Adds or updates a file entry in the manifest.\n   * Protected by lock to prevent race conditions during concurrent updates.\n   * \n   * @param filepath - Path to the file\n   * @param entry - File entry metadata\n   */\n  async updateFile(filepath: string, entry: FileEntry): Promise<void> {\n    // Chain this operation to the lock to ensure atomicity\n    this.updateLock = this.updateLock.then(async () => {\n      const manifest = await this.load() || this.createEmpty();\n      manifest.files[filepath] = entry;\n      await this.save(manifest);\n    }).catch(error => {\n      console.error(`[Lien] Failed to update manifest for ${filepath}: ${error}`);\n      // Return to reset lock - don't let errors block future operations\n      return undefined;\n    });\n    \n    // Wait for this operation to complete\n    await this.updateLock;\n  }\n  \n  /**\n   * Removes a file entry from the manifest.\n   * Protected by lock to prevent race conditions during concurrent updates.\n   * \n   * Note: If the manifest doesn't exist, this is a no-op (not an error).\n   * This can happen legitimately after clearing the index or on fresh installs.\n   * \n   * @param filepath - Path to the file to remove\n   */\n  async removeFile(filepath: string): Promise<void> {\n    // Chain this operation to the lock to ensure atomicity\n    this.updateLock = this.updateLock.then(async () => {\n      const manifest = await this.load();\n      if (!manifest) {\n        // No manifest exists - nothing to remove from (expected in some scenarios)\n        return;\n      }\n      \n      delete manifest.files[filepath];\n      await this.save(manifest);\n    }).catch(error => {\n      console.error(`[Lien] Failed to remove manifest entry for ${filepath}: ${error}`);\n      // Return to reset lock - don't let errors block future operations\n      return undefined;\n    });\n    \n    // Wait for this operation to complete\n    await this.updateLock;\n  }\n  \n  /**\n   * Updates multiple files at once (more efficient than individual updates).\n   * Protected by lock to prevent race conditions during concurrent updates.\n   * \n   * @param entries - Array of file entries to update\n   */\n  async updateFiles(entries: FileEntry[]): Promise<void> {\n    // Chain this operation to the lock to ensure atomicity\n    this.updateLock = this.updateLock.then(async () => {\n      const manifest = await this.load() || this.createEmpty();\n      \n      for (const entry of entries) {\n        manifest.files[entry.filepath] = entry;\n      }\n      \n      await this.save(manifest);\n    }).catch(error => {\n      console.error(`[Lien] Failed to update manifest for ${entries.length} files: ${error}`);\n      // Return to reset lock - don't let errors block future operations\n      return undefined;\n    });\n    \n    // Wait for this operation to complete\n    await this.updateLock;\n  }\n  \n  /**\n   * Updates the git state in the manifest.\n   * Protected by lock to prevent race conditions during concurrent updates.\n   * \n   * @param gitState - Current git state\n   */\n  async updateGitState(gitState: GitState): Promise<void> {\n    // Chain this operation to the lock to ensure atomicity\n    this.updateLock = this.updateLock.then(async () => {\n      const manifest = await this.load() || this.createEmpty();\n      \n      manifest.gitState = gitState;\n      await this.save(manifest);\n    }).catch(error => {\n      console.error(`[Lien] Failed to update git state in manifest: ${error}`);\n      // Return to reset lock - don't let errors block future operations\n      return undefined;\n    });\n    \n    // Wait for this operation to complete\n    await this.updateLock;\n  }\n  \n  /**\n   * Gets the list of files currently in the manifest\n   * \n   * @returns Array of filepaths\n   */\n  async getIndexedFiles(): Promise<string[]> {\n    const manifest = await this.load();\n    if (!manifest) return [];\n    \n    return Object.keys(manifest.files);\n  }\n  \n  /**\n   * Detects which files have changed based on mtime comparison\n   * \n   * @param currentFiles - Map of current files with their mtimes\n   * @returns Array of filepaths that have changed\n   */\n  async getChangedFiles(currentFiles: Map<string, number>): Promise<string[]> {\n    const manifest = await this.load();\n    if (!manifest) {\n      // No manifest = all files are \"changed\" (need full index)\n      return Array.from(currentFiles.keys());\n    }\n    \n    const changedFiles: string[] = [];\n    \n    for (const [filepath, mtime] of currentFiles) {\n      const entry = manifest.files[filepath];\n      \n      if (!entry) {\n        // New file\n        changedFiles.push(filepath);\n      } else if (entry.lastModified < mtime) {\n        // File modified since last index\n        changedFiles.push(filepath);\n      }\n    }\n    \n    return changedFiles;\n  }\n  \n  /**\n   * Gets files that are in the manifest but not in the current file list\n   * (i.e., deleted files)\n   * \n   * @param currentFiles - Set of current file paths\n   * @returns Array of deleted file paths\n   */\n  async getDeletedFiles(currentFiles: Set<string>): Promise<string[]> {\n    const manifest = await this.load();\n    if (!manifest) return [];\n    \n    const deletedFiles: string[] = [];\n    \n    for (const filepath of Object.keys(manifest.files)) {\n      if (!currentFiles.has(filepath)) {\n        deletedFiles.push(filepath);\n      }\n    }\n    \n    return deletedFiles;\n  }\n  \n  /**\n   * Clears the manifest file\n   */\n  async clear(): Promise<void> {\n    try {\n      await fs.unlink(this.manifestPath);\n    } catch (error) {\n      // Ignore error if file doesn't exist\n      if ((error as NodeJS.ErrnoException).code !== 'ENOENT') {\n        console.error(`[Lien] Warning: Failed to clear manifest: ${error}`);\n      }\n    }\n  }\n  \n  /**\n   * Creates an empty manifest with current version information\n   * \n   * @returns Empty manifest\n   */\n  private createEmpty(): IndexManifest {\n    return {\n      formatVersion: INDEX_FORMAT_VERSION,\n      lienVersion: getPackageVersion(),\n      lastIndexed: Date.now(),\n      files: {},\n    };\n  }\n}\n\n","/**\n * Version utilities for @liendev/core\n * \n * Core package has its own version. When CLI uses core,\n * it can override this with its own package version.\n */\n\n// Default version for core\n// In a real build, this would be injected or read from package.json\nlet coreVersion = '0.1.0';\n\n/**\n * Get the current package version\n */\nexport function getPackageVersion(): string {\n  return coreVersion;\n}\n\n/**\n * Set the package version (used by CLI to override with its version)\n */\nexport function setPackageVersion(version: string): void {\n  coreVersion = version;\n}\n\n/**\n * Get the full package info (for compatibility)\n */\nexport function getPackageInfo(): { version: string; name: string } {\n  return { version: coreVersion, name: '@liendev/core' };\n}\n","import { exec } from 'child_process';\nimport { promisify } from 'util';\nimport fs from 'fs/promises';\nimport path from 'path';\n\nconst execAsync = promisify(exec);\n\n/**\n * Checks if a directory is a git repository.\n * \n * @param rootDir - Directory to check\n * @returns true if directory is a git repo, false otherwise\n */\nexport async function isGitRepo(rootDir: string): Promise<boolean> {\n  try {\n    const gitDir = path.join(rootDir, '.git');\n    await fs.access(gitDir);\n    return true;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Gets the current git branch name.\n * \n * @param rootDir - Root directory of the git repository\n * @returns Branch name (e.g., \"main\", \"feature-branch\")\n * @throws Error if not a git repo or git command fails\n */\nexport async function getCurrentBranch(rootDir: string): Promise<string> {\n  try {\n    const { stdout } = await execAsync('git rev-parse --abbrev-ref HEAD', {\n      cwd: rootDir,\n      timeout: 5000, // 5 second timeout\n    });\n    return stdout.trim();\n  } catch (error) {\n    throw new Error(`Failed to get current branch: ${error}`);\n  }\n}\n\n/**\n * Gets the current git commit SHA (HEAD).\n * \n * @param rootDir - Root directory of the git repository\n * @returns Commit SHA (full 40-character hash)\n * @throws Error if not a git repo or git command fails\n */\nexport async function getCurrentCommit(rootDir: string): Promise<string> {\n  try {\n    const { stdout } = await execAsync('git rev-parse HEAD', {\n      cwd: rootDir,\n      timeout: 5000,\n    });\n    return stdout.trim();\n  } catch (error) {\n    throw new Error(`Failed to get current commit: ${error}`);\n  }\n}\n\n/**\n * Gets the list of files that changed between two git references.\n * \n * @param rootDir - Root directory of the git repository\n * @param fromRef - Starting reference (branch name, commit SHA, or tag)\n * @param toRef - Ending reference (branch name, commit SHA, or tag)\n * @returns Array of file paths (relative to repo root) that changed\n * @throws Error if git command fails\n */\nexport async function getChangedFiles(\n  rootDir: string,\n  fromRef: string,\n  toRef: string\n): Promise<string[]> {\n  try {\n    const { stdout } = await execAsync(\n      `git diff --name-only ${fromRef}...${toRef}`,\n      {\n        cwd: rootDir,\n        timeout: 10000, // 10 second timeout for diffs\n      }\n    );\n    \n    const files = stdout\n      .trim()\n      .split('\\n')\n      .filter(Boolean)\n      .map(file => path.join(rootDir, file)); // Convert to absolute paths\n    \n    return files;\n  } catch (error) {\n    throw new Error(`Failed to get changed files: ${error}`);\n  }\n}\n\n/**\n * Gets the list of files that changed in a specific commit.\n * \n * @param rootDir - Root directory of the git repository\n * @param commitSha - Commit SHA to check\n * @returns Array of file paths (absolute) that changed in this commit\n * @throws Error if git command fails\n */\nexport async function getChangedFilesInCommit(\n  rootDir: string,\n  commitSha: string\n): Promise<string[]> {\n  try {\n    const { stdout } = await execAsync(\n      `git diff-tree --no-commit-id --name-only -r ${commitSha}`,\n      {\n        cwd: rootDir,\n        timeout: 10000,\n      }\n    );\n    \n    const files = stdout\n      .trim()\n      .split('\\n')\n      .filter(Boolean)\n      .map(file => path.join(rootDir, file)); // Convert to absolute paths\n    \n    return files;\n  } catch (error) {\n    throw new Error(`Failed to get changed files in commit: ${error}`);\n  }\n}\n\n/**\n * Gets the list of files that changed between two commits.\n * More efficient than getChangedFiles for commit-to-commit comparisons.\n * \n * @param rootDir - Root directory of the git repository\n * @param fromCommit - Starting commit SHA\n * @param toCommit - Ending commit SHA\n * @returns Array of file paths (absolute) that changed between commits\n * @throws Error if git command fails\n */\nexport async function getChangedFilesBetweenCommits(\n  rootDir: string,\n  fromCommit: string,\n  toCommit: string\n): Promise<string[]> {\n  try {\n    const { stdout } = await execAsync(\n      `git diff --name-only ${fromCommit} ${toCommit}`,\n      {\n        cwd: rootDir,\n        timeout: 10000,\n      }\n    );\n    \n    const files = stdout\n      .trim()\n      .split('\\n')\n      .filter(Boolean)\n      .map(file => path.join(rootDir, file)); // Convert to absolute paths\n    \n    return files;\n  } catch (error) {\n    throw new Error(`Failed to get changed files between commits: ${error}`);\n  }\n}\n\n/**\n * Checks if git is installed and available.\n * \n * @returns true if git is available, false otherwise\n */\nexport async function isGitAvailable(): Promise<boolean> {\n  try {\n    await execAsync('git --version', { timeout: 3000 });\n    return true;\n  } catch {\n    return false;\n  }\n}\n\n","import fs from 'fs/promises';\nimport path from 'path';\nimport {\n  isGitRepo,\n  getCurrentBranch,\n  getCurrentCommit,\n  getChangedFiles,\n  getChangedFilesBetweenCommits,\n} from './utils.js';\n\nexport interface GitState {\n  branch: string;\n  commit: string;\n  timestamp: number;\n}\n\n/**\n * Tracks git state (branch and commit) and detects changes.\n * Persists state to disk to survive server restarts.\n */\nexport class GitStateTracker {\n  private stateFile: string;\n  private rootDir: string;\n  private currentState: GitState | null = null;\n  \n  constructor(rootDir: string, indexPath: string) {\n    this.rootDir = rootDir;\n    this.stateFile = path.join(indexPath, '.git-state.json');\n  }\n  \n  /**\n   * Loads the last known git state from disk.\n   * Returns null if no state file exists (first run).\n   */\n  private async loadState(): Promise<GitState | null> {\n    try {\n      const content = await fs.readFile(this.stateFile, 'utf-8');\n      return JSON.parse(content);\n    } catch {\n      // File doesn't exist or is invalid - this is fine for first run\n      return null;\n    }\n  }\n  \n  /**\n   * Saves the current git state to disk.\n   */\n  private async saveState(state: GitState): Promise<void> {\n    try {\n      const content = JSON.stringify(state, null, 2);\n      await fs.writeFile(this.stateFile, content, 'utf-8');\n    } catch (error) {\n      // Log but don't throw - state persistence is best-effort\n      console.error(`[Lien] Warning: Failed to save git state: ${error}`);\n    }\n  }\n  \n  /**\n   * Gets the current git state from the repository.\n   * \n   * @returns Current git state\n   * @throws Error if git commands fail\n   */\n  private async getCurrentGitState(): Promise<GitState> {\n    const branch = await getCurrentBranch(this.rootDir);\n    const commit = await getCurrentCommit(this.rootDir);\n    \n    return {\n      branch,\n      commit,\n      timestamp: Date.now(),\n    };\n  }\n  \n  /**\n   * Initializes the tracker by loading saved state and checking current state.\n   * Should be called once when MCP server starts.\n   * \n   * @returns Array of changed files if state changed, null if no changes or first run\n   */\n  async initialize(): Promise<string[] | null> {\n    // Check if this is a git repo\n    const isRepo = await isGitRepo(this.rootDir);\n    if (!isRepo) {\n      return null;\n    }\n    \n    try {\n      // Get current state\n      this.currentState = await this.getCurrentGitState();\n      \n      // Load previous state\n      const previousState = await this.loadState();\n      \n      if (!previousState) {\n        // First run - save current state\n        await this.saveState(this.currentState);\n        return null;\n      }\n      \n      // Check if state changed\n      const branchChanged = previousState.branch !== this.currentState.branch;\n      const commitChanged = previousState.commit !== this.currentState.commit;\n      \n      if (!branchChanged && !commitChanged) {\n        // No changes\n        return null;\n      }\n      \n      // State changed - get list of changed files\n      let changedFiles: string[] = [];\n      \n      if (branchChanged) {\n        // Branch changed - compare current branch with previous branch\n        try {\n          changedFiles = await getChangedFiles(\n            this.rootDir,\n            previousState.branch,\n            this.currentState.branch\n          );\n        } catch (error) {\n          // If branches diverged too much or don't exist, fall back to commit diff\n          console.error(`[Lien] Branch diff failed, using commit diff: ${error}`);\n          changedFiles = await getChangedFilesBetweenCommits(\n            this.rootDir,\n            previousState.commit,\n            this.currentState.commit\n          );\n        }\n      } else if (commitChanged) {\n        // Same branch, different commit\n        changedFiles = await getChangedFilesBetweenCommits(\n          this.rootDir,\n          previousState.commit,\n          this.currentState.commit\n        );\n      }\n      \n      // Save new state\n      await this.saveState(this.currentState);\n      \n      return changedFiles;\n    } catch (error) {\n      console.error(`[Lien] Failed to initialize git tracker: ${error}`);\n      return null;\n    }\n  }\n  \n  /**\n   * Checks for git state changes since last check.\n   * This is called periodically by the MCP server.\n   * \n   * @returns Array of changed files if state changed, null if no changes\n   */\n  async detectChanges(): Promise<string[] | null> {\n    // Check if this is a git repo\n    const isRepo = await isGitRepo(this.rootDir);\n    if (!isRepo) {\n      return null;\n    }\n    \n    try {\n      // Get current state\n      const newState = await this.getCurrentGitState();\n      \n      // If we don't have a previous state, just save current and return\n      if (!this.currentState) {\n        this.currentState = newState;\n        await this.saveState(newState);\n        return null;\n      }\n      \n      // Check if state changed\n      const branchChanged = this.currentState.branch !== newState.branch;\n      const commitChanged = this.currentState.commit !== newState.commit;\n      \n      if (!branchChanged && !commitChanged) {\n        // No changes\n        return null;\n      }\n      \n      // State changed - get list of changed files\n      let changedFiles: string[] = [];\n      \n      if (branchChanged) {\n        // Branch changed\n        try {\n          changedFiles = await getChangedFiles(\n            this.rootDir,\n            this.currentState.branch,\n            newState.branch\n          );\n        } catch (error) {\n          // Fall back to commit diff\n          console.error(`[Lien] Branch diff failed, using commit diff: ${error}`);\n          changedFiles = await getChangedFilesBetweenCommits(\n            this.rootDir,\n            this.currentState.commit,\n            newState.commit\n          );\n        }\n      } else if (commitChanged) {\n        // Same branch, different commit\n        changedFiles = await getChangedFilesBetweenCommits(\n          this.rootDir,\n          this.currentState.commit,\n          newState.commit\n        );\n      }\n      \n      // Update current state\n      this.currentState = newState;\n      await this.saveState(newState);\n      \n      return changedFiles;\n    } catch (error) {\n      console.error(`[Lien] Failed to detect git changes: ${error}`);\n      return null;\n    }\n  }\n  \n  /**\n   * Gets the current git state.\n   * Useful for status display.\n   */\n  getState(): GitState | null {\n    return this.currentState;\n  }\n  \n  /**\n   * Manually updates the saved state.\n   * Useful after manual reindexing to sync state.\n   */\n  async updateState(): Promise<void> {\n    try {\n      this.currentState = await this.getCurrentGitState();\n      await this.saveState(this.currentState);\n    } catch (error) {\n      console.error(`[Lien] Failed to update git state: ${error}`);\n    }\n  }\n}\n\n","import fs from 'fs/promises';\nimport path from 'path';\nimport { VectorDB } from '../vectordb/lancedb.js';\nimport { ManifestManager, IndexManifest } from './manifest.js';\nimport { scanCodebase, scanCodebaseWithFrameworks } from './scanner.js';\nimport { LienConfig, LegacyLienConfig, isModernConfig, isLegacyConfig } from '../config/schema.js';\nimport { GitStateTracker } from '../git/tracker.js';\nimport { isGitAvailable, isGitRepo, getChangedFiles } from '../git/utils.js';\nimport { normalizeToRelativePath } from './incremental.js';\n\n/**\n * Result of change detection, categorized by type of change\n */\nexport interface ChangeDetectionResult {\n  added: string[];      // New files not in previous index\n  modified: string[];   // Existing files that have been modified\n  deleted: string[];    // Files that were indexed but no longer exist\n  reason: 'mtime' | 'full' | 'git-state-changed';  // How changes were detected\n}\n\n/**\n * Check if git state has changed (branch switch, new commits).\n */\nasync function hasGitStateChanged(\n  rootDir: string,\n  dbPath: string,\n  savedGitState: IndexManifest['gitState']\n): Promise<{ changed: boolean; currentState?: ReturnType<GitStateTracker['getState']> }> {\n  if (!savedGitState) return { changed: false };\n\n  const gitAvailable = await isGitAvailable();\n  const isRepo = await isGitRepo(rootDir);\n  if (!gitAvailable || !isRepo) return { changed: false };\n\n  const gitTracker = new GitStateTracker(rootDir, dbPath);\n  await gitTracker.initialize();\n  const currentState = gitTracker.getState();\n\n  if (!currentState) return { changed: false };\n\n  const changed = currentState.branch !== savedGitState.branch ||\n                  currentState.commit !== savedGitState.commit;\n\n  return { changed, currentState };\n}\n\n/**\n * Categorize files from git diff into added, modified, deleted.\n */\nfunction categorizeChangedFiles(\n  changedFilesPaths: string[],\n  currentFileSet: Set<string>,\n  normalizedManifestFiles: Set<string>,\n  allFiles: string[]\n): { added: string[]; modified: string[]; deleted: string[] } {\n  const changedFilesSet = new Set(changedFilesPaths);\n  const added: string[] = [];\n  const modified: string[] = [];\n  const deleted: string[] = [];\n\n  // Categorize files from git diff\n  for (const filepath of changedFilesPaths) {\n    if (currentFileSet.has(filepath)) {\n      if (normalizedManifestFiles.has(filepath)) {\n        modified.push(filepath);\n      } else {\n        added.push(filepath);\n      }\n    }\n  }\n\n  // Find truly new files (not in git diff, but not in old manifest)\n  for (const filepath of allFiles) {\n    if (!normalizedManifestFiles.has(filepath) && !changedFilesSet.has(filepath)) {\n      added.push(filepath);\n    }\n  }\n\n  // Find deleted files (in old manifest but not in current)\n  for (const normalizedPath of normalizedManifestFiles) {\n    if (!currentFileSet.has(normalizedPath)) {\n      deleted.push(normalizedPath);\n    }\n  }\n\n  return { added, modified, deleted };\n}\n\n/**\n * Build normalized set of manifest file paths for comparison.\n */\nfunction normalizeManifestPaths(\n  manifestFiles: IndexManifest['files'],\n  rootDir: string\n): Set<string> {\n  const normalized = new Set<string>();\n  for (const filepath of Object.keys(manifestFiles)) {\n    normalized.add(normalizeToRelativePath(filepath, rootDir));\n  }\n  return normalized;\n}\n\n/**\n * Detect changes using git diff between commits.\n */\nasync function detectGitBasedChanges(\n  rootDir: string,\n  savedManifest: IndexManifest,\n  currentCommit: string,\n  config: LienConfig | LegacyLienConfig\n): Promise<ChangeDetectionResult> {\n  const changedFilesAbsolute = await getChangedFiles(\n    rootDir,\n    savedManifest.gitState!.commit,\n    currentCommit\n  );\n  const changedFilesPaths = changedFilesAbsolute.map(fp => normalizeToRelativePath(fp, rootDir));\n\n  const allFiles = await getAllFiles(rootDir, config);\n  const currentFileSet = new Set(allFiles);\n  const normalizedManifestFiles = normalizeManifestPaths(savedManifest.files, rootDir);\n\n  const { added, modified, deleted } = categorizeChangedFiles(\n    changedFilesPaths,\n    currentFileSet,\n    normalizedManifestFiles,\n    allFiles\n  );\n\n  return { added, modified, deleted, reason: 'git-state-changed' };\n}\n\n/**\n * Fall back to full reindex when git diff fails.\n */\nasync function fallbackToFullReindex(\n  rootDir: string,\n  savedManifest: IndexManifest,\n  config: LienConfig | LegacyLienConfig\n): Promise<ChangeDetectionResult> {\n  const allFiles = await getAllFiles(rootDir, config);\n  const currentFileSet = new Set(allFiles);\n\n  const deleted: string[] = [];\n  for (const filepath of Object.keys(savedManifest.files)) {\n    const normalizedPath = normalizeToRelativePath(filepath, rootDir);\n    if (!currentFileSet.has(normalizedPath)) {\n      deleted.push(normalizedPath);\n    }\n  }\n\n  return { added: allFiles, modified: [], deleted, reason: 'git-state-changed' };\n}\n\n/**\n * Detects which files have changed since last indexing.\n * Uses git state detection to handle branch switches, then falls back to mtime.\n */\nexport async function detectChanges(\n  rootDir: string,\n  vectorDB: VectorDB,\n  config: LienConfig | LegacyLienConfig\n): Promise<ChangeDetectionResult> {\n  const manifest = new ManifestManager(vectorDB.dbPath);\n  const savedManifest = await manifest.load();\n\n  // No manifest = first run = full index\n  if (!savedManifest) {\n    const allFiles = await getAllFiles(rootDir, config);\n    return { added: allFiles, modified: [], deleted: [], reason: 'full' };\n  }\n\n  // Check if git state has changed\n  const gitCheck = await hasGitStateChanged(rootDir, vectorDB.dbPath, savedManifest.gitState);\n\n  if (gitCheck.changed && gitCheck.currentState) {\n    try {\n      return await detectGitBasedChanges(rootDir, savedManifest, gitCheck.currentState.commit, config);\n    } catch (error) {\n      console.warn(`[Lien] Git diff failed, falling back to full reindex: ${error}`);\n      return await fallbackToFullReindex(rootDir, savedManifest, config);\n    }\n  }\n\n  // Use mtime-based detection for file-level changes\n  return await mtimeBasedDetection(rootDir, savedManifest, config);\n}\n\n/**\n * Gets all files in the project based on configuration.\n * Always returns relative paths for consistent comparison with manifest and git diff.\n */\nasync function getAllFiles(\n  rootDir: string,\n  config: LienConfig | LegacyLienConfig\n): Promise<string[]> {\n  let files: string[];\n  \n  if (isModernConfig(config) && config.frameworks.length > 0) {\n    files = await scanCodebaseWithFrameworks(rootDir, config);\n  } else if (isLegacyConfig(config)) {\n    files = await scanCodebase({\n      rootDir,\n      includePatterns: config.indexing.include,\n      excludePatterns: config.indexing.exclude,\n    });\n  } else {\n    files = await scanCodebase({\n      rootDir,\n      includePatterns: [],\n      excludePatterns: [],\n    });\n  }\n  \n  // Normalize all paths to relative for consistent comparison\n  return files.map(fp => normalizeToRelativePath(fp, rootDir));\n}\n\n/**\n * Detects changes by comparing file modification times\n */\nasync function mtimeBasedDetection(\n  rootDir: string,\n  savedManifest: IndexManifest,\n  config: LienConfig | LegacyLienConfig\n): Promise<ChangeDetectionResult> {\n  const added: string[] = [];\n  const modified: string[] = [];\n  const deleted: string[] = [];\n  \n  // Get all current files (already normalized to relative paths by getAllFiles)\n  const currentFiles = await getAllFiles(rootDir, config);\n  const currentFileSet = new Set(currentFiles);\n  \n  // Build a normalized map of manifest files for comparison\n  // This handles cases where manifest has absolute paths (from tests or legacy data)\n  const normalizedManifestFiles = new Map<string, typeof savedManifest.files[string]>();\n  for (const [filepath, entry] of Object.entries(savedManifest.files)) {\n    const normalizedPath = normalizeToRelativePath(filepath, rootDir);\n    normalizedManifestFiles.set(normalizedPath, entry);\n  }\n  \n  // Get mtimes for all current files\n  // Note: need to construct absolute path for fs.stat since currentFiles are relative\n  const fileStats = new Map<string, number>();\n  \n  for (const filepath of currentFiles) {\n    try {\n      // Construct absolute path for filesystem access (use path.join for cross-platform)\n      const absolutePath = path.isAbsolute(filepath) ? filepath : path.join(rootDir, filepath);\n      const stats = await fs.stat(absolutePath);\n      fileStats.set(filepath, stats.mtimeMs);\n    } catch {\n      // Ignore files we can't stat\n      continue;\n    }\n  }\n  \n  // Check for new and modified files\n  for (const [filepath, mtime] of fileStats) {\n    const entry = normalizedManifestFiles.get(filepath);\n    \n    if (!entry) {\n      // New file\n      added.push(filepath);\n    } else if (entry.lastModified < mtime) {\n      // File modified since last index\n      modified.push(filepath);\n    }\n  }\n  \n  // Check for deleted files (use normalized manifest paths)\n  for (const normalizedPath of normalizedManifestFiles.keys()) {\n    if (!currentFileSet.has(normalizedPath)) {\n      deleted.push(normalizedPath);\n    }\n  }\n  \n  return {\n    added,\n    modified,\n    deleted,\n    reason: 'mtime',\n  };\n}\n\n","import fs from 'fs/promises';\nimport path from 'path';\nimport { chunkFile } from './chunker.js';\nimport { EmbeddingService } from '../embeddings/types.js';\nimport { VectorDB } from '../vectordb/lancedb.js';\nimport { LienConfig, LegacyLienConfig, isModernConfig, isLegacyConfig } from '../config/schema.js';\nimport { ManifestManager } from './manifest.js';\nimport { EMBEDDING_MICRO_BATCH_SIZE } from '../constants.js';\nimport { CodeChunk } from './types.js';\nimport { Result, Ok, Err, isOk } from '../utils/result.js';\n\n/**\n * Normalize a file path to a consistent relative format.\n * This ensures paths from different sources (git diff, scanner, etc.)\n * are stored and queried consistently in the index.\n * \n * @param filepath - Absolute or relative file path\n * @param rootDir - Workspace root directory (defaults to cwd)\n * @returns Relative path from rootDir\n */\nexport function normalizeToRelativePath(filepath: string, rootDir?: string): string {\n  // Normalize root and strip trailing slash to ensure consistent comparison\n  const root = (rootDir || process.cwd()).replace(/\\\\/g, '/').replace(/\\/$/, '');\n  const normalized = filepath.replace(/\\\\/g, '/');\n  \n  // If already relative, return as-is\n  if (!path.isAbsolute(filepath)) {\n    return normalized;\n  }\n  \n  // Convert absolute to relative\n  if (normalized.startsWith(root + '/')) {\n    return normalized.slice(root.length + 1);\n  }\n  if (normalized.startsWith(root)) {\n    return normalized.slice(root.length);\n  }\n  \n  // Fallback: use path.relative\n  return path.relative(root, filepath).replace(/\\\\/g, '/');\n}\n\nexport interface IncrementalIndexOptions {\n  verbose?: boolean;\n}\n\n/**\n * Result of processing a file's content into chunks and embeddings.\n */\ninterface ProcessFileResult {\n  chunkCount: number;\n  vectors: Float32Array[];\n  chunks: CodeChunk[];\n  texts: string[];\n}\n\n/**\n * Result of processing a single file for incremental indexing.\n */\ninterface FileProcessResult {\n  filepath: string;\n  result: ProcessFileResult | null; // null for empty files\n  mtime: number;\n}\n\n/**\n * Shared helper that processes file content into chunks and embeddings.\n * This is the core logic shared between indexSingleFile and indexMultipleFiles.\n * \n * Returns null for empty files (0 chunks), which callers should handle appropriately.\n * \n * @param filepath - Path to the file being processed\n * @param content - File content\n * @param embeddings - Embeddings service\n * @param config - Lien configuration\n * @param verbose - Whether to log verbose output\n * @returns ProcessFileResult for non-empty files, null for empty files\n */\nasync function processFileContent(\n  filepath: string,\n  content: string,\n  embeddings: EmbeddingService,\n  config: LienConfig | LegacyLienConfig,\n  verbose: boolean\n): Promise<ProcessFileResult | null> {\n  // Get chunk settings (support both v0.3.0 and legacy v0.2.0 configs)\n  const chunkSize = isModernConfig(config)\n    ? config.core.chunkSize\n    : (isLegacyConfig(config) ? config.indexing.chunkSize : 75);\n  const chunkOverlap = isModernConfig(config)\n    ? config.core.chunkOverlap\n    : (isLegacyConfig(config) ? config.indexing.chunkOverlap : 10);\n  const useAST = isModernConfig(config)\n    ? config.chunking.useAST\n    : true;\n  const astFallback = isModernConfig(config)\n    ? config.chunking.astFallback\n    : 'line-based';\n  \n  // Chunk the file\n  const chunks = chunkFile(filepath, content, {\n    chunkSize,\n    chunkOverlap,\n    useAST,\n    astFallback,\n  });\n  \n  if (chunks.length === 0) {\n    // Empty file - return null so caller can handle appropriately\n    if (verbose) {\n      console.error(`[Lien] Empty file: ${filepath}`);\n    }\n    return null;\n  }\n  \n  // Generate embeddings for all chunks\n  // Use micro-batching to prevent event loop blocking\n  const texts = chunks.map(c => c.content);\n  const vectors: Float32Array[] = [];\n  \n  for (let j = 0; j < texts.length; j += EMBEDDING_MICRO_BATCH_SIZE) {\n    const microBatch = texts.slice(j, Math.min(j + EMBEDDING_MICRO_BATCH_SIZE, texts.length));\n    const microResults = await embeddings.embedBatch(microBatch);\n    vectors.push(...microResults);\n    \n    // Yield to event loop for responsiveness\n    if (texts.length > EMBEDDING_MICRO_BATCH_SIZE) {\n      await new Promise(resolve => setImmediate(resolve));\n    }\n  }\n  \n  return {\n    chunkCount: chunks.length,\n    vectors,\n    chunks,\n    texts,\n  };\n}\n\n/**\n * Indexes a single file incrementally by updating its chunks in the vector database.\n * This is the core function for incremental reindexing - it handles file changes,\n * deletions, and additions.\n * \n * @param filepath - Absolute path to the file to index\n * @param vectorDB - Initialized VectorDB instance\n * @param embeddings - Initialized embeddings service\n * @param config - Lien configuration\n * @param options - Optional settings\n */\nexport async function indexSingleFile(\n  filepath: string,\n  vectorDB: VectorDB,\n  embeddings: EmbeddingService,\n  config: LienConfig | LegacyLienConfig,\n  options: IncrementalIndexOptions = {}\n): Promise<void> {\n  const { verbose } = options;\n  \n  // Normalize to relative path for consistent storage and queries\n  // This ensures paths from git diff (absolute) match paths from scanner (relative)\n  const normalizedPath = normalizeToRelativePath(filepath);\n  \n  try {\n    // Check if file exists (use original filepath for filesystem operations)\n    try {\n      await fs.access(filepath);\n    } catch {\n      // File doesn't exist - delete from index and manifest using normalized path\n      if (verbose) {\n        console.error(`[Lien] File deleted: ${normalizedPath}`);\n      }\n      await vectorDB.deleteByFile(normalizedPath);\n      \n      const manifest = new ManifestManager(vectorDB.dbPath);\n      await manifest.removeFile(normalizedPath);\n      return;\n    }\n    \n    // Read file content\n    const content = await fs.readFile(filepath, 'utf-8');\n    \n    // Process file content (chunking + embeddings) - use normalized path for storage\n    const result = await processFileContent(normalizedPath, content, embeddings, config, verbose || false);\n    \n    // Get actual file mtime for manifest\n    const stats = await fs.stat(filepath);\n    const manifest = new ManifestManager(vectorDB.dbPath);\n    \n    if (result === null) {\n      // Empty file - remove from vector DB but keep in manifest with chunkCount: 0\n      await vectorDB.deleteByFile(normalizedPath);\n      await manifest.updateFile(normalizedPath, {\n        filepath: normalizedPath,\n        lastModified: stats.mtimeMs,\n        chunkCount: 0,\n      });\n      return;\n    }\n    \n    // Non-empty file - update in database (atomic: delete old + insert new)\n    await vectorDB.updateFile(\n      normalizedPath,\n      result.vectors,\n      result.chunks.map(c => c.metadata),\n      result.texts\n    );\n    \n    // Update manifest after successful indexing\n    await manifest.updateFile(normalizedPath, {\n      filepath: normalizedPath,\n      lastModified: stats.mtimeMs,\n      chunkCount: result.chunkCount,\n    });\n    \n    if (verbose) {\n      console.error(`[Lien] ‚úì Updated ${normalizedPath} (${result.chunkCount} chunks)`);\n    }\n  } catch (error) {\n    // Log error but don't throw - we want to continue with other files\n    console.error(`[Lien] ‚ö†Ô∏è  Failed to index ${normalizedPath}: ${error}`);\n  }\n}\n\n/**\n * Process a single file, returning a Result type.\n * This helper makes error handling explicit and testable.\n * \n * @param filepath - Original filepath (may be absolute)\n * @param normalizedPath - Normalized relative path for storage\n */\nasync function processSingleFileForIndexing(\n  filepath: string,\n  normalizedPath: string,\n  embeddings: EmbeddingService,\n  config: LienConfig | LegacyLienConfig,\n  verbose: boolean\n): Promise<Result<FileProcessResult, string>> {\n  try {\n    // Read file stats and content using original path (for filesystem access)\n    const stats = await fs.stat(filepath);\n    const content = await fs.readFile(filepath, 'utf-8');\n    \n    // Process content using normalized path (for storage)\n    const result = await processFileContent(normalizedPath, content, embeddings, config, verbose);\n    \n    return Ok({\n      filepath: normalizedPath,  // Store normalized path\n      result,\n      mtime: stats.mtimeMs,\n    });\n  } catch (error) {\n    return Err(`Failed to process ${normalizedPath}: ${error}`);\n  }\n}\n\n/**\n * Indexes multiple files incrementally.\n * Processes files sequentially for simplicity and reliability.\n * \n * Uses Result type for explicit error handling, making it easier to test\n * and reason about failure modes.\n * \n * Note: This function counts both successfully indexed files AND successfully\n * handled deletions (files that don't exist but were removed from the index).\n * \n * @param filepaths - Array of absolute file paths to index\n * @param vectorDB - Initialized VectorDB instance\n * @param embeddings - Initialized embeddings service\n * @param config - Lien configuration\n * @param options - Optional settings\n * @returns Number of successfully processed files (indexed or deleted)\n */\nexport async function indexMultipleFiles(\n  filepaths: string[],\n  vectorDB: VectorDB,\n  embeddings: EmbeddingService,\n  config: LienConfig | LegacyLienConfig,\n  options: IncrementalIndexOptions = {}\n): Promise<number> {\n  const { verbose } = options;\n  let processedCount = 0;\n  \n  // Batch manifest updates for performance\n  const manifestEntries: Array<{ filepath: string; chunkCount: number; mtime: number }> = [];\n  \n  // Process each file sequentially (simple and reliable)\n  for (const filepath of filepaths) {\n    // Normalize to relative path for consistent storage and queries\n    // This ensures paths from git diff (absolute) match paths from scanner (relative)\n    const normalizedPath = normalizeToRelativePath(filepath);\n    \n    const result = await processSingleFileForIndexing(filepath, normalizedPath, embeddings, config, verbose || false);\n    \n    if (isOk(result)) {\n      const { filepath: storedPath, result: processResult, mtime } = result.value;\n      \n      if (processResult === null) {\n        // Empty file - remove from vector DB but keep in manifest with chunkCount: 0\n        try {\n          await vectorDB.deleteByFile(storedPath);\n        } catch (error) {\n          // Ignore errors if file wasn't in index\n        }\n        \n        // Update manifest immediately for empty files (not batched)\n        const manifest = new ManifestManager(vectorDB.dbPath);\n        await manifest.updateFile(storedPath, {\n          filepath: storedPath,\n          lastModified: mtime,\n          chunkCount: 0,\n        });\n        \n        processedCount++;\n        continue;\n      }\n      \n      // Non-empty file - delete old chunks if they exist\n      try {\n        await vectorDB.deleteByFile(storedPath);\n      } catch (error) {\n        // Ignore - file might not be in index yet\n      }\n      \n      // Insert new chunks\n      await vectorDB.insertBatch(\n        processResult.vectors,\n        processResult.chunks.map(c => c.metadata),\n        processResult.texts\n      );\n      \n      // Queue manifest update (batch at end)\n      manifestEntries.push({\n        filepath: storedPath,\n        chunkCount: processResult.chunkCount,\n        mtime,\n      });\n      \n      if (verbose) {\n        console.error(`[Lien] ‚úì Updated ${storedPath} (${processResult.chunkCount} chunks)`);\n      }\n      \n      processedCount++;\n    } else {\n      // File doesn't exist or couldn't be read - handle deletion\n      if (verbose) {\n        console.error(`[Lien] ${result.error}`);\n      }\n      \n      try {\n        await vectorDB.deleteByFile(normalizedPath);\n        const manifest = new ManifestManager(vectorDB.dbPath);\n        await manifest.removeFile(normalizedPath);\n      } catch (error) {\n        // Ignore errors if file wasn't in index\n        if (verbose) {\n          console.error(`[Lien] Note: ${normalizedPath} not in index`);\n        }\n      }\n      \n      // Count as processed regardless of deletion success/failure\n      processedCount++;\n    }\n  }\n  \n  // Batch update manifest at the end (much faster than updating after each file)\n  if (manifestEntries.length > 0) {\n    const manifest = new ManifestManager(vectorDB.dbPath);\n    await manifest.updateFiles(\n      manifestEntries.map(entry => ({\n        filepath: entry.filepath,\n        lastModified: entry.mtime, // Use actual file mtime for accurate change detection\n        chunkCount: entry.chunkCount,\n      }))\n    );\n  }\n  \n  return processedCount;\n}\n\n","/**\n * Result type for explicit error handling.\n * \n * Provides a type-safe alternative to throwing exceptions, making error\n * handling explicit in function signatures.\n * \n * @example\n * ```typescript\n * function divide(a: number, b: number): Result<number, string> {\n *   if (b === 0) {\n *     return Err('Division by zero');\n *   }\n *   return Ok(a / b);\n * }\n * \n * const result = divide(10, 2);\n * if (isOk(result)) {\n *   console.log(result.value); // 5\n * } else {\n *   console.error(result.error);\n * }\n * ```\n */\n\n/**\n * Result type representing either success (Ok) or failure (Err)\n */\nexport type Result<T, E = Error> = \n  | { ok: true; value: T }\n  | { ok: false; error: E };\n\n/**\n * Creates a successful Result containing a value\n */\nexport function Ok<T>(value: T): Result<T, never> {\n  return { ok: true, value };\n}\n\n/**\n * Creates a failed Result containing an error\n */\nexport function Err<E>(error: E): Result<never, E> {\n  return { ok: false, error };\n}\n\n/**\n * Type guard to check if a Result is Ok\n */\nexport function isOk<T, E>(result: Result<T, E>): result is { ok: true; value: T } {\n  return result.ok;\n}\n\n/**\n * Type guard to check if a Result is Err\n */\nexport function isErr<T, E>(result: Result<T, E>): result is { ok: false; error: E } {\n  return !result.ok;\n}\n\n/**\n * Unwraps a Result, throwing if it's an error\n * @throws {E} The error if Result is Err\n */\nexport function unwrap<T, E>(result: Result<T, E>): T {\n  if (isOk(result)) {\n    return result.value;\n  }\n  throw result.error;\n}\n\n/**\n * Unwraps a Result or returns a default value if it's an error\n */\nexport function unwrapOr<T, E>(result: Result<T, E>, defaultValue: T): T {\n  if (isOk(result)) {\n    return result.value;\n  }\n  return defaultValue;\n}\n","/**\n * ChunkBatchProcessor - Handles concurrent chunk accumulation and batch processing.\n *\n * Extracted from performFullIndex to:\n * 1. Encapsulate mutex/lock management complexity\n * 2. Make the batch processing logic testable\n * 3. Separate concerns (accumulation vs processing vs coordination)\n *\n * Key responsibilities:\n * - Accumulate chunks from concurrent file processing\n * - Batch chunks for embedding generation\n * - Manage concurrent access with mutex pattern\n * - Process batches through embedding ‚Üí vectordb pipeline\n */\n\nimport type { VectorDB } from '../vectordb/lancedb.js';\nimport type { EmbeddingService } from '../embeddings/types.js';\nimport type { ProgressTracker } from './progress-tracker.js';\nimport type { CodeChunk } from './types.js';\nimport { EMBEDDING_MICRO_BATCH_SIZE } from '../constants.js';\n\n/** A chunk with its content ready for embedding */\nexport interface ChunkWithContent {\n  chunk: CodeChunk;\n  content: string;\n}\n\n/** Configuration for batch processing */\nexport interface BatchProcessorConfig {\n  /** Number of chunks to accumulate before triggering a batch */\n  batchThreshold: number;\n  /** Size of embedding batches (for API/memory limits) */\n  embeddingBatchSize: number;\n}\n\n/** Result of adding chunks - includes file metadata for manifest */\nexport interface FileIndexEntry {\n  filepath: string;\n  chunkCount: number;\n  mtime: number;\n}\n\n/**\n * Process embeddings in micro-batches to prevent event loop blocking.\n * Yields to the event loop between batches for UI responsiveness.\n */\nexport async function processEmbeddingMicroBatches(\n  texts: string[],\n  embeddings: EmbeddingService\n): Promise<Float32Array[]> {\n  const results: Float32Array[] = [];\n  \n  for (let j = 0; j < texts.length; j += EMBEDDING_MICRO_BATCH_SIZE) {\n    const microBatch = texts.slice(j, Math.min(j + EMBEDDING_MICRO_BATCH_SIZE, texts.length));\n    const microResults = await embeddings.embedBatch(microBatch);\n    results.push(...microResults);\n    \n    // Yield to event loop for UI responsiveness\n    await new Promise(resolve => setImmediate(resolve));\n  }\n  \n  return results;\n}\n\n/**\n * ChunkBatchProcessor handles the complex concurrent chunk accumulation\n * and batch processing logic for indexing.\n *\n * Usage:\n * ```typescript\n * const processor = new ChunkBatchProcessor(vectorDB, embeddings, config, tracker);\n *\n * // From concurrent file processing tasks:\n * await processor.addChunks(chunks, filepath, mtime);\n *\n * // After all files processed:\n * await processor.flush();\n *\n * // Get results:\n * const { processedChunks, indexedFiles } = processor.getResults();\n * ```\n */\nexport class ChunkBatchProcessor {\n  private readonly accumulator: ChunkWithContent[] = [];\n  private readonly indexedFiles: FileIndexEntry[] = [];\n  private processedChunkCount = 0;\n\n  // Mutex state for concurrent access protection\n  private addChunksLock: Promise<void> | null = null;\n  private processingQueue: Promise<void> | null = null;\n\n  constructor(\n    private readonly vectorDB: VectorDB,\n    private readonly embeddings: EmbeddingService,\n    private readonly config: BatchProcessorConfig,\n    private readonly progressTracker: ProgressTracker\n  ) {}\n\n  /**\n   * Add chunks from a processed file.\n   * Thread-safe: uses mutex to prevent race conditions with concurrent calls.\n   *\n   * @param chunks - Code chunks to add\n   * @param filepath - Source file path (for manifest)\n   * @param mtime - File modification time in ms (for change detection)\n   */\n  async addChunks(\n    chunks: CodeChunk[],\n    filepath: string,\n    mtime: number\n  ): Promise<void> {\n    if (chunks.length === 0) {\n      return;\n    }\n\n    // Wait for any in-progress add operation (mutex acquire)\n    if (this.addChunksLock) {\n      await this.addChunksLock;\n    }\n\n    // Create new lock promise\n    let releaseLock!: () => void;\n    this.addChunksLock = new Promise<void>(resolve => {\n      releaseLock = resolve;\n    });\n\n    try {\n      // Critical section: modify shared state\n      for (const chunk of chunks) {\n        this.accumulator.push({\n          chunk,\n          content: chunk.content,\n        });\n      }\n\n      // Track file for manifest\n      this.indexedFiles.push({\n        filepath,\n        chunkCount: chunks.length,\n        mtime,\n      });\n\n      // Process if batch threshold reached\n      if (this.accumulator.length >= this.config.batchThreshold) {\n        await this.triggerProcessing();\n      }\n    } finally {\n      // Release mutex\n      releaseLock();\n      this.addChunksLock = null;\n    }\n  }\n\n  /**\n   * Flush any remaining accumulated chunks.\n   * Call this after all files have been processed.\n   */\n  async flush(): Promise<void> {\n    this.progressTracker.setMessage?.('Processing final chunks...');\n    await this.triggerProcessing();\n  }\n\n  /**\n   * Get processing results.\n   */\n  getResults(): { processedChunks: number; indexedFiles: FileIndexEntry[] } {\n    return {\n      processedChunks: this.processedChunkCount,\n      indexedFiles: [...this.indexedFiles],\n    };\n  }\n\n  /**\n   * Trigger batch processing. Uses queue-based synchronization\n   * to prevent TOCTOU race conditions.\n   */\n  private async triggerProcessing(): Promise<void> {\n    // Chain onto existing processing promise to create a queue\n    if (this.processingQueue) {\n      this.processingQueue = this.processingQueue.then(() => this.doProcess());\n    } else {\n      this.processingQueue = this.doProcess();\n    }\n    return this.processingQueue;\n  }\n\n  /**\n   * The actual batch processing logic.\n   * Processes accumulated chunks through embedding ‚Üí vectordb pipeline.\n   */\n  private async doProcess(): Promise<void> {\n    if (this.accumulator.length === 0) {\n      return;\n    }\n\n    const currentPromise = this.processingQueue;\n\n    try {\n      // Drain accumulator atomically\n      const toProcess = this.accumulator.splice(0, this.accumulator.length);\n\n      // Process in batches for memory/API limits\n      for (let i = 0; i < toProcess.length; i += this.config.embeddingBatchSize) {\n        const batch = toProcess.slice(\n          i,\n          Math.min(i + this.config.embeddingBatchSize, toProcess.length)\n        );\n        const texts = batch.map(item => item.content);\n\n        // Generate embeddings\n        this.progressTracker.setMessage?.('Generating embeddings...');\n        const embeddingVectors = await processEmbeddingMicroBatches(texts, this.embeddings);\n        this.processedChunkCount += batch.length;\n\n        // Insert into vector database\n        this.progressTracker.setMessage?.(`Inserting ${batch.length} chunks...`);\n        await this.vectorDB.insertBatch(\n          embeddingVectors,\n          batch.map(item => item.chunk.metadata),\n          texts\n        );\n\n        // Yield to event loop\n        await new Promise(resolve => setImmediate(resolve));\n      }\n\n      this.progressTracker.setMessage?.('Processing files...');\n    } finally {\n      // Clear queue reference if we're the current operation\n      if (this.processingQueue === currentPromise) {\n        this.processingQueue = null;\n      }\n    }\n  }\n}\n","/**\n * Complexity analysis types for code quality insights\n */\n\n/**\n * Risk level ordering for comparison operations.\n * Higher value = higher risk.\n */\nexport const RISK_ORDER = { low: 0, medium: 1, high: 2, critical: 3 } as const;\n\n/**\n * Risk level type derived from RISK_ORDER keys\n */\nexport type RiskLevel = keyof typeof RISK_ORDER;\n\n/**\n * Type of complexity metric being measured\n */\nexport type ComplexityMetricType = 'cyclomatic' | 'cognitive' | 'halstead_effort' | 'halstead_bugs';\n\n/**\n * Halstead metric details for Halstead-type violations\n */\nexport interface HalsteadDetails {\n  volume: number;\n  difficulty: number;\n  effort: number;\n  bugs: number;\n}\n\nexport interface ComplexityViolation {\n  filepath: string;\n  startLine: number;\n  endLine: number;\n  symbolName: string;\n  symbolType: 'function' | 'method' | 'class' | 'file';\n  language: string;\n  complexity: number;\n  threshold: number;\n  severity: 'warning' | 'error';\n  message: string;\n  /** Type of complexity metric (cyclomatic vs cognitive vs halstead) */\n  metricType: ComplexityMetricType;\n  /** Halstead-specific details when metricType is halstead_* */\n  halsteadDetails?: HalsteadDetails;\n}\n\nexport interface FileComplexityData {\n  violations: ComplexityViolation[];\n  dependents: string[];\n  dependentCount?: number;\n  /** Test files associated with this source file. TODO: Populate when test-to-code mapping is implemented */\n  testAssociations: string[];\n  riskLevel: RiskLevel;\n  dependentComplexityMetrics?: {\n    averageComplexity: number;\n    maxComplexity: number;\n    filesWithComplexityData: number;\n  };\n}\n\nexport interface ComplexityReport {\n  summary: {\n    filesAnalyzed: number;\n    totalViolations: number;\n    bySeverity: { error: number; warning: number };\n    avgComplexity: number;\n    maxComplexity: number;\n  };\n  files: Record<string, FileComplexityData>;\n}\n\n","/**\n * Shared path matching utilities for dependency analysis.\n * \n * These functions handle path normalization and matching logic used by\n * dependency analysis to find reverse dependencies.\n */\n\n/**\n * Normalizes a file path for comparison.\n * \n * - Removes quotes and trims whitespace\n * - Converts backslashes to forward slashes\n * - Strips file extensions (.ts, .tsx, .js, .jsx)\n * - Converts absolute paths to relative (if within workspace root)\n * \n * @param path - The path to normalize\n * @param workspaceRoot - The workspace root directory (normalized with forward slashes)\n * @returns Normalized path\n */\nexport function normalizePath(path: string, workspaceRoot: string): string {\n  let normalized = path.replace(/['\"]/g, '').trim().replace(/\\\\/g, '/');\n  \n  // Normalize extensions: .ts/.tsx/.js/.jsx ‚Üí all treated as equivalent\n  // This handles TypeScript's ESM requirement of .js imports for .ts files\n  normalized = normalized.replace(/\\.(ts|tsx|js|jsx)$/, '');\n  \n  // Normalize to relative path if it starts with workspace root\n  if (normalized.startsWith(workspaceRoot + '/')) {\n    normalized = normalized.substring(workspaceRoot.length + 1);\n  }\n  \n  return normalized;\n}\n\n/**\n * Checks if a pattern matches at path component boundaries.\n * \n * Ensures matches occur at proper boundaries (/, .) to avoid false positives like:\n * - \"logger\" matching \"logger-utils\" ‚ùå\n * - \"src/logger\" matching \"src/logger-service\" ‚ùå\n * \n * @param str - The string to search in\n * @param pattern - The pattern to search for\n * @returns True if pattern matches at a boundary\n */\nexport function matchesAtBoundary(str: string, pattern: string): boolean {\n  const index = str.indexOf(pattern);\n  if (index === -1) return false;\n  \n  // Check character before match (must be start or path separator)\n  const charBefore = index > 0 ? str[index - 1] : '/';\n  if (charBefore !== '/' && index !== 0) return false;\n  \n  // Check character after match (must be end or path separator)\n  // Extensions are already stripped during normalization, so we only need to check for '/' as a valid path separator\n  const endIndex = index + pattern.length;\n  if (endIndex === str.length) return true;\n  const charAfter = str[endIndex];\n  return charAfter === '/';\n}\n\n/**\n * Determines if an import path matches a target file path.\n * \n * Handles various matching strategies:\n * 1. Exact match\n * 2. Target path appears in import (at boundaries)\n * 3. Import path appears in target (at boundaries)\n * 4. Relative imports (./logger vs src/utils/logger)\n * \n * @param normalizedImport - Normalized import path\n * @param normalizedTarget - Normalized target file path\n * @returns True if the import matches the target file\n */\nexport function matchesFile(normalizedImport: string, normalizedTarget: string): boolean {\n  // Exact match\n  if (normalizedImport === normalizedTarget) return true;\n  \n  // Strategy 1: Check if target path appears in import at path boundaries\n  if (matchesAtBoundary(normalizedImport, normalizedTarget)) {\n    return true;\n  }\n  \n  // Strategy 2: Check if import path appears in target (for longer target paths)\n  if (matchesAtBoundary(normalizedTarget, normalizedImport)) {\n    return true;\n  }\n  \n  // Strategy 3: Handle relative imports (./logger vs src/utils/logger)\n  // Remove leading ./ and ../ from import\n  const cleanedImport = normalizedImport.replace(/^(\\.\\.?\\/)+/, '');\n  if (matchesAtBoundary(cleanedImport, normalizedTarget) || \n      matchesAtBoundary(normalizedTarget, cleanedImport)) {\n    return true;\n  }\n  \n  return false;\n}\n\n/**\n * Gets a canonical path representation (relative to workspace, with extension).\n * \n * @param filepath - The file path to canonicalize\n * @param workspaceRoot - The workspace root directory (normalized with forward slashes)\n * @returns Canonical path\n */\nexport function getCanonicalPath(filepath: string, workspaceRoot: string): string {\n  let canonical = filepath.replace(/\\\\/g, '/');\n  if (canonical.startsWith(workspaceRoot + '/')) {\n    canonical = canonical.substring(workspaceRoot.length + 1);\n  }\n  return canonical;\n}\n\n/**\n * Determines if a file is a test file based on naming conventions.\n * \n * Uses precise regex patterns to avoid false positives:\n * - Files with .test. or .spec. extensions (e.g., foo.test.ts, bar.spec.js)\n * - Files in test/, tests/, or __tests__/ directories\n * \n * Avoids false positives like:\n * - contest.ts (contains \".test.\" but isn't a test)\n * - latest/config.ts (contains \"/test/\" but isn't a test)\n * \n * @param filepath - The file path to check\n * @returns True if the file is a test file\n */\nexport function isTestFile(filepath: string): boolean {\n  return /\\.(test|spec)\\.[^/]+$/.test(filepath) ||\n         /(^|[/\\\\])(test|tests|__tests__)[/\\\\]/.test(filepath);\n}\n","import { SearchResult } from '../vectordb/types.js';\nimport { normalizePath, getCanonicalPath, matchesFile, isTestFile } from '../utils/path-matching.js';\nimport { RISK_ORDER, RiskLevel } from '../insights/types.js';\n\n/**\n * Risk level thresholds for dependent count.\n * Based on impact analysis: more dependents = higher risk of breaking changes.\n */\nexport const DEPENDENT_COUNT_THRESHOLDS = {\n  LOW: 5,       // Few dependents, safe to change\n  MEDIUM: 15,   // Moderate impact, review dependents\n  HIGH: 30,     // High impact, careful planning needed\n} as const;\n\n/**\n * Complexity thresholds for risk assessment.\n * Based on cyclomatic complexity: higher complexity = harder to change safely.\n */\nexport const COMPLEXITY_THRESHOLDS = {\n  HIGH_COMPLEXITY_DEPENDENT: 10,  // Individual file is complex\n  CRITICAL_AVG: 15,              // Average complexity indicates systemic complexity\n  CRITICAL_MAX: 25,              // Peak complexity indicates hotspot\n  HIGH_AVG: 10,                  // Moderately complex on average\n  HIGH_MAX: 20,                  // Some complex functions exist\n  MEDIUM_AVG: 6,                 // Slightly above simple code\n  MEDIUM_MAX: 15,                // Occasional branching\n} as const;\n\nexport interface FileComplexityInfo {\n  filepath: string;\n  avgComplexity: number;\n  maxComplexity: number;\n  complexityScore: number;\n  chunksWithComplexity: number;\n}\n\nexport interface DependencyAnalysisResult {\n  dependents: Array<{\n    filepath: string;\n    isTestFile: boolean;\n  }>;\n  dependentCount: number;\n  riskLevel: RiskLevel;\n  complexityMetrics?: {\n    averageComplexity: number;\n    maxComplexity: number;\n    filesWithComplexityData: number;\n    highComplexityDependents: Array<{\n      filepath: string;\n      maxComplexity: number;\n      avgComplexity: number;\n    }>;\n    complexityRiskBoost: RiskLevel;\n  };\n}\n\n/**\n * Creates a cached path normalizer to avoid repeated string operations.\n * \n * @param workspaceRoot - The workspace root directory for path normalization\n * @returns A function that normalizes and caches file paths\n */\nfunction createPathNormalizer(workspaceRoot: string): (path: string) => string {\n  const cache = new Map<string, string>();\n  return (path: string): string => {\n    const cached = cache.get(path);\n    if (cached !== undefined) return cached;\n    const normalized = normalizePath(path, workspaceRoot);\n    cache.set(path, normalized);\n    return normalized;\n  };\n}\n\n/**\n * Builds an index mapping normalized import paths to chunks that import them.\n * Enables O(1) lookup instead of O(n*m) iteration.\n * \n * @param chunks - All chunks from the vector database\n * @param normalizePathCached - Cached path normalization function\n * @returns Map of normalized import paths to chunks that import them\n */\nfunction buildImportIndex(\n  chunks: SearchResult[],\n  normalizePathCached: (path: string) => string\n): Map<string, SearchResult[]> {\n  const importIndex = new Map<string, SearchResult[]>();\n  \n  for (const chunk of chunks) {\n    const imports = chunk.metadata.imports || [];\n    for (const imp of imports) {\n      const normalizedImport = normalizePathCached(imp);\n      let chunkList = importIndex.get(normalizedImport);\n      if (!chunkList) {\n        chunkList = [];\n        importIndex.set(normalizedImport, chunkList);\n      }\n      chunkList.push(chunk);\n    }\n  }\n  \n  return importIndex;\n}\n\n/**\n * Finds all chunks that import the target file using index + fuzzy matching.\n * \n * @param normalizedTarget - The normalized path of the target file\n * @param importIndex - Index mapping import paths to chunks\n * @returns Array of chunks that import the target file (deduplicated)\n */\nfunction findDependentChunks(\n  normalizedTarget: string,\n  importIndex: Map<string, SearchResult[]>\n): SearchResult[] {\n  const dependentChunks: SearchResult[] = [];\n  const seenChunkIds = new Set<string>();\n  \n  const addChunk = (chunk: SearchResult): void => {\n    const chunkId = `${chunk.metadata.file}:${chunk.metadata.startLine}-${chunk.metadata.endLine}`;\n    if (!seenChunkIds.has(chunkId)) {\n      dependentChunks.push(chunk);\n      seenChunkIds.add(chunkId);\n    }\n  };\n  \n  // Direct index lookup (fastest path)\n  const directMatches = importIndex.get(normalizedTarget);\n  if (directMatches) {\n    for (const chunk of directMatches) {\n      addChunk(chunk);\n    }\n  }\n  \n  // Fuzzy match for relative imports and path variations\n  // Note: This is O(M) where M = unique import paths. For large codebases with many\n  // violations, consider caching fuzzy match results at a higher level.\n  for (const [normalizedImport, chunks] of importIndex.entries()) {\n    if (normalizedImport !== normalizedTarget && matchesFile(normalizedImport, normalizedTarget)) {\n      for (const chunk of chunks) {\n        addChunk(chunk);\n      }\n    }\n  }\n  \n  return dependentChunks;\n}\n\n/**\n * Groups chunks by their canonical file path.\n * \n * @param chunks - Array of chunks to group\n * @param workspaceRoot - The workspace root directory\n * @returns Map of canonical file paths to their chunks\n */\nfunction groupChunksByFile(\n  chunks: SearchResult[],\n  workspaceRoot: string\n): Map<string, SearchResult[]> {\n  const chunksByFile = new Map<string, SearchResult[]>();\n  \n  for (const chunk of chunks) {\n    const canonical = getCanonicalPath(chunk.metadata.file, workspaceRoot);\n    let existing = chunksByFile.get(canonical);\n    if (!existing) {\n      existing = [];\n      chunksByFile.set(canonical, existing);\n    }\n    existing.push(chunk);\n  }\n  \n  return chunksByFile;\n}\n\n/**\n * Calculates complexity metrics for each file based on its chunks.\n * \n * @param chunksByFile - Map of file paths to their chunks\n * @returns Array of complexity info for files with complexity data\n */\nfunction calculateFileComplexities(\n  chunksByFile: Map<string, SearchResult[]>\n): FileComplexityInfo[] {\n  const fileComplexities: FileComplexityInfo[] = [];\n  \n  for (const [filepath, chunks] of chunksByFile.entries()) {\n    const complexities = chunks\n      .map(c => c.metadata.complexity)\n      .filter((c): c is number => typeof c === 'number' && c > 0);\n    \n    if (complexities.length > 0) {\n      const sum = complexities.reduce((a, b) => a + b, 0);\n      const avg = sum / complexities.length;\n      const max = Math.max(...complexities);\n      \n      fileComplexities.push({\n        filepath,\n        avgComplexity: Math.round(avg * 10) / 10,\n        maxComplexity: max,\n        complexityScore: sum,\n        chunksWithComplexity: complexities.length,\n      });\n    }\n  }\n  \n  return fileComplexities;\n}\n\n/**\n * Calculates overall complexity metrics from per-file data.\n * \n * @param fileComplexities - Array of per-file complexity info\n * @returns Aggregated complexity metrics, or undefined if no data\n */\nfunction calculateOverallComplexityMetrics(\n  fileComplexities: FileComplexityInfo[]\n): DependencyAnalysisResult['complexityMetrics'] | undefined {\n  if (fileComplexities.length === 0) {\n    return undefined;\n  }\n  \n  const allAvgs = fileComplexities.map(f => f.avgComplexity);\n  const allMaxes = fileComplexities.map(f => f.maxComplexity);\n  const totalAvg = allAvgs.reduce((a, b) => a + b, 0) / allAvgs.length;\n  const globalMax = Math.max(...allMaxes);\n  \n  // Identify high-complexity dependents (top 5)\n  const highComplexityDependents = fileComplexities\n    .filter(f => f.maxComplexity > COMPLEXITY_THRESHOLDS.HIGH_COMPLEXITY_DEPENDENT)\n    .sort((a, b) => b.maxComplexity - a.maxComplexity)\n    .slice(0, 5)\n    .map(f => ({\n      filepath: f.filepath,\n      maxComplexity: f.maxComplexity,\n      avgComplexity: f.avgComplexity,\n    }));\n  \n  // Calculate complexity-based risk boost\n  const complexityRiskBoost = calculateComplexityRiskBoost(totalAvg, globalMax);\n  \n  return {\n    averageComplexity: Math.round(totalAvg * 10) / 10,\n    maxComplexity: globalMax,\n    filesWithComplexityData: fileComplexities.length,\n    highComplexityDependents,\n    complexityRiskBoost,\n  };\n}\n\n/**\n * Determines risk level based on complexity thresholds.\n * \n * @param avgComplexity - Average complexity across all files\n * @param maxComplexity - Maximum complexity found in any file\n * @returns Risk level based on complexity thresholds\n */\nfunction calculateComplexityRiskBoost(avgComplexity: number, maxComplexity: number): RiskLevel {\n  if (avgComplexity > COMPLEXITY_THRESHOLDS.CRITICAL_AVG || maxComplexity > COMPLEXITY_THRESHOLDS.CRITICAL_MAX) {\n    return 'critical';\n  }\n  if (avgComplexity > COMPLEXITY_THRESHOLDS.HIGH_AVG || maxComplexity > COMPLEXITY_THRESHOLDS.HIGH_MAX) {\n    return 'high';\n  }\n  if (avgComplexity > COMPLEXITY_THRESHOLDS.MEDIUM_AVG || maxComplexity > COMPLEXITY_THRESHOLDS.MEDIUM_MAX) {\n    return 'medium';\n  }\n  return 'low';\n}\n\n/**\n * Calculates risk level based on dependent count.\n * \n * @param count - Number of dependent files\n * @returns Risk level based on dependent count thresholds\n */\nfunction calculateRiskLevelFromCount(count: number): RiskLevel {\n  if (count <= DEPENDENT_COUNT_THRESHOLDS.LOW) {\n    return 'low';\n  }\n  if (count <= DEPENDENT_COUNT_THRESHOLDS.MEDIUM) {\n    return 'medium';\n  }\n  if (count <= DEPENDENT_COUNT_THRESHOLDS.HIGH) {\n    return 'high';\n  }\n  return 'critical';\n}\n\n/**\n * Analyzes dependencies for a given file by finding all chunks that import it.\n * \n * @param targetFilepath - The file to analyze dependencies for\n * @param allChunks - All chunks from the vector database\n * @param workspaceRoot - The workspace root directory\n * @returns Dependency analysis including dependents, count, and risk level\n */\nexport function analyzeDependencies(\n  targetFilepath: string,\n  allChunks: SearchResult[],\n  workspaceRoot: string\n): DependencyAnalysisResult {\n  // Create cached path normalizer\n  const normalizePathCached = createPathNormalizer(workspaceRoot);\n  \n  // Build import index for efficient lookup\n  const importIndex = buildImportIndex(allChunks, normalizePathCached);\n  \n  // Find all dependent chunks\n  const normalizedTarget = normalizePathCached(targetFilepath);\n  const dependentChunks = findDependentChunks(normalizedTarget, importIndex);\n  \n  // Group by file for analysis\n  const chunksByFile = groupChunksByFile(dependentChunks, workspaceRoot);\n  \n  // Calculate complexity metrics\n  const fileComplexities = calculateFileComplexities(chunksByFile);\n  const complexityMetrics = calculateOverallComplexityMetrics(fileComplexities);\n  \n  // Build dependents list\n  const dependents = Array.from(chunksByFile.keys()).map(filepath => ({\n    filepath,\n    isTestFile: isTestFile(filepath),\n  }));\n  \n  // Calculate risk level\n  let riskLevel = calculateRiskLevelFromCount(dependents.length);\n  \n  // Boost risk level if complexity warrants it\n  if (complexityMetrics?.complexityRiskBoost) {\n    if (RISK_ORDER[complexityMetrics.complexityRiskBoost] > RISK_ORDER[riskLevel]) {\n      riskLevel = complexityMetrics.complexityRiskBoost;\n    }\n  }\n  \n  return {\n    dependents,\n    dependentCount: dependents.length,\n    riskLevel,\n    complexityMetrics,\n  };\n}\n","import { VectorDB } from '../vectordb/lancedb.js';\nimport { LienConfig } from '../config/schema.js';\nimport { ComplexityViolation, ComplexityReport, FileComplexityData, RISK_ORDER, RiskLevel, HalsteadDetails } from './types.js';\nimport { ChunkMetadata } from '../indexer/types.js';\nimport { analyzeDependencies } from '../indexer/dependency-analyzer.js';\nimport { SearchResult } from '../vectordb/types.js';\n\n/**\n * Hardcoded severity multipliers:\n * - Warning: triggers at 1x threshold (e.g., testPaths >= 15)\n * - Error: triggers at 2x threshold (e.g., testPaths >= 30)\n */\nconst SEVERITY = { warning: 1.0, error: 2.0 } as const;\n\n/**\n * Analyzer for code complexity based on indexed codebase\n */\nexport class ComplexityAnalyzer {\n  constructor(\n    private vectorDB: VectorDB,\n    private config: LienConfig\n  ) {}\n\n  /**\n   * Analyze complexity of codebase or specific files\n   * @param files - Optional list of specific files to analyze\n   * @returns Complexity report with violations and summary\n   */\n  async analyze(files?: string[]): Promise<ComplexityReport> {\n    // 1. Get all chunks from index (uses full scan internally for LanceDB)\n    // Note: We fetch all chunks even with --files filter because dependency analysis\n    // needs the complete dataset to find dependents accurately\n    const allChunks = await this.vectorDB.scanAll();\n    \n    // 2. Filter to specified files if provided\n    const chunks = files \n      ? allChunks.filter(c => this.matchesAnyFile(c.metadata.file, files))\n      : allChunks;\n    \n    // 3. Find violations from filtered chunks\n    const violations = this.findViolations(chunks);\n    \n    // 4. Build report - pass filtered chunks for file list, but keep violations from those files\n    const report = this.buildReport(violations, chunks);\n    \n    // 5. Enrich files with violations with dependency data\n    this.enrichWithDependencies(report, allChunks as SearchResult[]);\n    \n    return report;\n  }\n\n  /**\n   * Normalize a file path to a consistent relative format\n   * Converts absolute paths to relative paths from workspace root\n   */\n  private normalizeFilePath(filepath: string): string {\n    const workspaceRoot = process.cwd();\n    // Convert to forward slashes first\n    const normalized = filepath.replace(/\\\\/g, '/');\n    const normalizedRoot = workspaceRoot.replace(/\\\\/g, '/');\n    \n    // Convert absolute paths to relative\n    if (normalized.startsWith(normalizedRoot + '/')) {\n      return normalized.slice(normalizedRoot.length + 1);\n    }\n    if (normalized.startsWith(normalizedRoot)) {\n      return normalized.slice(normalizedRoot.length);\n    }\n    return normalized;\n  }\n\n  /**\n   * Check if a chunk's file matches any of the target files\n   * Uses exact match or suffix matching to avoid unintended matches\n   */\n  private matchesAnyFile(chunkFile: string, targetFiles: string[]): boolean {\n    // Normalize to forward slashes for cross-platform consistency\n    // Don't use path.normalize() as its behavior is platform-dependent\n    const normalizedChunkFile = chunkFile.replace(/\\\\/g, '/');\n    return targetFiles.some(target => {\n      const normalizedTarget = target.replace(/\\\\/g, '/');\n      // Exact match or target is a suffix of the chunk file\n      return normalizedChunkFile === normalizedTarget || \n             normalizedChunkFile.endsWith('/' + normalizedTarget);\n    });\n  }\n\n  /**\n   * Create a violation if complexity exceeds threshold\n   */\n  private createViolation(\n    metadata: ChunkMetadata,\n    complexity: number,\n    baseThreshold: number,\n    metricType: ComplexityViolation['metricType']\n  ): ComplexityViolation | null {\n    const warningThreshold = baseThreshold * SEVERITY.warning;\n    const errorThreshold = baseThreshold * SEVERITY.error;\n\n    if (complexity < warningThreshold) return null;\n\n    const violationSeverity = complexity >= errorThreshold ? 'error' : 'warning';\n    const effectiveThreshold = violationSeverity === 'error' ? errorThreshold : warningThreshold;\n    \n    // Human-friendly messages\n    const message = metricType === 'cyclomatic'\n      ? `Needs ~${complexity} test cases for full coverage (threshold: ${Math.round(effectiveThreshold)})`\n      : `Mental load ${complexity} exceeds threshold ${Math.round(effectiveThreshold)} (hard to follow)`;\n\n    return {\n      filepath: metadata.file,\n      startLine: metadata.startLine,\n      endLine: metadata.endLine,\n      symbolName: metadata.symbolName || 'unknown',\n      symbolType: metadata.symbolType as 'function' | 'method',\n      language: metadata.language,\n      complexity,\n      threshold: Math.round(effectiveThreshold),\n      severity: violationSeverity,\n      message,\n      metricType,\n    };\n  }\n\n  /**\n   * Deduplicate and filter chunks to only function/method types.\n   * Handles potential index duplicates by tracking file+line ranges.\n   */\n  private getUniqueFunctionChunks(\n    chunks: Array<{ content: string; metadata: ChunkMetadata }>\n  ): ChunkMetadata[] {\n    const seen = new Set<string>();\n    const result: ChunkMetadata[] = [];\n    \n    for (const { metadata } of chunks) {\n      if (metadata.symbolType !== 'function' && metadata.symbolType !== 'method') continue;\n      \n      const key = `${metadata.file}:${metadata.startLine}-${metadata.endLine}`;\n      if (seen.has(key)) continue;\n      \n      seen.add(key);\n      result.push(metadata);\n    }\n    \n    return result;\n  }\n\n  /**\n   * Convert Halstead effort to time in minutes.\n   * Formula: Time (seconds) = Effort / 18 (Stroud number for mental discrimination)\n   *          Time (minutes) = Effort / (18 * 60) = Effort / 1080\n   */\n  private effortToMinutes(effort: number): number {\n    return effort / 1080;\n  }\n\n  /**\n   * Format minutes as human-readable time (e.g., \"2h 30m\" or \"45m\")\n   */\n  private formatTime(minutes: number): string {\n    if (minutes >= 60) {\n      const hours = Math.floor(minutes / 60);\n      const mins = Math.round(minutes % 60);\n      return mins > 0 ? `${hours}h ${mins}m` : `${hours}h`;\n    }\n    return `${Math.round(minutes)}m`;\n  }\n\n  /**\n   * Create a Halstead violation if metrics exceed thresholds\n   */\n  private createHalsteadViolation(\n    metadata: ChunkMetadata,\n    metricValue: number,\n    threshold: number,\n    metricType: 'halstead_effort' | 'halstead_bugs'\n  ): ComplexityViolation | null {\n    const warningThreshold = threshold * SEVERITY.warning;\n    const errorThreshold = threshold * SEVERITY.error;\n\n    if (metricValue < warningThreshold) return null;\n\n    const violationSeverity = metricValue >= errorThreshold ? 'error' : 'warning';\n    const effectiveThreshold = violationSeverity === 'error' ? errorThreshold : warningThreshold;\n    \n    // For effort, show time in minutes; for bugs, show decimal with 2 places\n    let message: string;\n    if (metricType === 'halstead_effort') {\n      const timeMinutes = this.effortToMinutes(metricValue);\n      const thresholdMinutes = this.effortToMinutes(effectiveThreshold);\n      message = `Time to understand ~${this.formatTime(timeMinutes)} exceeds threshold ${this.formatTime(thresholdMinutes)}`;\n    } else {\n      message = `Estimated bugs ${metricValue.toFixed(2)} exceeds threshold ${effectiveThreshold.toFixed(1)}`;\n    }\n\n    const halsteadDetails: HalsteadDetails = {\n      volume: metadata.halsteadVolume || 0,\n      difficulty: metadata.halsteadDifficulty || 0,\n      effort: metadata.halsteadEffort || 0,\n      bugs: metadata.halsteadBugs || 0,\n    };\n\n    // Store human-scale values for complexity/threshold:\n    // - halstead_effort: rounded to integer minutes for readability (typical values 60-300)\n    // - halstead_bugs: kept as decimal for precision (typical values < 5, e.g. 1.5, 2.27)\n    let complexity: number;\n    let displayThreshold: number;\n    if (metricType === 'halstead_effort') {\n      // Convert raw effort to minutes and round for comparable deltas\n      complexity = Math.round(this.effortToMinutes(metricValue));\n      displayThreshold = Math.round(this.effortToMinutes(effectiveThreshold));\n    } else {\n      // halstead_bugs: store as decimal for precision in small values\n      complexity = metricValue;\n      displayThreshold = effectiveThreshold;\n    }\n\n    return {\n      filepath: metadata.file,\n      startLine: metadata.startLine,\n      endLine: metadata.endLine,\n      symbolName: metadata.symbolName || 'unknown',\n      symbolType: metadata.symbolType as 'function' | 'method',\n      language: metadata.language,\n      complexity,\n      threshold: displayThreshold,\n      severity: violationSeverity,\n      message,\n      metricType,\n      halsteadDetails,\n    };\n  }\n\n  /**\n   * Check complexity metrics and create violations for a single chunk.\n   */\n  private checkChunkComplexity(\n    metadata: ChunkMetadata,\n    thresholds: { testPaths: number; mentalLoad: number; halsteadEffort?: number; estimatedBugs?: number }\n  ): ComplexityViolation[] {\n    const violations: ComplexityViolation[] = [];\n    \n    // Check test paths (cyclomatic complexity)\n    if (metadata.complexity) {\n      const v = this.createViolation(metadata, metadata.complexity, thresholds.testPaths, 'cyclomatic');\n      if (v) violations.push(v);\n    }\n    \n    // Check mental load (cognitive complexity)\n    if (metadata.cognitiveComplexity) {\n      const v = this.createViolation(metadata, metadata.cognitiveComplexity, thresholds.mentalLoad, 'cognitive');\n      if (v) violations.push(v);\n    }\n    \n    // Check time to understand (Halstead effort)\n    if (thresholds.halsteadEffort && metadata.halsteadEffort) {\n      const v = this.createHalsteadViolation(metadata, metadata.halsteadEffort, thresholds.halsteadEffort, 'halstead_effort');\n      if (v) violations.push(v);\n    }\n    \n    // Check estimated bugs\n    if (thresholds.estimatedBugs && metadata.halsteadBugs) {\n      const v = this.createHalsteadViolation(metadata, metadata.halsteadBugs, thresholds.estimatedBugs, 'halstead_bugs');\n      if (v) violations.push(v);\n    }\n    \n    return violations;\n  }\n\n  /**\n   * Convert time in minutes to Halstead effort.\n   * This is the inverse of effortToMinutes().\n   * Formula: Time (seconds) = Effort / 18 (Stroud number)\n   *          So: Effort = Time (minutes) * 60 * 18 = Time * 1080\n   */\n  private minutesToEffort(minutes: number): number {\n    return minutes * 1080;\n  }\n\n  /**\n   * Find all complexity violations based on thresholds.\n   * Checks cyclomatic, cognitive, and Halstead complexity.\n   */\n  private findViolations(chunks: Array<{ content: string; metadata: ChunkMetadata }>): ComplexityViolation[] {\n    const configThresholds = this.config.complexity?.thresholds;\n    \n    // Convert timeToUnderstandMinutes to effort internally\n    const halsteadEffort = configThresholds?.timeToUnderstandMinutes \n      ? this.minutesToEffort(configThresholds.timeToUnderstandMinutes)\n      : this.minutesToEffort(60); // Default: 60 minutes = 64,800 effort\n    \n    const thresholds = { \n      testPaths: configThresholds?.testPaths ?? 15, \n      mentalLoad: configThresholds?.mentalLoad ?? 15, \n      halsteadEffort, // Converted from minutes to effort internally (see above)\n      estimatedBugs: configThresholds?.estimatedBugs ?? 1.5, // Direct decimal value (no conversion needed)\n    };\n    const functionChunks = this.getUniqueFunctionChunks(chunks);\n    \n    return functionChunks.flatMap(metadata => \n      this.checkChunkComplexity(metadata, thresholds)\n    );\n  }\n\n  /**\n   * Build the final report with summary and per-file data\n   */\n  private buildReport(\n    violations: ComplexityViolation[],\n    allChunks: Array<{ content: string; metadata: ChunkMetadata }>\n  ): ComplexityReport {\n    // Normalize violation filepaths and group by normalized path\n    const fileViolationsMap = new Map<string, ComplexityViolation[]>();\n    for (const violation of violations) {\n      const normalizedPath = this.normalizeFilePath(violation.filepath);\n      // Update violation's filepath to normalized form\n      violation.filepath = normalizedPath;\n      const existing = fileViolationsMap.get(normalizedPath) || [];\n      existing.push(violation);\n      fileViolationsMap.set(normalizedPath, existing);\n    }\n\n    // Get unique files from all analyzed chunks, normalized to relative paths\n    const analyzedFiles = new Set(allChunks.map(c => this.normalizeFilePath(c.metadata.file)));\n\n    // Build file data\n    const files: Record<string, FileComplexityData> = {};\n    for (const filepath of analyzedFiles) {\n      const fileViolations = fileViolationsMap.get(filepath) || [];\n      files[filepath] = {\n        violations: fileViolations,\n        dependents: [], // Will be enriched later if needed\n        testAssociations: [], // Will be enriched later if needed\n        riskLevel: this.calculateRiskLevel(fileViolations),\n      };\n    }\n\n    // Calculate summary statistics\n    const errorCount = violations.filter(v => v.severity === 'error').length;\n    const warningCount = violations.filter(v => v.severity === 'warning').length;\n\n    // Calculate average and max complexity from all chunks with complexity data\n    const complexityValues = allChunks\n      .filter(c => c.metadata.complexity !== undefined && c.metadata.complexity > 0)\n      .map(c => c.metadata.complexity!);\n\n    const avgComplexity = complexityValues.length > 0\n      ? complexityValues.reduce((sum, val) => sum + val, 0) / complexityValues.length\n      : 0;\n\n    const maxComplexity = complexityValues.length > 0\n      ? Math.max(...complexityValues)\n      : 0;\n\n    return {\n      summary: {\n        filesAnalyzed: analyzedFiles.size,\n        totalViolations: violations.length,\n        bySeverity: { error: errorCount, warning: warningCount },\n        avgComplexity: Math.round(avgComplexity * 10) / 10, // Round to 1 decimal\n        maxComplexity,\n      },\n      files,\n    };\n  }\n\n  /**\n   * Calculate risk level based on violations\n   */\n  private calculateRiskLevel(violations: ComplexityViolation[]): RiskLevel {\n    if (violations.length === 0) return 'low';\n\n    const hasErrors = violations.some(v => v.severity === 'error');\n    const errorCount = violations.filter(v => v.severity === 'error').length;\n\n    if (errorCount >= 3) return 'critical';\n    if (hasErrors) return 'high';\n    if (violations.length >= 3) return 'medium';\n    return 'low';\n  }\n\n  /**\n   * Enrich files with violations with dependency data\n   * This adds:\n   * - List of dependent files (who imports this?)\n   * - Boosted risk level based on dependents + complexity\n   */\n  private enrichWithDependencies(\n    report: ComplexityReport,\n    allChunks: SearchResult[]\n  ): void {\n    const workspaceRoot = process.cwd();\n\n    // Only enrich files that have violations (to save computation)\n    const filesWithViolations = Object.entries(report.files)\n      .filter(([_, data]) => data.violations.length > 0)\n      .map(([filepath, _]) => filepath);\n\n    for (const filepath of filesWithViolations) {\n      const fileData = report.files[filepath];\n      \n      // Analyze dependencies for this file\n      const depAnalysis = analyzeDependencies(filepath, allChunks, workspaceRoot);\n      \n      // Update file data with dependency information\n      fileData.dependents = depAnalysis.dependents.map(d => d.filepath);\n      fileData.dependentCount = depAnalysis.dependentCount;\n      \n      // Boost risk level based on dependency analysis\n      // Take the higher of the two risk levels\n      if (RISK_ORDER[depAnalysis.riskLevel] > RISK_ORDER[fileData.riskLevel]) {\n        fileData.riskLevel = depAnalysis.riskLevel;\n      }\n      \n      // Add complexity metrics if available\n      if (depAnalysis.complexityMetrics) {\n        fileData.dependentComplexityMetrics = {\n          averageComplexity: depAnalysis.complexityMetrics.averageComplexity,\n          maxComplexity: depAnalysis.complexityMetrics.maxComplexity,\n          filesWithComplexityData: depAnalysis.complexityMetrics.filesWithComplexityData,\n        };\n      }\n    }\n  }\n}\n\n","/**\n * @liendev/core - Lien's indexing and analysis engine\n * \n * This is the public API for:\n * - @liendev/cli (CLI commands)\n * - @liendev/action (GitHub Action)\n * - @liendev/cloud (Cloud workers)\n * - Third-party integrations\n * \n * @example\n * ```typescript\n * import {\n *   indexCodebase,\n *   VectorDB,\n *   ComplexityAnalyzer,\n *   loadConfig,\n * } from '@liendev/core';\n * \n * // Index a codebase\n * const result = await indexCodebase({ rootDir: '/path/to/project' });\n * \n * // Run complexity analysis\n * const db = await VectorDB.load('/path/to/project');\n * const config = await loadConfig('/path/to/project');\n * const analyzer = new ComplexityAnalyzer(db, config);\n * const report = await analyzer.analyze();\n * ```\n */\n\n// =============================================================================\n// INDEXING\n// =============================================================================\n\nexport { indexCodebase } from './indexer/index.js';\nexport type { IndexingOptions, IndexingProgress, IndexingResult } from './indexer/index.js';\nexport { ManifestManager } from './indexer/manifest.js';\nexport type { IndexManifest, FileEntry } from './indexer/manifest.js';\nexport { chunkFile } from './indexer/chunker.js';\nexport { scanCodebase, scanCodebaseWithFrameworks, detectLanguage } from './indexer/scanner.js';\nexport { indexSingleFile, indexMultipleFiles, normalizeToRelativePath } from './indexer/incremental.js';\nexport { extractSymbols } from './indexer/symbol-extractor.js';\n\n// =============================================================================\n// EMBEDDINGS\n// =============================================================================\n\nexport { LocalEmbeddings } from './embeddings/local.js';\nexport { CachedEmbeddings } from './embeddings/cache.js';\nexport type { EmbeddingService } from './embeddings/types.js';\nexport { EMBEDDING_DIMENSION, EMBEDDING_DIMENSIONS } from './embeddings/types.js';\n\n// =============================================================================\n// VECTOR DATABASE\n// =============================================================================\n\nexport { VectorDB } from './vectordb/lancedb.js';\nexport type { VectorDBInterface, SearchResult } from './vectordb/types.js';\nexport { calculateRelevance } from './vectordb/relevance.js';\nexport type { RelevanceCategory } from './vectordb/relevance.js';\nexport { readVersionFile, writeVersionFile } from './vectordb/version.js';\n\n// =============================================================================\n// COMPLEXITY ANALYSIS\n// =============================================================================\n\nexport { ComplexityAnalyzer } from './insights/complexity-analyzer.js';\nexport { formatReport, formatTextReport, formatJsonReport, formatSarifReport } from './insights/formatters/index.js';\nexport type { OutputFormat } from './insights/formatters/index.js';\n\n// =============================================================================\n// CONFIGURATION\n// =============================================================================\n\nimport { ConfigService, configService as _configService } from './config/service.js';\nimport { defaultConfig as _defaultConfig, isLegacyConfig, isModernConfig } from './config/schema.js';\nimport type { LienConfig, LegacyLienConfig, FrameworkConfig, FrameworkInstance } from './config/schema.js';\n\nexport { ConfigService, _configService as configService };\nexport type { ValidationResult, MigrationResult } from './config/service.js';\nexport { MigrationManager } from './config/migration-manager.js';\nexport { migrateConfig, migrateConfigFile } from './config/migration.js';\nexport { _defaultConfig as defaultConfig, isLegacyConfig, isModernConfig };\nexport type { LienConfig, LegacyLienConfig, FrameworkConfig, FrameworkInstance };\n\n// Convenience re-exports\nexport const loadConfig = (rootDir?: string) => _configService.load(rootDir);\nexport const saveConfig = (rootDir: string, config: LienConfig) => \n  _configService.save(rootDir, config);\nexport const createDefaultConfig = () => _defaultConfig;\n\n// =============================================================================\n// GIT UTILITIES\n// =============================================================================\n\nexport {\n  isGitRepo,\n  isGitAvailable,\n  getCurrentBranch,\n  getCurrentCommit,\n  getChangedFiles,\n  getChangedFilesBetweenCommits,\n} from './git/utils.js';\n\nexport { GitStateTracker } from './git/tracker.js';\nexport type { GitState } from './git/tracker.js';\n\n// =============================================================================\n// FRAMEWORK DETECTION\n// =============================================================================\n\nexport {\n  groupByConfidence,\n  selectByPriority,\n  resolveFrameworkConflicts,\n  runAllDetectors,\n  detectAllFrameworks,\n  getDetectionSummary,\n} from './frameworks/detector-service.js';\nexport type { DetectionWithPriority, GroupedDetections } from './frameworks/detector-service.js';\nexport { frameworkDetectors, registerFramework, getFrameworkDetector } from './frameworks/registry.js';\nexport type { FrameworkDetector, DetectionResult, DetectionOptions } from './frameworks/types.js';\nexport { laravelDetector } from './frameworks/laravel/detector.js';\nexport { nodejsDetector } from './frameworks/nodejs/detector.js';\nexport { phpDetector } from './frameworks/php/detector.js';\nexport { shopifyDetector } from './frameworks/shopify/detector.js';\n\n// =============================================================================\n// ERRORS\n// =============================================================================\n\nexport {\n  LienError,\n  LienErrorCode,\n  ConfigError,\n  IndexingError,\n  EmbeddingError,\n  DatabaseError,\n  wrapError,\n  isLienError,\n  getErrorMessage,\n  getErrorStack,\n} from './errors/index.js';\n\n// =============================================================================\n// TYPES\n// =============================================================================\n\nexport type {\n  // Chunks\n  ChunkMetadata,\n  CodeChunk,\n  ScanOptions,\n  \n  // Complexity\n  RiskLevel,\n  ComplexityMetricType,\n  HalsteadDetails,\n  ComplexityViolation,\n  FileComplexityData,\n  ComplexityReport,\n} from './types/index.js';\n\nexport { RISK_ORDER } from './types/index.js';\n\n// =============================================================================\n// CONSTANTS\n// =============================================================================\n\nexport {\n  DEFAULT_CHUNK_SIZE,\n  DEFAULT_CHUNK_OVERLAP,\n  DEFAULT_CONCURRENCY,\n  DEFAULT_EMBEDDING_BATCH_SIZE,\n  EMBEDDING_MICRO_BATCH_SIZE,\n  VECTOR_DB_MAX_BATCH_SIZE,\n  VECTOR_DB_MIN_BATCH_SIZE,\n  DEFAULT_EMBEDDING_MODEL,\n  DEFAULT_PORT,\n  VERSION_CHECK_INTERVAL_MS,\n  DEFAULT_GIT_POLL_INTERVAL_MS,\n  DEFAULT_DEBOUNCE_MS,\n  INDEX_FORMAT_VERSION,\n} from './constants.js';\n\n// =============================================================================\n// UTILITIES\n// =============================================================================\n\nexport { Result, Ok, Err, isOk, isErr, unwrap, unwrapOr } from './utils/result.js';\n","/**\n * GitHub API helpers for the action\n */\n\nimport * as core from '@actions/core';\nimport * as github from '@actions/github';\n\ntype Octokit = ReturnType<typeof github.getOctokit>;\n\n/**\n * PR context for review\n */\nexport interface PRContext {\n  owner: string;\n  repo: string;\n  pullNumber: number;\n  title: string;\n  baseSha: string;\n  headSha: string;\n}\n\n/**\n * Get PR context from the GitHub event\n */\nexport function getPRContext(): PRContext | null {\n  const { context } = github;\n\n  if (!context.payload.pull_request) {\n    core.warning('This action only works on pull_request events');\n    return null;\n  }\n\n  const pr = context.payload.pull_request;\n\n  return {\n    owner: context.repo.owner,\n    repo: context.repo.repo,\n    pullNumber: pr.number,\n    title: pr.title,\n    baseSha: pr.base.sha,\n    headSha: pr.head.sha,\n  };\n}\n\n/**\n * Get list of files changed in the PR\n */\nexport async function getPRChangedFiles(\n  octokit: Octokit,\n  prContext: PRContext\n): Promise<string[]> {\n  const files: string[] = [];\n  let page = 1;\n  const perPage = 100;\n\n  while (true) {\n    const response = await octokit.rest.pulls.listFiles({\n      owner: prContext.owner,\n      repo: prContext.repo,\n      pull_number: prContext.pullNumber,\n      per_page: perPage,\n      page,\n    });\n\n    for (const file of response.data) {\n      // Only include added or modified files (not deleted)\n      if (file.status !== 'removed') {\n        files.push(file.filename);\n      }\n    }\n\n    if (response.data.length < perPage) {\n      break;\n    }\n    page++;\n  }\n\n  return files;\n}\n\n/**\n * Post a comment on the PR\n */\nexport async function postPRComment(\n  octokit: Octokit,\n  prContext: PRContext,\n  body: string\n): Promise<void> {\n  // Check for existing Lien comment to update instead of creating new\n  const existingComment = await findExistingComment(octokit, prContext);\n\n  if (existingComment) {\n    core.info(`Updating existing comment ${existingComment.id}`);\n    await octokit.rest.issues.updateComment({\n      owner: prContext.owner,\n      repo: prContext.repo,\n      comment_id: existingComment.id,\n      body,\n    });\n  } else {\n    core.info('Creating new comment');\n    await octokit.rest.issues.createComment({\n      owner: prContext.owner,\n      repo: prContext.repo,\n      issue_number: prContext.pullNumber,\n      body,\n    });\n  }\n}\n\n/**\n * Find existing Lien review comment to update\n */\nasync function findExistingComment(\n  octokit: Octokit,\n  prContext: PRContext\n): Promise<{ id: number } | null> {\n  const COMMENT_MARKER = '<!-- lien-ai-review -->';\n\n  const comments = await octokit.rest.issues.listComments({\n    owner: prContext.owner,\n    repo: prContext.repo,\n    issue_number: prContext.pullNumber,\n  });\n\n  for (const comment of comments.data) {\n    if (comment.body?.includes(COMMENT_MARKER)) {\n      return { id: comment.id };\n    }\n  }\n\n  return null;\n}\n\n/**\n * Get code snippet from a file at a specific commit\n */\nexport async function getFileContent(\n  octokit: Octokit,\n  prContext: PRContext,\n  filepath: string,\n  startLine: number,\n  endLine: number\n): Promise<string | null> {\n  try {\n    const response = await octokit.rest.repos.getContent({\n      owner: prContext.owner,\n      repo: prContext.repo,\n      path: filepath,\n      ref: prContext.headSha,\n    });\n\n    if ('content' in response.data) {\n      const content = Buffer.from(response.data.content, 'base64').toString(\n        'utf-8'\n      );\n      const lines = content.split('\\n');\n      // Line numbers are 1-based, array is 0-based\n      const snippet = lines.slice(startLine - 1, endLine).join('\\n');\n      return snippet;\n    }\n  } catch (error) {\n    core.warning(`Failed to get content for ${filepath}: ${error}`);\n  }\n\n  return null;\n}\n\n/**\n * Create an Octokit instance from token\n */\nexport function createOctokit(token: string): Octokit {\n  return github.getOctokit(token);\n}\n\n/**\n * Line comment for PR review\n */\nexport interface LineComment {\n  path: string;\n  line: number;\n  body: string;\n}\n\n/**\n * Post a review with line-specific comments\n */\nexport async function postPRReview(\n  octokit: Octokit,\n  prContext: PRContext,\n  comments: LineComment[],\n  summaryBody: string\n): Promise<void> {\n  if (comments.length === 0) {\n    // No line comments, just post summary as regular comment\n    await postPRComment(octokit, prContext, summaryBody);\n    return;\n  }\n\n  core.info(`Creating review with ${comments.length} line comments`);\n\n  try {\n    // Create a review with line comments\n    await octokit.rest.pulls.createReview({\n      owner: prContext.owner,\n      repo: prContext.repo,\n      pull_number: prContext.pullNumber,\n      commit_id: prContext.headSha,\n      event: 'COMMENT', // Don't approve or request changes, just comment\n      body: summaryBody,\n      comments: comments.map((c) => ({\n        path: c.path,\n        line: c.line,\n        body: c.body,\n      })),\n    });\n\n    core.info('Review posted successfully');\n  } catch (error) {\n    // If line comments fail (e.g., lines not in diff), fall back to regular comment\n    core.warning(`Failed to post line comments: ${error}`);\n    core.info('Falling back to regular PR comment');\n    await postPRComment(octokit, prContext, summaryBody);\n  }\n}\n\n/**\n * Marker comments for the PR description stats badge\n */\nconst DESCRIPTION_START_MARKER = '<!-- lien-stats -->';\nconst DESCRIPTION_END_MARKER = '<!-- /lien-stats -->';\n\n/**\n * Update the PR description with a stats badge\n * Appends or replaces the stats section at the bottom of the description\n */\nexport async function updatePRDescription(\n  octokit: Octokit,\n  prContext: PRContext,\n  badgeMarkdown: string\n): Promise<void> {\n  try {\n    // Get current PR\n    const { data: pr } = await octokit.rest.pulls.get({\n      owner: prContext.owner,\n      repo: prContext.repo,\n      pull_number: prContext.pullNumber,\n    });\n\n    const currentBody = pr.body || '';\n    const wrappedBadge = `${DESCRIPTION_START_MARKER}\\n${badgeMarkdown}\\n${DESCRIPTION_END_MARKER}`;\n\n    let newBody: string;\n\n    // Check if we already have a stats section\n    const startIdx = currentBody.indexOf(DESCRIPTION_START_MARKER);\n    const endIdx = currentBody.indexOf(DESCRIPTION_END_MARKER);\n\n    if (startIdx !== -1 && endIdx !== -1 && endIdx > startIdx) {\n      // Replace existing section\n      newBody =\n        currentBody.slice(0, startIdx) +\n        wrappedBadge +\n        currentBody.slice(endIdx + DESCRIPTION_END_MARKER.length);\n      core.info('Updating existing stats badge in PR description');\n    } else {\n      // Append to end\n      newBody = currentBody.trim() + '\\n\\n---\\n\\n' + wrappedBadge;\n      core.info('Adding stats badge to PR description');\n    }\n\n    // Update the PR\n    await octokit.rest.pulls.update({\n      owner: prContext.owner,\n      repo: prContext.repo,\n      pull_number: prContext.pullNumber,\n      body: newBody,\n    });\n\n    core.info('PR description updated with complexity stats');\n  } catch (error) {\n    // Don't fail the action if we can't update the description\n    core.warning(`Failed to update PR description: ${error}`);\n  }\n}\n\n/**\n * Parse unified diff patch to extract line numbers that can receive comments\n * Exported for testing\n */\nexport function parsePatchLines(patch: string): Set<number> {\n  const lines = new Set<number>();\n  let currentLine = 0;\n\n  for (const patchLine of patch.split('\\n')) {\n    // Hunk header: @@ -start,count +start,count @@\n    const hunkMatch = patchLine.match(/^@@ -\\d+(?:,\\d+)? \\+(\\d+)(?:,\\d+)? @@/);\n    if (hunkMatch) {\n      currentLine = parseInt(hunkMatch[1], 10);\n      continue;\n    }\n\n    // Added or context line (can have comments)\n    if (patchLine.startsWith('+') || patchLine.startsWith(' ')) {\n      if (!patchLine.startsWith('+++')) {\n        lines.add(currentLine);\n        currentLine++;\n      }\n    }\n    // Deleted lines (-) don't increment currentLine\n  }\n\n  return lines;\n}\n\n/**\n * Get lines that are in the PR diff (only these can have line comments)\n * Handles pagination for PRs with 100+ files\n */\nexport async function getPRDiffLines(\n  octokit: Octokit,\n  prContext: PRContext\n): Promise<Map<string, Set<number>>> {\n  const diffLines = new Map<string, Set<number>>();\n\n  // Use pagination to handle PRs with 100+ files\n  const iterator = octokit.paginate.iterator(octokit.rest.pulls.listFiles, {\n    owner: prContext.owner,\n    repo: prContext.repo,\n    pull_number: prContext.pullNumber,\n    per_page: 100,\n  });\n\n  for await (const response of iterator) {\n    for (const file of response.data) {\n      if (!file.patch) continue;\n\n      const lines = parsePatchLines(file.patch);\n      if (lines.size > 0) {\n        diffLines.set(file.filename, lines);\n      }\n    }\n  }\n\n  return diffLines;\n}\n\n","/**\n * OpenRouter API client for LLM access\n */\n\nimport * as core from '@actions/core';\nimport type { ComplexityViolation } from '@liendev/core';\nimport { buildBatchedCommentsPrompt } from './prompt.js';\n\n/**\n * OpenRouter API response structure\n * Cost is returned in usage.cost when usage accounting is enabled\n * See: https://openrouter.ai/docs/guides/guides/usage-accounting\n */\nexport interface OpenRouterResponse {\n  id: string;\n  choices: Array<{\n    message: {\n      role: string;\n      content: string;\n    };\n    finish_reason: string;\n  }>;\n  usage?: {\n    prompt_tokens: number;\n    completion_tokens: number;\n    total_tokens: number;\n    cost?: number; // Returned when usage: { include: true } is set in request\n  };\n}\n\nconst OPENROUTER_API_URL = 'https://openrouter.ai/api/v1/chat/completions';\n\n/**\n * Token usage tracking\n */\nexport interface TokenUsage {\n  promptTokens: number;\n  completionTokens: number;\n  totalTokens: number;\n  cost: number; // Actual cost from OpenRouter API\n}\n\n/**\n * Global token usage accumulator\n */\nlet totalUsage: TokenUsage = {\n  promptTokens: 0,\n  completionTokens: 0,\n  totalTokens: 0,\n  cost: 0,\n};\n\n/**\n * Reset token usage (call at start of review)\n */\nexport function resetTokenUsage(): void {\n  totalUsage = {\n    promptTokens: 0,\n    completionTokens: 0,\n    totalTokens: 0,\n    cost: 0,\n  };\n}\n\n/**\n * Get current token usage\n */\nexport function getTokenUsage(): TokenUsage {\n  return { ...totalUsage };\n}\n\n/**\n * Accumulate token usage from API response\n * Cost is returned in usage.cost when usage accounting is enabled\n */\nfunction trackUsage(\n  usage: { prompt_tokens: number; completion_tokens: number; total_tokens: number; cost?: number } | undefined\n): void {\n  if (!usage) return;\n\n  totalUsage.promptTokens += usage.prompt_tokens;\n  totalUsage.completionTokens += usage.completion_tokens;\n  totalUsage.totalTokens += usage.total_tokens;\n  totalUsage.cost += usage.cost || 0;\n}\n\n/**\n * Parse JSON comments response from AI, handling markdown code blocks\n * Returns null if parsing fails after retry attempts\n * Exported for testing\n */\nexport function parseCommentsResponse(content: string): Record<string, string> | null {\n  // Try extracting JSON from markdown code block first\n  const codeBlockMatch = content.match(/```(?:json)?\\s*([\\s\\S]*?)```/);\n  const jsonStr = (codeBlockMatch ? codeBlockMatch[1] : content).trim();\n\n  core.info(`Parsing JSON response (${jsonStr.length} chars)`);\n\n  try {\n    const parsed = JSON.parse(jsonStr);\n    core.info(`Successfully parsed ${Object.keys(parsed).length} comments`);\n    return parsed;\n  } catch (parseError) {\n    core.warning(`Initial JSON parse failed: ${parseError}`);\n  }\n\n  // Aggressive retry: extract any JSON object from response\n  const objectMatch = content.match(/\\{[\\s\\S]*\\}/);\n  if (objectMatch) {\n    try {\n      const parsed = JSON.parse(objectMatch[0]);\n      core.info(`Recovered JSON with aggressive parsing: ${Object.keys(parsed).length} comments`);\n      return parsed;\n    } catch (retryError) {\n      core.warning(`Retry parsing also failed: ${retryError}`);\n    }\n  }\n\n  core.warning(`Full response content:\\n${content}`);\n  return null;\n}\n\n/**\n * Generate an AI review using OpenRouter\n */\nexport async function generateReview(\n  prompt: string,\n  apiKey: string,\n  model: string\n): Promise<string> {\n  core.info(`Calling OpenRouter with model: ${model}`);\n\n  const response = await fetch(OPENROUTER_API_URL, {\n    method: 'POST',\n    headers: {\n      Authorization: `Bearer ${apiKey}`,\n      'Content-Type': 'application/json',\n      'HTTP-Referer': 'https://github.com/getlien/lien',\n      'X-Title': 'Veille by Lien',\n    },\n    body: JSON.stringify({\n      model,\n      messages: [\n        {\n          role: 'system',\n          content:\n            'You are an expert code reviewer. Provide actionable, specific feedback on code complexity issues. Be concise but thorough.',\n        },\n        {\n          role: 'user',\n          content: prompt,\n        },\n      ],\n      max_tokens: 2000,\n      temperature: 0.3, // Lower temperature for more consistent reviews\n      // Enable usage accounting to get cost data\n      // https://openrouter.ai/docs/guides/guides/usage-accounting\n      usage: {\n        include: true,\n      },\n    }),\n  });\n\n  if (!response.ok) {\n    const errorText = await response.text();\n    throw new Error(\n      `OpenRouter API error (${response.status}): ${errorText}`\n    );\n  }\n\n  const data = (await response.json()) as OpenRouterResponse;\n\n  if (!data.choices || data.choices.length === 0) {\n    throw new Error('No response from OpenRouter');\n  }\n\n  const review = data.choices[0].message.content;\n\n  // Cost is in usage.cost when usage accounting is enabled\n  if (data.usage) {\n    trackUsage(data.usage);\n    const costStr = data.usage.cost ? ` ($${data.usage.cost.toFixed(6)})` : '';\n    core.info(\n      `Tokens: ${data.usage.prompt_tokens} in, ${data.usage.completion_tokens} out${costStr}`\n    );\n  }\n\n  return review;\n}\n\n/**\n * Call OpenRouter API with batched comments prompt\n */\nasync function callBatchedCommentsAPI(\n  prompt: string,\n  apiKey: string,\n  model: string\n): Promise<OpenRouterResponse> {\n  const response = await fetch(OPENROUTER_API_URL, {\n    method: 'POST',\n    headers: {\n      Authorization: `Bearer ${apiKey}`,\n      'Content-Type': 'application/json',\n      'HTTP-Referer': 'https://github.com/getlien/lien',\n      'X-Title': 'Veille by Lien',\n    },\n    body: JSON.stringify({\n      model,\n      messages: [\n        {\n          role: 'system',\n          content:\n            'You are an expert code reviewer. Write detailed, actionable comments with specific refactoring suggestions. Respond ONLY with valid JSON.',\n        },\n        { role: 'user', content: prompt },\n      ],\n      max_tokens: 4096,\n      temperature: 0.3,\n      usage: { include: true },\n    }),\n  });\n\n  if (!response.ok) {\n    const errorText = await response.text();\n    throw new Error(`OpenRouter API error (${response.status}): ${errorText}`);\n  }\n\n  const data = (await response.json()) as OpenRouterResponse;\n\n  if (!data.choices || data.choices.length === 0) {\n    throw new Error('No response from OpenRouter');\n  }\n\n  return data;\n}\n\n/**\n * Map parsed comments to violations, with fallback for missing comments\n * Exported for testing\n */\nexport function mapCommentsToViolations(\n  commentsMap: Record<string, string> | null,\n  violations: ComplexityViolation[]\n): Map<ComplexityViolation, string> {\n  const results = new Map<ComplexityViolation, string>();\n  const fallbackMessage = (v: ComplexityViolation) =>\n    `This ${v.symbolType} exceeds the complexity threshold. Consider refactoring to improve readability and testability.`;\n\n  if (!commentsMap) {\n    for (const violation of violations) {\n      results.set(violation, fallbackMessage(violation));\n    }\n    return results;\n  }\n\n  for (const violation of violations) {\n    const key = `${violation.filepath}::${violation.symbolName}`;\n    const comment = commentsMap[key];\n\n    if (comment) {\n      results.set(violation, comment.replace(/\\\\n/g, '\\n'));\n    } else {\n      core.warning(`No comment generated for ${key}`);\n      results.set(violation, fallbackMessage(violation));\n    }\n  }\n\n  return results;\n}\n\n/**\n * Generate line comments for multiple violations in a single API call\n * \n * This is more efficient than individual calls:\n * - System prompt only sent once (saves ~100 tokens per violation)\n * - AI has full context of all violations (can identify patterns)\n * - Single API call = faster execution\n */\nexport async function generateLineComments(\n  violations: ComplexityViolation[],\n  codeSnippets: Map<string, string>,\n  apiKey: string,\n  model: string\n): Promise<Map<ComplexityViolation, string>> {\n  if (violations.length === 0) {\n    return new Map();\n  }\n\n  core.info(`Generating comments for ${violations.length} violations in single batch`);\n\n  const prompt = buildBatchedCommentsPrompt(violations, codeSnippets);\n  const data = await callBatchedCommentsAPI(prompt, apiKey, model);\n\n  if (data.usage) {\n    trackUsage(data.usage);\n    const costStr = data.usage.cost ? ` ($${data.usage.cost.toFixed(6)})` : '';\n    core.info(`Batch tokens: ${data.usage.prompt_tokens} in, ${data.usage.completion_tokens} out${costStr}`);\n  }\n\n  const commentsMap = parseCommentsResponse(data.choices[0].message.content);\n  return mapCommentsToViolations(commentsMap, violations);\n}\n\n","/**\n * Prompt builder for AI code review\n */\n\nimport collect from 'collect.js';\nimport type { ComplexityReport, ComplexityViolation } from '@liendev/core';\nimport type { PRContext } from './github.js';\nimport type { ComplexityDelta, DeltaSummary } from './delta.js';\nimport { formatDelta } from './delta.js';\nimport { formatTime, formatDeltaValue } from './format.js';\n\n/**\n * Create a unique key for delta lookups\n * Includes metricType since a function can have multiple metric violations\n */\nfunction createDeltaKey(v: { filepath: string; symbolName: string; metricType: string }): string {\n  return `${v.filepath}::${v.symbolName}::${v.metricType}`;\n}\n\n/**\n * Build a lookup map from deltas for quick access\n */\nfunction buildDeltaMap(deltas: ComplexityDelta[] | null): Map<string, ComplexityDelta> {\n  if (!deltas) return new Map();\n  \n  return new Map(\n    collect(deltas)\n      .map(d => [createDeltaKey(d), d] as [string, ComplexityDelta])\n      .all()\n  );\n}\n\n/**\n * Get human-readable label for a metric type\n */\nexport function getMetricLabel(metricType: string): string {\n  switch (metricType) {\n    case 'cognitive': return 'mental load';\n    case 'cyclomatic': return 'test paths';\n    case 'halstead_effort': return 'time to understand';\n    case 'halstead_bugs': return 'estimated bugs';\n    default: return 'complexity';\n  }\n}\n\n/**\n * Format complexity value based on metric type for display\n */\nexport function formatComplexityValue(metricType: string, value: number): string {\n  switch (metricType) {\n    case 'halstead_effort':\n      return `~${formatTime(value)}`;\n    case 'halstead_bugs':\n      return value.toFixed(2);\n    case 'cyclomatic':\n      return `${value} tests`;\n    default:\n      return value.toString();\n  }\n}\n\n/**\n * Format threshold value based on metric type for display\n */\nexport function formatThresholdValue(metricType: string, value: number): string {\n  switch (metricType) {\n    case 'halstead_effort':\n      return formatTime(value);\n    case 'halstead_bugs':\n      return value.toFixed(1);\n    default:\n      return value.toString();\n  }\n}\n\n/**\n * Format a single violation line with optional delta\n */\nfunction formatViolationLine(v: ComplexityViolation, deltaMap: Map<string, ComplexityDelta>): string {\n  const delta = deltaMap.get(createDeltaKey(v));\n  const deltaStr = delta ? ` (${formatDelta(delta.delta)})` : '';\n  const metricLabel = getMetricLabel(v.metricType);\n  const valueDisplay = formatComplexityValue(v.metricType, v.complexity);\n  const thresholdDisplay = formatThresholdValue(v.metricType, v.threshold);\n  return `  - ${v.symbolName} (${v.symbolType}): ${metricLabel} ${valueDisplay}${deltaStr} (threshold: ${thresholdDisplay}) [${v.severity}]`;\n}\n\n/**\n * Build violations summary grouped by file\n */\nfunction buildViolationsSummary(\n  files: ComplexityReport['files'],\n  deltaMap: Map<string, ComplexityDelta>\n): string {\n  return Object.entries(files)\n    .filter(([_, data]) => data.violations.length > 0)\n    .map(([filepath, data]) => {\n      const violationList = data.violations\n        .map(v => formatViolationLine(v, deltaMap))\n        .join('\\n');\n      return `**${filepath}** (risk: ${data.riskLevel})\\n${violationList}`;\n    })\n    .join('\\n\\n');\n}\n\n/**\n * Build delta context section showing complexity changes\n */\nfunction buildDeltaContext(deltas: ComplexityDelta[] | null): string {\n  if (!deltas || deltas.length === 0) return '';\n  \n  const improved = deltas.filter(d => d.severity === 'improved');\n  const degraded = deltas.filter(d => (d.severity === 'error' || d.severity === 'warning') && d.delta > 0);\n  const newFuncs = deltas.filter(d => d.severity === 'new');\n  const deleted = deltas.filter(d => d.severity === 'deleted');\n  \n  const formatChange = (d: ComplexityDelta): string => {\n    const from = d.baseComplexity ?? 'new';\n    const to = d.headComplexity ?? 'removed';\n    return `  - ${d.symbolName}: ${from} ‚Üí ${to} (${formatDelta(d.delta)})`;\n  };\n  \n  const sections = [\n    `\\n## Complexity Changes (vs base branch)`,\n    `- **Degraded**: ${degraded.length} function(s) got more complex`,\n    `- **Improved**: ${improved.length} function(s) got simpler`,\n    `- **New**: ${newFuncs.length} new complex function(s)`,\n    `- **Removed**: ${deleted.length} complex function(s) deleted`,\n  ];\n  \n  if (degraded.length > 0) sections.push(`\\nFunctions that got worse:\\n${degraded.map(formatChange).join('\\n')}`);\n  if (improved.length > 0) sections.push(`\\nFunctions that improved:\\n${improved.map(formatChange).join('\\n')}`);\n  if (newFuncs.length > 0) sections.push(`\\nNew complex functions:\\n${newFuncs.map(d => `  - ${d.symbolName}: complexity ${d.headComplexity}`).join('\\n')}`);\n  \n  return sections.join('\\n');\n}\n\n/**\n * Build code snippets section\n */\nfunction buildSnippetsSection(codeSnippets: Map<string, string>): string {\n  return Array.from(codeSnippets.entries())\n    .map(([key, code]) => {\n      const [filepath, symbolName] = key.split('::');\n      return `### ${filepath} - ${symbolName}\\n\\`\\`\\`\\n${code}\\n\\`\\`\\``;\n    })\n    .join('\\n\\n');\n}\n\n/**\n * Build the review prompt from complexity report\n */\nexport function buildReviewPrompt(\n  report: ComplexityReport,\n  prContext: PRContext,\n  codeSnippets: Map<string, string>,\n  deltas: ComplexityDelta[] | null = null\n): string {\n  const { summary, files } = report;\n  const deltaMap = buildDeltaMap(deltas);\n  const violationsByFile = Object.entries(files).filter(([_, data]) => data.violations.length > 0);\n  const violationsSummary = buildViolationsSummary(files, deltaMap);\n  const snippetsSection = buildSnippetsSection(codeSnippets);\n  const deltaContext = buildDeltaContext(deltas);\n\n  return `# Code Complexity Review Request\n\n## Context\n- **Repository**: ${prContext.owner}/${prContext.repo}\n- **PR**: #${prContext.pullNumber} - ${prContext.title}\n- **Files with violations**: ${violationsByFile.length}\n- **Total violations**: ${summary.totalViolations} (${summary.bySeverity.error} errors, ${summary.bySeverity.warning} warnings)\n${deltaContext}\n## Complexity Violations Found\n\n${violationsSummary}\n\n## Code Snippets\n\n${snippetsSection || '_No code snippets available_'}\n\n## Your Task\n\nFor each violation:\n1. **Explain** why this complexity is problematic in this specific context\n2. **Suggest** concrete refactoring steps (not generic advice like \"break into smaller functions\")\n3. **Prioritize** which violations are most important to address - focus on functions that got WORSE (higher delta)\n4. If the complexity seems justified for the use case, say so\n5. Celebrate improvements! If a function got simpler, acknowledge it.\n\nFormat your response as a PR review comment with:\n- A brief summary at the top (2-3 sentences)\n- File-by-file breakdown with specific suggestions\n- Prioritized list of recommended changes\n\nBe concise but actionable. Focus on the highest-impact improvements.`;\n}\n\n/**\n * Build a minimal prompt when there are no violations\n */\nexport function buildNoViolationsMessage(prContext: PRContext, deltas: ComplexityDelta[] | null = null): string {\n  let deltaMessage = '';\n  \n  if (deltas && deltas.length > 0) {\n    const improved = deltas.filter(d => d.severity === 'improved' || d.severity === 'deleted');\n    if (improved.length > 0) {\n      deltaMessage = `\\n\\nüéâ **Great job!** This PR improved complexity in ${improved.length} function(s).`;\n    }\n  }\n\n  return `<!-- lien-ai-review -->\n## ‚úÖ Lien Complexity Analysis\n\nNo complexity violations found in PR #${prContext.pullNumber}.\n\nAll analyzed functions are within the configured complexity threshold.${deltaMessage}`;\n}\n\n/**\n * Token usage info for display\n */\nexport interface TokenUsageInfo {\n  totalTokens: number;\n  cost: number;\n}\n\n/**\n * Group deltas by metric type and sum their values\n */\nfunction groupDeltasByMetric(deltas: ComplexityDelta[]): Record<string, number> {\n  return collect(deltas)\n    .groupBy('metricType')\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    .map((group: any) => group.sum('delta'))\n    .all() as unknown as Record<string, number>;\n}\n\n/**\n * Build metric breakdown string with emojis\n * Note: getMetricEmoji is defined below (line ~441) to avoid duplication\n */\nfunction buildMetricBreakdownForDisplay(deltaByMetric: Record<string, number>): string {\n  const metricOrder = ['cyclomatic', 'cognitive', 'halstead_effort', 'halstead_bugs'];\n  const emojiMap: Record<string, string> = {\n    cyclomatic: 'üîÄ',\n    cognitive: 'üß†',\n    halstead_effort: '‚è±Ô∏è',\n    halstead_bugs: 'üêõ',\n  };\n  return collect(metricOrder)\n    .map(metricType => {\n      const metricDelta = deltaByMetric[metricType] || 0;\n      const emoji = emojiMap[metricType] || 'üìä';\n      const sign = metricDelta >= 0 ? '+' : '';\n      return `${emoji} ${sign}${formatDeltaValue(metricType, metricDelta)}`;\n    })\n    .all()\n    .join(' | ');\n}\n\n/**\n * Categorize deltas into improved vs degraded counts\n */\nfunction categorizeDeltas(deltas: ComplexityDelta[]): { improved: number; degraded: number } {\n  return deltas.reduce((acc, d) => {\n    if (['improved', 'deleted'].includes(d.severity)) acc.improved++;\n    else if (['warning', 'error', 'new'].includes(d.severity)) acc.degraded++;\n    return acc;\n  }, { improved: 0, degraded: 0 });\n}\n\n/**\n * Determine trend emoji based on total delta\n */\nfunction getTrendEmoji(totalDelta: number): string {\n  if (totalDelta > 0) return '‚¨ÜÔ∏è';\n  if (totalDelta < 0) return '‚¨áÔ∏è';\n  return '‚û°Ô∏è';\n}\n\n/**\n * Format delta display with per-metric breakdown\n */\nfunction formatDeltaDisplay(deltas: ComplexityDelta[] | null | undefined): string {\n  if (!deltas || deltas.length === 0) return '';\n  \n  const { improved, degraded } = categorizeDeltas(deltas);\n  const deltaByMetric = groupDeltasByMetric(deltas);\n  const metricBreakdown = buildMetricBreakdownForDisplay(deltaByMetric);\n  const totalDelta = Object.values(deltaByMetric).reduce((sum, v) => sum + v, 0);\n  const trend = getTrendEmoji(totalDelta);\n\n  let display = `\\n\\n**Complexity Change:** ${metricBreakdown} ${trend}`;\n  if (improved > 0) display += ` | ${improved} improved`;\n  if (degraded > 0) display += ` | ${degraded} degraded`;\n  return display;\n}\n\n/**\n * Format token usage stats for display\n */\nfunction formatTokenStats(tokenUsage: TokenUsageInfo | undefined): string {\n  if (!tokenUsage || tokenUsage.totalTokens <= 0) return '';\n  return `\\n- Tokens: ${tokenUsage.totalTokens.toLocaleString()} ($${tokenUsage.cost.toFixed(4)})`;\n}\n\n/**\n * Format fallback note for boy scout rule\n */\nfunction formatFallbackNote(isFallback: boolean): string {\n  if (!isFallback) return '';\n  return `\\n\\n> üí° *These violations exist in files touched by this PR but not on changed lines. Consider the [boy scout rule](https://www.oreilly.com/library/view/97-things-every/9780596809515/ch08.html): leave the code cleaner than you found it!*\\n`;\n}\n\n/**\n * Format the AI review as a GitHub comment\n */\nexport function formatReviewComment(\n  aiReview: string,\n  report: ComplexityReport,\n  isFallback = false,\n  tokenUsage?: TokenUsageInfo,\n  deltas?: ComplexityDelta[] | null\n): string {\n  const { summary } = report;\n  const deltaDisplay = formatDeltaDisplay(deltas);\n  const fallbackNote = formatFallbackNote(isFallback);\n  const tokenStats = formatTokenStats(tokenUsage);\n\n  return `<!-- lien-ai-review -->\n## üëÅÔ∏è Veille\n\n${summary.totalViolations} issue${summary.totalViolations === 1 ? '' : 's'} spotted in this PR.${deltaDisplay}${fallbackNote}\n\n---\n\n${aiReview}\n\n---\n\n<details>\n<summary>üìä Analysis Details</summary>\n\n- Files analyzed: ${summary.filesAnalyzed}\n- Average complexity: ${summary.avgComplexity.toFixed(1)}\n- Max complexity: ${summary.maxComplexity}${tokenStats}\n\n</details>\n\n*[Veille](https://lien.dev) by Lien*`;\n}\n\n/**\n * Get the key for a violation (for code snippet mapping)\n */\nexport function getViolationKey(violation: ComplexityViolation): string {\n  return `${violation.filepath}::${violation.symbolName}`;\n}\n\n/**\n * Determine human-friendly status message based on violations and delta.\n * Prioritizes positive messaging when PR improves complexity.\n */\nfunction determineStatus(\n  report: ComplexityReport | null,\n  deltaSummary: DeltaSummary | null\n): { emoji: string; message: string } {\n  const violations = report?.summary.totalViolations ?? 0;\n  const errors = report?.summary.bySeverity.error ?? 0;\n  const delta = deltaSummary?.totalDelta ?? 0;\n  const newViolations = deltaSummary?.newFunctions ?? 0;\n  const preExisting = Math.max(0, violations - newViolations);\n\n  // PR improved complexity - celebrate it!\n  if (delta < 0) {\n    if (preExisting > 0) {\n      return {\n        emoji: '‚úÖ',\n        message: `**Improved!** Complexity reduced by ${Math.abs(delta)}. ${preExisting} pre-existing issue${preExisting === 1 ? '' : 's'} remain${preExisting === 1 ? 's' : ''} in touched files.`,\n      };\n    }\n    return { emoji: '‚úÖ', message: `**Improved!** This PR reduces complexity by ${Math.abs(delta)}.` };\n  }\n\n  // New violations introduced - these need attention\n  if (newViolations > 0 && errors > 0) {\n    return {\n      emoji: 'üî¥',\n      message: `**Review required** - ${newViolations} new function${newViolations === 1 ? ' is' : 's are'} too complex.`,\n    };\n  }\n\n  if (newViolations > 0) {\n    return {\n      emoji: '‚ö†Ô∏è',\n      message: `**Needs attention** - ${newViolations} new function${newViolations === 1 ? ' is' : 's are'} more complex than recommended.`,\n    };\n  }\n\n  // Only pre-existing violations (no new ones)\n  if (violations > 0) {\n    return {\n      emoji: '‚û°Ô∏è',\n      message: `**Stable** - ${preExisting} pre-existing issue${preExisting === 1 ? '' : 's'} in touched files (none introduced).`,\n    };\n  }\n\n  // No violations at all\n  if (delta > 0) {\n    return { emoji: '‚û°Ô∏è', message: '**Stable** - Complexity increased slightly but within limits.' };\n  }\n\n  return { emoji: '‚úÖ', message: '**Good** - No complexity issues found.' };\n}\n\n/**\n * Format delta display string with sign and trend emoji\n */\nfunction formatBadgeDelta(deltaSummary: DeltaSummary | null): string {\n  if (!deltaSummary) return '‚Äî';\n\n  const sign = deltaSummary.totalDelta >= 0 ? '+' : '';\n  const trend = deltaSummary.totalDelta > 0 ? '‚¨ÜÔ∏è' : deltaSummary.totalDelta < 0 ? '‚¨áÔ∏è' : '‚û°Ô∏è';\n  return `${sign}${deltaSummary.totalDelta} ${trend}`;\n}\n\n/**\n * Get emoji for metric type\n */\nfunction getMetricEmoji(metricType: string): string {\n  switch (metricType) {\n    case 'cyclomatic': return 'üîÄ';\n    case 'cognitive': return 'üß†';\n    case 'halstead_effort': return '‚è±Ô∏è';\n    case 'halstead_bugs': return 'üêõ';\n    default: return 'üìä';\n  }\n}\n\n/**\n * Build the PR description stats badge\n * Human-friendly summary with metrics table\n */\nexport function buildDescriptionBadge(\n  report: ComplexityReport | null,\n  deltaSummary: DeltaSummary | null,\n  deltas: ComplexityDelta[] | null\n): string {\n  const status = determineStatus(report, deltaSummary);\n\n  // Build metric breakdown table with violations and deltas\n  let metricTable = '';\n  if (report && report.summary.totalViolations > 0) {\n    // Count violations by metric type using collect.js\n    const byMetric = collect(Object.values(report.files))\n      .flatMap(f => f.violations)\n      .countBy('metricType')\n      .all() as unknown as Record<string, number>;\n\n    // Calculate delta by metric type using collect.js\n    // Note: collect.js groupBy returns groups needing sum() - types are limited\n    const deltaByMetric: Record<string, number> = deltas\n      ? collect(deltas)\n          .groupBy('metricType')\n          // eslint-disable-next-line @typescript-eslint/no-explicit-any\n          .map((group: any) => group.sum('delta'))\n          .all() as unknown as Record<string, number>\n      : {};\n\n    // Build table rows (only show metrics with violations)\n    const metricOrder = ['cyclomatic', 'cognitive', 'halstead_effort', 'halstead_bugs'];\n    const rows = collect(metricOrder)\n      .filter(metricType => byMetric[metricType] > 0)\n      .map(metricType => {\n        const emoji = getMetricEmoji(metricType);\n        const label = getMetricLabel(metricType);\n        const count = byMetric[metricType];\n        const delta = deltaByMetric[metricType] || 0;\n        const deltaStr = deltas ? (delta >= 0 ? `+${delta}` : `${delta}`) : '‚Äî';\n        return `| ${emoji} ${label} | ${count} | ${deltaStr} |`;\n      })\n      .all() as string[];\n\n    if (rows.length > 0) {\n      metricTable = `\n| Metric | Violations | Change |\n|--------|:----------:|:------:|\n${rows.join('\\n')}\n`;\n    }\n  }\n\n  return `### üëÅÔ∏è Veille\n\n${status.emoji} ${status.message}\n${metricTable}\n*[Veille](https://lien.dev) by Lien*`;\n}\n\n/**\n * Build Halstead details string for prompts\n */\nfunction formatHalsteadContext(violation: ComplexityViolation): string {\n  if (!violation.metricType?.startsWith('halstead_')) return '';\n  if (!violation.halsteadDetails) return '';\n  \n  const details = violation.halsteadDetails;\n  return `\\n**Halstead Metrics**: Volume: ${details.volume?.toLocaleString()}, Difficulty: ${details.difficulty?.toFixed(1)}, Effort: ${details.effort?.toLocaleString()}, Est. bugs: ${details.bugs?.toFixed(3)}`;\n}\n\n/**\n * Build a prompt for generating a single line comment for a violation\n */\nexport function buildLineCommentPrompt(\n  violation: ComplexityViolation,\n  codeSnippet: string | null\n): string {\n  const snippetSection = codeSnippet\n    ? `\\n\\n**Code:**\\n\\`\\`\\`\\n${codeSnippet}\\n\\`\\`\\``\n    : '';\n  \n  const metricType = violation.metricType || 'cyclomatic';\n  const metricLabel = getMetricLabel(metricType);\n  const valueDisplay = formatComplexityValue(metricType, violation.complexity);\n  const thresholdDisplay = formatThresholdValue(metricType, violation.threshold);\n  const halsteadContext = formatHalsteadContext(violation);\n\n  return `You are reviewing code for complexity. Generate an actionable review comment.\n\n**Function**: \\`${violation.symbolName}\\` (${violation.symbolType})\n**Complexity**: ${valueDisplay} ${metricLabel} (threshold: ${thresholdDisplay})${halsteadContext}\n${snippetSection}\n\nWrite a code review comment that includes:\n\n1. **Problem** (1 sentence): What specific pattern makes this complex (e.g., \"5 levels of nested conditionals\", \"switch with embedded if-chains\", \"many unique operators\")\n\n2. **Refactoring** (2-3 sentences): Concrete steps to reduce complexity. Be SPECIFIC:\n   - Name the exact functions to extract (e.g., \"Extract \\`handleAdminDelete()\\` and \\`handleModeratorDelete()\\`\")\n   - Suggest specific patterns (strategy, lookup table, early returns)\n   - For Halstead metrics: suggest introducing named constants, reducing operator variety, or extracting complex expressions\n   - If applicable, show a brief code sketch\n\n3. **Benefit** (1 sentence): What improves (testability, readability, etc.)\n\nFormat as a single cohesive comment without headers. Be direct and specific to THIS code.`;\n}\n\n/**\n * Build a summary comment when using line-specific reviews\n */\nexport function buildLineSummaryComment(\n  report: ComplexityReport,\n  prContext: PRContext\n): string {\n  const { summary } = report;\n  const emoji = summary.bySeverity.error > 0 ? 'üî¥' : 'üü°';\n\n  return `<!-- lien-ai-review -->\n## ${emoji} Veille\n\n${summary.totalViolations} issue${summary.totalViolations === 1 ? '' : 's'} spotted in this PR.\n\nSee inline comments below for specific suggestions.\n\n<details>\n<summary>üìä Details</summary>\n\n- Files analyzed: ${summary.filesAnalyzed}\n- Average complexity: ${summary.avgComplexity.toFixed(1)}\n- Max complexity: ${summary.maxComplexity}\n\n</details>\n\n*[Veille](https://lien.dev) by Lien*`;\n}\n\n/**\n * Build a batched prompt for generating multiple line comments at once\n * This is more efficient than individual prompts as:\n * - System prompt only sent once\n * - AI has full context of all violations\n * - Fewer API calls = faster + cheaper\n */\nexport function buildBatchedCommentsPrompt(\n  violations: ComplexityViolation[],\n  codeSnippets: Map<string, string>\n): string {\n  const violationsText = violations\n    .map((v, i) => {\n      const key = `${v.filepath}::${v.symbolName}`;\n      const snippet = codeSnippets.get(key);\n      const snippetSection = snippet\n        ? `\\nCode:\\n\\`\\`\\`\\n${snippet}\\n\\`\\`\\``\n        : '';\n      \n      const metricType = v.metricType || 'cyclomatic';\n      const metricLabel = getMetricLabel(metricType);\n      const valueDisplay = formatComplexityValue(metricType, v.complexity);\n      const thresholdDisplay = formatThresholdValue(metricType, v.threshold);\n      const halsteadContext = formatHalsteadContext(v);\n\n      return `### ${i + 1}. ${v.filepath}::${v.symbolName}\n- **Function**: \\`${v.symbolName}\\` (${v.symbolType})\n- **Complexity**: ${valueDisplay} ${metricLabel} (threshold: ${thresholdDisplay})${halsteadContext}\n- **Severity**: ${v.severity}${snippetSection}`;\n    })\n    .join('\\n\\n');\n\n  // Build JSON keys for the response format\n  const jsonKeys = violations\n    .map((v) => `  \"${v.filepath}::${v.symbolName}\": \"your comment here\"`)\n    .join(',\\n');\n\n  return `You are a senior engineer reviewing code for complexity. Generate thoughtful, context-aware review comments.\n\n## Violations to Review\n\n${violationsText}\n\n## Instructions\n\nFor each violation, write a code review comment that:\n\n1. **Identifies the specific pattern** causing complexity (not just \"too complex\")\n   - Is it nested conditionals? Long parameter lists? Multiple responsibilities?\n   - For Halstead metrics: many unique operators/operands, complex expressions\n   - Be specific: \"5 levels of nesting\" not \"deeply nested\"\n\n2. **Suggests a concrete fix** with a short code example (3-5 lines)\n   - Consider: early returns, guard clauses, lookup tables, extracting helpers, strategy pattern\n   - For Halstead: named constants, reducing operator variety, extracting complex expressions\n   - Name specific functions: \"Extract \\`handleAdminCase()\\`\" not \"extract a function\"\n   - Choose the SIMPLEST fix that addresses the issue (KISS principle)\n\n3. **Acknowledges context** when relevant\n   - If this is an orchestration function, complexity may be acceptable\n   - If the logic is inherently complex (state machines, parsers), say so\n   - Don't suggest over-engineering for marginal gains\n\nBe direct and specific to THIS code. Avoid generic advice like \"break into smaller functions.\"\n\nIMPORTANT: Do NOT include headers like \"Complexity: X\" or emojis - we add those.\n\n## Response Format\n\nRespond with ONLY valid JSON. Each key is \"filepath::symbolName\", value is the comment text.\nUse \\\\n for newlines within comments.\n\n\\`\\`\\`json\n{\n${jsonKeys}\n}\n\\`\\`\\``;\n}\n\n","/**\n * Complexity delta calculation\n * Compares base branch complexity to head branch complexity\n */\n\nimport * as core from '@actions/core';\nimport collect from 'collect.js';\nimport type {\n  ComplexityReport,\n  ComplexityViolation,\n} from '@liendev/core';\n\n/**\n * Complexity delta for a single function/method\n */\nexport interface ComplexityDelta {\n  filepath: string;\n  symbolName: string;\n  symbolType: string;\n  startLine: number;\n  metricType: string; // which metric this delta is for\n  baseComplexity: number | null; // null = new function\n  headComplexity: number | null; // null = deleted function\n  delta: number; // positive = worse, negative = better\n  threshold: number;\n  severity: 'warning' | 'error' | 'improved' | 'new' | 'deleted';\n}\n\n/**\n * Summary of complexity changes in a PR\n */\nexport interface DeltaSummary {\n  totalDelta: number; // net change across all functions\n  improved: number; // count of functions that got simpler\n  degraded: number; // count of functions that got more complex\n  newFunctions: number; // count of new functions with violations\n  deletedFunctions: number; // count of deleted functions (freed complexity)\n  unchanged: number; // count of functions with same complexity\n}\n\n/**\n * Create a key for a function+metric to match across base/head\n * Includes metricType since a function can have multiple metric violations\n */\nfunction getFunctionKey(filepath: string, symbolName: string, metricType: string): string {\n  return `${filepath}::${symbolName}::${metricType}`;\n}\n\n/**\n * Build a map of function complexities from a report\n */\nfunction buildComplexityMap(\n  report: ComplexityReport | null,\n  files: string[]\n): Map<string, { complexity: number; violation: ComplexityViolation }> {\n  if (!report) return new Map();\n\n  type MapEntry = [string, { complexity: number; violation: ComplexityViolation }];\n\n  // Flatten violations from all requested files and build map entries\n  const entries = collect(files)\n    .map(filepath => ({ filepath, fileData: report.files[filepath] }))\n    .filter(({ fileData }) => !!fileData)\n    .flatMap(({ filepath, fileData }) =>\n      fileData.violations.map(violation => [\n        getFunctionKey(filepath, violation.symbolName, violation.metricType),\n        { complexity: violation.complexity, violation }\n      ] as MapEntry)\n    )\n    .all() as unknown as MapEntry[];\n\n  return new Map(entries);\n}\n\n/**\n * Determine severity based on complexity change\n */\nfunction determineSeverity(\n  baseComplexity: number | null,\n  headComplexity: number,\n  delta: number,\n  threshold: number\n): ComplexityDelta['severity'] {\n  if (baseComplexity === null) return 'new';\n  if (delta < 0) return 'improved';\n  return headComplexity >= threshold * 2 ? 'error' : 'warning';\n}\n\n/**\n * Create a delta object from violation data\n */\nfunction createDelta(\n  violation: ComplexityViolation,\n  baseComplexity: number | null,\n  headComplexity: number | null,\n  severity: ComplexityDelta['severity']\n): ComplexityDelta {\n  const delta = baseComplexity !== null && headComplexity !== null\n    ? headComplexity - baseComplexity\n    : headComplexity ?? -(baseComplexity ?? 0);\n\n  return {\n    filepath: violation.filepath,\n    symbolName: violation.symbolName,\n    symbolType: violation.symbolType,\n    startLine: violation.startLine,\n    metricType: violation.metricType,\n    baseComplexity,\n    headComplexity,\n    delta,\n    threshold: violation.threshold,\n    severity,\n  };\n}\n\n/**\n * Calculate complexity deltas between base and head\n */\nexport function calculateDeltas(\n  baseReport: ComplexityReport | null,\n  headReport: ComplexityReport,\n  changedFiles: string[]\n): ComplexityDelta[] {\n  const baseMap = buildComplexityMap(baseReport, changedFiles);\n  const headMap = buildComplexityMap(headReport, changedFiles);\n  const seenBaseKeys = new Set<string>();\n\n  // Process head violations\n  const headDeltas = collect(Array.from(headMap.entries()))\n    .map(([key, headData]) => {\n      const baseData = baseMap.get(key);\n      if (baseData) seenBaseKeys.add(key);\n\n      const baseComplexity = baseData?.complexity ?? null;\n      const headComplexity = headData.complexity;\n      const delta = baseComplexity !== null ? headComplexity - baseComplexity : headComplexity;\n      const severity = determineSeverity(baseComplexity, headComplexity, delta, headData.violation.threshold);\n\n      return createDelta(headData.violation, baseComplexity, headComplexity, severity);\n    })\n    .all() as ComplexityDelta[];\n\n  // Process deleted functions (in base but not in head)\n  const deletedDeltas = collect(Array.from(baseMap.entries()))\n    .filter(([key]) => !seenBaseKeys.has(key))\n    .map(([_, baseData]) => createDelta(baseData.violation, baseData.complexity, null, 'deleted'))\n    .all() as ComplexityDelta[];\n\n  const deltas = [...headDeltas, ...deletedDeltas];\n\n  // Sort by delta (worst first), then by absolute complexity\n  deltas.sort((a, b) => {\n    // Errors first, then warnings, then new, then improved, then deleted\n    const severityOrder = { error: 0, warning: 1, new: 2, improved: 3, deleted: 4 };\n    if (severityOrder[a.severity] !== severityOrder[b.severity]) {\n      return severityOrder[a.severity] - severityOrder[b.severity];\n    }\n    // Within same severity, sort by delta (worse first)\n    return b.delta - a.delta;\n  });\n\n  return deltas;\n}\n\n/**\n * Calculate summary statistics for deltas\n */\nexport function calculateDeltaSummary(deltas: ComplexityDelta[]): DeltaSummary {\n  const collection = collect(deltas);\n  \n  // Categorize each delta\n  const categorized = collection.map(d => {\n    if (d.severity === 'improved') return 'improved';\n    if (d.severity === 'new') return 'new';\n    if (d.severity === 'deleted') return 'deleted';\n    // error/warning: check delta direction\n    if (d.delta > 0) return 'degraded';\n    if (d.delta === 0) return 'unchanged';\n    return 'improved';\n  });\n\n  const counts = categorized.countBy().all() as unknown as Record<string, number>;\n\n  return {\n    totalDelta: collection.sum('delta') as number,\n    improved: counts['improved'] || 0,\n    degraded: counts['degraded'] || 0,\n    newFunctions: counts['new'] || 0,\n    deletedFunctions: counts['deleted'] || 0,\n    unchanged: counts['unchanged'] || 0,\n  };\n}\n\n/**\n * Format delta for display\n */\nexport function formatDelta(delta: number): string {\n  if (delta > 0) return `+${delta} ‚¨ÜÔ∏è`;\n  if (delta < 0) return `${delta} ‚¨áÔ∏è`;\n  return '¬±0';\n}\n\n/**\n * Format severity emoji\n */\nexport function formatSeverityEmoji(severity: ComplexityDelta['severity']): string {\n  switch (severity) {\n    case 'error':\n      return 'üî¥';\n    case 'warning':\n      return 'üü°';\n    case 'improved':\n      return 'üü¢';\n    case 'new':\n      return 'üÜï';\n    case 'deleted':\n      return 'üóëÔ∏è';\n  }\n}\n\n/**\n * Log delta summary\n */\nexport function logDeltaSummary(summary: DeltaSummary): void {\n  const sign = summary.totalDelta >= 0 ? '+' : '';\n  core.info(`Complexity delta: ${sign}${summary.totalDelta}`);\n  core.info(`  Degraded: ${summary.degraded}, Improved: ${summary.improved}`);\n  core.info(`  New: ${summary.newFunctions}, Deleted: ${summary.deletedFunctions}`);\n}\n\n","/**\n * Format time in minutes as human-readable (e.g., \"7h 54m\", \"-7h 54m\", or \"45m\")\n * Handles both positive values (for thresholds) and negative values (for deltas).\n * Rounds total minutes first to avoid edge cases like \"1h 60m\".\n */\nexport function formatTime(minutes: number): string {\n  const sign = minutes < 0 ? '-' : '';\n  const roundedMinutes = Math.round(Math.abs(minutes));\n  if (roundedMinutes >= 60) {\n    const hours = Math.floor(roundedMinutes / 60);\n    const mins = roundedMinutes % 60;\n    return mins > 0 ? `${sign}${hours}h ${mins}m` : `${sign}${hours}h`;\n  }\n  return `${sign}${roundedMinutes}m`;\n}\n\n/**\n * Format delta value for display based on metric type.\n * - halstead_bugs: 2 decimal places\n * - halstead_effort: human-readable time (e.g., \"-7h 54m\")\n * - others: rounded integer\n */\nexport function formatDeltaValue(metricType: string, delta: number): string {\n  if (metricType === 'halstead_bugs') {\n    return delta.toFixed(2);\n  }\n  // halstead_effort is stored in minutes - format as hours for readability\n  if (metricType === 'halstead_effort') {\n    return formatTime(delta);\n  }\n  return String(Math.round(delta));\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AACA,WAAO,UAAU;AACjB,aAAS,SAAS,GAAG,GAAG,KAAK;AAC3B,UAAI,aAAa,OAAQ,KAAI,WAAW,GAAG,GAAG;AAC9C,UAAI,aAAa,OAAQ,KAAI,WAAW,GAAG,GAAG;AAE9C,UAAI,IAAI,MAAM,GAAG,GAAG,GAAG;AAEvB,aAAO,KAAK;AAAA,QACV,OAAO,EAAE,CAAC;AAAA,QACV,KAAK,EAAE,CAAC;AAAA,QACR,KAAK,IAAI,MAAM,GAAG,EAAE,CAAC,CAAC;AAAA,QACtB,MAAM,IAAI,MAAM,EAAE,CAAC,IAAI,EAAE,QAAQ,EAAE,CAAC,CAAC;AAAA,QACrC,MAAM,IAAI,MAAM,EAAE,CAAC,IAAI,EAAE,MAAM;AAAA,MACjC;AAAA,IACF;AAEA,aAAS,WAAW,KAAK,KAAK;AAC5B,UAAI,IAAI,IAAI,MAAM,GAAG;AACrB,aAAO,IAAI,EAAE,CAAC,IAAI;AAAA,IACpB;AAEA,aAAS,QAAQ;AACjB,aAAS,MAAM,GAAG,GAAG,KAAK;AACxB,UAAI,MAAM,KAAK,MAAM,OAAO;AAC5B,UAAI,KAAK,IAAI,QAAQ,CAAC;AACtB,UAAI,KAAK,IAAI,QAAQ,GAAG,KAAK,CAAC;AAC9B,UAAI,IAAI;AAER,UAAI,MAAM,KAAK,KAAK,GAAG;AACrB,YAAG,MAAI,GAAG;AACR,iBAAO,CAAC,IAAI,EAAE;AAAA,QAChB;AACA,eAAO,CAAC;AACR,eAAO,IAAI;AAEX,eAAO,KAAK,KAAK,CAAC,QAAQ;AACxB,cAAI,KAAK,IAAI;AACX,iBAAK,KAAK,CAAC;AACX,iBAAK,IAAI,QAAQ,GAAG,IAAI,CAAC;AAAA,UAC3B,WAAW,KAAK,UAAU,GAAG;AAC3B,qBAAS,CAAE,KAAK,IAAI,GAAG,EAAG;AAAA,UAC5B,OAAO;AACL,kBAAM,KAAK,IAAI;AACf,gBAAI,MAAM,MAAM;AACd,qBAAO;AACP,sBAAQ;AAAA,YACV;AAEA,iBAAK,IAAI,QAAQ,GAAG,IAAI,CAAC;AAAA,UAC3B;AAEA,cAAI,KAAK,MAAM,MAAM,IAAI,KAAK;AAAA,QAChC;AAEA,YAAI,KAAK,QAAQ;AACf,mBAAS,CAAE,MAAM,KAAM;AAAA,QACzB;AAAA,MACF;AAEA,aAAO;AAAA,IACT;AAAA;AAAA;;;AC7DA;AAAA;AAAA;AAAA,QAAI,WAAW;AAEf,WAAO,UAAU;AAEjB,QAAI,WAAW,YAAU,KAAK,OAAO,IAAE;AACvC,QAAI,UAAU,WAAS,KAAK,OAAO,IAAE;AACrC,QAAI,WAAW,YAAU,KAAK,OAAO,IAAE;AACvC,QAAI,WAAW,YAAU,KAAK,OAAO,IAAE;AACvC,QAAI,YAAY,aAAW,KAAK,OAAO,IAAE;AAEzC,aAAS,QAAQ,KAAK;AACpB,aAAO,SAAS,KAAK,EAAE,KAAK,MACxB,SAAS,KAAK,EAAE,IAChB,IAAI,WAAW,CAAC;AAAA,IACtB;AAEA,aAAS,aAAa,KAAK;AACzB,aAAO,IAAI,MAAM,MAAM,EAAE,KAAK,QAAQ,EAC3B,MAAM,KAAK,EAAE,KAAK,OAAO,EACzB,MAAM,KAAK,EAAE,KAAK,QAAQ,EAC1B,MAAM,KAAK,EAAE,KAAK,QAAQ,EAC1B,MAAM,KAAK,EAAE,KAAK,SAAS;AAAA,IACxC;AAEA,aAAS,eAAe,KAAK;AAC3B,aAAO,IAAI,MAAM,QAAQ,EAAE,KAAK,IAAI,EACzB,MAAM,OAAO,EAAE,KAAK,GAAG,EACvB,MAAM,QAAQ,EAAE,KAAK,GAAG,EACxB,MAAM,QAAQ,EAAE,KAAK,GAAG,EACxB,MAAM,SAAS,EAAE,KAAK,GAAG;AAAA,IACtC;AAMA,aAAS,gBAAgB,KAAK;AAC5B,UAAI,CAAC;AACH,eAAO,CAAC,EAAE;AAEZ,UAAI,QAAQ,CAAC;AACb,UAAI,IAAI,SAAS,KAAK,KAAK,GAAG;AAE9B,UAAI,CAAC;AACH,eAAO,IAAI,MAAM,GAAG;AAEtB,UAAI,MAAM,EAAE;AACZ,UAAI,OAAO,EAAE;AACb,UAAI,OAAO,EAAE;AACb,UAAI,IAAI,IAAI,MAAM,GAAG;AAErB,QAAE,EAAE,SAAO,CAAC,KAAK,MAAM,OAAO;AAC9B,UAAI,YAAY,gBAAgB,IAAI;AACpC,UAAI,KAAK,QAAQ;AACf,UAAE,EAAE,SAAO,CAAC,KAAK,UAAU,MAAM;AACjC,UAAE,KAAK,MAAM,GAAG,SAAS;AAAA,MAC3B;AAEA,YAAM,KAAK,MAAM,OAAO,CAAC;AAEzB,aAAO;AAAA,IACT;AAEA,aAAS,UAAU,KAAK;AACtB,UAAI,CAAC;AACH,eAAO,CAAC;AAQV,UAAI,IAAI,OAAO,GAAG,CAAC,MAAM,MAAM;AAC7B,cAAM,WAAW,IAAI,OAAO,CAAC;AAAA,MAC/B;AAEA,aAAOA,QAAO,aAAa,GAAG,GAAG,IAAI,EAAE,IAAI,cAAc;AAAA,IAC3D;AAEA,aAAS,QAAQ,KAAK;AACpB,aAAO,MAAM,MAAM;AAAA,IACrB;AACA,aAAS,SAAS,IAAI;AACpB,aAAO,SAAS,KAAK,EAAE;AAAA,IACzB;AAEA,aAAS,IAAI,GAAG,GAAG;AACjB,aAAO,KAAK;AAAA,IACd;AACA,aAAS,IAAI,GAAG,GAAG;AACjB,aAAO,KAAK;AAAA,IACd;AAEA,aAASA,QAAO,KAAK,OAAO;AAC1B,UAAI,aAAa,CAAC;AAElB,UAAI,IAAI,SAAS,KAAK,KAAK,GAAG;AAC9B,UAAI,CAAC,EAAG,QAAO,CAAC,GAAG;AAGnB,UAAI,MAAM,EAAE;AACZ,UAAI,OAAO,EAAE,KAAK,SACdA,QAAO,EAAE,MAAM,KAAK,IACpB,CAAC,EAAE;AAEP,UAAI,MAAM,KAAK,EAAE,GAAG,GAAG;AACrB,iBAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACpC,cAAI,YAAY,MAAK,MAAM,EAAE,OAAO,MAAM,KAAK,CAAC;AAChD,qBAAW,KAAK,SAAS;AAAA,QAC3B;AAAA,MACF,OAAO;AACL,YAAI,oBAAoB,iCAAiC,KAAK,EAAE,IAAI;AACpE,YAAI,kBAAkB,uCAAuC,KAAK,EAAE,IAAI;AACxE,YAAI,aAAa,qBAAqB;AACtC,YAAI,YAAY,EAAE,KAAK,QAAQ,GAAG,KAAK;AACvC,YAAI,CAAC,cAAc,CAAC,WAAW;AAE7B,cAAI,EAAE,KAAK,MAAM,YAAY,GAAG;AAC9B,kBAAM,EAAE,MAAM,MAAM,EAAE,OAAO,WAAW,EAAE;AAC1C,mBAAOA,QAAO,GAAG;AAAA,UACnB;AACA,iBAAO,CAAC,GAAG;AAAA,QACb;AAEA,YAAI;AACJ,YAAI,YAAY;AACd,cAAI,EAAE,KAAK,MAAM,MAAM;AAAA,QACzB,OAAO;AACL,cAAI,gBAAgB,EAAE,IAAI;AAC1B,cAAI,EAAE,WAAW,GAAG;AAElB,gBAAIA,QAAO,EAAE,CAAC,GAAG,KAAK,EAAE,IAAI,OAAO;AACnC,gBAAI,EAAE,WAAW,GAAG;AAClB,qBAAO,KAAK,IAAI,SAAS,GAAG;AAC1B,uBAAO,EAAE,MAAM,EAAE,CAAC,IAAI;AAAA,cACxB,CAAC;AAAA,YACH;AAAA,UACF;AAAA,QACF;AAIA,YAAI;AAEJ,YAAI,YAAY;AACd,cAAI,IAAI,QAAQ,EAAE,CAAC,CAAC;AACpB,cAAI,IAAI,QAAQ,EAAE,CAAC,CAAC;AACpB,cAAI,QAAQ,KAAK,IAAI,EAAE,CAAC,EAAE,QAAQ,EAAE,CAAC,EAAE,MAAM;AAC7C,cAAI,OAAO,EAAE,UAAU,IACnB,KAAK,IAAI,QAAQ,EAAE,CAAC,CAAC,CAAC,IACtB;AACJ,cAAI,OAAO;AACX,cAAI,UAAU,IAAI;AAClB,cAAI,SAAS;AACX,oBAAQ;AACR,mBAAO;AAAA,UACT;AACA,cAAI,MAAM,EAAE,KAAK,QAAQ;AAEzB,cAAI,CAAC;AAEL,mBAAS,IAAI,GAAG,KAAK,GAAG,CAAC,GAAG,KAAK,MAAM;AACrC,gBAAI;AACJ,gBAAI,iBAAiB;AACnB,kBAAI,OAAO,aAAa,CAAC;AACzB,kBAAI,MAAM;AACR,oBAAI;AAAA,YACR,OAAO;AACL,kBAAI,OAAO,CAAC;AACZ,kBAAI,KAAK;AACP,oBAAI,OAAO,QAAQ,EAAE;AACrB,oBAAI,OAAO,GAAG;AACZ,sBAAI,IAAI,IAAI,MAAM,OAAO,CAAC,EAAE,KAAK,GAAG;AACpC,sBAAI,IAAI;AACN,wBAAI,MAAM,IAAI,EAAE,MAAM,CAAC;AAAA;AAEvB,wBAAI,IAAI;AAAA,gBACZ;AAAA,cACF;AAAA,YACF;AACA,cAAE,KAAK,CAAC;AAAA,UACV;AAAA,QACF,OAAO;AACL,cAAI,CAAC;AAEL,mBAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,KAAK;AACjC,cAAE,KAAK,MAAM,GAAGA,QAAO,EAAE,CAAC,GAAG,KAAK,CAAC;AAAA,UACrC;AAAA,QACF;AAEA,iBAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,KAAK;AACjC,mBAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACpC,gBAAI,YAAY,MAAM,EAAE,CAAC,IAAI,KAAK,CAAC;AACnC,gBAAI,CAAC,SAAS,cAAc;AAC1B,yBAAW,KAAK,SAAS;AAAA,UAC7B;AAAA,QACF;AAAA,MACF;AAEA,aAAO;AAAA,IACT;AAAA;AAAA;;;ACzMA;AAAA;AAAA;AACA,aAAS,UAAW,SAAS;AAC3B,aAAO,MAAM,QAAQ,OAAO,IACxB,UACA,CAAC,OAAO;AAAA,IACd;AAEA,QAAM,QAAQ;AACd,QAAM,QAAQ;AACd,QAAM,SAAS;AACf,QAAM,wBAAwB;AAC9B,QAAM,mCAAmC;AACzC,QAAM,4CAA4C;AAClD,QAAM,qCAAqC;AAC3C,QAAM,sBAAsB;AAM5B,QAAM,0BAA0B;AAEhC,QAAM,QAAQ;AAGd,QAAI,iBAAiB;AAErB,QAAI,OAAO,WAAW,aAAa;AACjC,uBAAiB,OAAO,IAAI,aAAa;AAAA,IAC3C;AACA,QAAM,aAAa;AAEnB,QAAM,SAAS,CAAC,QAAQ,KAAK,UAC3B,OAAO,eAAe,QAAQ,KAAK,EAAC,MAAK,CAAC;AAE5C,QAAM,qBAAqB;AAE3B,QAAM,eAAe,MAAM;AAI3B,QAAM,gBAAgB,WAAS,MAAM;AAAA,MACnC;AAAA,MACA,CAACC,QAAO,MAAM,OAAO,KAAK,WAAW,CAAC,KAAK,GAAG,WAAW,CAAC,IACtDA,SAGA;AAAA,IACN;AAGA,QAAM,sBAAsB,aAAW;AACrC,YAAM,EAAC,OAAM,IAAI;AACjB,aAAO,QAAQ,MAAM,GAAG,SAAS,SAAS,CAAC;AAAA,IAC7C;AAaA,QAAM,YAAY;AAAA;AAAA,MAGhB;AAAA;AAAA;AAAA;AAAA,QAIE;AAAA,QACA,CAAAA,WAASA,OAAM,QAAQ,IAAI,MAAM,IAC7B,QACA;AAAA,MACN;AAAA;AAAA,MAGA;AAAA,QACE;AAAA,QACA,MAAM;AAAA,MACR;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAmBA;AAAA,QACE;AAAA,QACA,CAAAA,WAAS,KAAKA,MAAK;AAAA,MACrB;AAAA,MAEA;AAAA;AAAA,QAEE;AAAA,QACA,MAAM;AAAA,MACR;AAAA;AAAA,MAGA;AAAA;AAAA;AAAA;AAAA,QAKE;AAAA,QACA,MAAM;AAAA,MACR;AAAA;AAAA,MAGA;AAAA,QACE;AAAA,QACA,MAAM;AAAA,MACR;AAAA,MAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAOE;AAAA;AAAA,QAGA,MAAM;AAAA,MACR;AAAA;AAAA,MAGA;AAAA;AAAA;AAAA;AAAA,QAIE;AAAA,QACA,SAAS,mBAAoB;AAE3B,iBAAO,CAAC,UAAU,KAAK,IAAI,IAavB,cAIA;AAAA,QACN;AAAA,MACF;AAAA;AAAA,MAGA;AAAA;AAAA,QAEE;AAAA;AAAA;AAAA;AAAA,QAMA,CAAC,GAAG,OAAO,QAAQ,QAAQ,IAAI,IAAI,SAO/B,oBAMA;AAAA,MACN;AAAA;AAAA,MAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAOE;AAAA;AAAA;AAAA,QAIA,CAAC,GAAG,IAAI,OAAO;AAMb,gBAAM,YAAY,GAAG,QAAQ,SAAS,SAAS;AAC/C,iBAAO,KAAK;AAAA,QACd;AAAA,MACF;AAAA,MAEA;AAAA;AAAA;AAAA;AAAA,QAIE;AAAA,QACA,MAAM;AAAA,MACR;AAAA,MAEA;AAAA;AAAA,QAEE;AAAA,QACA,MAAM;AAAA,MACR;AAAA,MAEA;AAAA;AAAA;AAAA;AAAA,QAKE;AAAA,QACA,CAACA,QAAO,YAAY,OAAO,WAAW,UAAU,eAAe,SAE3D,MAAM,KAAK,GAAG,oBAAoB,SAAS,CAAC,GAAG,KAAK,KACpD,UAAU,MACR,UAAU,SAAS,MAAM,IAIvB,IAAI,cAAc,KAAK,CAAC,GAAG,SAAS,MAGpC,OACF;AAAA,MACR;AAAA;AAAA,MAGA;AAAA;AAAA;AAAA,QAGE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAcA,CAAAA,WAAS,MAAM,KAAKA,MAAK,IAErB,GAAGA,MAAK,MAER,GAAGA,MAAK;AAAA,MACd;AAAA;AAAA,MAGA;AAAA,QACE;AAAA,QACA,CAAC,GAAG,OAAO;AACT,gBAAM,SAAS,KAOX,GAAG,EAAE,UAIL;AAEJ,iBAAO,GAAG,MAAM;AAAA,QAClB;AAAA,MACF;AAAA,IACF;AAGA,QAAM,aAAa,uBAAO,OAAO,IAAI;AAGrC,QAAM,YAAY,CAAC,SAAS,eAAe;AACzC,UAAI,SAAS,WAAW,OAAO;AAE/B,UAAI,CAAC,QAAQ;AACX,iBAAS,UAAU;AAAA,UACjB,CAAC,MAAM,YAAY,KAAK,QAAQ,QAAQ,CAAC,GAAG,QAAQ,CAAC,EAAE,KAAK,OAAO,CAAC;AAAA,UACpE;AAAA,QACF;AACA,mBAAW,OAAO,IAAI;AAAA,MACxB;AAEA,aAAO,aACH,IAAI,OAAO,QAAQ,GAAG,IACtB,IAAI,OAAO,MAAM;AAAA,IACvB;AAEA,QAAM,WAAW,aAAW,OAAO,YAAY;AAG/C,QAAM,eAAe,aAAW,WAC3B,SAAS,OAAO,KAChB,CAAC,sBAAsB,KAAK,OAAO,KACnC,CAAC,iCAAiC,KAAK,OAAO,KAG9C,QAAQ,QAAQ,GAAG,MAAM;AAE9B,QAAM,eAAe,aAAW,QAAQ,MAAM,mBAAmB;AAEjE,QAAM,aAAN,MAAiB;AAAA,MACf,YACE,QACA,SACA,UACA,OACA;AACA,aAAK,SAAS;AACd,aAAK,UAAU;AACf,aAAK,WAAW;AAChB,aAAK,QAAQ;AAAA,MACf;AAAA,IACF;AAEA,QAAM,aAAa,CAAC,SAAS,eAAe;AAC1C,YAAM,SAAS;AACf,UAAI,WAAW;AAGf,UAAI,QAAQ,QAAQ,GAAG,MAAM,GAAG;AAC9B,mBAAW;AACX,kBAAU,QAAQ,OAAO,CAAC;AAAA,MAC5B;AAEA,gBAAU,QAGT,QAAQ,2CAA2C,GAAG,EAGtD,QAAQ,oCAAoC,GAAG;AAEhD,YAAM,QAAQ,UAAU,SAAS,UAAU;AAE3C,aAAO,IAAI;AAAA,QACT;AAAA,QACA;AAAA,QACA;AAAA,QACA;AAAA,MACF;AAAA,IACF;AAEA,QAAM,aAAa,CAAC,SAAS,SAAS;AACpC,YAAM,IAAI,KAAK,OAAO;AAAA,IACxB;AAEA,QAAM,YAAY,CAACC,QAAM,cAAc,YAAY;AACjD,UAAI,CAAC,SAASA,MAAI,GAAG;AACnB,eAAO;AAAA,UACL,oCAAoC,YAAY;AAAA,UAChD;AAAA,QACF;AAAA,MACF;AAGA,UAAI,CAACA,QAAM;AACT,eAAO,QAAQ,0BAA0B,SAAS;AAAA,MACpD;AAGA,UAAI,UAAU,cAAcA,MAAI,GAAG;AACjC,cAAM,IAAI;AACV,eAAO;AAAA,UACL,oBAAoB,CAAC,qBAAqB,YAAY;AAAA,UACtD;AAAA,QACF;AAAA,MACF;AAEA,aAAO;AAAA,IACT;AAEA,QAAM,gBAAgB,CAAAA,WAAQ,wBAAwB,KAAKA,MAAI;AAE/D,cAAU,gBAAgB;AAC1B,cAAU,UAAU,OAAK;AAEzB,QAAMC,UAAN,MAAa;AAAA,MACX,YAAa;AAAA,QACX,aAAa;AAAA,QACb,aAAa;AAAA,QACb,qBAAqB;AAAA,MACvB,IAAI,CAAC,GAAG;AACN,eAAO,MAAM,YAAY,IAAI;AAE7B,aAAK,SAAS,CAAC;AACf,aAAK,cAAc;AACnB,aAAK,sBAAsB;AAC3B,aAAK,WAAW;AAAA,MAClB;AAAA,MAEA,aAAc;AACZ,aAAK,eAAe,uBAAO,OAAO,IAAI;AACtC,aAAK,aAAa,uBAAO,OAAO,IAAI;AAAA,MACtC;AAAA,MAEA,YAAa,SAAS;AAEpB,YAAI,WAAW,QAAQ,UAAU,GAAG;AAClC,eAAK,SAAS,KAAK,OAAO,OAAO,QAAQ,MAAM;AAC/C,eAAK,SAAS;AACd;AAAA,QACF;AAEA,YAAI,aAAa,OAAO,GAAG;AACzB,gBAAM,OAAO,WAAW,SAAS,KAAK,WAAW;AACjD,eAAK,SAAS;AACd,eAAK,OAAO,KAAK,IAAI;AAAA,QACvB;AAAA,MACF;AAAA;AAAA,MAGA,IAAK,SAAS;AACZ,aAAK,SAAS;AAEd;AAAA,UACE,SAAS,OAAO,IACZ,aAAa,OAAO,IACpB;AAAA,QACN,EAAE,QAAQ,KAAK,aAAa,IAAI;AAIhC,YAAI,KAAK,QAAQ;AACf,eAAK,WAAW;AAAA,QAClB;AAEA,eAAO;AAAA,MACT;AAAA;AAAA,MAGA,WAAY,SAAS;AACnB,eAAO,KAAK,IAAI,OAAO;AAAA,MACzB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAkBA,SAAUD,QAAM,gBAAgB;AAC9B,YAAI,UAAU;AACd,YAAI,YAAY;AAEhB,aAAK,OAAO,QAAQ,UAAQ;AAC1B,gBAAM,EAAC,SAAQ,IAAI;AACnB,cACE,cAAc,YAAY,YAAY,aACnC,YAAY,CAAC,WAAW,CAAC,aAAa,CAAC,gBAC1C;AACA;AAAA,UACF;AAEA,gBAAM,UAAU,KAAK,MAAM,KAAKA,MAAI;AAEpC,cAAI,SAAS;AACX,sBAAU,CAAC;AACX,wBAAY;AAAA,UACd;AAAA,QACF,CAAC;AAED,eAAO;AAAA,UACL;AAAA,UACA;AAAA,QACF;AAAA,MACF;AAAA;AAAA,MAGA,MAAO,cAAc,OAAO,gBAAgB,QAAQ;AAClD,cAAMA,SAAO,gBAER,UAAU,QAAQ,YAAY;AAEnC;AAAA,UACEA;AAAA,UACA;AAAA,UACA,KAAK,sBACD,eACA;AAAA,QACN;AAEA,eAAO,KAAK,GAAGA,QAAM,OAAO,gBAAgB,MAAM;AAAA,MACpD;AAAA,MAEA,GAAIA,QAAM,OAAO,gBAAgB,QAAQ;AACvC,YAAIA,UAAQ,OAAO;AACjB,iBAAO,MAAMA,MAAI;AAAA,QACnB;AAEA,YAAI,CAAC,QAAQ;AAGX,mBAASA,OAAK,MAAM,KAAK;AAAA,QAC3B;AAEA,eAAO,IAAI;AAGX,YAAI,CAAC,OAAO,QAAQ;AAClB,iBAAO,MAAMA,MAAI,IAAI,KAAK,SAASA,QAAM,cAAc;AAAA,QACzD;AAEA,cAAM,SAAS,KAAK;AAAA,UAClB,OAAO,KAAK,KAAK,IAAI;AAAA,UACrB;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAGA,eAAO,MAAMA,MAAI,IAAI,OAAO,UAGxB,SACA,KAAK,SAASA,QAAM,cAAc;AAAA,MACxC;AAAA,MAEA,QAASA,QAAM;AACb,eAAO,KAAK,MAAMA,QAAM,KAAK,cAAc,KAAK,EAAE;AAAA,MACpD;AAAA,MAEA,eAAgB;AACd,eAAO,CAAAA,WAAQ,CAAC,KAAK,QAAQA,MAAI;AAAA,MACnC;AAAA,MAEA,OAAQ,OAAO;AACb,eAAO,UAAU,KAAK,EAAE,OAAO,KAAK,aAAa,CAAC;AAAA,MACpD;AAAA;AAAA,MAGA,KAAMA,QAAM;AACV,eAAO,KAAK,MAAMA,QAAM,KAAK,YAAY,IAAI;AAAA,MAC/C;AAAA,IACF;AAEA,QAAM,UAAU,aAAW,IAAIC,QAAO,OAAO;AAE7C,QAAM,cAAc,CAAAD,WAClB,UAAUA,UAAQ,UAAU,QAAQA,MAAI,GAAGA,QAAM,YAAY;AAE/D,YAAQ,cAAc;AAGtB,YAAQ,UAAU;AAElB,WAAO,UAAU;AAKjB;AAAA;AAAA,MAEE,OAAO,YAAY,gBAEjB,QAAQ,OAAO,QAAQ,IAAI,qBACxB,QAAQ,aAAa;AAAA,MAE1B;AAEA,YAAM,YAAY,SAAO,YAAY,KAAK,GAAG,KAC1C,wBAAwB,KAAK,GAAG,IAC/B,MACA,IAAI,QAAQ,OAAO,GAAG;AAE1B,gBAAU,UAAU;AAIpB,YAAM,iCAAiC;AACvC,gBAAU,gBAAgB,CAAAA,WACxB,+BAA+B,KAAKA,MAAI,KACrC,cAAcA,MAAI;AAAA,IACzB;AAAA;AAAA;;;AC/lBA,YAAYE,WAAU;AACtB,YAAYC,UAAQ;AACpB,SAAS,gBAAgB;AACzB,OAAOC,cAAa;;;ACHpB,OAAOC,UAAQ;;;ACLf,IAAM,OAAN,MAAW;AAAA,EACV;AAAA,EACA;AAAA,EAEA,YAAY,OAAO;AAClB,SAAK,QAAQ;AAAA,EACd;AACD;AAEA,IAAqB,QAArB,MAA2B;AAAA,EAC1B;AAAA,EACA;AAAA,EACA;AAAA,EAEA,cAAc;AACb,SAAK,MAAM;AAAA,EACZ;AAAA,EAEA,QAAQ,OAAO;AACd,UAAM,OAAO,IAAI,KAAK,KAAK;AAE3B,QAAI,KAAK,OAAO;AACf,WAAK,MAAM,OAAO;AAClB,WAAK,QAAQ;AAAA,IACd,OAAO;AACN,WAAK,QAAQ;AACb,WAAK,QAAQ;AAAA,IACd;AAEA,SAAK;AAAA,EACN;AAAA,EAEA,UAAU;AACT,UAAM,UAAU,KAAK;AACrB,QAAI,CAAC,SAAS;AACb;AAAA,IACD;AAEA,SAAK,QAAQ,KAAK,MAAM;AACxB,SAAK;AAGL,QAAI,CAAC,KAAK,OAAO;AAChB,WAAK,QAAQ;AAAA,IACd;AAEA,WAAO,QAAQ;AAAA,EAChB;AAAA,EAEA,OAAO;AACN,QAAI,CAAC,KAAK,OAAO;AAChB;AAAA,IACD;AAEA,WAAO,KAAK,MAAM;AAAA,EAInB;AAAA,EAEA,QAAQ;AACP,SAAK,QAAQ;AACb,SAAK,QAAQ;AACb,SAAK,QAAQ;AAAA,EACd;AAAA,EAEA,IAAI,OAAO;AACV,WAAO,KAAK;AAAA,EACb;AAAA,EAEA,EAAG,OAAO,QAAQ,IAAI;AACrB,QAAI,UAAU,KAAK;AAEnB,WAAO,SAAS;AACf,YAAM,QAAQ;AACd,gBAAU,QAAQ;AAAA,IACnB;AAAA,EACD;AAAA,EAEA,CAAE,QAAQ;AACT,WAAO,KAAK,OAAO;AAClB,YAAM,KAAK,QAAQ;AAAA,IACpB;AAAA,EACD;AACD;;;ACxFA,SAAQ,qBAAoB;AAEb,SAAR,OAAwB,aAAa;AAC3C,MAAI,GAAG,OAAO,UAAU,WAAW,KAAK,gBAAgB,OAAO,sBAAsB,cAAc,IAAI;AACtG,UAAM,IAAI,UAAU,qDAAqD;AAAA,EAC1E;AAEA,QAAM,QAAQ,IAAI,MAAM;AACxB,MAAI,cAAc;AAElB,QAAM,OAAO,MAAM;AAClB;AAEA,QAAI,MAAM,OAAO,GAAG;AACnB,YAAM,QAAQ,EAAE;AAAA,IACjB;AAAA,EACD;AAEA,QAAMC,OAAM,OAAO,WAAW,SAAS,eAAe;AACrD;AAEA,UAAM,UAAU,YAAY,UAAU,GAAG,UAAU,GAAG;AAEtD,YAAQ,MAAM;AAEd,QAAI;AACH,YAAM;AAAA,IACP,QAAQ;AAAA,IAAC;AAET,SAAK;AAAA,EACN;AAEA,QAAM,UAAU,CAAC,WAAW,SAAS,eAAe;AACnD,UAAM;AAAA,MACL,cAAc,KAAKA,KAAI,KAAK,QAAW,WAAW,SAAS,UAAU,CAAC;AAAA,IACvE;AAEA,KAAC,YAAY;AAKZ,YAAM,QAAQ,QAAQ;AAEtB,UAAI,cAAc,eAAe,MAAM,OAAO,GAAG;AAChD,cAAM,QAAQ,EAAE;AAAA,MACjB;AAAA,IACD,GAAG;AAAA,EACJ;AAEA,QAAM,YAAY,CAAC,cAAc,eAAe,IAAI,QAAQ,aAAW;AACtE,YAAQ,WAAW,SAAS,UAAU;AAAA,EACvC,CAAC;AAED,SAAO,iBAAiB,WAAW;AAAA,IAClC,aAAa;AAAA,MACZ,KAAK,MAAM;AAAA,IACZ;AAAA,IACA,cAAc;AAAA,MACb,KAAK,MAAM,MAAM;AAAA,IAClB;AAAA,IACA,YAAY;AAAA,MACX,QAAQ;AACP,cAAM,MAAM;AAAA,MACb;AAAA,IACD;AAAA,EACD,CAAC;AAED,SAAO;AACR;;;ACtEA,6BAAmB;;;ACAnB,IAAM,qBAAqB,OAAO;AAC3B,IAAM,qBAA6C,CACxD,YAC6B;AAC7B,MAAI,OAAO,YAAY,UAAU;AAC/B,UAAM,IAAI,UAAU,iBAAiB;;AAGvC,MAAI,QAAQ,SAAS,oBAAoB;AACvC,UAAM,IAAI,UAAU,qBAAqB;;AAE7C;;;ACPA,IAAM,eAAsE;EAC1E,aAAa,CAAC,wBAAwB,IAAI;EAC1C,aAAa,CAAC,iBAAiB,IAAI;EACnC,aAAa,CAAC,eAAyB,KAAK;EAC5C,aAAa,CAAC,cAAc,IAAI;EAChC,aAAa,CAAC,WAAW,IAAI;EAC7B,aAAa,CAAC,WAAW,IAAI;EAC7B,aAAa,CAAC,gBAAgB,MAAM,IAAI;EACxC,aAAa,CAAC,WAAW,IAAI;EAC7B,aAAa,CAAC,UAAU,IAAI;EAC5B,aAAa,CAAC,UAAU,IAAI;EAC5B,aAAa,CAAC,yBAAyB,IAAI;EAC3C,aAAa,CAAC,WAAW,IAAI;EAC7B,YAAY,CAAC,+BAA+B,IAAI;EAChD,cAAc,CAAC,aAAa,KAAK;;AAKnC,IAAM,cAAc,CAAC,MAAc,EAAE,QAAQ,aAAa,MAAM;AAEhE,IAAM,eAAe,CAAC,MACpB,EAAE,QAAQ,4BAA4B,MAAM;AAG9C,IAAM,iBAAiB,CAAC,WAA6B,OAAO,KAAK,EAAE;AAe5D,IAAM,aAAa,CACxBC,OACA,aACoB;AACpB,QAAM,MAAM;AAEZ,MAAIA,MAAK,OAAO,GAAG,MAAM,KAAK;AAC5B,UAAM,IAAI,MAAM,2BAA2B;;AAG7C,QAAM,SAAmB,CAAA;AACzB,QAAM,OAAiB,CAAA;AAEvB,MAAI,IAAI,MAAM;AACd,MAAI,WAAW;AACf,MAAI,QAAQ;AACZ,MAAI,WAAW;AACf,MAAI,SAAS;AACb,MAAI,SAAS;AACb,MAAI,aAAa;AACjB,QAAO,QAAO,IAAIA,MAAK,QAAQ;AAC7B,UAAM,IAAIA,MAAK,OAAO,CAAC;AACvB,SAAK,MAAM,OAAO,MAAM,QAAQ,MAAM,MAAM,GAAG;AAC7C,eAAS;AACT;AACA;;AAGF,QAAI,MAAM,OAAO,YAAY,CAAC,UAAU;AACtC,eAAS,IAAI;AACb;;AAGF,eAAW;AACX,QAAI,MAAM,MAAM;AACd,UAAI,CAAC,UAAU;AACb,mBAAW;AACX;AACA;;;AAIJ,QAAI,MAAM,OAAO,CAAC,UAAU;AAE1B,iBAAW,CAAC,KAAK,CAAC,MAAM,GAAG,GAAG,CAAC,KAAK,OAAO,QAAQ,YAAY,GAAG;AAChE,YAAIA,MAAK,WAAW,KAAK,CAAC,GAAG;AAE3B,cAAI,YAAY;AACd,mBAAO,CAAC,MAAM,OAAOA,MAAK,SAAS,KAAK,IAAI;;AAE9C,eAAK,IAAI;AACT,cAAI;AAAK,iBAAK,KAAK,IAAI;;AAClB,mBAAO,KAAK,IAAI;AACrB,kBAAQ,SAAS;AACjB,mBAAS;;;;AAMf,eAAW;AACX,QAAI,YAAY;AAGd,UAAI,IAAI,YAAY;AAClB,eAAO,KAAK,YAAY,UAAU,IAAI,MAAM,YAAY,CAAC,CAAC;iBACjD,MAAM,YAAY;AAC3B,eAAO,KAAK,YAAY,CAAC,CAAC;;AAE5B,mBAAa;AACb;AACA;;AAKF,QAAIA,MAAK,WAAW,MAAM,IAAI,CAAC,GAAG;AAChC,aAAO,KAAK,YAAY,IAAI,GAAG,CAAC;AAChC,WAAK;AACL;;AAEF,QAAIA,MAAK,WAAW,KAAK,IAAI,CAAC,GAAG;AAC/B,mBAAa;AACb,WAAK;AACL;;AAIF,WAAO,KAAK,YAAY,CAAC,CAAC;AAC1B;;AAGF,MAAI,SAAS,GAAG;AAGd,WAAO,CAAC,IAAI,OAAO,GAAG,KAAK;;AAK7B,MAAI,CAAC,OAAO,UAAU,CAAC,KAAK,QAAQ;AAClC,WAAO,CAAC,MAAM,OAAOA,MAAK,SAAS,KAAK,IAAI;;AAO9C,MACE,KAAK,WAAW,KAChB,OAAO,WAAW,KAClB,SAAS,KAAK,OAAO,CAAC,CAAC,KACvB,CAAC,QACD;AACA,UAAM,IAAI,OAAO,CAAC,EAAE,WAAW,IAAI,OAAO,CAAC,EAAE,MAAM,EAAE,IAAI,OAAO,CAAC;AACjE,WAAO,CAAC,aAAa,CAAC,GAAG,OAAO,SAAS,KAAK,KAAK;;AAGrD,QAAM,UAAU,OAAO,SAAS,MAAM,MAAM,eAAe,MAAM,IAAI;AACrE,QAAM,QAAQ,OAAO,SAAS,KAAK,OAAO,eAAe,IAAI,IAAI;AACjE,QAAM,OACJ,OAAO,UAAU,KAAK,SAClB,MAAM,UAAU,MAAM,QAAQ,MAC9B,OAAO,SACP,UACA;AAEN,SAAO,CAAC,MAAM,OAAO,SAAS,KAAK,IAAI;AACzC;;;AC7JO,IAAM,WAAW,CACtB,GACA,EACE,uBAAuB,MAAK,IACsB,CAAA,MAClD;AACF,SAAO,uBACH,EAAE,QAAQ,kBAAkB,IAAI,IAChC,EAAE,QAAQ,6BAA6B,MAAM,EAAE,QAAQ,cAAc,IAAI;AAC/E;;;ACoBA,IAAM,QAAQ,oBAAI,IAAiB,CAAC,KAAK,KAAK,KAAK,KAAK,GAAG,CAAC;AAC5D,IAAM,gBAAgB,CAAC,MACrB,MAAM,IAAI,CAAgB;AAM5B,IAAM,mBAAmB;AACzB,IAAM,aAAa;AAKnB,IAAM,kBAAkB,oBAAI,IAAI,CAAC,KAAK,GAAG,CAAC;AAE1C,IAAM,WAAW,oBAAI,IAAI,CAAC,MAAM,GAAG,CAAC;AACpC,IAAM,aAAa,IAAI,IAAI,iBAAiB;AAC5C,IAAM,eAAe,CAAC,MACpB,EAAE,QAAQ,4BAA4B,MAAM;AAG9C,IAAM,QAAQ;AAGd,IAAM,OAAO,QAAQ;AAGrB,IAAM,cAAc,QAAQ;AAKtB,IAAO,MAAP,MAAO,KAAG;EACd;EACS;EAET;EACA,SAAkB;EAClB,SAA2B,CAAA;EAClB;EACA;EACT;EACA,cAAuB;EACvB;EACA;;;EAGA,YAAqB;EAErB,YACE,MACA,QACA,UAA4B,CAAA,GAAE;AAE9B,SAAK,OAAO;AAEZ,QAAI;AAAM,WAAK,YAAY;AAC3B,SAAK,UAAU;AACf,SAAK,QAAQ,KAAK,UAAU,KAAK,QAAQ,QAAQ;AACjD,SAAK,WAAW,KAAK,UAAU,OAAO,UAAU,KAAK,MAAM;AAC3D,SAAK,QAAQ,KAAK,UAAU,OAAO,CAAA,IAAK,KAAK,MAAM;AACnD,QAAI,SAAS,OAAO,CAAC,KAAK,MAAM;AAAa,WAAK,MAAM,KAAK,IAAI;AACjE,SAAK,eAAe,KAAK,UAAU,KAAK,QAAQ,OAAO,SAAS;EAClE;EAEA,IAAI,WAAQ;AAEV,QAAI,KAAK,cAAc;AAAW,aAAO,KAAK;AAE9C,eAAW,KAAK,KAAK,QAAQ;AAC3B,UAAI,OAAO,MAAM;AAAU;AAC3B,UAAI,EAAE,QAAQ,EAAE;AAAU,eAAQ,KAAK,YAAY;;AAGrD,WAAO,KAAK;EACd;;EAGA,WAAQ;AACN,QAAI,KAAK,cAAc;AAAW,aAAO,KAAK;AAC9C,QAAI,CAAC,KAAK,MAAM;AACd,aAAQ,KAAK,YAAY,KAAK,OAAO,IAAI,OAAK,OAAO,CAAC,CAAC,EAAE,KAAK,EAAE;WAC3D;AACL,aAAQ,KAAK,YACX,KAAK,OAAO,MAAM,KAAK,OAAO,IAAI,OAAK,OAAO,CAAC,CAAC,EAAE,KAAK,GAAG,IAAI;;EAEpE;EAEA,YAAS;AAEP,QAAI,SAAS,KAAK;AAAO,YAAM,IAAI,MAAM,0BAA0B;AACnE,QAAI,KAAK;AAAa,aAAO;AAI7B,SAAK,SAAQ;AACb,SAAK,cAAc;AACnB,QAAI;AACJ,WAAQ,IAAI,KAAK,MAAM,IAAG,GAAK;AAC7B,UAAI,EAAE,SAAS;AAAK;AAEpB,UAAI,IAAqB;AACzB,UAAI,KAAK,EAAE;AACX,aAAO,IAAI;AACT,iBACM,IAAI,EAAE,eAAe,GACzB,CAAC,GAAG,QAAQ,IAAI,GAAG,OAAO,QAC1B,KACA;AACA,qBAAW,QAAQ,EAAE,QAAQ;AAE3B,gBAAI,OAAO,SAAS,UAAU;AAC5B,oBAAM,IAAI,MAAM,8BAA8B;;AAGhD,iBAAK,OAAO,GAAG,OAAO,CAAC,CAAC;;;AAG5B,YAAI;AACJ,aAAK,EAAE;;;AAGX,WAAO;EACT;EAEA,QAAQ,OAAuB;AAC7B,eAAW,KAAK,OAAO;AACrB,UAAI,MAAM;AAAI;AAEd,UAAI,OAAO,MAAM,YAAY,EAAE,aAAa,QAAO,EAAE,YAAY,OAAO;AACtE,cAAM,IAAI,MAAM,mBAAmB,CAAC;;AAGtC,WAAK,OAAO,KAAK,CAAC;;EAEtB;EAEA,SAAM;AACJ,UAAM,MACJ,KAAK,SAAS,OACV,KAAK,OAAO,MAAK,EAAG,IAAI,OAAM,OAAO,MAAM,WAAW,IAAI,EAAE,OAAM,CAAG,IACrE,CAAC,KAAK,MAAM,GAAG,KAAK,OAAO,IAAI,OAAM,EAAU,OAAM,CAAE,CAAC;AAC9D,QAAI,KAAK,QAAO,KAAM,CAAC,KAAK;AAAM,UAAI,QAAQ,CAAA,CAAE;AAChD,QACE,KAAK,MAAK,MACT,SAAS,KAAK,SACZ,KAAK,MAAM,eAAe,KAAK,SAAS,SAAS,MACpD;AACA,UAAI,KAAK,CAAA,CAAE;;AAEb,WAAO;EACT;EAEA,UAAO;AACL,QAAI,KAAK,UAAU;AAAM,aAAO;AAEhC,QAAI,CAAC,KAAK,SAAS,QAAO;AAAI,aAAO;AACrC,QAAI,KAAK,iBAAiB;AAAG,aAAO;AAEpC,UAAM,IAAI,KAAK;AACf,aAAS,IAAI,GAAG,IAAI,KAAK,cAAc,KAAK;AAC1C,YAAM,KAAK,EAAE,OAAO,CAAC;AACrB,UAAI,EAAE,cAAc,QAAO,GAAG,SAAS,MAAM;AAC3C,eAAO;;;AAGX,WAAO;EACT;EAEA,QAAK;AACH,QAAI,KAAK,UAAU;AAAM,aAAO;AAChC,QAAI,KAAK,SAAS,SAAS;AAAK,aAAO;AACvC,QAAI,CAAC,KAAK,SAAS,MAAK;AAAI,aAAO;AACnC,QAAI,CAAC,KAAK;AAAM,aAAO,KAAK,SAAS,MAAK;AAG1C,UAAM,KAAK,KAAK,UAAU,KAAK,QAAQ,OAAO,SAAS;AAEvD,WAAO,KAAK,iBAAiB,KAAK;EACpC;EAEA,OAAO,MAAkB;AACvB,QAAI,OAAO,SAAS;AAAU,WAAK,KAAK,IAAI;;AACvC,WAAK,KAAK,KAAK,MAAM,IAAI,CAAC;EACjC;EAEA,MAAM,QAAW;AACf,UAAM,IAAI,IAAI,KAAI,KAAK,MAAM,MAAM;AACnC,eAAW,KAAK,KAAK,QAAQ;AAC3B,QAAE,OAAO,CAAC;;AAEZ,WAAO;EACT;EAEA,OAAO,UACL,KACA,KACA,KACA,KAAqB;AAErB,QAAI,WAAW;AACf,QAAI,UAAU;AACd,QAAI,aAAa;AACjB,QAAI,WAAW;AACf,QAAI,IAAI,SAAS,MAAM;AAErB,UAAIC,KAAI;AACR,UAAIC,OAAM;AACV,aAAOD,KAAI,IAAI,QAAQ;AACrB,cAAM,IAAI,IAAI,OAAOA,IAAG;AAGxB,YAAI,YAAY,MAAM,MAAM;AAC1B,qBAAW,CAAC;AACZ,UAAAC,QAAO;AACP;;AAGF,YAAI,SAAS;AACX,cAAID,OAAM,aAAa,GAAG;AACxB,gBAAI,MAAM,OAAO,MAAM,KAAK;AAC1B,yBAAW;;qBAEJ,MAAM,OAAO,EAAEA,OAAM,aAAa,KAAK,WAAW;AAC3D,sBAAU;;AAEZ,UAAAC,QAAO;AACP;mBACS,MAAM,KAAK;AACpB,oBAAU;AACV,uBAAaD;AACb,qBAAW;AACX,UAAAC,QAAO;AACP;;AAGF,YAAI,CAAC,IAAI,SAAS,cAAc,CAAC,KAAK,IAAI,OAAOD,EAAC,MAAM,KAAK;AAC3D,cAAI,KAAKC,IAAG;AACZ,UAAAA,OAAM;AACN,gBAAMC,OAAM,IAAI,KAAI,GAAG,GAAG;AAC1B,UAAAF,KAAI,KAAI,UAAU,KAAKE,MAAKF,IAAG,GAAG;AAClC,cAAI,KAAKE,IAAG;AACZ;;AAEF,QAAAD,QAAO;;AAET,UAAI,KAAKA,IAAG;AACZ,aAAOD;;AAKT,QAAI,IAAI,MAAM;AACd,QAAI,OAAO,IAAI,KAAI,MAAM,GAAG;AAC5B,UAAM,QAAe,CAAA;AACrB,QAAI,MAAM;AACV,WAAO,IAAI,IAAI,QAAQ;AACrB,YAAM,IAAI,IAAI,OAAO,GAAG;AAGxB,UAAI,YAAY,MAAM,MAAM;AAC1B,mBAAW,CAAC;AACZ,eAAO;AACP;;AAGF,UAAI,SAAS;AACX,YAAI,MAAM,aAAa,GAAG;AACxB,cAAI,MAAM,OAAO,MAAM,KAAK;AAC1B,uBAAW;;mBAEJ,MAAM,OAAO,EAAE,MAAM,aAAa,KAAK,WAAW;AAC3D,oBAAU;;AAEZ,eAAO;AACP;iBACS,MAAM,KAAK;AACpB,kBAAU;AACV,qBAAa;AACb,mBAAW;AACX,eAAO;AACP;;AAGF,UAAI,cAAc,CAAC,KAAK,IAAI,OAAO,CAAC,MAAM,KAAK;AAC7C,aAAK,KAAK,GAAG;AACb,cAAM;AACN,cAAME,OAAM,IAAI,KAAI,GAAG,IAAI;AAC3B,aAAK,KAAKA,IAAG;AACb,YAAI,KAAI,UAAU,KAAKA,MAAK,GAAG,GAAG;AAClC;;AAEF,UAAI,MAAM,KAAK;AACb,aAAK,KAAK,GAAG;AACb,cAAM;AACN,cAAM,KAAK,IAAI;AACf,eAAO,IAAI,KAAI,MAAM,GAAG;AACxB;;AAEF,UAAI,MAAM,KAAK;AACb,YAAI,QAAQ,MAAM,IAAI,OAAO,WAAW,GAAG;AACzC,cAAI,YAAY;;AAElB,aAAK,KAAK,GAAG;AACb,cAAM;AACN,YAAI,KAAK,GAAG,OAAO,IAAI;AACvB,eAAO;;AAET,aAAO;;AAMT,QAAI,OAAO;AACX,QAAI,YAAY;AAChB,QAAI,SAAS,CAAC,IAAI,UAAU,MAAM,CAAC,CAAC;AACpC,WAAO;EACT;EAEA,OAAO,SAAS,SAAiB,UAA4B,CAAA,GAAE;AAC7D,UAAM,MAAM,IAAI,KAAI,MAAM,QAAW,OAAO;AAC5C,SAAI,UAAU,SAAS,KAAK,GAAG,OAAO;AACtC,WAAO;EACT;;;EAIA,cAAW;AAGT,QAAI,SAAS,KAAK;AAAO,aAAO,KAAK,MAAM,YAAW;AAEtD,UAAMC,QAAO,KAAK,SAAQ;AAC1B,UAAM,CAAC,IAAI,MAAMC,WAAU,KAAK,IAAI,KAAK,eAAc;AAIvD,UAAM,WACJA,aACA,KAAK,aACJ,KAAK,SAAS,UACb,CAAC,KAAK,SAAS,mBACfD,MAAK,YAAW,MAAOA,MAAK,YAAW;AAC3C,QAAI,CAAC,UAAU;AACb,aAAO;;AAGT,UAAM,SAAS,KAAK,SAAS,SAAS,MAAM,OAAO,QAAQ,MAAM;AACjE,WAAO,OAAO,OAAO,IAAI,OAAO,IAAI,EAAE,KAAK,KAAK,GAAG;MACjD,MAAM;MACN,OAAOA;KACR;EACH;EAEA,IAAI,UAAO;AACT,WAAO,KAAK;EACd;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAuEA,eACE,UAAkB;AAElB,UAAM,MAAM,YAAY,CAAC,CAAC,KAAK,SAAS;AACxC,QAAI,KAAK,UAAU;AAAM,WAAK,UAAS;AACvC,QAAI,CAAC,KAAK,MAAM;AACd,YAAM,UAAU,KAAK,QAAO,KAAM,KAAK,MAAK;AAC5C,YAAM,MAAM,KAAK,OACd,IAAI,OAAI;AACP,cAAM,CAAC,IAAI,GAAGC,WAAU,KAAK,IAC3B,OAAO,MAAM,WACT,KAAI,WAAW,GAAG,KAAK,WAAW,OAAO,IACzC,EAAE,eAAe,QAAQ;AAC/B,aAAK,YAAY,KAAK,aAAaA;AACnC,aAAK,SAAS,KAAK,UAAU;AAC7B,eAAO;MACT,CAAC,EACA,KAAK,EAAE;AAEV,UAAIC,SAAQ;AACZ,UAAI,KAAK,QAAO,GAAI;AAClB,YAAI,OAAO,KAAK,OAAO,CAAC,MAAM,UAAU;AAMtC,gBAAM,iBACJ,KAAK,OAAO,WAAW,KAAK,SAAS,IAAI,KAAK,OAAO,CAAC,CAAC;AACzD,cAAI,CAAC,gBAAgB;AACnB,kBAAM,MAAM;AAGZ,kBAAM;;cAEH,OAAO,IAAI,IAAI,IAAI,OAAO,CAAC,CAAC;cAE5B,IAAI,WAAW,KAAK,KAAK,IAAI,IAAI,IAAI,OAAO,CAAC,CAAC;cAE9C,IAAI,WAAW,QAAQ,KAAK,IAAI,IAAI,IAAI,OAAO,CAAC,CAAC;;AAGpD,kBAAM,YAAY,CAAC,OAAO,CAAC,YAAY,IAAI,IAAI,IAAI,OAAO,CAAC,CAAC;AAE5D,YAAAA,SAAQ,aAAa,mBAAmB,YAAY,aAAa;;;;AAMvE,UAAI,MAAM;AACV,UACE,KAAK,MAAK,KACV,KAAK,MAAM,eACX,KAAK,SAAS,SAAS,KACvB;AACA,cAAM;;AAER,YAAMC,SAAQD,SAAQ,MAAM;AAC5B,aAAO;QACLC;QACA,SAAS,GAAG;QACX,KAAK,YAAY,CAAC,CAAC,KAAK;QACzB,KAAK;;;AAQT,UAAM,WAAW,KAAK,SAAS,OAAO,KAAK,SAAS;AAEpD,UAAM,QAAQ,KAAK,SAAS,MAAM,cAAc;AAChD,QAAI,OAAO,KAAK,eAAe,GAAG;AAElC,QAAI,KAAK,QAAO,KAAM,KAAK,MAAK,KAAM,CAAC,QAAQ,KAAK,SAAS,KAAK;AAGhE,YAAM,IAAI,KAAK,SAAQ;AACvB,WAAK,SAAS,CAAC,CAAC;AAChB,WAAK,OAAO;AACZ,WAAK,YAAY;AACjB,aAAO,CAAC,GAAG,SAAS,KAAK,SAAQ,CAAE,GAAG,OAAO,KAAK;;AAIpD,QAAI,iBACF,CAAC,YAAY,YAAY,OAAO,CAAC,aAC7B,KACA,KAAK,eAAe,IAAI;AAC9B,QAAI,mBAAmB,MAAM;AAC3B,uBAAiB;;AAEnB,QAAI,gBAAgB;AAClB,aAAO,MAAM,IAAI,OAAO,cAAc;;AAIxC,QAAI,QAAQ;AACZ,QAAI,KAAK,SAAS,OAAO,KAAK,WAAW;AACvC,eAAS,KAAK,QAAO,KAAM,CAAC,MAAM,aAAa,MAAM;WAChD;AACL,YAAM,QACJ,KAAK,SAAS;;QAEV,QACC,KAAK,QAAO,KAAM,CAAC,OAAO,CAAC,WAAW,aAAa,MACpD,OACA;UACA,KAAK,SAAS,MACd,MACA,KAAK,SAAS,MACd,OACA,KAAK,SAAS,OAAO,iBACrB,MACA,KAAK,SAAS,OAAO,iBACrB,OACA,IAAI,KAAK,IAAI;AACnB,cAAQ,QAAQ,OAAO;;AAEzB,WAAO;MACL;MACA,SAAS,IAAI;MACZ,KAAK,YAAY,CAAC,CAAC,KAAK;MACzB,KAAK;;EAET;EAEA,eAAe,KAAY;AACzB,WAAO,KAAK,OACT,IAAI,OAAI;AAGP,UAAI,OAAO,MAAM,UAAU;AACzB,cAAM,IAAI,MAAM,8BAA8B;;AAIhD,YAAM,CAAC,IAAI,GAAG,WAAW,KAAK,IAAI,EAAE,eAAe,GAAG;AACtD,WAAK,SAAS,KAAK,UAAU;AAC7B,aAAO;IACT,CAAC,EACA,OAAO,OAAK,EAAE,KAAK,QAAO,KAAM,KAAK,MAAK,MAAO,CAAC,CAAC,CAAC,EACpD,KAAK,GAAG;EACb;EAEA,OAAO,WACLH,OACAC,WACA,UAAmB,OAAK;AAExB,QAAI,WAAW;AACf,QAAI,KAAK;AACT,QAAI,QAAQ;AACZ,aAAS,IAAI,GAAG,IAAID,MAAK,QAAQ,KAAK;AACpC,YAAM,IAAIA,MAAK,OAAO,CAAC;AACvB,UAAI,UAAU;AACZ,mBAAW;AACX,eAAO,WAAW,IAAI,CAAC,IAAI,OAAO,MAAM;AACxC;;AAEF,UAAI,MAAM,MAAM;AACd,YAAI,MAAMA,MAAK,SAAS,GAAG;AACzB,gBAAM;eACD;AACL,qBAAW;;AAEb;;AAEF,UAAI,MAAM,KAAK;AACb,cAAM,CAAC,KAAK,WAAW,UAAU,KAAK,IAAI,WAAWA,OAAM,CAAC;AAC5D,YAAI,UAAU;AACZ,gBAAM;AACN,kBAAQ,SAAS;AACjB,eAAK,WAAW;AAChB,UAAAC,YAAWA,aAAY;AACvB;;;AAGJ,UAAI,MAAM,KAAK;AACb,YAAI,WAAWD,UAAS;AAAK,gBAAM;;AAC9B,gBAAM;AACX,QAAAC,YAAW;AACX;;AAEF,UAAI,MAAM,KAAK;AACb,cAAM;AACN,QAAAA,YAAW;AACX;;AAEF,YAAM,aAAa,CAAC;;AAEtB,WAAO,CAAC,IAAI,SAASD,KAAI,GAAG,CAAC,CAACC,WAAU,KAAK;EAC/C;;;;ACjpBK,IAAM,SAAS,CACpB,GACA,EACE,uBAAuB,MAAK,IACsB,CAAA,MAClD;AAIF,SAAO,uBACH,EAAE,QAAQ,cAAc,MAAM,IAC9B,EAAE,QAAQ,gBAAgB,MAAM;AACtC;;;ALoBO,IAAM,YAAY,CACvB,GACA,SACA,UAA4B,CAAA,MAC1B;AACF,qBAAmB,OAAO;AAG1B,MAAI,CAAC,QAAQ,aAAa,QAAQ,OAAO,CAAC,MAAM,KAAK;AACnD,WAAO;;AAGT,SAAO,IAAI,UAAU,SAAS,OAAO,EAAE,MAAM,CAAC;AAChD;AAGA,IAAM,eAAe;AACrB,IAAM,iBAAiB,CAACG,SAAgB,CAAC,MACvC,CAAC,EAAE,WAAW,GAAG,KAAK,EAAE,SAASA,IAAG;AACtC,IAAM,oBAAoB,CAACA,SAAgB,CAAC,MAAc,EAAE,SAASA,IAAG;AACxE,IAAM,uBAAuB,CAACA,SAAe;AAC3C,EAAAA,OAAMA,KAAI,YAAW;AACrB,SAAO,CAAC,MAAc,CAAC,EAAE,WAAW,GAAG,KAAK,EAAE,YAAW,EAAG,SAASA,IAAG;AAC1E;AACA,IAAM,0BAA0B,CAACA,SAAe;AAC9C,EAAAA,OAAMA,KAAI,YAAW;AACrB,SAAO,CAAC,MAAc,EAAE,YAAW,EAAG,SAASA,IAAG;AACpD;AACA,IAAM,gBAAgB;AACtB,IAAM,kBAAkB,CAAC,MAAc,CAAC,EAAE,WAAW,GAAG,KAAK,EAAE,SAAS,GAAG;AAC3E,IAAM,qBAAqB,CAAC,MAC1B,MAAM,OAAO,MAAM,QAAQ,EAAE,SAAS,GAAG;AAC3C,IAAM,YAAY;AAClB,IAAM,cAAc,CAAC,MAAc,MAAM,OAAO,MAAM,QAAQ,EAAE,WAAW,GAAG;AAC9E,IAAM,SAAS;AACf,IAAM,WAAW,CAAC,MAAc,EAAE,WAAW,KAAK,CAAC,EAAE,WAAW,GAAG;AACnE,IAAM,cAAc,CAAC,MAAc,EAAE,WAAW,KAAK,MAAM,OAAO,MAAM;AACxE,IAAM,WAAW;AACjB,IAAM,mBAAmB,CAAC,CAAC,IAAIA,OAAM,EAAE,MAAuB;AAC5D,QAAM,QAAQ,gBAAgB,CAAC,EAAE,CAAC;AAClC,MAAI,CAACA;AAAK,WAAO;AACjB,EAAAA,OAAMA,KAAI,YAAW;AACrB,SAAO,CAAC,MAAc,MAAM,CAAC,KAAK,EAAE,YAAW,EAAG,SAASA,IAAG;AAChE;AACA,IAAM,sBAAsB,CAAC,CAAC,IAAIA,OAAM,EAAE,MAAuB;AAC/D,QAAM,QAAQ,mBAAmB,CAAC,EAAE,CAAC;AACrC,MAAI,CAACA;AAAK,WAAO;AACjB,EAAAA,OAAMA,KAAI,YAAW;AACrB,SAAO,CAAC,MAAc,MAAM,CAAC,KAAK,EAAE,YAAW,EAAG,SAASA,IAAG;AAChE;AACA,IAAM,gBAAgB,CAAC,CAAC,IAAIA,OAAM,EAAE,MAAuB;AACzD,QAAM,QAAQ,mBAAmB,CAAC,EAAE,CAAC;AACrC,SAAO,CAACA,OAAM,QAAQ,CAAC,MAAc,MAAM,CAAC,KAAK,EAAE,SAASA,IAAG;AACjE;AACA,IAAM,aAAa,CAAC,CAAC,IAAIA,OAAM,EAAE,MAAuB;AACtD,QAAM,QAAQ,gBAAgB,CAAC,EAAE,CAAC;AAClC,SAAO,CAACA,OAAM,QAAQ,CAAC,MAAc,MAAM,CAAC,KAAK,EAAE,SAASA,IAAG;AACjE;AACA,IAAM,kBAAkB,CAAC,CAAC,EAAE,MAAuB;AACjD,QAAM,MAAM,GAAG;AACf,SAAO,CAAC,MAAc,EAAE,WAAW,OAAO,CAAC,EAAE,WAAW,GAAG;AAC7D;AACA,IAAM,qBAAqB,CAAC,CAAC,EAAE,MAAuB;AACpD,QAAM,MAAM,GAAG;AACf,SAAO,CAAC,MAAc,EAAE,WAAW,OAAO,MAAM,OAAO,MAAM;AAC/D;AAGA,IAAM,kBACJ,OAAO,YAAY,YAAY,UAC1B,OAAO,QAAQ,QAAQ,YACtB,QAAQ,OACR,QAAQ,IAAI,kCACd,QAAQ,WACR;AAGN,IAAM,OAAsC;EAC1C,OAAO,EAAE,KAAK,KAAI;EAClB,OAAO,EAAE,KAAK,IAAG;;AAIZ,IAAM,MAAM,oBAAoB,UAAU,KAAK,MAAM,MAAM,KAAK,MAAM;AAC7E,UAAU,MAAM;AAET,IAAM,WAAW,OAAO,aAAa;AAC5C,UAAU,WAAW;AAIrB,IAAMC,SAAQ;AAGd,IAAMC,QAAOD,SAAQ;AAKrB,IAAM,aAAa;AAInB,IAAM,eAAe;AAEd,IAAM,SACX,CAAC,SAAiB,UAA4B,CAAA,MAC9C,CAAC,MACC,UAAU,GAAG,SAAS,OAAO;AACjC,UAAU,SAAS;AAEnB,IAAM,MAAM,CAAC,GAAqB,IAAsB,CAAA,MACtD,OAAO,OAAO,CAAA,GAAI,GAAG,CAAC;AAEjB,IAAM,WAAW,CAAC,QAA2C;AAClE,MAAI,CAAC,OAAO,OAAO,QAAQ,YAAY,CAAC,OAAO,KAAK,GAAG,EAAE,QAAQ;AAC/D,WAAO;;AAGT,QAAM,OAAO;AAEb,QAAM,IAAI,CAAC,GAAW,SAAiB,UAA4B,CAAA,MACjE,KAAK,GAAG,SAAS,IAAI,KAAK,OAAO,CAAC;AAEpC,SAAO,OAAO,OAAO,GAAG;IACtB,WAAW,MAAM,kBAAkB,KAAK,UAAS;MAC/C,YAAY,SAAiB,UAA4B,CAAA,GAAE;AACzD,cAAM,SAAS,IAAI,KAAK,OAAO,CAAC;MAClC;MACA,OAAO,SAAS,SAAyB;AACvC,eAAO,KAAK,SAAS,IAAI,KAAK,OAAO,CAAC,EAAE;MAC1C;;IAGF,KAAK,MAAM,YAAY,KAAK,IAAG;;MAE7B,YACE,MACA,QACA,UAA4B,CAAA,GAAE;AAE9B,cAAM,MAAM,QAAQ,IAAI,KAAK,OAAO,CAAC;MACvC;;MAGA,OAAO,SAAS,SAAiB,UAA4B,CAAA,GAAE;AAC7D,eAAO,KAAK,IAAI,SAAS,SAAS,IAAI,KAAK,OAAO,CAAC;MACrD;;IAGF,UAAU,CACR,GACA,UAA0D,CAAA,MACvD,KAAK,SAAS,GAAG,IAAI,KAAK,OAAO,CAAC;IAEvC,QAAQ,CACN,GACA,UAA0D,CAAA,MACvD,KAAK,OAAO,GAAG,IAAI,KAAK,OAAO,CAAC;IAErC,QAAQ,CAAC,SAAiB,UAA4B,CAAA,MACpD,KAAK,OAAO,SAAS,IAAI,KAAK,OAAO,CAAC;IAExC,UAAU,CAAC,YAA8B,KAAK,SAAS,IAAI,KAAK,OAAO,CAAC;IAExE,QAAQ,CAAC,SAAiB,UAA4B,CAAA,MACpD,KAAK,OAAO,SAAS,IAAI,KAAK,OAAO,CAAC;IAExC,aAAa,CAAC,SAAiB,UAA4B,CAAA,MACzD,KAAK,YAAY,SAAS,IAAI,KAAK,OAAO,CAAC;IAE7C,OAAO,CAAC,MAAgB,SAAiB,UAA4B,CAAA,MACnE,KAAK,MAAM,MAAM,SAAS,IAAI,KAAK,OAAO,CAAC;IAE7C,KAAK,KAAK;IACV;GACD;AACH;AACA,UAAU,WAAW;AAYd,IAAM,cAAc,CACzB,SACA,UAA4B,CAAA,MAC1B;AACF,qBAAmB,OAAO;AAI1B,MAAI,QAAQ,WAAW,CAAC,mBAAmB,KAAK,OAAO,GAAG;AAExD,WAAO,CAAC,OAAO;;AAGjB,aAAO,uBAAAE,SAAO,OAAO;AACvB;AACA,UAAU,cAAc;AAcjB,IAAM,SAAS,CAAC,SAAiB,UAA4B,CAAA,MAClE,IAAI,UAAU,SAAS,OAAO,EAAE,OAAM;AACxC,UAAU,SAAS;AAEZ,IAAM,QAAQ,CACnB,MACA,SACA,UAA4B,CAAA,MAC1B;AACF,QAAM,KAAK,IAAI,UAAU,SAAS,OAAO;AACzC,SAAO,KAAK,OAAO,OAAK,GAAG,MAAM,CAAC,CAAC;AACnC,MAAI,GAAG,QAAQ,UAAU,CAAC,KAAK,QAAQ;AACrC,SAAK,KAAK,OAAO;;AAEnB,SAAO;AACT;AACA,UAAU,QAAQ;AAGlB,IAAM,YAAY;AAClB,IAAMC,gBAAe,CAAC,MACpB,EAAE,QAAQ,4BAA4B,MAAM;AAUxC,IAAO,YAAP,MAAgB;EACpB;EACA;EACA;EAEA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EAEA;EACA;EACA;EAEA;EACA,YAAY,SAAiB,UAA4B,CAAA,GAAE;AACzD,uBAAmB,OAAO;AAE1B,cAAU,WAAW,CAAA;AACrB,SAAK,UAAU;AACf,SAAK,UAAU;AACf,SAAK,WAAW,QAAQ,YAAY;AACpC,SAAK,YAAY,KAAK,aAAa;AACnC,SAAK,uBACH,CAAC,CAAC,QAAQ,wBAAwB,QAAQ,uBAAuB;AACnE,QAAI,KAAK,sBAAsB;AAC7B,WAAK,UAAU,KAAK,QAAQ,QAAQ,OAAO,GAAG;;AAEhD,SAAK,0BAA0B,CAAC,CAAC,QAAQ;AACzC,SAAK,SAAS;AACd,SAAK,SAAS;AACd,SAAK,WAAW,CAAC,CAAC,QAAQ;AAC1B,SAAK,UAAU;AACf,SAAK,QAAQ;AACb,SAAK,UAAU,CAAC,CAAC,QAAQ;AACzB,SAAK,SAAS,CAAC,CAAC,KAAK,QAAQ;AAC7B,SAAK,qBACH,QAAQ,uBAAuB,SAC3B,QAAQ,qBACR,CAAC,EAAE,KAAK,aAAa,KAAK;AAEhC,SAAK,UAAU,CAAA;AACf,SAAK,YAAY,CAAA;AACjB,SAAK,MAAM,CAAA;AAGX,SAAK,KAAI;EACX;EAEA,WAAQ;AACN,QAAI,KAAK,QAAQ,iBAAiB,KAAK,IAAI,SAAS,GAAG;AACrD,aAAO;;AAET,eAAW,WAAW,KAAK,KAAK;AAC9B,iBAAW,QAAQ,SAAS;AAC1B,YAAI,OAAO,SAAS;AAAU,iBAAO;;;AAGzC,WAAO;EACT;EAEA,SAAS,GAAQ;EAAG;EAEpB,OAAI;AACF,UAAM,UAAU,KAAK;AACrB,UAAM,UAAU,KAAK;AAGrB,QAAI,CAAC,QAAQ,aAAa,QAAQ,OAAO,CAAC,MAAM,KAAK;AACnD,WAAK,UAAU;AACf;;AAGF,QAAI,CAAC,SAAS;AACZ,WAAK,QAAQ;AACb;;AAIF,SAAK,YAAW;AAGhB,SAAK,UAAU,CAAC,GAAG,IAAI,IAAI,KAAK,YAAW,CAAE,CAAC;AAE9C,QAAI,QAAQ,OAAO;AACjB,WAAK,QAAQ,IAAI,SAAgB,QAAQ,MAAM,GAAG,IAAI;;AAGxD,SAAK,MAAM,KAAK,SAAS,KAAK,OAAO;AAWrC,UAAM,eAAe,KAAK,QAAQ,IAAI,OAAK,KAAK,WAAW,CAAC,CAAC;AAC7D,SAAK,YAAY,KAAK,WAAW,YAAY;AAC7C,SAAK,MAAM,KAAK,SAAS,KAAK,SAAS;AAGvC,QAAI,MAAM,KAAK,UAAU,IAAI,CAAC,GAAG,GAAG,OAAM;AACxC,UAAI,KAAK,aAAa,KAAK,oBAAoB;AAE7C,cAAM,QACJ,EAAE,CAAC,MAAM,MACT,EAAE,CAAC,MAAM,OACR,EAAE,CAAC,MAAM,OAAO,CAAC,UAAU,KAAK,EAAE,CAAC,CAAC,MACrC,CAAC,UAAU,KAAK,EAAE,CAAC,CAAC;AACtB,cAAM,UAAU,WAAW,KAAK,EAAE,CAAC,CAAC;AACpC,YAAI,OAAO;AACT,iBAAO,CAAC,GAAG,EAAE,MAAM,GAAG,CAAC,GAAG,GAAG,EAAE,MAAM,CAAC,EAAE,IAAI,QAAM,KAAK,MAAM,EAAE,CAAC,CAAC;mBACxD,SAAS;AAClB,iBAAO,CAAC,EAAE,CAAC,GAAG,GAAG,EAAE,MAAM,CAAC,EAAE,IAAI,QAAM,KAAK,MAAM,EAAE,CAAC,CAAC;;;AAGzD,aAAO,EAAE,IAAI,QAAM,KAAK,MAAM,EAAE,CAAC;IACnC,CAAC;AAED,SAAK,MAAM,KAAK,SAAS,GAAG;AAG5B,SAAK,MAAM,IAAI,OACb,OAAK,EAAE,QAAQ,KAAK,MAAM,EAAE;AAI9B,QAAI,KAAK,WAAW;AAClB,eAAS,IAAI,GAAG,IAAI,KAAK,IAAI,QAAQ,KAAK;AACxC,cAAM,IAAI,KAAK,IAAI,CAAC;AACpB,YACE,EAAE,CAAC,MAAM,MACT,EAAE,CAAC,MAAM,MACT,KAAK,UAAU,CAAC,EAAE,CAAC,MAAM,OACzB,OAAO,EAAE,CAAC,MAAM,YAChB,YAAY,KAAK,EAAE,CAAC,CAAC,GACrB;AACA,YAAE,CAAC,IAAI;;;;AAKb,SAAK,MAAM,KAAK,SAAS,KAAK,GAAG;EACnC;;;;;;EAOA,WAAW,WAAqB;AAE9B,QAAI,KAAK,QAAQ,YAAY;AAC3B,eAAS,IAAI,GAAG,IAAI,UAAU,QAAQ,KAAK;AACzC,iBAAS,IAAI,GAAG,IAAI,UAAU,CAAC,EAAE,QAAQ,KAAK;AAC5C,cAAI,UAAU,CAAC,EAAE,CAAC,MAAM,MAAM;AAC5B,sBAAU,CAAC,EAAE,CAAC,IAAI;;;;;AAM1B,UAAM,EAAE,oBAAoB,EAAC,IAAK,KAAK;AAEvC,QAAI,qBAAqB,GAAG;AAE1B,kBAAY,KAAK,qBAAqB,SAAS;AAC/C,kBAAY,KAAK,sBAAsB,SAAS;eACvC,qBAAqB,GAAG;AAEjC,kBAAY,KAAK,iBAAiB,SAAS;WACtC;AAEL,kBAAY,KAAK,0BAA0B,SAAS;;AAGtD,WAAO;EACT;;EAGA,0BAA0B,WAAqB;AAC7C,WAAO,UAAU,IAAI,WAAQ;AAC3B,UAAI,KAAa;AACjB,aAAO,QAAQ,KAAK,MAAM,QAAQ,MAAM,KAAK,CAAC,IAAI;AAChD,YAAI,IAAI;AACR,eAAO,MAAM,IAAI,CAAC,MAAM,MAAM;AAC5B;;AAEF,YAAI,MAAM,IAAI;AACZ,gBAAM,OAAO,IAAI,IAAI,EAAE;;;AAG3B,aAAO;IACT,CAAC;EACH;;EAGA,iBAAiB,WAAqB;AACpC,WAAO,UAAU,IAAI,WAAQ;AAC3B,cAAQ,MAAM,OAAO,CAAC,KAAe,SAAQ;AAC3C,cAAM,OAAO,IAAI,IAAI,SAAS,CAAC;AAC/B,YAAI,SAAS,QAAQ,SAAS,MAAM;AAClC,iBAAO;;AAET,YAAI,SAAS,MAAM;AACjB,cAAI,QAAQ,SAAS,QAAQ,SAAS,OAAO,SAAS,MAAM;AAC1D,gBAAI,IAAG;AACP,mBAAO;;;AAGX,YAAI,KAAK,IAAI;AACb,eAAO;MACT,GAAG,CAAA,CAAE;AACL,aAAO,MAAM,WAAW,IAAI,CAAC,EAAE,IAAI;IACrC,CAAC;EACH;EAEA,qBAAqB,OAAwB;AAC3C,QAAI,CAAC,MAAM,QAAQ,KAAK,GAAG;AACzB,cAAQ,KAAK,WAAW,KAAK;;AAE/B,QAAI,eAAwB;AAC5B,OAAG;AACD,qBAAe;AAEf,UAAI,CAAC,KAAK,yBAAyB;AACjC,iBAAS,IAAI,GAAG,IAAI,MAAM,SAAS,GAAG,KAAK;AACzC,gBAAM,IAAI,MAAM,CAAC;AAEjB,cAAI,MAAM,KAAK,MAAM,MAAM,MAAM,CAAC,MAAM;AAAI;AAC5C,cAAI,MAAM,OAAO,MAAM,IAAI;AACzB,2BAAe;AACf,kBAAM,OAAO,GAAG,CAAC;AACjB;;;AAGJ,YACE,MAAM,CAAC,MAAM,OACb,MAAM,WAAW,MAChB,MAAM,CAAC,MAAM,OAAO,MAAM,CAAC,MAAM,KAClC;AACA,yBAAe;AACf,gBAAM,IAAG;;;AAKb,UAAI,KAAa;AACjB,aAAO,QAAQ,KAAK,MAAM,QAAQ,MAAM,KAAK,CAAC,IAAI;AAChD,cAAM,IAAI,MAAM,KAAK,CAAC;AACtB,YAAI,KAAK,MAAM,OAAO,MAAM,QAAQ,MAAM,MAAM;AAC9C,yBAAe;AACf,gBAAM,OAAO,KAAK,GAAG,CAAC;AACtB,gBAAM;;;aAGH;AACT,WAAO,MAAM,WAAW,IAAI,CAAC,EAAE,IAAI;EACrC;;;;;;;;;;;;;;;;;;;EAoBA,qBAAqB,WAAqB;AACxC,QAAI,eAAe;AACnB,OAAG;AACD,qBAAe;AAEf,eAAS,SAAS,WAAW;AAC3B,YAAI,KAAa;AACjB,eAAO,QAAQ,KAAK,MAAM,QAAQ,MAAM,KAAK,CAAC,IAAI;AAChD,cAAI,MAAc;AAClB,iBAAO,MAAM,MAAM,CAAC,MAAM,MAAM;AAE9B;;AAIF,cAAI,MAAM,IAAI;AACZ,kBAAM,OAAO,KAAK,GAAG,MAAM,EAAE;;AAG/B,cAAI,OAAO,MAAM,KAAK,CAAC;AACvB,gBAAM,IAAI,MAAM,KAAK,CAAC;AACtB,gBAAM,KAAK,MAAM,KAAK,CAAC;AACvB,cAAI,SAAS;AAAM;AACnB,cACE,CAAC,KACD,MAAM,OACN,MAAM,QACN,CAAC,MACD,OAAO,OACP,OAAO,MACP;AACA;;AAEF,yBAAe;AAEf,gBAAM,OAAO,IAAI,CAAC;AAClB,gBAAM,QAAQ,MAAM,MAAM,CAAC;AAC3B,gBAAM,EAAE,IAAI;AACZ,oBAAU,KAAK,KAAK;AACpB;;AAIF,YAAI,CAAC,KAAK,yBAAyB;AACjC,mBAAS,IAAI,GAAG,IAAI,MAAM,SAAS,GAAG,KAAK;AACzC,kBAAM,IAAI,MAAM,CAAC;AAEjB,gBAAI,MAAM,KAAK,MAAM,MAAM,MAAM,CAAC,MAAM;AAAI;AAC5C,gBAAI,MAAM,OAAO,MAAM,IAAI;AACzB,6BAAe;AACf,oBAAM,OAAO,GAAG,CAAC;AACjB;;;AAGJ,cACE,MAAM,CAAC,MAAM,OACb,MAAM,WAAW,MAChB,MAAM,CAAC,MAAM,OAAO,MAAM,CAAC,MAAM,KAClC;AACA,2BAAe;AACf,kBAAM,IAAG;;;AAKb,YAAI,KAAa;AACjB,eAAO,QAAQ,KAAK,MAAM,QAAQ,MAAM,KAAK,CAAC,IAAI;AAChD,gBAAM,IAAI,MAAM,KAAK,CAAC;AACtB,cAAI,KAAK,MAAM,OAAO,MAAM,QAAQ,MAAM,MAAM;AAC9C,2BAAe;AACf,kBAAM,UAAU,OAAO,KAAK,MAAM,KAAK,CAAC,MAAM;AAC9C,kBAAM,QAAQ,UAAU,CAAC,GAAG,IAAI,CAAA;AAChC,kBAAM,OAAO,KAAK,GAAG,GAAG,GAAG,KAAK;AAChC,gBAAI,MAAM,WAAW;AAAG,oBAAM,KAAK,EAAE;AACrC,kBAAM;;;;aAIL;AAET,WAAO;EACT;;;;;;;;EASA,sBAAsB,WAAqB;AACzC,aAAS,IAAI,GAAG,IAAI,UAAU,SAAS,GAAG,KAAK;AAC7C,eAAS,IAAI,IAAI,GAAG,IAAI,UAAU,QAAQ,KAAK;AAC7C,cAAM,UAAU,KAAK,WACnB,UAAU,CAAC,GACX,UAAU,CAAC,GACX,CAAC,KAAK,uBAAuB;AAE/B,YAAI,SAAS;AACX,oBAAU,CAAC,IAAI,CAAA;AACf,oBAAU,CAAC,IAAI;AACf;;;;AAIN,WAAO,UAAU,OAAO,QAAM,GAAG,MAAM;EACzC;EAEA,WACE,GACA,GACA,eAAwB,OAAK;AAE7B,QAAI,KAAK;AACT,QAAI,KAAK;AACT,QAAI,SAAmB,CAAA;AACvB,QAAI,QAAgB;AACpB,WAAO,KAAK,EAAE,UAAU,KAAK,EAAE,QAAQ;AACrC,UAAI,EAAE,EAAE,MAAM,EAAE,EAAE,GAAG;AACnB,eAAO,KAAK,UAAU,MAAM,EAAE,EAAE,IAAI,EAAE,EAAE,CAAC;AACzC;AACA;iBACS,gBAAgB,EAAE,EAAE,MAAM,QAAQ,EAAE,EAAE,MAAM,EAAE,KAAK,CAAC,GAAG;AAChE,eAAO,KAAK,EAAE,EAAE,CAAC;AACjB;iBACS,gBAAgB,EAAE,EAAE,MAAM,QAAQ,EAAE,EAAE,MAAM,EAAE,KAAK,CAAC,GAAG;AAChE,eAAO,KAAK,EAAE,EAAE,CAAC;AACjB;iBAEA,EAAE,EAAE,MAAM,OACV,EAAE,EAAE,MACH,KAAK,QAAQ,OAAO,CAAC,EAAE,EAAE,EAAE,WAAW,GAAG,MAC1C,EAAE,EAAE,MAAM,MACV;AACA,YAAI,UAAU;AAAK,iBAAO;AAC1B,gBAAQ;AACR,eAAO,KAAK,EAAE,EAAE,CAAC;AACjB;AACA;iBAEA,EAAE,EAAE,MAAM,OACV,EAAE,EAAE,MACH,KAAK,QAAQ,OAAO,CAAC,EAAE,EAAE,EAAE,WAAW,GAAG,MAC1C,EAAE,EAAE,MAAM,MACV;AACA,YAAI,UAAU;AAAK,iBAAO;AAC1B,gBAAQ;AACR,eAAO,KAAK,EAAE,EAAE,CAAC;AACjB;AACA;aACK;AACL,eAAO;;;AAKX,WAAO,EAAE,WAAW,EAAE,UAAU;EAClC;EAEA,cAAW;AACT,QAAI,KAAK;AAAU;AAEnB,UAAM,UAAU,KAAK;AACrB,QAAI,SAAS;AACb,QAAI,eAAe;AAEnB,aAAS,IAAI,GAAG,IAAI,QAAQ,UAAU,QAAQ,OAAO,CAAC,MAAM,KAAK,KAAK;AACpE,eAAS,CAAC;AACV;;AAGF,QAAI;AAAc,WAAK,UAAU,QAAQ,MAAM,YAAY;AAC3D,SAAK,SAAS;EAChB;;;;;;EAOA,SAAS,MAAgB,SAAwB,UAAmB,OAAK;AACvE,UAAM,UAAU,KAAK;AAKrB,QAAI,KAAK,WAAW;AAClB,YAAM,YAAY,OAAO,KAAK,CAAC,MAAM,YAAY,YAAY,KAAK,KAAK,CAAC,CAAC;AACzE,YAAM,UACJ,CAAC,aACD,KAAK,CAAC,MAAM,MACZ,KAAK,CAAC,MAAM,MACZ,KAAK,CAAC,MAAM,OACZ,YAAY,KAAK,KAAK,CAAC,CAAC;AAE1B,YAAM,eACJ,OAAO,QAAQ,CAAC,MAAM,YAAY,YAAY,KAAK,QAAQ,CAAC,CAAC;AAC/D,YAAM,aACJ,CAAC,gBACD,QAAQ,CAAC,MAAM,MACf,QAAQ,CAAC,MAAM,MACf,QAAQ,CAAC,MAAM,OACf,OAAO,QAAQ,CAAC,MAAM,YACtB,YAAY,KAAK,QAAQ,CAAC,CAAC;AAE7B,YAAM,MAAM,UAAU,IAAI,YAAY,IAAI;AAC1C,YAAM,MAAM,aAAa,IAAI,eAAe,IAAI;AAChD,UAAI,OAAO,QAAQ,YAAY,OAAO,QAAQ,UAAU;AACtD,cAAM,CAAC,IAAI,EAAE,IAAsB,CAAC,KAAK,GAAG,GAAG,QAAQ,GAAG,CAAW;AACrE,YAAI,GAAG,YAAW,MAAO,GAAG,YAAW,GAAI;AACzC,kBAAQ,GAAG,IAAI;AACf,cAAI,MAAM,KAAK;AACb,sBAAU,QAAQ,MAAM,GAAG;qBAClB,MAAM,KAAK;AACpB,mBAAO,KAAK,MAAM,GAAG;;;;;AAQ7B,UAAM,EAAE,oBAAoB,EAAC,IAAK,KAAK;AACvC,QAAI,qBAAqB,GAAG;AAC1B,aAAO,KAAK,qBAAqB,IAAI;;AAGvC,SAAK,MAAM,YAAY,MAAM,EAAE,MAAM,QAAO,CAAE;AAC9C,SAAK,MAAM,YAAY,KAAK,QAAQ,QAAQ,MAAM;AAElD,aACM,KAAK,GAAG,KAAK,GAAG,KAAK,KAAK,QAAQ,KAAK,QAAQ,QACnD,KAAK,MAAM,KAAK,IAChB,MAAM,MACN;AACA,WAAK,MAAM,eAAe;AAC1B,UAAI,IAAI,QAAQ,EAAE;AAClB,UAAI,IAAI,KAAK,EAAE;AAEf,WAAK,MAAM,SAAS,GAAG,CAAC;AAKxB,UAAI,MAAM,OAAO;AACf,eAAO;;AAIT,UAAI,MAAM,UAAU;AAClB,aAAK,MAAM,YAAY,CAAC,SAAS,GAAG,CAAC,CAAC;AAwBtC,YAAI,KAAK;AACT,YAAI,KAAK,KAAK;AACd,YAAI,OAAO,IAAI;AACb,eAAK,MAAM,eAAe;AAO1B,iBAAO,KAAK,IAAI,MAAM;AACpB,gBACE,KAAK,EAAE,MAAM,OACb,KAAK,EAAE,MAAM,QACZ,CAAC,QAAQ,OAAO,KAAK,EAAE,EAAE,OAAO,CAAC,MAAM;AAExC,qBAAO;;AAEX,iBAAO;;AAIT,eAAO,KAAK,IAAI;AACd,cAAI,YAAY,KAAK,EAAE;AAEvB,eAAK,MAAM,oBAAoB,MAAM,IAAI,SAAS,IAAI,SAAS;AAG/D,cAAI,KAAK,SAAS,KAAK,MAAM,EAAE,GAAG,QAAQ,MAAM,EAAE,GAAG,OAAO,GAAG;AAC7D,iBAAK,MAAM,yBAAyB,IAAI,IAAI,SAAS;AAErD,mBAAO;iBACF;AAGL,gBACE,cAAc,OACd,cAAc,QACb,CAAC,QAAQ,OAAO,UAAU,OAAO,CAAC,MAAM,KACzC;AACA,mBAAK,MAAM,iBAAiB,MAAM,IAAI,SAAS,EAAE;AACjD;;AAIF,iBAAK,MAAM,0CAA0C;AACrD;;;AAOJ,YAAI,SAAS;AAEX,eAAK,MAAM,4BAA4B,MAAM,IAAI,SAAS,EAAE;AAC5D,cAAI,OAAO,IAAI;AACb,mBAAO;;;AAIX,eAAO;;AAMT,UAAI;AACJ,UAAI,OAAO,MAAM,UAAU;AACzB,cAAM,MAAM;AACZ,aAAK,MAAM,gBAAgB,GAAG,GAAG,GAAG;aAC/B;AACL,cAAM,EAAE,KAAK,CAAC;AACd,aAAK,MAAM,iBAAiB,GAAG,GAAG,GAAG;;AAGvC,UAAI,CAAC;AAAK,eAAO;;AAenB,QAAI,OAAO,MAAM,OAAO,IAAI;AAG1B,aAAO;eACE,OAAO,IAAI;AAIpB,aAAO;eACE,OAAO,IAAI;AAKpB,aAAO,OAAO,KAAK,KAAK,KAAK,EAAE,MAAM;WAGhC;AAEL,YAAM,IAAI,MAAM,MAAM;;EAG1B;EAEA,cAAW;AACT,WAAO,YAAY,KAAK,SAAS,KAAK,OAAO;EAC/C;EAEA,MAAM,SAAe;AACnB,uBAAmB,OAAO;AAE1B,UAAM,UAAU,KAAK;AAGrB,QAAI,YAAY;AAAM,aAAO;AAC7B,QAAI,YAAY;AAAI,aAAO;AAI3B,QAAI;AACJ,QAAI,WAA4C;AAChD,QAAK,IAAI,QAAQ,MAAM,MAAM,GAAI;AAC/B,iBAAW,QAAQ,MAAM,cAAc;eAC7B,IAAI,QAAQ,MAAM,YAAY,GAAI;AAC5C,kBACE,QAAQ,SACJ,QAAQ,MACN,0BACA,uBACF,QAAQ,MACR,oBACA,gBACJ,EAAE,CAAC,CAAC;eACI,IAAI,QAAQ,MAAM,QAAQ,GAAI;AACxC,kBACE,QAAQ,SACJ,QAAQ,MACN,sBACA,mBACF,QAAQ,MACR,gBACA,YACJ,CAAC;eACO,IAAI,QAAQ,MAAM,aAAa,GAAI;AAC7C,iBAAW,QAAQ,MAAM,qBAAqB;eACpC,IAAI,QAAQ,MAAM,SAAS,GAAI;AACzC,iBAAW;;AAGb,UAAM,KAAK,IAAI,SAAS,SAAS,KAAK,OAAO,EAAE,YAAW;AAC1D,QAAI,YAAY,OAAO,OAAO,UAAU;AAEtC,cAAQ,eAAe,IAAI,QAAQ,EAAE,OAAO,SAAQ,CAAE;;AAExD,WAAO;EACT;EAEA,SAAM;AACJ,QAAI,KAAK,UAAU,KAAK,WAAW;AAAO,aAAO,KAAK;AAQtD,UAAM,MAAM,KAAK;AAEjB,QAAI,CAAC,IAAI,QAAQ;AACf,WAAK,SAAS;AACd,aAAO,KAAK;;AAEd,UAAM,UAAU,KAAK;AAErB,UAAM,UAAU,QAAQ,aACpBF,QACA,QAAQ,MACR,aACA;AACJ,UAAM,QAAQ,IAAI,IAAI,QAAQ,SAAS,CAAC,GAAG,IAAI,CAAA,CAAE;AAQjD,QAAI,KAAK,IACN,IAAI,aAAU;AACb,YAAM,KAAmC,QAAQ,IAAI,OAAI;AACvD,YAAI,aAAa,QAAQ;AACvB,qBAAW,KAAK,EAAE,MAAM,MAAM,EAAE;AAAG,kBAAM,IAAI,CAAC;;AAEhD,eAAO,OAAO,MAAM,WAChBE,cAAa,CAAC,IACd,MAAM,WACN,WACA,EAAE;MACR,CAAC;AACD,SAAG,QAAQ,CAAC,GAAG,MAAK;AAClB,cAAM,OAAO,GAAG,IAAI,CAAC;AACrB,cAAM,OAAO,GAAG,IAAI,CAAC;AACrB,YAAI,MAAM,YAAY,SAAS,UAAU;AACvC;;AAEF,YAAI,SAAS,QAAW;AACtB,cAAI,SAAS,UAAa,SAAS,UAAU;AAC3C,eAAG,IAAI,CAAC,IAAI,YAAY,UAAU,UAAU;iBACvC;AACL,eAAG,CAAC,IAAI;;mBAED,SAAS,QAAW;AAC7B,aAAG,IAAI,CAAC,IAAI,OAAO,YAAY,UAAU;mBAChC,SAAS,UAAU;AAC5B,aAAG,IAAI,CAAC,IAAI,OAAO,eAAe,UAAU,SAAS;AACrD,aAAG,IAAI,CAAC,IAAI;;MAEhB,CAAC;AACD,aAAO,GAAG,OAAO,OAAK,MAAM,QAAQ,EAAE,KAAK,GAAG;IAChD,CAAC,EACA,KAAK,GAAG;AAIX,UAAM,CAAC,MAAM,KAAK,IAAI,IAAI,SAAS,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,IAAI,EAAE;AAG7D,SAAK,MAAM,OAAO,KAAK,QAAQ;AAG/B,QAAI,KAAK;AAAQ,WAAK,SAAS,KAAK;AAEpC,QAAI;AACF,WAAK,SAAS,IAAI,OAAO,IAAI,CAAC,GAAG,KAAK,EAAE,KAAK,EAAE,CAAC;aAEzC,IAAI;AAEX,WAAK,SAAS;;AAGhB,WAAO,KAAK;EACd;EAEA,WAAW,GAAS;AAKlB,QAAI,KAAK,yBAAyB;AAChC,aAAO,EAAE,MAAM,GAAG;eACT,KAAK,aAAa,cAAc,KAAK,CAAC,GAAG;AAElD,aAAO,CAAC,IAAI,GAAG,EAAE,MAAM,KAAK,CAAC;WACxB;AACL,aAAO,EAAE,MAAM,KAAK;;EAExB;EAEA,MAAM,GAAW,UAAU,KAAK,SAAO;AACrC,SAAK,MAAM,SAAS,GAAG,KAAK,OAAO;AAGnC,QAAI,KAAK,SAAS;AAChB,aAAO;;AAET,QAAI,KAAK,OAAO;AACd,aAAO,MAAM;;AAGf,QAAI,MAAM,OAAO,SAAS;AACxB,aAAO;;AAGT,UAAM,UAAU,KAAK;AAGrB,QAAI,KAAK,WAAW;AAClB,UAAI,EAAE,MAAM,IAAI,EAAE,KAAK,GAAG;;AAI5B,UAAM,KAAK,KAAK,WAAW,CAAC;AAC5B,SAAK,MAAM,KAAK,SAAS,SAAS,EAAE;AAOpC,UAAM,MAAM,KAAK;AACjB,SAAK,MAAM,KAAK,SAAS,OAAO,GAAG;AAGnC,QAAI,WAAmB,GAAG,GAAG,SAAS,CAAC;AACvC,QAAI,CAAC,UAAU;AACb,eAAS,IAAI,GAAG,SAAS,GAAG,CAAC,YAAY,KAAK,GAAG,KAAK;AACpD,mBAAW,GAAG,CAAC;;;AAInB,aAAS,IAAI,GAAG,IAAI,IAAI,QAAQ,KAAK;AACnC,YAAM,UAAU,IAAI,CAAC;AACrB,UAAI,OAAO;AACX,UAAI,QAAQ,aAAa,QAAQ,WAAW,GAAG;AAC7C,eAAO,CAAC,QAAQ;;AAElB,YAAM,MAAM,KAAK,SAAS,MAAM,SAAS,OAAO;AAChD,UAAI,KAAK;AACP,YAAI,QAAQ,YAAY;AACtB,iBAAO;;AAET,eAAO,CAAC,KAAK;;;AAMjB,QAAI,QAAQ,YAAY;AACtB,aAAO;;AAET,WAAO,KAAK;EACd;EAEA,OAAO,SAAS,KAAqB;AACnC,WAAO,UAAU,SAAS,GAAG,EAAE;EACjC;;AAOF,UAAU,MAAM;AAChB,UAAU,YAAY;AACtB,UAAU,SAAS;AACnB,UAAU,WAAW;;;AMzqCrB,IAAM,OACJ,OAAO,gBAAgB,YACvB,eACA,OAAO,YAAY,QAAQ,aACvB,cACA;AAEN,IAAM,SAAS,oBAAI,IAAG;AAMtB,IAAM,UACJ,OAAO,YAAY,YAAY,CAAC,CAAC,UAAU,UAAU,CAAA;AAIvD,IAAM,cAAc,CAClB,KACA,MACA,MACA,OACE;AACF,SAAO,QAAQ,gBAAgB,aAC3B,QAAQ,YAAY,KAAK,MAAM,MAAM,EAAE,IACvC,QAAQ,MAAM,IAAI,IAAI,KAAK,IAAI,KAAK,GAAG,EAAE;AAC/C;AAEA,IAAI,KAAK,WAAW;AACpB,IAAI,KAAK,WAAW;AAGpB,IAAI,OAAO,OAAO,aAAa;AAE7B,OAAK,MAAM,YAAW;IACpB;IACA,WAAqC,CAAA;IACrC;IACA,UAAmB;IACnB,iBAAiB,GAAW,IAAwB;AAClD,WAAK,SAAS,KAAK,EAAE;IACvB;;AAGF,OAAK,MAAM,gBAAe;IACxB,cAAA;AACE,qBAAc;IAChB;IACA,SAAS,IAAI,GAAE;IACf,MAAM,QAAW;AACf,UAAI,KAAK,OAAO;AAAS;AAEzB,WAAK,OAAO,SAAS;AAErB,WAAK,OAAO,UAAU;AAEtB,iBAAW,MAAM,KAAK,OAAO,UAAU;AACrC,WAAG,MAAM;;AAEX,WAAK,OAAO,UAAU,MAAM;IAC9B;;AAEF,MAAI,yBACF,QAAQ,KAAK,gCAAgC;AAC/C,QAAM,iBAAiB,MAAK;AAC1B,QAAI,CAAC;AAAwB;AAC7B,6BAAyB;AACzB,gBACE,oaAOA,uBACA,WACA,cAAc;EAElB;;AAIF,IAAM,aAAa,CAAC,SAAiB,CAAC,OAAO,IAAI,IAAI;AAErD,IAAM,OAAO,OAAO,MAAM;AAI1B,IAAM,WAAW,CAAC,MAChB,KAAK,MAAM,KAAK,MAAM,CAAC,KAAK,IAAI,KAAK,SAAS,CAAC;AAcjD,IAAM,eAAe,CAAC,QACpB,CAAC,SAAS,GAAG,IACT,OACA,OAAO,KAAK,IAAI,GAAG,CAAC,IACpB,aACA,OAAO,KAAK,IAAI,GAAG,EAAE,IACrB,cACA,OAAO,KAAK,IAAI,GAAG,EAAE,IACrB,cACA,OAAO,OAAO,mBACd,YACA;AAGN,IAAM,YAAN,cAAwB,MAAa;EACnC,YAAY,MAAY;AACtB,UAAM,IAAI;AACV,SAAK,KAAK,CAAC;EACb;;AAMF,IAAM,QAAN,MAAM,OAAK;EACT;EACA;;EAEA,OAAO,gBAAyB;EAChC,OAAO,OAAO,KAAW;AACvB,UAAM,UAAU,aAAa,GAAG;AAChC,QAAI,CAAC;AAAS,aAAO,CAAA;AACrB,WAAM,gBAAgB;AACtB,UAAM,IAAI,IAAI,OAAM,KAAK,OAAO;AAChC,WAAM,gBAAgB;AACtB,WAAO;EACT;EACA,YACE,KACA,SAAyC;AAGzC,QAAI,CAAC,OAAM,eAAe;AACxB,YAAM,IAAI,UAAU,yCAAyC;;AAG/D,SAAK,OAAO,IAAI,QAAQ,GAAG;AAC3B,SAAK,SAAS;EAChB;EACA,KAAK,GAAQ;AACX,SAAK,KAAK,KAAK,QAAQ,IAAI;EAC7B;EACA,MAAG;AACD,WAAO,KAAK,KAAK,EAAE,KAAK,MAAM;EAChC;;AAu7BI,IAAO,WAAP,MAAO,UAAQ;;EAIV;EACA;EACA;EACA;EACA;EACA;;;;EAKT;;;;EAKA;;;;EAIA;;;;EAIA;;;;EAIA;;;;EAIA;;;;EAKA;;;;EAIA;;;;EAIA;;;;EAIA;;;;EAIA;;;;EAIA;;;;EAIA;;;;EAIA;;;;EAIA;;EAGA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EAEA;EACA;EACA;;;;;;;;;;EAWA,OAAO,sBAIL,GAAqB;AACrB,WAAO;;MAEL,QAAQ,EAAE;MACV,MAAM,EAAE;MACR,OAAO,EAAE;MACT,QAAQ,EAAE;MACV,SAAS,EAAE;MACX,SAAS,EAAE;MACX,MAAM,EAAE;MACR,MAAM,EAAE;MACR,IAAI,OAAI;AACN,eAAO,EAAE;MACX;MACA,IAAI,OAAI;AACN,eAAO,EAAE;MACX;MACA,MAAM,EAAE;;MAER,mBAAmB,CAAC,MAAW,EAAE,mBAAmB,CAAC;MACrD,iBAAiB,CACf,GACA,OACA,SACA,YAEA,EAAE,iBACA,GACA,OACA,SACA,OAAO;MAEX,YAAY,CAAC,UACX,EAAE,YAAY,KAAc;MAC9B,SAAS,CAAC,YACR,EAAE,SAAS,OAAO;MACpB,UAAU,CAAC,YACT,EAAE,UAAU,OAAO;MACrB,SAAS,CAAC,UACR,EAAE,SAAS,KAAc;;EAE/B;;;;;EAOA,IAAI,MAAG;AACL,WAAO,KAAK;EACd;;;;EAIA,IAAI,UAAO;AACT,WAAO,KAAK;EACd;;;;EAIA,IAAI,iBAAc;AAChB,WAAO,KAAK;EACd;;;;EAIA,IAAI,OAAI;AACN,WAAO,KAAK;EACd;;;;EAIA,IAAI,cAAW;AACb,WAAO,KAAK;EACd;EACA,IAAI,aAAU;AACZ,WAAO,KAAK;EACd;;;;EAIA,IAAI,UAAO;AACT,WAAO,KAAK;EACd;;;;EAIA,IAAI,eAAY;AACd,WAAO,KAAK;EACd;EAEA,YACE,SAAwD;AAExD,UAAM,EACJ,MAAM,GACN,KACA,gBAAgB,GAChB,cACA,gBACA,gBACA,YACA,SACA,cACA,gBACA,aACA,UAAU,GACV,eAAe,GACf,iBACA,aACA,YACA,0BACA,oBACA,4BACA,wBACA,iBAAgB,IACd;AAEJ,QAAI,QAAQ,KAAK,CAAC,SAAS,GAAG,GAAG;AAC/B,YAAM,IAAI,UAAU,0CAA0C;;AAGhE,UAAM,YAAY,MAAM,aAAa,GAAG,IAAI;AAC5C,QAAI,CAAC,WAAW;AACd,YAAM,IAAI,MAAM,wBAAwB,GAAG;;AAG7C,SAAK,OAAO;AACZ,SAAK,WAAW;AAChB,SAAK,eAAe,gBAAgB,KAAK;AACzC,SAAK,kBAAkB;AACvB,QAAI,KAAK,iBAAiB;AACxB,UAAI,CAAC,KAAK,YAAY,CAAC,KAAK,cAAc;AACxC,cAAM,IAAI,UACR,oEAAoE;;AAGxE,UAAI,OAAO,KAAK,oBAAoB,YAAY;AAC9C,cAAM,IAAI,UAAU,qCAAqC;;;AAI7D,QACE,eAAe,UACf,OAAO,eAAe,YACtB;AACA,YAAM,IAAI,UAAU,0CAA0C;;AAEhE,SAAK,cAAc;AAEnB,QACE,gBAAgB,UAChB,OAAO,gBAAgB,YACvB;AACA,YAAM,IAAI,UACR,6CAA6C;;AAGjD,SAAK,eAAe;AACpB,SAAK,kBAAkB,CAAC,CAAC;AAEzB,SAAK,UAAU,oBAAI,IAAG;AACtB,SAAK,WAAW,IAAI,MAAM,GAAG,EAAE,KAAK,MAAS;AAC7C,SAAK,WAAW,IAAI,MAAM,GAAG,EAAE,KAAK,MAAS;AAC7C,SAAK,QAAQ,IAAI,UAAU,GAAG;AAC9B,SAAK,QAAQ,IAAI,UAAU,GAAG;AAC9B,SAAK,QAAQ;AACb,SAAK,QAAQ;AACb,SAAK,QAAQ,MAAM,OAAO,GAAG;AAC7B,SAAK,QAAQ;AACb,SAAK,kBAAkB;AAEvB,QAAI,OAAO,YAAY,YAAY;AACjC,WAAK,WAAW;;AAElB,QAAI,OAAO,iBAAiB,YAAY;AACtC,WAAK,gBAAgB;AACrB,WAAK,YAAY,CAAA;WACZ;AACL,WAAK,gBAAgB;AACrB,WAAK,YAAY;;AAEnB,SAAK,cAAc,CAAC,CAAC,KAAK;AAC1B,SAAK,mBAAmB,CAAC,CAAC,KAAK;AAE/B,SAAK,iBAAiB,CAAC,CAAC;AACxB,SAAK,cAAc,CAAC,CAAC;AACrB,SAAK,2BAA2B,CAAC,CAAC;AAClC,SAAK,6BAA6B,CAAC,CAAC;AACpC,SAAK,yBAAyB,CAAC,CAAC;AAChC,SAAK,mBAAmB,CAAC,CAAC;AAG1B,QAAI,KAAK,iBAAiB,GAAG;AAC3B,UAAI,KAAK,aAAa,GAAG;AACvB,YAAI,CAAC,SAAS,KAAK,QAAQ,GAAG;AAC5B,gBAAM,IAAI,UACR,iDAAiD;;;AAIvD,UAAI,CAAC,SAAS,KAAK,YAAY,GAAG;AAChC,cAAM,IAAI,UACR,sDAAsD;;AAG1D,WAAK,wBAAuB;;AAG9B,SAAK,aAAa,CAAC,CAAC;AACpB,SAAK,qBAAqB,CAAC,CAAC;AAC5B,SAAK,iBAAiB,CAAC,CAAC;AACxB,SAAK,iBAAiB,CAAC,CAAC;AACxB,SAAK,gBACH,SAAS,aAAa,KAAK,kBAAkB,IACzC,gBACA;AACN,SAAK,eAAe,CAAC,CAAC;AACtB,SAAK,MAAM,OAAO;AAClB,QAAI,KAAK,KAAK;AACZ,UAAI,CAAC,SAAS,KAAK,GAAG,GAAG;AACvB,cAAM,IAAI,UACR,6CAA6C;;AAGjD,WAAK,uBAAsB;;AAI7B,QAAI,KAAK,SAAS,KAAK,KAAK,QAAQ,KAAK,KAAK,aAAa,GAAG;AAC5D,YAAM,IAAI,UACR,kDAAkD;;AAGtD,QAAI,CAAC,KAAK,gBAAgB,CAAC,KAAK,QAAQ,CAAC,KAAK,UAAU;AACtD,YAAM,OAAO;AACb,UAAI,WAAW,IAAI,GAAG;AACpB,eAAO,IAAI,IAAI;AACf,cAAM,MACJ;AAEF,oBAAY,KAAK,yBAAyB,MAAM,SAAQ;;;EAG9D;;;;;EAMA,gBAAgB,KAAM;AACpB,WAAO,KAAK,QAAQ,IAAI,GAAG,IAAI,WAAW;EAC5C;EAEA,yBAAsB;AACpB,UAAM,OAAO,IAAI,UAAU,KAAK,IAAI;AACpC,UAAM,SAAS,IAAI,UAAU,KAAK,IAAI;AACtC,SAAK,QAAQ;AACb,SAAK,UAAU;AAEf,SAAK,cAAc,CAAC,OAAO,KAAK,QAAQ,KAAK,IAAG,MAAM;AACpD,aAAO,KAAK,IAAI,QAAQ,IAAI,QAAQ;AACpC,WAAK,KAAK,IAAI;AACd,UAAI,QAAQ,KAAK,KAAK,cAAc;AAClC,cAAM,IAAI,WAAW,MAAK;AACxB,cAAI,KAAK,SAAS,KAAK,GAAG;AACxB,iBAAK,QAAQ,KAAK,SAAS,KAAK,GAAQ,QAAQ;;QAEpD,GAAG,MAAM,CAAC;AAGV,YAAI,EAAE,OAAO;AACX,YAAE,MAAK;;;IAIb;AAEA,SAAK,iBAAiB,WAAQ;AAC5B,aAAO,KAAK,IAAI,KAAK,KAAK,MAAM,IAAI,KAAK,IAAG,IAAK;IACnD;AAEA,SAAK,aAAa,CAAC,QAAQ,UAAS;AAClC,UAAI,KAAK,KAAK,GAAG;AACf,cAAM,MAAM,KAAK,KAAK;AACtB,cAAM,QAAQ,OAAO,KAAK;AAE1B,YAAI,CAAC,OAAO,CAAC;AAAO;AACpB,eAAO,MAAM;AACb,eAAO,QAAQ;AACf,eAAO,MAAM,aAAa,OAAM;AAChC,cAAM,MAAM,OAAO,MAAM;AACzB,eAAO,eAAe,MAAM;;IAEhC;AAIA,QAAI,YAAY;AAChB,UAAM,SAAS,MAAK;AAClB,YAAM,IAAI,KAAK,IAAG;AAClB,UAAI,KAAK,gBAAgB,GAAG;AAC1B,oBAAY;AACZ,cAAM,IAAI,WACR,MAAO,YAAY,GACnB,KAAK,aAAa;AAIpB,YAAI,EAAE,OAAO;AACX,YAAE,MAAK;;;AAIX,aAAO;IACT;AAEA,SAAK,kBAAkB,SAAM;AAC3B,YAAM,QAAQ,KAAK,QAAQ,IAAI,GAAG;AAClC,UAAI,UAAU,QAAW;AACvB,eAAO;;AAET,YAAM,MAAM,KAAK,KAAK;AACtB,YAAM,QAAQ,OAAO,KAAK;AAC1B,UAAI,CAAC,OAAO,CAAC,OAAO;AAClB,eAAO;;AAET,YAAM,OAAO,aAAa,OAAM,KAAM;AACtC,aAAO,MAAM;IACf;AAEA,SAAK,WAAW,WAAQ;AACtB,YAAM,IAAI,OAAO,KAAK;AACtB,YAAM,IAAI,KAAK,KAAK;AACpB,aAAO,CAAC,CAAC,KAAK,CAAC,CAAC,MAAM,aAAa,OAAM,KAAM,IAAI;IACrD;EACF;;EAGA,iBAAyC,MAAK;EAAE;EAChD,aACE,MAAK;EAAE;EACT,cAMY,MAAK;EAAE;;EAGnB,WAAsC,MAAM;EAE5C,0BAAuB;AACrB,UAAM,QAAQ,IAAI,UAAU,KAAK,IAAI;AACrC,SAAK,kBAAkB;AACvB,SAAK,SAAS;AACd,SAAK,kBAAkB,WAAQ;AAC7B,WAAK,mBAAmB,MAAM,KAAK;AACnC,YAAM,KAAK,IAAI;IACjB;AACA,SAAK,eAAe,CAAC,GAAG,GAAG,MAAM,oBAAmB;AAGlD,UAAI,KAAK,mBAAmB,CAAC,GAAG;AAC9B,eAAO;;AAET,UAAI,CAAC,SAAS,IAAI,GAAG;AACnB,YAAI,iBAAiB;AACnB,cAAI,OAAO,oBAAoB,YAAY;AACzC,kBAAM,IAAI,UAAU,oCAAoC;;AAE1D,iBAAO,gBAAgB,GAAG,CAAC;AAC3B,cAAI,CAAC,SAAS,IAAI,GAAG;AACnB,kBAAM,IAAI,UACR,0DAA0D;;eAGzD;AACL,gBAAM,IAAI,UACR,2HAEwB;;;AAI9B,aAAO;IACT;AACA,SAAK,eAAe,CAClB,OACA,MACA,WACE;AACF,YAAM,KAAK,IAAI;AACf,UAAI,KAAK,UAAU;AACjB,cAAM,UAAU,KAAK,WAAY,MAAM,KAAK;AAC5C,eAAO,KAAK,kBAAkB,SAAS;AACrC,eAAK,OAAO,IAAI;;;AAGpB,WAAK,mBAAmB,MAAM,KAAK;AACnC,UAAI,QAAQ;AACV,eAAO,YAAY;AACnB,eAAO,sBAAsB,KAAK;;IAEtC;EACF;EAEA,kBAA0C,QAAK;EAAE;EACjD,eAIY,CAAC,IAAI,IAAI,QAAO;EAAE;EAC9B,eAKqB,CACnB,IACA,IACA,MACA,oBACE;AACF,QAAI,QAAQ,iBAAiB;AAC3B,YAAM,IAAI,UACR,kEAAkE;;AAGtE,WAAO;EACT;EAEA,CAAC,SAAS,EAAE,aAAa,KAAK,WAAU,IAAK,CAAA,GAAE;AAC7C,QAAI,KAAK,OAAO;AACd,eAAS,IAAI,KAAK,OAAO,QAAQ;AAC/B,YAAI,CAAC,KAAK,cAAc,CAAC,GAAG;AAC1B;;AAEF,YAAI,cAAc,CAAC,KAAK,SAAS,CAAC,GAAG;AACnC,gBAAM;;AAER,YAAI,MAAM,KAAK,OAAO;AACpB;eACK;AACL,cAAI,KAAK,MAAM,CAAC;;;;EAIxB;EAEA,CAAC,UAAU,EAAE,aAAa,KAAK,WAAU,IAAK,CAAA,GAAE;AAC9C,QAAI,KAAK,OAAO;AACd,eAAS,IAAI,KAAK,OAAO,QAAQ;AAC/B,YAAI,CAAC,KAAK,cAAc,CAAC,GAAG;AAC1B;;AAEF,YAAI,cAAc,CAAC,KAAK,SAAS,CAAC,GAAG;AACnC,gBAAM;;AAER,YAAI,MAAM,KAAK,OAAO;AACpB;eACK;AACL,cAAI,KAAK,MAAM,CAAC;;;;EAIxB;EAEA,cAAc,OAAY;AACxB,WACE,UAAU,UACV,KAAK,QAAQ,IAAI,KAAK,SAAS,KAAK,CAAM,MAAM;EAEpD;;;;;EAMA,CAAC,UAAO;AACN,eAAW,KAAK,KAAK,SAAQ,GAAI;AAC/B,UACE,KAAK,SAAS,CAAC,MAAM,UACrB,KAAK,SAAS,CAAC,MAAM,UACrB,CAAC,KAAK,mBAAmB,KAAK,SAAS,CAAC,CAAC,GACzC;AACA,cAAM,CAAC,KAAK,SAAS,CAAC,GAAG,KAAK,SAAS,CAAC,CAAC;;;EAG/C;;;;;;;EAQA,CAAC,WAAQ;AACP,eAAW,KAAK,KAAK,UAAS,GAAI;AAChC,UACE,KAAK,SAAS,CAAC,MAAM,UACrB,KAAK,SAAS,CAAC,MAAM,UACrB,CAAC,KAAK,mBAAmB,KAAK,SAAS,CAAC,CAAC,GACzC;AACA,cAAM,CAAC,KAAK,SAAS,CAAC,GAAG,KAAK,SAAS,CAAC,CAAC;;;EAG/C;;;;;EAMA,CAAC,OAAI;AACH,eAAW,KAAK,KAAK,SAAQ,GAAI;AAC/B,YAAM,IAAI,KAAK,SAAS,CAAC;AACzB,UACE,MAAM,UACN,CAAC,KAAK,mBAAmB,KAAK,SAAS,CAAC,CAAC,GACzC;AACA,cAAM;;;EAGZ;;;;;;;EAQA,CAAC,QAAK;AACJ,eAAW,KAAK,KAAK,UAAS,GAAI;AAChC,YAAM,IAAI,KAAK,SAAS,CAAC;AACzB,UACE,MAAM,UACN,CAAC,KAAK,mBAAmB,KAAK,SAAS,CAAC,CAAC,GACzC;AACA,cAAM;;;EAGZ;;;;;EAMA,CAAC,SAAM;AACL,eAAW,KAAK,KAAK,SAAQ,GAAI;AAC/B,YAAM,IAAI,KAAK,SAAS,CAAC;AACzB,UACE,MAAM,UACN,CAAC,KAAK,mBAAmB,KAAK,SAAS,CAAC,CAAC,GACzC;AACA,cAAM,KAAK,SAAS,CAAC;;;EAG3B;;;;;;;EAQA,CAAC,UAAO;AACN,eAAW,KAAK,KAAK,UAAS,GAAI;AAChC,YAAM,IAAI,KAAK,SAAS,CAAC;AACzB,UACE,MAAM,UACN,CAAC,KAAK,mBAAmB,KAAK,SAAS,CAAC,CAAC,GACzC;AACA,cAAM,KAAK,SAAS,CAAC;;;EAG3B;;;;;EAMA,CAAC,OAAO,QAAQ,IAAC;AACf,WAAO,KAAK,QAAO;EACrB;;;;;;EAOA,CAAC,OAAO,WAAW,IAAI;;;;;EAMvB,KACE,IACA,aAA4C,CAAA,GAAE;AAE9C,eAAW,KAAK,KAAK,SAAQ,GAAI;AAC/B,YAAM,IAAI,KAAK,SAAS,CAAC;AACzB,YAAM,QAAQ,KAAK,mBAAmB,CAAC,IACnC,EAAE,uBACF;AACJ,UAAI,UAAU;AAAW;AACzB,UAAI,GAAG,OAAO,KAAK,SAAS,CAAC,GAAQ,IAAI,GAAG;AAC1C,eAAO,KAAK,IAAI,KAAK,SAAS,CAAC,GAAQ,UAAU;;;EAGvD;;;;;;;;;;;;EAaA,QACE,IACA,QAAa,MAAI;AAEjB,eAAW,KAAK,KAAK,SAAQ,GAAI;AAC/B,YAAM,IAAI,KAAK,SAAS,CAAC;AACzB,YAAM,QAAQ,KAAK,mBAAmB,CAAC,IACnC,EAAE,uBACF;AACJ,UAAI,UAAU;AAAW;AACzB,SAAG,KAAK,OAAO,OAAO,KAAK,SAAS,CAAC,GAAQ,IAAI;;EAErD;;;;;EAMA,SACE,IACA,QAAa,MAAI;AAEjB,eAAW,KAAK,KAAK,UAAS,GAAI;AAChC,YAAM,IAAI,KAAK,SAAS,CAAC;AACzB,YAAM,QAAQ,KAAK,mBAAmB,CAAC,IACnC,EAAE,uBACF;AACJ,UAAI,UAAU;AAAW;AACzB,SAAG,KAAK,OAAO,OAAO,KAAK,SAAS,CAAC,GAAQ,IAAI;;EAErD;;;;;EAMA,aAAU;AACR,QAAI,UAAU;AACd,eAAW,KAAK,KAAK,UAAU,EAAE,YAAY,KAAI,CAAE,GAAG;AACpD,UAAI,KAAK,SAAS,CAAC,GAAG;AACpB,aAAK,QAAQ,KAAK,SAAS,CAAC,GAAQ,QAAQ;AAC5C,kBAAU;;;AAGd,WAAO;EACT;;;;;;;;;;;;;EAcA,KAAK,KAAM;AACT,UAAM,IAAI,KAAK,QAAQ,IAAI,GAAG;AAC9B,QAAI,MAAM;AAAW,aAAO;AAC5B,UAAM,IAAI,KAAK,SAAS,CAAC;AACzB,UAAM,QAAuB,KAAK,mBAAmB,CAAC,IAClD,EAAE,uBACF;AACJ,QAAI,UAAU;AAAW,aAAO;AAChC,UAAM,QAA2B,EAAE,MAAK;AACxC,QAAI,KAAK,SAAS,KAAK,SAAS;AAC9B,YAAM,MAAM,KAAK,MAAM,CAAC;AACxB,YAAM,QAAQ,KAAK,QAAQ,CAAC;AAC5B,UAAI,OAAO,OAAO;AAChB,cAAM,SAAS,OAAO,KAAK,IAAG,IAAK;AACnC,cAAM,MAAM;AACZ,cAAM,QAAQ,KAAK,IAAG;;;AAG1B,QAAI,KAAK,QAAQ;AACf,YAAM,OAAO,KAAK,OAAO,CAAC;;AAE5B,WAAO;EACT;;;;;;;;;;;;;;EAeA,OAAI;AACF,UAAM,MAAgC,CAAA;AACtC,eAAW,KAAK,KAAK,SAAS,EAAE,YAAY,KAAI,CAAE,GAAG;AACnD,YAAM,MAAM,KAAK,SAAS,CAAC;AAC3B,YAAM,IAAI,KAAK,SAAS,CAAC;AACzB,YAAM,QAAuB,KAAK,mBAAmB,CAAC,IAClD,EAAE,uBACF;AACJ,UAAI,UAAU,UAAa,QAAQ;AAAW;AAC9C,YAAM,QAA2B,EAAE,MAAK;AACxC,UAAI,KAAK,SAAS,KAAK,SAAS;AAC9B,cAAM,MAAM,KAAK,MAAM,CAAC;AAGxB,cAAM,MAAM,KAAK,IAAG,IAAM,KAAK,QAAQ,CAAC;AACxC,cAAM,QAAQ,KAAK,MAAM,KAAK,IAAG,IAAK,GAAG;;AAE3C,UAAI,KAAK,QAAQ;AACf,cAAM,OAAO,KAAK,OAAO,CAAC;;AAE5B,UAAI,QAAQ,CAAC,KAAK,KAAK,CAAC;;AAE1B,WAAO;EACT;;;;;;;;;;EAWA,KAAK,KAA6B;AAChC,SAAK,MAAK;AACV,eAAW,CAAC,KAAK,KAAK,KAAK,KAAK;AAC9B,UAAI,MAAM,OAAO;AAOf,cAAM,MAAM,KAAK,IAAG,IAAK,MAAM;AAC/B,cAAM,QAAQ,KAAK,IAAG,IAAK;;AAE7B,WAAK,IAAI,KAAK,MAAM,OAAO,KAAK;;EAEpC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EAgCA,IACE,GACA,GACA,aAA4C,CAAA,GAAE;AAE9C,QAAI,MAAM,QAAW;AACnB,WAAK,OAAO,CAAC;AACb,aAAO;;AAET,UAAM,EACJ,MAAM,KAAK,KACX,OACA,iBAAiB,KAAK,gBACtB,kBAAkB,KAAK,iBACvB,OAAM,IACJ;AACJ,QAAI,EAAE,cAAc,KAAK,YAAW,IAAK;AAEzC,UAAM,OAAO,KAAK,aAChB,GACA,GACA,WAAW,QAAQ,GACnB,eAAe;AAIjB,QAAI,KAAK,gBAAgB,OAAO,KAAK,cAAc;AACjD,UAAI,QAAQ;AACV,eAAO,MAAM;AACb,eAAO,uBAAuB;;AAGhC,WAAK,QAAQ,GAAG,KAAK;AACrB,aAAO;;AAET,QAAI,QAAQ,KAAK,UAAU,IAAI,SAAY,KAAK,QAAQ,IAAI,CAAC;AAC7D,QAAI,UAAU,QAAW;AAEvB,cACE,KAAK,UAAU,IACX,KAAK,QACL,KAAK,MAAM,WAAW,IACtB,KAAK,MAAM,IAAG,IACd,KAAK,UAAU,KAAK,OACpB,KAAK,OAAO,KAAK,IACjB,KAAK;AAEX,WAAK,SAAS,KAAK,IAAI;AACvB,WAAK,SAAS,KAAK,IAAI;AACvB,WAAK,QAAQ,IAAI,GAAG,KAAK;AACzB,WAAK,MAAM,KAAK,KAAK,IAAI;AACzB,WAAK,MAAM,KAAK,IAAI,KAAK;AACzB,WAAK,QAAQ;AACb,WAAK;AACL,WAAK,aAAa,OAAO,MAAM,MAAM;AACrC,UAAI;AAAQ,eAAO,MAAM;AACzB,oBAAc;WACT;AAEL,WAAK,YAAY,KAAK;AACtB,YAAM,SAAS,KAAK,SAAS,KAAK;AAClC,UAAI,MAAM,QAAQ;AAChB,YAAI,KAAK,mBAAmB,KAAK,mBAAmB,MAAM,GAAG;AAC3D,iBAAO,kBAAkB,MAAM,IAAI,MAAM,UAAU,CAAC;AACpD,gBAAM,EAAE,sBAAsB,EAAC,IAAK;AACpC,cAAI,MAAM,UAAa,CAAC,gBAAgB;AACtC,gBAAI,KAAK,aAAa;AACpB,mBAAK,WAAW,GAAQ,GAAG,KAAK;;AAElC,gBAAI,KAAK,kBAAkB;AACzB,mBAAK,WAAW,KAAK,CAAC,GAAQ,GAAG,KAAK,CAAC;;;mBAGlC,CAAC,gBAAgB;AAC1B,cAAI,KAAK,aAAa;AACpB,iBAAK,WAAW,QAAa,GAAG,KAAK;;AAEvC,cAAI,KAAK,kBAAkB;AACzB,iBAAK,WAAW,KAAK,CAAC,QAAa,GAAG,KAAK,CAAC;;;AAGhD,aAAK,gBAAgB,KAAK;AAC1B,aAAK,aAAa,OAAO,MAAM,MAAM;AACrC,aAAK,SAAS,KAAK,IAAI;AACvB,YAAI,QAAQ;AACV,iBAAO,MAAM;AACb,gBAAM,WACJ,UAAU,KAAK,mBAAmB,MAAM,IACpC,OAAO,uBACP;AACN,cAAI,aAAa;AAAW,mBAAO,WAAW;;iBAEvC,QAAQ;AACjB,eAAO,MAAM;;;AAGjB,QAAI,QAAQ,KAAK,CAAC,KAAK,OAAO;AAC5B,WAAK,uBAAsB;;AAE7B,QAAI,KAAK,OAAO;AACd,UAAI,CAAC,aAAa;AAChB,aAAK,YAAY,OAAO,KAAK,KAAK;;AAEpC,UAAI;AAAQ,aAAK,WAAW,QAAQ,KAAK;;AAE3C,QAAI,CAAC,kBAAkB,KAAK,oBAAoB,KAAK,WAAW;AAC9D,YAAM,KAAK,KAAK;AAChB,UAAI;AACJ,aAAQ,OAAO,IAAI,MAAK,GAAK;AAC3B,aAAK,gBAAgB,GAAG,IAAI;;;AAGhC,WAAO;EACT;;;;;EAMA,MAAG;AACD,QAAI;AACF,aAAO,KAAK,OAAO;AACjB,cAAM,MAAM,KAAK,SAAS,KAAK,KAAK;AACpC,aAAK,OAAO,IAAI;AAChB,YAAI,KAAK,mBAAmB,GAAG,GAAG;AAChC,cAAI,IAAI,sBAAsB;AAC5B,mBAAO,IAAI;;mBAEJ,QAAQ,QAAW;AAC5B,iBAAO;;;;AAIX,UAAI,KAAK,oBAAoB,KAAK,WAAW;AAC3C,cAAM,KAAK,KAAK;AAChB,YAAI;AACJ,eAAQ,OAAO,IAAI,MAAK,GAAK;AAC3B,eAAK,gBAAgB,GAAG,IAAI;;;;EAIpC;EAEA,OAAO,MAAa;AAClB,UAAM,OAAO,KAAK;AAClB,UAAM,IAAI,KAAK,SAAS,IAAI;AAC5B,UAAM,IAAI,KAAK,SAAS,IAAI;AAC5B,QAAI,KAAK,mBAAmB,KAAK,mBAAmB,CAAC,GAAG;AACtD,QAAE,kBAAkB,MAAM,IAAI,MAAM,SAAS,CAAC;eACrC,KAAK,eAAe,KAAK,kBAAkB;AACpD,UAAI,KAAK,aAAa;AACpB,aAAK,WAAW,GAAG,GAAG,OAAO;;AAE/B,UAAI,KAAK,kBAAkB;AACzB,aAAK,WAAW,KAAK,CAAC,GAAG,GAAG,OAAO,CAAC;;;AAGxC,SAAK,gBAAgB,IAAI;AAEzB,QAAI,MAAM;AACR,WAAK,SAAS,IAAI,IAAI;AACtB,WAAK,SAAS,IAAI,IAAI;AACtB,WAAK,MAAM,KAAK,IAAI;;AAEtB,QAAI,KAAK,UAAU,GAAG;AACpB,WAAK,QAAQ,KAAK,QAAQ;AAC1B,WAAK,MAAM,SAAS;WACf;AACL,WAAK,QAAQ,KAAK,MAAM,IAAI;;AAE9B,SAAK,QAAQ,OAAO,CAAC;AACrB,SAAK;AACL,WAAO;EACT;;;;;;;;;;;;;;;;;EAkBA,IAAI,GAAM,aAA4C,CAAA,GAAE;AACtD,UAAM,EAAE,iBAAiB,KAAK,gBAAgB,OAAM,IAClD;AACF,UAAM,QAAQ,KAAK,QAAQ,IAAI,CAAC;AAChC,QAAI,UAAU,QAAW;AACvB,YAAM,IAAI,KAAK,SAAS,KAAK;AAC7B,UACE,KAAK,mBAAmB,CAAC,KACzB,EAAE,yBAAyB,QAC3B;AACA,eAAO;;AAET,UAAI,CAAC,KAAK,SAAS,KAAK,GAAG;AACzB,YAAI,gBAAgB;AAClB,eAAK,eAAe,KAAK;;AAE3B,YAAI,QAAQ;AACV,iBAAO,MAAM;AACb,eAAK,WAAW,QAAQ,KAAK;;AAE/B,eAAO;iBACE,QAAQ;AACjB,eAAO,MAAM;AACb,aAAK,WAAW,QAAQ,KAAK;;eAEtB,QAAQ;AACjB,aAAO,MAAM;;AAEf,WAAO;EACT;;;;;;;;EASA,KAAK,GAAM,cAA8C,CAAA,GAAE;AACzD,UAAM,EAAE,aAAa,KAAK,WAAU,IAAK;AACzC,UAAM,QAAQ,KAAK,QAAQ,IAAI,CAAC;AAChC,QACE,UAAU,UACT,CAAC,cAAc,KAAK,SAAS,KAAK,GACnC;AACA;;AAEF,UAAM,IAAI,KAAK,SAAS,KAAK;AAE7B,WAAO,KAAK,mBAAmB,CAAC,IAAI,EAAE,uBAAuB;EAC/D;EAEA,iBACE,GACA,OACA,SACA,SAAY;AAEZ,UAAM,IAAI,UAAU,SAAY,SAAY,KAAK,SAAS,KAAK;AAC/D,QAAI,KAAK,mBAAmB,CAAC,GAAG;AAC9B,aAAO;;AAGT,UAAM,KAAK,IAAI,GAAE;AACjB,UAAM,EAAE,OAAM,IAAK;AAEnB,YAAQ,iBAAiB,SAAS,MAAM,GAAG,MAAM,OAAO,MAAM,GAAG;MAC/D,QAAQ,GAAG;KACZ;AAED,UAAM,YAAY;MAChB,QAAQ,GAAG;MACX;MACA;;AAGF,UAAM,KAAK,CACTC,IACA,cAAc,UACG;AACjB,YAAM,EAAE,QAAO,IAAK,GAAG;AACvB,YAAM,cAAc,QAAQ,oBAAoBA,OAAM;AACtD,UAAI,QAAQ,QAAQ;AAClB,YAAI,WAAW,CAAC,aAAa;AAC3B,kBAAQ,OAAO,eAAe;AAC9B,kBAAQ,OAAO,aAAa,GAAG,OAAO;AACtC,cAAI;AAAa,oBAAQ,OAAO,oBAAoB;eAC/C;AACL,kBAAQ,OAAO,gBAAgB;;;AAGnC,UAAI,WAAW,CAAC,eAAe,CAAC,aAAa;AAC3C,eAAO,UAAU,GAAG,OAAO,MAAM;;AAGnC,YAAMC,MAAK;AACX,UAAI,KAAK,SAAS,KAAc,MAAM,GAAG;AACvC,YAAID,OAAM,QAAW;AACnB,cAAIC,IAAG,sBAAsB;AAC3B,iBAAK,SAAS,KAAc,IAAIA,IAAG;iBAC9B;AACL,iBAAK,QAAQ,GAAG,OAAO;;eAEpB;AACL,cAAI,QAAQ;AAAQ,oBAAQ,OAAO,eAAe;AAClD,eAAK,IAAI,GAAGD,IAAG,UAAU,OAAO;;;AAGpC,aAAOA;IACT;AAEA,UAAM,KAAK,CAAC,OAAW;AACrB,UAAI,QAAQ,QAAQ;AAClB,gBAAQ,OAAO,gBAAgB;AAC/B,gBAAQ,OAAO,aAAa;;AAE9B,aAAO,UAAU,EAAE;IACrB;AAEA,UAAM,YAAY,CAAC,OAA0B;AAC3C,YAAM,EAAE,QAAO,IAAK,GAAG;AACvB,YAAM,oBACJ,WAAW,QAAQ;AACrB,YAAM,aACJ,qBAAqB,QAAQ;AAC/B,YAAM,WAAW,cAAc,QAAQ;AACvC,YAAMC,MAAK;AACX,UAAI,KAAK,SAAS,KAAc,MAAM,GAAG;AAGvC,cAAM,MAAM,CAAC,YAAYA,IAAG,yBAAyB;AACrD,YAAI,KAAK;AACP,eAAK,QAAQ,GAAG,OAAO;mBACd,CAAC,mBAAmB;AAK7B,eAAK,SAAS,KAAc,IAAIA,IAAG;;;AAGvC,UAAI,YAAY;AACd,YAAI,QAAQ,UAAUA,IAAG,yBAAyB,QAAW;AAC3D,kBAAQ,OAAO,gBAAgB;;AAEjC,eAAOA,IAAG;iBACDA,IAAG,eAAeA,KAAI;AAC/B,cAAM;;IAEV;AAEA,UAAM,QAAQ,CACZ,KACA,QACE;AACF,YAAM,MAAM,KAAK,eAAe,GAAG,GAAG,SAAS;AAC/C,UAAI,OAAO,eAAe,SAAS;AACjC,YAAI,KAAK,CAAAD,OAAK,IAAIA,OAAM,SAAY,SAAYA,EAAC,GAAG,GAAG;;AAKzD,SAAG,OAAO,iBAAiB,SAAS,MAAK;AACvC,YACE,CAAC,QAAQ,oBACT,QAAQ,wBACR;AACA,cAAI,MAAS;AAEb,cAAI,QAAQ,wBAAwB;AAClC,kBAAM,CAAAA,OAAK,GAAGA,IAAG,IAAI;;;MAG3B,CAAC;IACH;AAEA,QAAI,QAAQ;AAAQ,cAAQ,OAAO,kBAAkB;AACrD,UAAM,IAAI,IAAI,QAAQ,KAAK,EAAE,KAAK,IAAI,EAAE;AACxC,UAAM,KAAyB,OAAO,OAAO,GAAG;MAC9C,mBAAmB;MACnB,sBAAsB;MACtB,YAAY;KACb;AAED,QAAI,UAAU,QAAW;AAEvB,WAAK,IAAI,GAAG,IAAI,EAAE,GAAG,UAAU,SAAS,QAAQ,OAAS,CAAE;AAC3D,cAAQ,KAAK,QAAQ,IAAI,CAAC;WACrB;AACL,WAAK,SAAS,KAAK,IAAI;;AAEzB,WAAO;EACT;EAEA,mBAAmB,GAAM;AACvB,QAAI,CAAC,KAAK;AAAiB,aAAO;AAClC,UAAM,IAAI;AACV,WACE,CAAC,CAAC,KACF,aAAa,WACb,EAAE,eAAe,sBAAsB,KACvC,EAAE,6BAA6B;EAEnC;EA+GA,MAAM,MACJ,GACA,eAAgD,CAAA,GAAE;AAElD,UAAM;;MAEJ,aAAa,KAAK;MAClB,iBAAiB,KAAK;MACtB,qBAAqB,KAAK;;MAE1B,MAAM,KAAK;MACX,iBAAiB,KAAK;MACtB,OAAO;MACP,kBAAkB,KAAK;MACvB,cAAc,KAAK;;MAEnB,2BAA2B,KAAK;MAChC,6BAA6B,KAAK;MAClC,mBAAmB,KAAK;MACxB,yBAAyB,KAAK;MAC9B;MACA,eAAe;MACf;MACA;IAAM,IACJ;AAEJ,QAAI,CAAC,KAAK,iBAAiB;AACzB,UAAI;AAAQ,eAAO,QAAQ;AAC3B,aAAO,KAAK,IAAI,GAAG;QACjB;QACA;QACA;QACA;OACD;;AAGH,UAAM,UAAU;MACd;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;MACA;;AAGF,QAAI,QAAQ,KAAK,QAAQ,IAAI,CAAC;AAC9B,QAAI,UAAU,QAAW;AACvB,UAAI;AAAQ,eAAO,QAAQ;AAC3B,YAAM,IAAI,KAAK,iBAAiB,GAAG,OAAO,SAAS,OAAO;AAC1D,aAAQ,EAAE,aAAa;WAClB;AAEL,YAAM,IAAI,KAAK,SAAS,KAAK;AAC7B,UAAI,KAAK,mBAAmB,CAAC,GAAG;AAC9B,cAAM,QACJ,cAAc,EAAE,yBAAyB;AAC3C,YAAI,QAAQ;AACV,iBAAO,QAAQ;AACf,cAAI;AAAO,mBAAO,gBAAgB;;AAEpC,eAAO,QAAQ,EAAE,uBAAwB,EAAE,aAAa;;AAK1D,YAAM,UAAU,KAAK,SAAS,KAAK;AACnC,UAAI,CAAC,gBAAgB,CAAC,SAAS;AAC7B,YAAI;AAAQ,iBAAO,QAAQ;AAC3B,aAAK,YAAY,KAAK;AACtB,YAAI,gBAAgB;AAClB,eAAK,eAAe,KAAK;;AAE3B,YAAI;AAAQ,eAAK,WAAW,QAAQ,KAAK;AACzC,eAAO;;AAKT,YAAM,IAAI,KAAK,iBAAiB,GAAG,OAAO,SAAS,OAAO;AAC1D,YAAM,WAAW,EAAE,yBAAyB;AAC5C,YAAM,WAAW,YAAY;AAC7B,UAAI,QAAQ;AACV,eAAO,QAAQ,UAAU,UAAU;AACnC,YAAI,YAAY;AAAS,iBAAO,gBAAgB;;AAElD,aAAO,WAAW,EAAE,uBAAwB,EAAE,aAAa;;EAE/D;EAoCA,MAAM,WACJ,GACA,eAAgD,CAAA,GAAE;AAElD,UAAM,IAAI,MAAM,KAAK,MACnB,GACA,YAI8C;AAEhD,QAAI,MAAM;AAAW,YAAM,IAAI,MAAM,4BAA4B;AACjE,WAAO;EACT;EAqCA,KAAK,GAAM,cAA8C,CAAA,GAAE;AACzD,UAAM,aAAa,KAAK;AACxB,QAAI,CAAC,YAAY;AACf,YAAM,IAAI,MAAM,uCAAuC;;AAEzD,UAAM,EAAE,SAAS,cAAc,GAAG,QAAO,IAAK;AAC9C,UAAM,IAAI,KAAK,IAAI,GAAG,OAAO;AAC7B,QAAI,CAAC,gBAAgB,MAAM;AAAW,aAAO;AAC7C,UAAM,KAAK,WAAW,GAAG,GAAG;MAC1B;MACA;KACqC;AACvC,SAAK,IAAI,GAAG,IAAI,OAAO;AACvB,WAAO;EACT;;;;;;;EAQA,IAAI,GAAM,aAA4C,CAAA,GAAE;AACtD,UAAM,EACJ,aAAa,KAAK,YAClB,iBAAiB,KAAK,gBACtB,qBAAqB,KAAK,oBAC1B,OAAM,IACJ;AACJ,UAAM,QAAQ,KAAK,QAAQ,IAAI,CAAC;AAChC,QAAI,UAAU,QAAW;AACvB,YAAM,QAAQ,KAAK,SAAS,KAAK;AACjC,YAAM,WAAW,KAAK,mBAAmB,KAAK;AAC9C,UAAI;AAAQ,aAAK,WAAW,QAAQ,KAAK;AACzC,UAAI,KAAK,SAAS,KAAK,GAAG;AACxB,YAAI;AAAQ,iBAAO,MAAM;AAEzB,YAAI,CAAC,UAAU;AACb,cAAI,CAAC,oBAAoB;AACvB,iBAAK,QAAQ,GAAG,QAAQ;;AAE1B,cAAI,UAAU;AAAY,mBAAO,gBAAgB;AACjD,iBAAO,aAAa,QAAQ;eACvB;AACL,cACE,UACA,cACA,MAAM,yBAAyB,QAC/B;AACA,mBAAO,gBAAgB;;AAEzB,iBAAO,aAAa,MAAM,uBAAuB;;aAE9C;AACL,YAAI;AAAQ,iBAAO,MAAM;AAMzB,YAAI,UAAU;AACZ,iBAAO,MAAM;;AAEf,aAAK,YAAY,KAAK;AACtB,YAAI,gBAAgB;AAClB,eAAK,eAAe,KAAK;;AAE3B,eAAO;;eAEA,QAAQ;AACjB,aAAO,MAAM;;EAEjB;EAEA,SAAS,GAAU,GAAQ;AACzB,SAAK,MAAM,CAAC,IAAI;AAChB,SAAK,MAAM,CAAC,IAAI;EAClB;EAEA,YAAY,OAAY;AAStB,QAAI,UAAU,KAAK,OAAO;AACxB,UAAI,UAAU,KAAK,OAAO;AACxB,aAAK,QAAQ,KAAK,MAAM,KAAK;aACxB;AACL,aAAK,SACH,KAAK,MAAM,KAAK,GAChB,KAAK,MAAM,KAAK,CAAU;;AAG9B,WAAK,SAAS,KAAK,OAAO,KAAK;AAC/B,WAAK,QAAQ;;EAEjB;;;;;;EAOA,OAAO,GAAI;AACT,WAAO,KAAK,QAAQ,GAAG,QAAQ;EACjC;EAEA,QAAQ,GAAM,QAA8B;AAC1C,QAAI,UAAU;AACd,QAAI,KAAK,UAAU,GAAG;AACpB,YAAM,QAAQ,KAAK,QAAQ,IAAI,CAAC;AAChC,UAAI,UAAU,QAAW;AACvB,kBAAU;AACV,YAAI,KAAK,UAAU,GAAG;AACpB,eAAK,OAAO,MAAM;eACb;AACL,eAAK,gBAAgB,KAAK;AAC1B,gBAAM,IAAI,KAAK,SAAS,KAAK;AAC7B,cAAI,KAAK,mBAAmB,CAAC,GAAG;AAC9B,cAAE,kBAAkB,MAAM,IAAI,MAAM,SAAS,CAAC;qBACrC,KAAK,eAAe,KAAK,kBAAkB;AACpD,gBAAI,KAAK,aAAa;AACpB,mBAAK,WAAW,GAAQ,GAAG,MAAM;;AAEnC,gBAAI,KAAK,kBAAkB;AACzB,mBAAK,WAAW,KAAK,CAAC,GAAQ,GAAG,MAAM,CAAC;;;AAG5C,eAAK,QAAQ,OAAO,CAAC;AACrB,eAAK,SAAS,KAAK,IAAI;AACvB,eAAK,SAAS,KAAK,IAAI;AACvB,cAAI,UAAU,KAAK,OAAO;AACxB,iBAAK,QAAQ,KAAK,MAAM,KAAK;qBACpB,UAAU,KAAK,OAAO;AAC/B,iBAAK,QAAQ,KAAK,MAAM,KAAK;iBACxB;AACL,kBAAM,KAAK,KAAK,MAAM,KAAK;AAC3B,iBAAK,MAAM,EAAE,IAAI,KAAK,MAAM,KAAK;AACjC,kBAAM,KAAK,KAAK,MAAM,KAAK;AAC3B,iBAAK,MAAM,EAAE,IAAI,KAAK,MAAM,KAAK;;AAEnC,eAAK;AACL,eAAK,MAAM,KAAK,KAAK;;;;AAI3B,QAAI,KAAK,oBAAoB,KAAK,WAAW,QAAQ;AACnD,YAAM,KAAK,KAAK;AAChB,UAAI;AACJ,aAAQ,OAAO,IAAI,MAAK,GAAK;AAC3B,aAAK,gBAAgB,GAAG,IAAI;;;AAGhC,WAAO;EACT;;;;EAKA,QAAK;AACH,WAAO,KAAK,OAAO,QAAQ;EAC7B;EACA,OAAO,QAA8B;AACnC,eAAW,SAAS,KAAK,UAAU,EAAE,YAAY,KAAI,CAAE,GAAG;AACxD,YAAM,IAAI,KAAK,SAAS,KAAK;AAC7B,UAAI,KAAK,mBAAmB,CAAC,GAAG;AAC9B,UAAE,kBAAkB,MAAM,IAAI,MAAM,SAAS,CAAC;aACzC;AACL,cAAM,IAAI,KAAK,SAAS,KAAK;AAC7B,YAAI,KAAK,aAAa;AACpB,eAAK,WAAW,GAAQ,GAAQ,MAAM;;AAExC,YAAI,KAAK,kBAAkB;AACzB,eAAK,WAAW,KAAK,CAAC,GAAQ,GAAQ,MAAM,CAAC;;;;AAKnD,SAAK,QAAQ,MAAK;AAClB,SAAK,SAAS,KAAK,MAAS;AAC5B,SAAK,SAAS,KAAK,MAAS;AAC5B,QAAI,KAAK,SAAS,KAAK,SAAS;AAC9B,WAAK,MAAM,KAAK,CAAC;AACjB,WAAK,QAAQ,KAAK,CAAC;;AAErB,QAAI,KAAK,QAAQ;AACf,WAAK,OAAO,KAAK,CAAC;;AAEpB,SAAK,QAAQ;AACb,SAAK,QAAQ;AACb,SAAK,MAAM,SAAS;AACpB,SAAK,kBAAkB;AACvB,SAAK,QAAQ;AACb,QAAI,KAAK,oBAAoB,KAAK,WAAW;AAC3C,YAAM,KAAK,KAAK;AAChB,UAAI;AACJ,aAAQ,OAAO,IAAI,MAAK,GAAK;AAC3B,aAAK,gBAAgB,GAAG,IAAI;;;EAGlC;;;;ACl2FF,SAAS,OAAO,aAAa;AAE7B,SAAS,qBAAqB;AAE9B,SACE,WACA,WAAW,WACX,aACA,cACA,gBAAgB,WACX;AACP,YAAY,cAAc;AAM1B,SAAS,OAAO,SAAS,UAAU,gBAAgB;;;ACXnD,SAAS,oBAAoB;AAC7B,OAAO,YAAY;AACnB,SAAS,qBAAqB;AAT9B,IAAM,OACJ,OAAO,YAAY,YAAY,UAC3B,UACA;EACE,QAAQ;EACR,QAAQ;;AAiBT,IAAM,WAAW,CACtB,MAEA,CAAC,CAAC,KACF,OAAO,MAAM,aACZ,aAAa,YACZ,aAAa,UACb,WAAW,CAAC,KACZ,WAAW,CAAC;AAKT,IAAM,aAAa,CAAC,MACzB,CAAC,CAAC,KACF,OAAO,MAAM,YACb,aAAa,gBACb,OAAQ,EAAwB,SAAS;AAExC,EAAwB,SAAS,OAAO,SAAS,UAAU;AAKvD,IAAM,aAAa,CAAC,MACzB,CAAC,CAAC,KACF,OAAO,MAAM,YACb,aAAa,gBACb,OAAQ,EAAwB,UAAU,cAC1C,OAAQ,EAAwB,QAAQ;AAE1C,IAAM,MAAM,OAAO,KAAK;AACxB,IAAM,iBAAiB,OAAO,cAAc;AAC5C,IAAM,cAAc,OAAO,YAAY;AACvC,IAAM,eAAe,OAAO,aAAa;AACzC,IAAM,gBAAgB,OAAO,cAAc;AAC3C,IAAM,SAAS,OAAO,QAAQ;AAC9B,IAAM,OAAO,OAAO,MAAM;AAC1B,IAAM,QAAQ,OAAO,OAAO;AAC5B,IAAM,aAAa,OAAO,YAAY;AACtC,IAAM,WAAW,OAAO,UAAU;AAClC,IAAM,UAAU,OAAO,SAAS;AAChC,IAAM,UAAU,OAAO,SAAS;AAChC,IAAM,SAAS,OAAO,QAAQ;AAC9B,IAAM,SAAS,OAAO,QAAQ;AAC9B,IAAM,SAAS,OAAO,QAAQ;AAC9B,IAAM,QAAQ,OAAO,OAAO;AAC5B,IAAM,eAAe,OAAO,cAAc;AAC1C,IAAM,aAAa,OAAO,YAAY;AACtC,IAAM,cAAc,OAAO,aAAa;AACxC,IAAM,aAAa,OAAO,YAAY;AAEtC,IAAM,YAAY,OAAO,WAAW;AAEpC,IAAM,QAAQ,OAAO,OAAO;AAC5B,IAAM,WAAW,OAAO,UAAU;AAClC,IAAM,UAAU,OAAO,SAAS;AAChC,IAAM,WAAW,OAAO,UAAU;AAClC,IAAM,QAAQ,OAAO,OAAO;AAC5B,IAAM,QAAQ,OAAO,OAAO;AAC5B,IAAM,UAAU,OAAO,SAAS;AAChC,IAAM,SAAS,OAAO,QAAQ;AAC9B,IAAM,gBAAgB,OAAO,eAAe;AAC5C,IAAM,YAAY,OAAO,WAAW;AAEpC,IAAM,QAAQ,CAAC,OAA6B,QAAQ,QAAO,EAAG,KAAK,EAAE;AACrE,IAAM,UAAU,CAAC,OAA6B,GAAE;AAMhD,IAAM,WAAW,CAAC,OAChB,OAAO,SAAS,OAAO,YAAY,OAAO;AAE5C,IAAM,oBAAoB,CAAC,MACzB,aAAa,eACZ,CAAC,CAAC,KACD,OAAO,MAAM,YACb,EAAE,eACF,EAAE,YAAY,SAAS,iBACvB,EAAE,cAAc;AAEpB,IAAM,oBAAoB,CAAC,MACzB,CAAC,OAAO,SAAS,CAAC,KAAK,YAAY,OAAO,CAAC;AAqB7C,IAAM,OAAN,MAAU;EACR;EACA;EACA;EACA;EACA,YACE,KACA,MACA,MAAiB;AAEjB,SAAK,MAAM;AACX,SAAK,OAAO;AACZ,SAAK,OAAO;AACZ,SAAK,UAAU,MAAM,IAAI,MAAM,EAAC;AAChC,SAAK,KAAK,GAAG,SAAS,KAAK,OAAO;EACpC;EACA,SAAM;AACJ,SAAK,KAAK,eAAe,SAAS,KAAK,OAAO;EAChD;;;EAGA,YAAY,KAAQ;EAAG;;EAEvB,MAAG;AACD,SAAK,OAAM;AACX,QAAI,KAAK,KAAK;AAAK,WAAK,KAAK,IAAG;EAClC;;AASF,IAAM,kBAAN,cAAiC,KAAO;EACtC,SAAM;AACJ,SAAK,IAAI,eAAe,SAAS,KAAK,WAAW;AACjD,UAAM,OAAM;EACd;EACA,YACE,KACA,MACA,MAAiB;AAEjB,UAAM,KAAK,MAAM,IAAI;AACrB,SAAK,cAAc,QAAM,KAAK,KAAK,SAAS,EAAE;AAC9C,QAAI,GAAG,SAAS,KAAK,WAAW;EAClC;;AA8IF,IAAM,sBAAsB,CAC1B,MACoC,CAAC,CAAC,EAAE;AAE1C,IAAM,oBAAoB,CACxB,MAEA,CAAC,EAAE,cAAc,CAAC,CAAC,EAAE,YAAY,EAAE,aAAa;AAa5C,IAAO,WAAP,cAOI,aAAY;EAGpB,CAAC,OAAO,IAAa;EACrB,CAAC,MAAM,IAAa;EACpB,CAAC,KAAK,IAAmB,CAAA;EACzB,CAAC,MAAM,IAAa,CAAA;EACpB,CAAC,UAAU;EACX,CAAC,QAAQ;EACT,CAAC,KAAK;EACN,CAAC,OAAO;EACR,CAAC,GAAG,IAAa;EACjB,CAAC,WAAW,IAAa;EACzB,CAAC,YAAY,IAAa;EAC1B,CAAC,MAAM,IAAa;EACpB,CAAC,aAAa,IAAa;EAC3B,CAAC,YAAY,IAAY;EACzB,CAAC,SAAS,IAAa;EACvB,CAAC,MAAM;EACP,CAAC,OAAO,IAAa;EACrB,CAAC,aAAa,IAAY;EAC1B,CAAC,SAAS,IAAa;;;;EAKvB,WAAoB;;;;EAIpB,WAAoB;;;;;;;EAQpB,eACK,MAI+B;AAElC,UAAM,UAAoC,KAAK,CAAC,KAC9C,CAAA;AACF,UAAK;AACL,QAAI,QAAQ,cAAc,OAAO,QAAQ,aAAa,UAAU;AAC9D,YAAM,IAAI,UACR,kDAAkD;IAEtD;AACA,QAAI,oBAAoB,OAAO,GAAG;AAChC,WAAK,UAAU,IAAI;AACnB,WAAK,QAAQ,IAAI;IACnB,WAAW,kBAAkB,OAAO,GAAG;AACrC,WAAK,QAAQ,IAAI,QAAQ;AACzB,WAAK,UAAU,IAAI;IACrB,OAAO;AACL,WAAK,UAAU,IAAI;AACnB,WAAK,QAAQ,IAAI;IACnB;AACA,SAAK,KAAK,IAAI,CAAC,CAAC,QAAQ;AACxB,SAAK,OAAO,IAAI,KAAK,QAAQ,IACxB,IAAI,cAAc,KAAK,QAAQ,CAAC,IACjC;AAGJ,QAAI,WAAW,QAAQ,sBAAsB,MAAM;AACjD,aAAO,eAAe,MAAM,UAAU,EAAE,KAAK,MAAM,KAAK,MAAM,EAAC,CAAE;IACnE;AAEA,QAAI,WAAW,QAAQ,qBAAqB,MAAM;AAChD,aAAO,eAAe,MAAM,SAAS,EAAE,KAAK,MAAM,KAAK,KAAK,EAAC,CAAE;IACjE;AAEA,UAAM,EAAE,OAAM,IAAK;AACnB,QAAI,QAAQ;AACV,WAAK,MAAM,IAAI;AACf,UAAI,OAAO,SAAS;AAClB,aAAK,KAAK,EAAC;MACb,OAAO;AACL,eAAO,iBAAiB,SAAS,MAAM,KAAK,KAAK,EAAC,CAAE;MACtD;IACF;EACF;;;;;;;;;;EAWA,IAAI,eAAY;AACd,WAAO,KAAK,YAAY;EAC1B;;;;EAKA,IAAI,WAAQ;AACV,WAAO,KAAK,QAAQ;EACtB;;;;EAKA,IAAI,SAAS,MAAI;AACf,UAAM,IAAI,MAAM,4CAA4C;EAC9D;;;;EAKA,YAAY,MAAuB;AACjC,UAAM,IAAI,MAAM,4CAA4C;EAC9D;;;;EAKA,IAAI,aAAU;AACZ,WAAO,KAAK,UAAU;EACxB;;;;EAKA,IAAI,WAAW,KAAG;AAChB,UAAM,IAAI,MAAM,8CAA8C;EAChE;;;;EAKA,KAAK,OAAO,IAAC;AACX,WAAO,KAAK,KAAK;EACnB;;;;;;;;EAQA,KAAK,OAAO,EAAE,GAAU;AACtB,SAAK,KAAK,IAAI,KAAK,KAAK,KAAK,CAAC,CAAC;EACjC;;EAGA,CAAC,KAAK,IAAC;AACL,SAAK,OAAO,IAAI;AAChB,SAAK,KAAK,SAAS,KAAK,MAAM,GAAG,MAAM;AACvC,SAAK,QAAQ,KAAK,MAAM,GAAG,MAAM;EACnC;;;;EAKA,IAAI,UAAO;AACT,WAAO,KAAK,OAAO;EACrB;;;;;EAKA,IAAI,QAAQ,GAAC;EAAG;EA0BhB,MACE,OACA,UACA,IAAe;AAEf,QAAI,KAAK,OAAO;AAAG,aAAO;AAC1B,QAAI,KAAK,GAAG;AAAG,YAAM,IAAI,MAAM,iBAAiB;AAEhD,QAAI,KAAK,SAAS,GAAG;AACnB,WAAK,KACH,SACA,OAAO,OACL,IAAI,MAAM,gDAAgD,GAC1D,EAAE,MAAM,uBAAsB,CAAE,CACjC;AAEH,aAAO;IACT;AAEA,QAAI,OAAO,aAAa,YAAY;AAClC,WAAK;AACL,iBAAW;IACb;AAEA,QAAI,CAAC;AAAU,iBAAW;AAE1B,UAAM,KAAK,KAAK,KAAK,IAAI,QAAQ;AAMjC,QAAI,CAAC,KAAK,UAAU,KAAK,CAAC,OAAO,SAAS,KAAK,GAAG;AAChD,UAAI,kBAAkB,KAAK,GAAG;AAE5B,gBAAQ,OAAO,KACb,MAAM,QACN,MAAM,YACN,MAAM,UAAU;MAEpB,WAAW,kBAAkB,KAAK,GAAG;AAEnC,gBAAQ,OAAO,KAAK,KAAK;MAC3B,WAAW,OAAO,UAAU,UAAU;AACpC,cAAM,IAAI,MACR,sDAAsD;MAE1D;IACF;AAIA,QAAI,KAAK,UAAU,GAAG;AAGpB,UAAI,KAAK,OAAO,KAAK,KAAK,YAAY,MAAM;AAAG,aAAK,KAAK,EAAE,IAAI;AAG/D,UAAI,KAAK,OAAO;AAAG,aAAK,KAAK,QAAQ,KAAyB;;AACzD,aAAK,UAAU,EAAE,KAAyB;AAE/C,UAAI,KAAK,YAAY,MAAM;AAAG,aAAK,KAAK,UAAU;AAElD,UAAI;AAAI,WAAG,EAAE;AAEb,aAAO,KAAK,OAAO;IACrB;AAIA,QAAI,CAAE,MAAkC,QAAQ;AAC9C,UAAI,KAAK,YAAY,MAAM;AAAG,aAAK,KAAK,UAAU;AAClD,UAAI;AAAI,WAAG,EAAE;AACb,aAAO,KAAK,OAAO;IACrB;AAIA,QACE,OAAO,UAAU;IAEjB,EAAE,aAAa,KAAK,QAAQ,KAAK,CAAC,KAAK,OAAO,GAAG,WACjD;AAEA,cAAQ,OAAO,KAAK,OAAO,QAAQ;IACrC;AAEA,QAAI,OAAO,SAAS,KAAK,KAAK,KAAK,QAAQ,GAAG;AAE5C,cAAQ,KAAK,OAAO,EAAE,MAAM,KAAK;IACnC;AAGA,QAAI,KAAK,OAAO,KAAK,KAAK,YAAY,MAAM;AAAG,WAAK,KAAK,EAAE,IAAI;AAE/D,QAAI,KAAK,OAAO;AAAG,WAAK,KAAK,QAAQ,KAAyB;;AACzD,WAAK,UAAU,EAAE,KAAyB;AAE/C,QAAI,KAAK,YAAY,MAAM;AAAG,WAAK,KAAK,UAAU;AAElD,QAAI;AAAI,SAAG,EAAE;AAEb,WAAO,KAAK,OAAO;EACrB;;;;;;;;;;;;;;EAeA,KAAK,GAAiB;AACpB,QAAI,KAAK,SAAS;AAAG,aAAO;AAC5B,SAAK,SAAS,IAAI;AAElB,QACE,KAAK,YAAY,MAAM,KACvB,MAAM,KACL,KAAK,IAAI,KAAK,YAAY,GAC3B;AACA,WAAK,cAAc,EAAC;AACpB,aAAO;IACT;AAEA,QAAI,KAAK,UAAU;AAAG,UAAI;AAE1B,QAAI,KAAK,MAAM,EAAE,SAAS,KAAK,CAAC,KAAK,UAAU,GAAG;AAGhD,WAAK,MAAM,IAAI;QACZ,KAAK,QAAQ,IACV,KAAK,MAAM,EAAE,KAAK,EAAE,IACpB,OAAO,OACL,KAAK,MAAM,GACX,KAAK,YAAY,CAAC;;IAG5B;AAEA,UAAM,MAAM,KAAK,IAAI,EAAE,KAAK,MAAM,KAAK,MAAM,EAAE,CAAC,CAAU;AAC1D,SAAK,cAAc,EAAC;AACpB,WAAO;EACT;EAEA,CAAC,IAAI,EAAE,GAAkB,OAAY;AACnC,QAAI,KAAK,UAAU;AAAG,WAAK,WAAW,EAAC;SAClC;AACH,YAAM,IAAI;AACV,UAAI,MAAM,EAAE,UAAU,MAAM;AAAM,aAAK,WAAW,EAAC;eAC1C,OAAO,MAAM,UAAU;AAC9B,aAAK,MAAM,EAAE,CAAC,IAAI,EAAE,MAAM,CAAC;AAC3B,gBAAQ,EAAE,MAAM,GAAG,CAAC;AACpB,aAAK,YAAY,KAAK;MACxB,OAAO;AACL,aAAK,MAAM,EAAE,CAAC,IAAI,EAAE,SAAS,CAAC;AAC9B,gBAAQ,EAAE,SAAS,GAAG,CAAC;AACvB,aAAK,YAAY,KAAK;MACxB;IACF;AAEA,SAAK,KAAK,QAAQ,KAAK;AAEvB,QAAI,CAAC,KAAK,MAAM,EAAE,UAAU,CAAC,KAAK,GAAG;AAAG,WAAK,KAAK,OAAO;AAEzD,WAAO;EACT;EAUA,IACE,OACA,UACA,IAAe;AAEf,QAAI,OAAO,UAAU,YAAY;AAC/B,WAAK;AACL,cAAQ;IACV;AACA,QAAI,OAAO,aAAa,YAAY;AAClC,WAAK;AACL,iBAAW;IACb;AACA,QAAI,UAAU;AAAW,WAAK,MAAM,OAAO,QAAQ;AACnD,QAAI;AAAI,WAAK,KAAK,OAAO,EAAE;AAC3B,SAAK,GAAG,IAAI;AACZ,SAAK,WAAW;AAMhB,QAAI,KAAK,OAAO,KAAK,CAAC,KAAK,MAAM;AAAG,WAAK,cAAc,EAAC;AACxD,WAAO;EACT;;EAGA,CAAC,MAAM,IAAC;AACN,QAAI,KAAK,SAAS;AAAG;AAErB,QAAI,CAAC,KAAK,aAAa,KAAK,CAAC,KAAK,KAAK,EAAE,QAAQ;AAC/C,WAAK,SAAS,IAAI;IACpB;AACA,SAAK,MAAM,IAAI;AACf,SAAK,OAAO,IAAI;AAChB,SAAK,KAAK,QAAQ;AAClB,QAAI,KAAK,MAAM,EAAE;AAAQ,WAAK,KAAK,EAAC;aAC3B,KAAK,GAAG;AAAG,WAAK,cAAc,EAAC;;AACnC,WAAK,KAAK,OAAO;EACxB;;;;;;;;;;EAWA,SAAM;AACJ,WAAO,KAAK,MAAM,EAAC;EACrB;;;;EAKA,QAAK;AACH,SAAK,OAAO,IAAI;AAChB,SAAK,MAAM,IAAI;AACf,SAAK,SAAS,IAAI;EACpB;;;;EAKA,IAAI,YAAS;AACX,WAAO,KAAK,SAAS;EACvB;;;;;EAMA,IAAI,UAAO;AACT,WAAO,KAAK,OAAO;EACrB;;;;EAKA,IAAI,SAAM;AACR,WAAO,KAAK,MAAM;EACpB;EAEA,CAAC,UAAU,EAAE,OAAY;AACvB,QAAI,KAAK,UAAU;AAAG,WAAK,YAAY,KAAK;;AACvC,WAAK,YAAY,KAAM,MAAkC;AAC9D,SAAK,MAAM,EAAE,KAAK,KAAK;EACzB;EAEA,CAAC,WAAW,IAAC;AACX,QAAI,KAAK,UAAU;AAAG,WAAK,YAAY,KAAK;;AAE1C,WAAK,YAAY,KACf,KAAK,MAAM,EAAE,CAAC,EACd;AACJ,WAAO,KAAK,MAAM,EAAE,MAAK;EAC3B;EAEA,CAAC,KAAK,EAAE,UAAmB,OAAK;AAC9B,OAAG;IAAC,SACF,KAAK,UAAU,EAAE,KAAK,WAAW,EAAC,CAAE,KACpC,KAAK,MAAM,EAAE;AAGf,QAAI,CAAC,WAAW,CAAC,KAAK,MAAM,EAAE,UAAU,CAAC,KAAK,GAAG;AAAG,WAAK,KAAK,OAAO;EACvE;EAEA,CAAC,UAAU,EAAE,OAAY;AACvB,SAAK,KAAK,QAAQ,KAAK;AACvB,WAAO,KAAK,OAAO;EACrB;;;;;;EAOA,KAAkC,MAAS,MAAkB;AAC3D,QAAI,KAAK,SAAS;AAAG,aAAO;AAC5B,SAAK,SAAS,IAAI;AAElB,UAAM,QAAQ,KAAK,WAAW;AAC9B,WAAO,QAAQ,CAAA;AACf,QAAI,SAAS,KAAK,UAAU,SAAS,KAAK;AAAQ,WAAK,MAAM;;AACxD,WAAK,MAAM,KAAK,QAAQ;AAC7B,SAAK,cAAc,CAAC,CAAC,KAAK;AAG1B,QAAI,OAAO;AACT,UAAI,KAAK;AAAK,aAAK,IAAG;IACxB,OAAO;AAGL,WAAK,KAAK,EAAE,KACV,CAAC,KAAK,cACF,IAAI,KAAY,MAAyB,MAAM,IAAI,IACnD,IAAI,gBAAuB,MAAyB,MAAM,IAAI,CAAC;AAErE,UAAI,KAAK,KAAK;AAAG,cAAM,MAAM,KAAK,MAAM,EAAC,CAAE;;AACtC,aAAK,MAAM,EAAC;IACnB;AAEA,WAAO;EACT;;;;;;;;;EAUA,OAAoC,MAAO;AACzC,UAAM,IAAI,KAAK,KAAK,EAAE,KAAK,CAAAE,OAAKA,GAAE,SAAS,IAAI;AAC/C,QAAI,GAAG;AACL,UAAI,KAAK,KAAK,EAAE,WAAW,GAAG;AAC5B,YAAI,KAAK,OAAO,KAAK,KAAK,aAAa,MAAM,GAAG;AAC9C,eAAK,OAAO,IAAI;QAClB;AACA,aAAK,KAAK,IAAI,CAAA;MAChB;AAAO,aAAK,KAAK,EAAE,OAAO,KAAK,KAAK,EAAE,QAAQ,CAAC,GAAG,CAAC;AACnD,QAAE,OAAM;IACV;EACF;;;;EAKA,YACE,IACA,SAAwC;AAExC,WAAO,KAAK,GAAG,IAAI,OAAO;EAC5B;;;;;;;;;;;;;;;;;;EAmBA,GACE,IACA,SAAwC;AAExC,UAAM,MAAM,MAAM,GAChB,IACA,OAA+B;AAEjC,QAAI,OAAO,QAAQ;AACjB,WAAK,SAAS,IAAI;AAClB,WAAK,aAAa;AAClB,UAAI,CAAC,KAAK,KAAK,EAAE,UAAU,CAAC,KAAK,OAAO,GAAG;AACzC,aAAK,MAAM,EAAC;MACd;IACF,WAAW,OAAO,cAAc,KAAK,YAAY,MAAM,GAAG;AACxD,YAAM,KAAK,UAAU;IACvB,WAAW,SAAS,EAAE,KAAK,KAAK,WAAW,GAAG;AAC5C,YAAM,KAAK,EAAE;AACb,WAAK,mBAAmB,EAAE;IAC5B,WAAW,OAAO,WAAW,KAAK,aAAa,GAAG;AAChD,YAAM,IAAI;AACV,UAAI,KAAK,KAAK;AAAG,cAAM,MAAM,EAAE,KAAK,MAAM,KAAK,aAAa,CAAC,CAAC;;AACzD,UAAE,KAAK,MAAM,KAAK,aAAa,CAAC;IACvC;AACA,WAAO;EACT;;;;EAKA,eACE,IACA,SAAwC;AAExC,WAAO,KAAK,IAAI,IAAI,OAAO;EAC7B;;;;;;;;;EAUA,IACE,IACA,SAAwC;AAExC,UAAM,MAAM,MAAM,IAChB,IACA,OAA+B;AAKjC,QAAI,OAAO,QAAQ;AACjB,WAAK,aAAa,IAAI,KAAK,UAAU,MAAM,EAAE;AAC7C,UACE,KAAK,aAAa,MAAM,KACxB,CAAC,KAAK,SAAS,KACf,CAAC,KAAK,KAAK,EAAE,QACb;AACA,aAAK,OAAO,IAAI;MAClB;IACF;AACA,WAAO;EACT;;;;;;;;;EAUA,mBAA+C,IAAU;AACvD,UAAM,MAAM,MAAM,mBAAmB,EAAiC;AACtE,QAAI,OAAO,UAAU,OAAO,QAAW;AACrC,WAAK,aAAa,IAAI;AACtB,UAAI,CAAC,KAAK,SAAS,KAAK,CAAC,KAAK,KAAK,EAAE,QAAQ;AAC3C,aAAK,OAAO,IAAI;MAClB;IACF;AACA,WAAO;EACT;;;;EAKA,IAAI,aAAU;AACZ,WAAO,KAAK,WAAW;EACzB;EAEA,CAAC,cAAc,IAAC;AACd,QACE,CAAC,KAAK,YAAY,KAClB,CAAC,KAAK,WAAW,KACjB,CAAC,KAAK,SAAS,KACf,KAAK,MAAM,EAAE,WAAW,KACxB,KAAK,GAAG,GACR;AACA,WAAK,YAAY,IAAI;AACrB,WAAK,KAAK,KAAK;AACf,WAAK,KAAK,WAAW;AACrB,WAAK,KAAK,QAAQ;AAClB,UAAI,KAAK,MAAM;AAAG,aAAK,KAAK,OAAO;AACnC,WAAK,YAAY,IAAI;IACvB;EACF;;;;;;;;;;;;;;;;;;;;;;;;;EA0BA,KACE,OACG,MAAmB;AAEtB,UAAM,OAAO,KAAK,CAAC;AAEnB,QACE,OAAO,WACP,OAAO,WACP,OAAO,aACP,KAAK,SAAS,GACd;AACA,aAAO;IACT,WAAW,OAAO,QAAQ;AACxB,aAAO,CAAC,KAAK,UAAU,KAAK,CAAC,OACzB,QACA,KAAK,KAAK,KACT,MAAM,MAAM,KAAK,QAAQ,EAAE,IAAa,CAAC,GAAG,QAC7C,KAAK,QAAQ,EAAE,IAAa;IAClC,WAAW,OAAO,OAAO;AACvB,aAAO,KAAK,OAAO,EAAC;IACtB,WAAW,OAAO,SAAS;AACzB,WAAK,MAAM,IAAI;AAEf,UAAI,CAAC,KAAK,WAAW,KAAK,CAAC,KAAK,SAAS;AAAG,eAAO;AACnD,YAAMC,OAAM,MAAM,KAAK,OAAO;AAC9B,WAAK,mBAAmB,OAAO;AAC/B,aAAOA;IACT,WAAW,OAAO,SAAS;AACzB,WAAK,aAAa,IAAI;AACtB,YAAM,KAAK,OAAO,IAAI;AACtB,YAAMA,OACJ,CAAC,KAAK,MAAM,KAAK,KAAK,UAAU,OAAO,EAAE,SACrC,MAAM,KAAK,SAAS,IAAI,IACxB;AACN,WAAK,cAAc,EAAC;AACpB,aAAOA;IACT,WAAW,OAAO,UAAU;AAC1B,YAAMA,OAAM,MAAM,KAAK,QAAQ;AAC/B,WAAK,cAAc,EAAC;AACpB,aAAOA;IACT,WAAW,OAAO,YAAY,OAAO,aAAa;AAChD,YAAMA,OAAM,MAAM,KAAK,EAAE;AACzB,WAAK,mBAAmB,EAAE;AAC1B,aAAOA;IACT;AAGA,UAAM,MAAM,MAAM,KAAK,IAAc,GAAG,IAAI;AAC5C,SAAK,cAAc,EAAC;AACpB,WAAO;EACT;EAEA,CAAC,QAAQ,EAAE,MAAW;AACpB,eAAW,KAAK,KAAK,KAAK,GAAG;AAC3B,UAAI,EAAE,KAAK,MAAM,IAAa,MAAM;AAAO,aAAK,MAAK;IACvD;AACA,UAAM,MAAM,KAAK,SAAS,IAAI,QAAQ,MAAM,KAAK,QAAQ,IAAI;AAC7D,SAAK,cAAc,EAAC;AACpB,WAAO;EACT;EAEA,CAAC,OAAO,IAAC;AACP,QAAI,KAAK,WAAW;AAAG,aAAO;AAE9B,SAAK,WAAW,IAAI;AACpB,SAAK,WAAW;AAChB,WAAO,KAAK,KAAK,KACZ,MAAM,MAAM,KAAK,QAAQ,EAAC,CAAE,GAAG,QAChC,KAAK,QAAQ,EAAC;EACpB;EAEA,CAAC,QAAQ,IAAC;AACR,QAAI,KAAK,OAAO,GAAG;AACjB,YAAM,OAAO,KAAK,OAAO,EAAE,IAAG;AAC9B,UAAI,MAAM;AACR,mBAAW,KAAK,KAAK,KAAK,GAAG;AAC3B,YAAE,KAAK,MAAM,IAAa;QAC5B;AACA,YAAI,CAAC,KAAK,SAAS;AAAG,gBAAM,KAAK,QAAQ,IAAI;MAC/C;IACF;AAEA,eAAW,KAAK,KAAK,KAAK,GAAG;AAC3B,QAAE,IAAG;IACP;AACA,UAAM,MAAM,MAAM,KAAK,KAAK;AAC5B,SAAK,mBAAmB,KAAK;AAC7B,WAAO;EACT;;;;;EAMA,MAAM,UAAO;AACX,UAAM,MAAwC,OAAO,OAAO,CAAA,GAAI;MAC9D,YAAY;KACb;AACD,QAAI,CAAC,KAAK,UAAU;AAAG,UAAI,aAAa;AAGxC,UAAM,IAAI,KAAK,QAAO;AACtB,SAAK,GAAG,QAAQ,OAAI;AAClB,UAAI,KAAK,CAAC;AACV,UAAI,CAAC,KAAK,UAAU;AAClB,YAAI,cAAe,EAA8B;IACrD,CAAC;AACD,UAAM;AACN,WAAO;EACT;;;;;;;EAQA,MAAM,SAAM;AACV,QAAI,KAAK,UAAU,GAAG;AACpB,YAAM,IAAI,MAAM,6BAA6B;IAC/C;AACA,UAAM,MAAM,MAAM,KAAK,QAAO;AAC9B,WACE,KAAK,QAAQ,IACT,IAAI,KAAK,EAAE,IACX,OAAO,OAAO,KAAiB,IAAI,UAAU;EAErD;;;;EAKA,MAAM,UAAO;AACX,WAAO,IAAI,QAAc,CAAC,SAAS,WAAU;AAC3C,WAAK,GAAG,WAAW,MAAM,OAAO,IAAI,MAAM,kBAAkB,CAAC,CAAC;AAC9D,WAAK,GAAG,SAAS,QAAM,OAAO,EAAE,CAAC;AACjC,WAAK,GAAG,OAAO,MAAM,QAAO,CAAE;IAChC,CAAC;EACH;;;;;;EAOA,CAAC,OAAO,aAAa,IAAC;AAGpB,SAAK,SAAS,IAAI;AAClB,QAAI,UAAU;AACd,UAAM,OAAO,YAAgD;AAC3D,WAAK,MAAK;AACV,gBAAU;AACV,aAAO,EAAE,OAAO,QAAW,MAAM,KAAI;IACvC;AACA,UAAM,OAAO,MAA2C;AACtD,UAAI;AAAS,eAAO,KAAI;AACxB,YAAM,MAAM,KAAK,KAAI;AACrB,UAAI,QAAQ;AAAM,eAAO,QAAQ,QAAQ,EAAE,MAAM,OAAO,OAAO,IAAG,CAAE;AAEpE,UAAI,KAAK,GAAG;AAAG,eAAO,KAAI;AAE1B,UAAI;AACJ,UAAI;AACJ,YAAM,QAAQ,CAAC,OAAe;AAC5B,aAAK,IAAI,QAAQ,MAAM;AACvB,aAAK,IAAI,OAAO,KAAK;AACrB,aAAK,IAAI,WAAW,SAAS;AAC7B,aAAI;AACJ,eAAO,EAAE;MACX;AACA,YAAM,SAAS,CAAC,UAAgB;AAC9B,aAAK,IAAI,SAAS,KAAK;AACvB,aAAK,IAAI,OAAO,KAAK;AACrB,aAAK,IAAI,WAAW,SAAS;AAC7B,aAAK,MAAK;AACV,gBAAQ,EAAE,OAAO,MAAM,CAAC,CAAC,KAAK,GAAG,EAAC,CAAE;MACtC;AACA,YAAM,QAAQ,MAAK;AACjB,aAAK,IAAI,SAAS,KAAK;AACvB,aAAK,IAAI,QAAQ,MAAM;AACvB,aAAK,IAAI,WAAW,SAAS;AAC7B,aAAI;AACJ,gBAAQ,EAAE,MAAM,MAAM,OAAO,OAAS,CAAE;MAC1C;AACA,YAAM,YAAY,MAAM,MAAM,IAAI,MAAM,kBAAkB,CAAC;AAC3D,aAAO,IAAI,QAA+B,CAACC,MAAK,QAAO;AACrD,iBAAS;AACT,kBAAUA;AACV,aAAK,KAAK,WAAW,SAAS;AAC9B,aAAK,KAAK,SAAS,KAAK;AACxB,aAAK,KAAK,OAAO,KAAK;AACtB,aAAK,KAAK,QAAQ,MAAM;MAC1B,CAAC;IACH;AAEA,WAAO;MACL;MACA,OAAO;MACP,QAAQ;MACR,CAAC,OAAO,aAAa,IAAC;AACpB,eAAO;MACT;;EAEJ;;;;;;;EAQA,CAAC,OAAO,QAAQ,IAAC;AAGf,SAAK,SAAS,IAAI;AAClB,QAAI,UAAU;AACd,UAAM,OAAO,MAAiC;AAC5C,WAAK,MAAK;AACV,WAAK,IAAI,OAAO,IAAI;AACpB,WAAK,IAAI,WAAW,IAAI;AACxB,WAAK,IAAI,OAAO,IAAI;AACpB,gBAAU;AACV,aAAO,EAAE,MAAM,MAAM,OAAO,OAAS;IACvC;AAEA,UAAM,OAAO,MAAkC;AAC7C,UAAI;AAAS,eAAO,KAAI;AACxB,YAAM,QAAQ,KAAK,KAAI;AACvB,aAAO,UAAU,OAAO,KAAI,IAAK,EAAE,MAAM,OAAO,MAAK;IACvD;AAEA,SAAK,KAAK,OAAO,IAAI;AACrB,SAAK,KAAK,OAAO,IAAI;AACrB,SAAK,KAAK,WAAW,IAAI;AAEzB,WAAO;MACL;MACA,OAAO;MACP,QAAQ;MACR,CAAC,OAAO,QAAQ,IAAC;AACf,eAAO;MACT;;EAEJ;;;;;;;;;;;;;EAcA,QAAQ,IAAY;AAClB,QAAI,KAAK,SAAS,GAAG;AACnB,UAAI;AAAI,aAAK,KAAK,SAAS,EAAE;;AACxB,aAAK,KAAK,SAAS;AACxB,aAAO;IACT;AAEA,SAAK,SAAS,IAAI;AAClB,SAAK,SAAS,IAAI;AAGlB,SAAK,MAAM,EAAE,SAAS;AACtB,SAAK,YAAY,IAAI;AAErB,UAAM,KAAK;AAGX,QAAI,OAAO,GAAG,UAAU,cAAc,CAAC,KAAK,MAAM;AAAG,SAAG,MAAK;AAE7D,QAAI;AAAI,WAAK,KAAK,SAAS,EAAE;;AAExB,WAAK,KAAK,SAAS;AAExB,WAAO;EACT;;;;;;;;EASA,WAAW,WAAQ;AACjB,WAAO;EACT;;;;ADrzCF,IAAM,eAAe,IAAI;AA2EzB,IAAM,YAAqB;EACzB;EACA,SAAS;EACT;EACA;EACA;EACA,UAAU;IACR;IACA;IACA;IACA;;;AAKJ,IAAM,eAAe,CAAC,aACpB,CAAC,YAAY,aAAa,aAAa,aAAa,WAClD,YACA;EACE,GAAG;EACH,GAAG;EACH,UAAU;IACR,GAAG,UAAU;IACb,GAAI,SAAS,YAAY,CAAA;;;AAKjC,IAAM,iBAAiB;AACvB,IAAM,aAAa,CAAC,aAClB,SAAS,QAAQ,OAAO,IAAI,EAAE,QAAQ,gBAAgB,MAAM;AAG9D,IAAM,YAAY;AAElB,IAAM,UAAU;AAChB,IAAM,QAAQ;AACd,IAAM,QAAQ;AACd,IAAM,QAAQ;AACd,IAAM,QAAQ;AACd,IAAM,QAAQ;AACd,IAAM,QAAQ;AACd,IAAM,SAAS;AACf,IAAM,OAAO;AAab,IAAM,eAAe,CAAC;AAGtB,IAAM,iBAAiB;AAEvB,IAAM,eAAe;AAErB,IAAM,UAAU;AAGhB,IAAM,SAAS;AAGf,IAAM,cAAc;AAEpB,IAAM,cAAc;AAEpB,IAAM,WAAW,UAAU,SAAS;AACpC,IAAM,WAAW;AAEjB,IAAM,YAAY,CAAC,MACjB,EAAE,OAAM,IAAK,QACX,EAAE,YAAW,IAAK,QAClB,EAAE,eAAc,IAAK,QACrB,EAAE,kBAAiB,IAAK,QACxB,EAAE,cAAa,IAAK,QACpB,EAAE,SAAQ,IAAK,SACf,EAAE,OAAM,IAAK,QACb;AAGJ,IAAM,iBAAiB,oBAAI,IAAG;AAC9B,IAAM,YAAY,CAAC,MAAa;AAC9B,QAAM,IAAI,eAAe,IAAI,CAAC;AAC9B,MAAI;AAAG,WAAO;AACd,QAAM,IAAI,EAAE,UAAU,MAAM;AAC5B,iBAAe,IAAI,GAAG,CAAC;AACvB,SAAO;AACT;AAEA,IAAM,uBAAuB,oBAAI,IAAG;AACpC,IAAM,kBAAkB,CAAC,MAAa;AACpC,QAAM,IAAI,qBAAqB,IAAI,CAAC;AACpC,MAAI;AAAG,WAAO;AACd,QAAM,IAAI,UAAU,EAAE,YAAW,CAAE;AACnC,uBAAqB,IAAI,GAAG,CAAC;AAC7B,SAAO;AACT;AAoBM,IAAO,eAAP,cAA4B,SAAwB;EACxD,cAAA;AACE,UAAM,EAAE,KAAK,IAAG,CAAE;EACpB;;AAmBI,IAAO,gBAAP,cAA6B,SAA4B;EAC7D,YAAY,UAAkB,KAAK,MAAI;AACrC,UAAM;MACJ;;MAEA,iBAAiB,OAAK,EAAE,SAAS;KAClC;EACH;;AAUF,IAAM,WAAW,OAAO,qBAAqB;AAevC,IAAgB,WAAhB,MAAwB;;;;;;;;;;EAU5B;;;;;;EAMA;;;;;;EAMA;;;;;;EAMA;;;;;EAKA;;;;;EAMA,QAAiB;;EAajB;;EAGA;EACA,IAAI,MAAG;AACL,WAAO,KAAK;EACd;EACA;EACA,IAAI,OAAI;AACN,WAAO,KAAK;EACd;EACA;EACA,IAAI,QAAK;AACP,WAAO,KAAK;EACd;EACA;EACA,IAAI,MAAG;AACL,WAAO,KAAK;EACd;EACA;EACA,IAAI,MAAG;AACL,WAAO,KAAK;EACd;EACA;EACA,IAAI,OAAI;AACN,WAAO,KAAK;EACd;EACA;EACA,IAAI,UAAO;AACT,WAAO,KAAK;EACd;EACA;EACA,IAAI,MAAG;AACL,WAAO,KAAK;EACd;EACA;EACA,IAAI,OAAI;AACN,WAAO,KAAK;EACd;EACA;EACA,IAAI,SAAM;AACR,WAAO,KAAK;EACd;EACA;EACA,IAAI,UAAO;AACT,WAAO,KAAK;EACd;EACA;EACA,IAAI,UAAO;AACT,WAAO,KAAK;EACd;EACA;EACA,IAAI,UAAO;AACT,WAAO,KAAK;EACd;EACA;EACA,IAAI,cAAW;AACb,WAAO,KAAK;EACd;EACA;EACA,IAAI,QAAK;AACP,WAAO,KAAK;EACd;EACA;EACA,IAAI,QAAK;AACP,WAAO,KAAK;EACd;EACA;EACA,IAAI,QAAK;AACP,WAAO,KAAK;EACd;EACA;EACA,IAAI,YAAS;AACX,WAAO,KAAK;EACd;EAEA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;;;;;;;EAQA,IAAI,aAAU;AACZ,YAAQ,KAAK,UAAU,MAAM,SAAQ;EACvC;;;;;EAMA,IAAI,OAAI;AACN,WAAO,KAAK;EACd;;;;;;;EAQA,YACE,MACA,OAAe,SACf,MACA,OACA,QACA,UACA,MAAc;AAEd,SAAK,OAAO;AACZ,SAAK,aAAa,SAAS,gBAAgB,IAAI,IAAI,UAAU,IAAI;AACjE,SAAK,QAAQ,OAAO;AACpB,SAAK,SAAS;AACd,SAAK,QAAQ;AACb,SAAK,OAAO,QAAQ;AACpB,SAAK,YAAY;AACjB,SAAK,YAAY,KAAK;AACtB,SAAK,YAAY,KAAK;AACtB,SAAK,iBAAiB,KAAK;AAC3B,SAAK,SAAS,KAAK;AACnB,QAAI,KAAK,QAAQ;AACf,WAAK,MAAM,KAAK,OAAO;IACzB,OAAO;AACL,WAAK,MAAM,aAAa,KAAK,EAAE;IACjC;EACF;;;;;;EAOA,QAAK;AACH,QAAI,KAAK,WAAW;AAAW,aAAO,KAAK;AAC3C,QAAI,CAAC,KAAK;AAAQ,aAAQ,KAAK,SAAS;AACxC,WAAQ,KAAK,SAAS,KAAK,OAAO,MAAK,IAAK;EAC9C;;;;EAkBA,gBAAa;AACX,WAAO,KAAK;EACd;;;;EAKA,QAAQC,QAAa;AACnB,QAAI,CAACA,QAAM;AACT,aAAO;IACT;AACA,UAAM,WAAW,KAAK,cAAcA,MAAI;AACxC,UAAM,MAAMA,OAAK,UAAU,SAAS,MAAM;AAC1C,UAAM,WAAW,IAAI,MAAM,KAAK,QAAQ;AACxC,UAAM,SACJ,WACE,KAAK,QAAQ,QAAQ,EAAE,cAAc,QAAQ,IAC7C,KAAK,cAAc,QAAQ;AAC/B,WAAO;EACT;EAEA,cAAc,UAAkB;AAC9B,QAAI,IAAc;AAClB,eAAW,QAAQ,UAAU;AAC3B,UAAI,EAAE,MAAM,IAAI;IAClB;AACA,WAAO;EACT;;;;;;;;;EAUA,WAAQ;AACN,UAAM,SAAS,KAAK,UAAU,IAAI,IAAI;AACtC,QAAI,QAAQ;AACV,aAAO;IACT;AACA,UAAM,WAAqB,OAAO,OAAO,CAAA,GAAI,EAAE,aAAa,EAAC,CAAE;AAC/D,SAAK,UAAU,IAAI,MAAM,QAAQ;AACjC,SAAK,SAAS,CAAC;AACf,WAAO;EACT;;;;;;;;;;;;;;EAeA,MAAM,UAAkB,MAAe;AACrC,QAAI,aAAa,MAAM,aAAa,KAAK;AACvC,aAAO;IACT;AACA,QAAI,aAAa,MAAM;AACrB,aAAO,KAAK,UAAU;IACxB;AAGA,UAAM,WAAW,KAAK,SAAQ;AAC9B,UAAM,OACJ,KAAK,SAAS,gBAAgB,QAAQ,IAAI,UAAU,QAAQ;AAC9D,eAAW,KAAK,UAAU;AACxB,UAAI,EAAE,eAAe,MAAM;AACzB,eAAO;MACT;IACF;AAKA,UAAM,IAAI,KAAK,SAAS,KAAK,MAAM;AACnC,UAAM,WACJ,KAAK,YAAY,KAAK,YAAY,IAAI,WAAW;AACnD,UAAM,SAAS,KAAK,SAAS,UAAU,SAAS;MAC9C,GAAG;MACH,QAAQ;MACR;KACD;AAED,QAAI,CAAC,KAAK,WAAU,GAAI;AACtB,aAAO,SAAS;IAClB;AAIA,aAAS,KAAK,MAAM;AACpB,WAAO;EACT;;;;;EAMA,WAAQ;AACN,QAAI,KAAK;AAAO,aAAO;AACvB,QAAI,KAAK,cAAc,QAAW;AAChC,aAAO,KAAK;IACd;AACA,UAAM,OAAO,KAAK;AAClB,UAAM,IAAI,KAAK;AACf,QAAI,CAAC,GAAG;AACN,aAAQ,KAAK,YAAY,KAAK;IAChC;AACA,UAAM,KAAK,EAAE,SAAQ;AACrB,WAAO,MAAM,CAAC,MAAM,CAAC,EAAE,SAAS,KAAK,KAAK,OAAO;EACnD;;;;;;;EAQA,gBAAa;AACX,QAAI,KAAK,QAAQ;AAAK,aAAO,KAAK,SAAQ;AAC1C,QAAI,KAAK;AAAO,aAAO;AACvB,QAAI,KAAK,mBAAmB;AAAW,aAAO,KAAK;AACnD,UAAM,OAAO,KAAK;AAClB,UAAM,IAAI,KAAK;AACf,QAAI,CAAC,GAAG;AACN,aAAQ,KAAK,iBAAiB,KAAK,cAAa;IAClD;AACA,UAAM,KAAK,EAAE,cAAa;AAC1B,WAAO,MAAM,CAAC,MAAM,CAAC,EAAE,SAAS,KAAK,OAAO;EAC9C;;;;EAKA,WAAQ;AACN,QAAI,KAAK,cAAc,QAAW;AAChC,aAAO,KAAK;IACd;AACA,UAAM,OAAO,KAAK;AAClB,UAAM,IAAI,KAAK;AACf,QAAI,CAAC,GAAG;AACN,aAAQ,KAAK,YAAY,KAAK;IAChC;AACA,UAAM,KAAK,EAAE,SAAQ;AACrB,UAAM,KAAK,MAAM,CAAC,EAAE,SAAS,KAAK,KAAK,OAAO;AAC9C,WAAQ,KAAK,YAAY;EAC3B;;;;;;;EAQA,gBAAa;AACX,QAAI,KAAK,mBAAmB;AAAW,aAAO,KAAK;AACnD,QAAI,KAAK,QAAQ;AAAK,aAAQ,KAAK,iBAAiB,KAAK,SAAQ;AACjE,QAAI,CAAC,KAAK,QAAQ;AAChB,YAAMC,KAAI,KAAK,SAAQ,EAAG,QAAQ,OAAO,GAAG;AAC5C,UAAI,aAAa,KAAKA,EAAC,GAAG;AACxB,eAAQ,KAAK,iBAAiB,OAAOA,EAAC;MACxC,OAAO;AACL,eAAQ,KAAK,iBAAiBA;MAChC;IACF;AACA,UAAM,IAAI,KAAK;AACf,UAAM,OAAO,EAAE,cAAa;AAC5B,UAAM,MAAM,QAAQ,CAAC,QAAQ,CAAC,EAAE,SAAS,KAAK,OAAO,KAAK;AAC1D,WAAQ,KAAK,iBAAiB;EAChC;;;;;;;;EASA,YAAS;AACP,YAAQ,KAAK,QAAQ,UAAU;EACjC;EAEA,OAAO,MAAU;AACf,WAAO,KAAK,KAAK,IAAI,EAAE,EAAC;EAC1B;EAEA,UAAO;AACL,WACE,KAAK,UAAS,IAAK,YACjB,KAAK,YAAW,IAAK,cACrB,KAAK,OAAM,IAAK,SAChB,KAAK,eAAc,IAAK,iBACxB,KAAK,OAAM,IAAK,SAChB,KAAK,kBAAiB,IAAK,oBAC3B,KAAK,cAAa,IAAK;;MACD,KAAK,SAAQ,IAAK,WACxC;;EAGN;;;;EAKA,SAAM;AACJ,YAAQ,KAAK,QAAQ,UAAU;EACjC;;;;EAKA,cAAW;AACT,YAAQ,KAAK,QAAQ,UAAU;EACjC;;;;EAKA,oBAAiB;AACf,YAAQ,KAAK,QAAQ,UAAU;EACjC;;;;EAKA,gBAAa;AACX,YAAQ,KAAK,QAAQ,UAAU;EACjC;;;;EAKA,SAAM;AACJ,YAAQ,KAAK,QAAQ,UAAU;EACjC;;;;EAKA,WAAQ;AACN,YAAQ,KAAK,QAAQ,UAAU;EACjC;;;;EAKA,iBAAc;AACZ,YAAQ,KAAK,QAAQ,WAAW;EAClC;;;;;;;;EASA,cAAW;AACT,WAAO,KAAK,QAAQ,eAAe,OAAO;EAC5C;;;;;;;;;EAUA,iBAAc;AACZ,WAAO,KAAK;EACd;;;;;;;;;EAUA,iBAAc;AACZ,WAAO,KAAK;EACd;;;;;;;;;EAUA,gBAAa;AACX,UAAM,WAAW,KAAK,SAAQ;AAC9B,WAAO,SAAS,MAAM,GAAG,SAAS,WAAW;EAC/C;;;;;;;;EASA,cAAW;AACT,QAAI,KAAK;AAAa,aAAO;AAC7B,QAAI,CAAC,KAAK;AAAQ,aAAO;AAEzB,UAAM,OAAO,KAAK,QAAQ;AAC1B,WAAO,EACJ,SAAS,WAAW,SAAS,SAC9B,KAAK,QAAQ,eACb,KAAK,QAAQ;EAEjB;;;;;EAMA,gBAAa;AACX,WAAO,CAAC,EAAE,KAAK,QAAQ;EACzB;;;;;;EAOA,WAAQ;AACN,WAAO,CAAC,EAAE,KAAK,QAAQ;EACzB;;;;;;;;;;;;EAaA,QAAQ,GAAS;AACf,WAAO,CAAC,KAAK,SACT,KAAK,eAAe,UAAU,CAAC,IAC/B,KAAK,eAAe,gBAAgB,CAAC;EAC3C;;;;;;;;;EAUA,MAAM,WAAQ;AACZ,UAAM,SAAS,KAAK;AACpB,QAAI,QAAQ;AACV,aAAO;IACT;AACA,QAAI,CAAC,KAAK,YAAW,GAAI;AACvB,aAAO;IACT;AAGA,QAAI,CAAC,KAAK,QAAQ;AAChB,aAAO;IACT;AAEA,QAAI;AACF,YAAM,OAAO,MAAM,KAAK,IAAI,SAAS,SAAS,KAAK,SAAQ,CAAE;AAC7D,YAAM,cAAc,MAAM,KAAK,OAAO,SAAQ,IAAK,QAAQ,IAAI;AAC/D,UAAI,YAAY;AACd,eAAQ,KAAK,cAAc;MAC7B;IACF,SAAS,IAAI;AACX,WAAK,cAAe,GAA6B,IAAI;AACrD,aAAO;IACT;EACF;;;;EAKA,eAAY;AACV,UAAM,SAAS,KAAK;AACpB,QAAI,QAAQ;AACV,aAAO;IACT;AACA,QAAI,CAAC,KAAK,YAAW,GAAI;AACvB,aAAO;IACT;AAGA,QAAI,CAAC,KAAK,QAAQ;AAChB,aAAO;IACT;AAEA,QAAI;AACF,YAAM,OAAO,KAAK,IAAI,aAAa,KAAK,SAAQ,CAAE;AAClD,YAAM,aAAa,KAAK,OAAO,aAAY,GAAI,QAAQ,IAAI;AAC3D,UAAI,YAAY;AACd,eAAQ,KAAK,cAAc;MAC7B;IACF,SAAS,IAAI;AACX,WAAK,cAAe,GAA6B,IAAI;AACrD,aAAO;IACT;EACF;EAEA,gBAAgB,UAAkB;AAEhC,SAAK,SAAS;AAEd,aAAS,IAAI,SAAS,aAAa,IAAI,SAAS,QAAQ,KAAK;AAC3D,YAAM,IAAI,SAAS,CAAC;AACpB,UAAI;AAAG,UAAE,YAAW;IACtB;EACF;EAEA,cAAW;AAET,QAAI,KAAK,QAAQ;AAAQ;AACzB,SAAK,SAAS,KAAK,QAAQ,UAAU;AACrC,SAAK,oBAAmB;EAC1B;EAEA,sBAAmB;AAEjB,UAAM,WAAW,KAAK,SAAQ;AAC9B,aAAS,cAAc;AACvB,eAAW,KAAK,UAAU;AACxB,QAAE,YAAW;IACf;EACF;EAEA,mBAAgB;AACd,SAAK,SAAS;AACd,SAAK,aAAY;EACnB;;EAGA,eAAY;AAMV,QAAI,KAAK,QAAQ;AAAS;AAE1B,QAAI,IAAI,KAAK;AAGb,SAAK,IAAI,UAAU;AAAO,WAAK;AAC/B,SAAK,QAAQ,IAAI;AACjB,SAAK,oBAAmB;EAC1B;EAEA,aAAa,OAAe,IAAE;AAE5B,QAAI,SAAS,aAAa,SAAS,SAAS;AAC1C,WAAK,aAAY;IACnB,WAAW,SAAS,UAAU;AAC5B,WAAK,YAAW;IAClB,OAAO;AACL,WAAK,SAAQ,EAAG,cAAc;IAChC;EACF;EAEA,WAAW,OAAe,IAAE;AAG1B,QAAI,SAAS,WAAW;AAEtB,YAAM,IAAI,KAAK;AACf,QAAE,aAAY;IAChB,WAAW,SAAS,UAAU;AAE5B,WAAK,YAAW;IAClB;EACF;EAEA,cAAc,OAAe,IAAE;AAC7B,QAAI,MAAM,KAAK;AACf,WAAO;AACP,QAAI,SAAS;AAAU,aAAO;AAE9B,QAAI,SAAS,YAAY,SAAS,WAAW;AAG3C,aAAO;IACT;AACA,SAAK,QAAQ;AAIb,QAAI,SAAS,aAAa,KAAK,QAAQ;AACrC,WAAK,OAAO,aAAY;IAC1B;EAEF;EAEA,iBAAiB,GAAW,GAAW;AACrC,WACE,KAAK,0BAA0B,GAAG,CAAC,KACnC,KAAK,oBAAoB,GAAG,CAAC;EAEjC;EAEA,oBAAoB,GAAW,GAAW;AAExC,UAAM,OAAO,UAAU,CAAC;AACxB,UAAM,QAAQ,KAAK,SAAS,EAAE,MAAM,MAAM,EAAE,QAAQ,KAAI,CAAE;AAC1D,UAAM,OAAO,MAAM,QAAQ;AAC3B,QAAI,SAAS,SAAS,SAAS,SAAS,SAAS,SAAS;AACxD,YAAM,SAAS;IACjB;AACA,MAAE,QAAQ,KAAK;AACf,MAAE;AACF,WAAO;EACT;EAEA,0BAA0B,GAAW,GAAW;AAC9C,aAAS,IAAI,EAAE,aAAa,IAAI,EAAE,QAAQ,KAAK;AAC7C,YAAM,SAAS,EAAE,CAAC;AAClB,YAAM,OACJ,KAAK,SAAS,gBAAgB,EAAE,IAAI,IAAI,UAAU,EAAE,IAAI;AAC1D,UAAI,SAAS,OAAQ,YAAY;AAC/B;MACF;AAEA,aAAO,KAAK,qBAAqB,GAAG,QAAS,GAAG,CAAC;IACnD;EACF;EAEA,qBACE,GACA,GACA,OACA,GAAW;AAEX,UAAM,IAAI,EAAE;AAEZ,MAAE,QAAS,EAAE,QAAQ,eAAgB,UAAU,CAAC;AAEhD,QAAI,MAAM,EAAE;AAAM,QAAE,OAAO,EAAE;AAI7B,QAAI,UAAU,EAAE,aAAa;AAC3B,UAAI,UAAU,EAAE,SAAS;AAAG,UAAE,IAAG;;AAC5B,UAAE,OAAO,OAAO,CAAC;AACtB,QAAE,QAAQ,CAAC;IACb;AACA,MAAE;AACF,WAAO;EACT;;;;;;;;;;;;;;;;EAiBA,MAAM,QAAK;AACT,SAAK,KAAK,QAAQ,YAAY,GAAG;AAC/B,UAAI;AACF,aAAK,WAAW,MAAM,KAAK,IAAI,SAAS,MAAM,KAAK,SAAQ,CAAE,CAAC;AAC9D,eAAO;MACT,SAAS,IAAI;AACX,aAAK,WAAY,GAA6B,IAAI;MACpD;IACF;EACF;;;;EAKA,YAAS;AACP,SAAK,KAAK,QAAQ,YAAY,GAAG;AAC/B,UAAI;AACF,aAAK,WAAW,KAAK,IAAI,UAAU,KAAK,SAAQ,CAAE,CAAC;AACnD,eAAO;MACT,SAAS,IAAI;AACX,aAAK,WAAY,GAA6B,IAAI;MACpD;IACF;EACF;EAEA,WAAW,IAAS;AAClB,UAAM,EACJ,OACA,SACA,WACA,aACA,SACA,QACA,OACA,SACA,KACA,KACA,KACA,MACA,OACA,SACA,OACA,MACA,MACA,IAAG,IACD;AACJ,SAAK,SAAS;AACd,SAAK,WAAW;AAChB,SAAK,aAAa;AAClB,SAAK,eAAe;AACpB,SAAK,WAAW;AAChB,SAAK,UAAU;AACf,SAAK,SAAS;AACd,SAAK,WAAW;AAChB,SAAK,OAAO;AACZ,SAAK,OAAO;AACZ,SAAK,OAAO;AACZ,SAAK,QAAQ;AACb,SAAK,SAAS;AACd,SAAK,WAAW;AAChB,SAAK,SAAS;AACd,SAAK,QAAQ;AACb,SAAK,QAAQ;AACb,SAAK,OAAO;AACZ,UAAM,OAAO,UAAU,EAAE;AAEzB,SAAK,QAAS,KAAK,QAAQ,eAAgB,OAAO;AAClD,QAAI,SAAS,WAAW,SAAS,SAAS,SAAS,OAAO;AACxD,WAAK,SAAS;IAChB;EACF;EAEA,eAGc,CAAA;EACd,qBAA8B;EAC9B,iBAAiB,UAAgB;AAC/B,SAAK,qBAAqB;AAC1B,UAAM,MAAM,KAAK,aAAa,MAAK;AACnC,SAAK,aAAa,SAAS;AAC3B,QAAI,QAAQ,QAAM,GAAG,MAAM,QAAQ,CAAC;EACtC;;;;;;;;;;;;;;;;;EAkBA,UACE,IACA,aAAsB,OAAK;AAE3B,QAAI,CAAC,KAAK,WAAU,GAAI;AACtB,UAAI;AAAY,WAAG,MAAM,CAAA,CAAE;;AACtB,uBAAe,MAAM,GAAG,MAAM,CAAA,CAAE,CAAC;AACtC;IACF;AAEA,UAAM,WAAW,KAAK,SAAQ;AAC9B,QAAI,KAAK,cAAa,GAAI;AACxB,YAAM,IAAI,SAAS,MAAM,GAAG,SAAS,WAAW;AAChD,UAAI;AAAY,WAAG,MAAM,CAAC;;AACrB,uBAAe,MAAM,GAAG,MAAM,CAAC,CAAC;AACrC;IACF;AAGA,SAAK,aAAa,KAAK,EAAE;AACzB,QAAI,KAAK,oBAAoB;AAC3B;IACF;AACA,SAAK,qBAAqB;AAI1B,UAAM,WAAW,KAAK,SAAQ;AAC9B,SAAK,IAAI,QAAQ,UAAU,EAAE,eAAe,KAAI,GAAI,CAAC,IAAI,YAAW;AAClE,UAAI,IAAI;AACN,aAAK,aAAc,GAA6B,IAAI;AACpD,iBAAS,cAAc;MACzB,OAAO;AAGL,mBAAW,KAAK,SAAS;AACvB,eAAK,iBAAiB,GAAG,QAAQ;QACnC;AACA,aAAK,gBAAgB,QAAQ;MAC/B;AACA,WAAK,iBAAiB,SAAS,MAAM,GAAG,SAAS,WAAW,CAAC;AAC7D;IACF,CAAC;EACH;EAEA;;;;;;;;;;EAWA,MAAM,UAAO;AACX,QAAI,CAAC,KAAK,WAAU,GAAI;AACtB,aAAO,CAAA;IACT;AAEA,UAAM,WAAW,KAAK,SAAQ;AAC9B,QAAI,KAAK,cAAa,GAAI;AACxB,aAAO,SAAS,MAAM,GAAG,SAAS,WAAW;IAC/C;AAIA,UAAM,WAAW,KAAK,SAAQ;AAC9B,QAAI,KAAK,uBAAuB;AAC9B,YAAM,KAAK;IACb,OAAO;AAEL,UAAI,UAAsB,MAAK;MAAE;AAEjC,WAAK,wBAAwB,IAAI,QAC/B,SAAQ,UAAU,GAAI;AAExB,UAAI;AACF,mBAAW,KAAK,MAAM,KAAK,IAAI,SAAS,QAAQ,UAAU;UACxD,eAAe;SAChB,GAAG;AACF,eAAK,iBAAiB,GAAG,QAAQ;QACnC;AACA,aAAK,gBAAgB,QAAQ;MAC/B,SAAS,IAAI;AACX,aAAK,aAAc,GAA6B,IAAI;AACpD,iBAAS,cAAc;MACzB;AACA,WAAK,wBAAwB;AAC7B,cAAO;IACT;AACA,WAAO,SAAS,MAAM,GAAG,SAAS,WAAW;EAC/C;;;;EAKA,cAAW;AACT,QAAI,CAAC,KAAK,WAAU,GAAI;AACtB,aAAO,CAAA;IACT;AAEA,UAAM,WAAW,KAAK,SAAQ;AAC9B,QAAI,KAAK,cAAa,GAAI;AACxB,aAAO,SAAS,MAAM,GAAG,SAAS,WAAW;IAC/C;AAIA,UAAM,WAAW,KAAK,SAAQ;AAC9B,QAAI;AACF,iBAAW,KAAK,KAAK,IAAI,YAAY,UAAU;QAC7C,eAAe;OAChB,GAAG;AACF,aAAK,iBAAiB,GAAG,QAAQ;MACnC;AACA,WAAK,gBAAgB,QAAQ;IAC/B,SAAS,IAAI;AACX,WAAK,aAAc,GAA6B,IAAI;AACpD,eAAS,cAAc;IACzB;AACA,WAAO,SAAS,MAAM,GAAG,SAAS,WAAW;EAC/C;EAEA,aAAU;AACR,QAAI,KAAK,QAAQ;AAAU,aAAO;AAClC,UAAM,OAAO,OAAO,KAAK;AAGzB,QAAI,EAAE,SAAS,WAAW,SAAS,SAAS,SAAS,QAAQ;AAC3D,aAAO;IACT;AAEA,WAAO;EACT;EAEA,WACE,MACA,YAAqC;AAErC,YACG,KAAK,QAAQ,WAAW,SACzB,EAAE,KAAK,QAAQ,aACf,CAAC,KAAK,IAAI,IAAI,MACb,CAAC,cAAc,WAAW,IAAI;EAEnC;;;;;;;;;;EAWA,MAAM,WAAQ;AACZ,QAAI,KAAK;AAAW,aAAO,KAAK;AAChC,SAAK,cAAc,cAAc,UAAU,KAAK;AAAO,aAAO;AAC9D,QAAI;AACF,YAAM,KAAK,MAAM,KAAK,IAAI,SAAS,SAAS,KAAK,SAAQ,CAAE;AAC3D,aAAQ,KAAK,YAAY,KAAK,QAAQ,EAAE;IAC1C,SAAS,GAAG;AACV,WAAK,iBAAgB;IACvB;EACF;;;;EAKA,eAAY;AACV,QAAI,KAAK;AAAW,aAAO,KAAK;AAChC,SAAK,cAAc,cAAc,UAAU,KAAK;AAAO,aAAO;AAC9D,QAAI;AACF,YAAM,KAAK,KAAK,IAAI,aAAa,KAAK,SAAQ,CAAE;AAChD,aAAQ,KAAK,YAAY,KAAK,QAAQ,EAAE;IAC1C,SAAS,GAAG;AACV,WAAK,iBAAgB;IACvB;EACF;;;;;;;EAQA,CAAC,QAAQ,EAAE,QAAgB;AACzB,QAAI,WAAW;AAAM;AACrB,WAAO,QAAQ;AACf,SAAK,QAAQ;AAEb,UAAM,UAAU,oBAAI,IAAc,CAAA,CAAE;AACpC,QAAI,KAAK,CAAA;AACT,QAAI,IAAc;AAClB,WAAO,KAAK,EAAE,QAAQ;AACpB,cAAQ,IAAI,CAAC;AACb,QAAE,YAAY,GAAG,KAAK,KAAK,GAAG;AAC9B,QAAE,iBAAiB,GAAG,KAAK,GAAG;AAC9B,UAAI,EAAE;AACN,SAAG,KAAK,IAAI;IACd;AAEA,QAAI;AACJ,WAAO,KAAK,EAAE,UAAU,CAAC,QAAQ,IAAI,CAAC,GAAG;AACvC,QAAE,YAAY;AACd,QAAE,iBAAiB;AACnB,UAAI,EAAE;IACR;EACF;;AASI,IAAO,YAAP,MAAO,mBAAkB,SAAQ;;;;EAIrC,MAAY;;;;EAIZ,WAAmB;;;;;;;EAQnB,YACE,MACA,OAAe,SACf,MACA,OACA,QACA,UACA,MAAc;AAEd,UAAM,MAAM,MAAM,MAAM,OAAO,QAAQ,UAAU,IAAI;EACvD;;;;EAKA,SAAS,MAAc,OAAe,SAAS,OAAiB,CAAA,GAAE;AAChE,WAAO,IAAI,WACT,MACA,MACA,KAAK,MACL,KAAK,OACL,KAAK,QACL,KAAK,cAAa,GAClB,IAAI;EAER;;;;EAKA,cAAcD,QAAY;AACxB,WAAO,MAAM,MAAMA,MAAI,EAAE;EAC3B;;;;EAKA,QAAQ,UAAgB;AACtB,eAAW,WAAW,SAAS,YAAW,CAAE;AAC5C,QAAI,aAAa,KAAK,KAAK,MAAM;AAC/B,aAAO,KAAK;IACd;AAEA,eAAW,CAAC,SAAS,IAAI,KAAK,OAAO,QAAQ,KAAK,KAAK,GAAG;AACxD,UAAI,KAAK,SAAS,UAAU,OAAO,GAAG;AACpC,eAAQ,KAAK,MAAM,QAAQ,IAAI;MACjC;IACF;AAEA,WAAQ,KAAK,MAAM,QAAQ,IAAI,IAAI,gBACjC,UACA,IAAI,EACJ;EACJ;;;;EAKA,SAAS,UAAkB,UAAkB,KAAK,KAAK,MAAI;AAIzD,eAAW,SACR,YAAW,EACX,QAAQ,OAAO,IAAI,EACnB,QAAQ,gBAAgB,MAAM;AACjC,WAAO,aAAa;EACtB;;AAQI,IAAO,YAAP,MAAO,mBAAkB,SAAQ;;;;EAIrC,WAAgB;;;;EAIhB,MAAW;;;;;;;EAQX,YACE,MACA,OAAe,SACf,MACA,OACA,QACA,UACA,MAAc;AAEd,UAAM,MAAM,MAAM,MAAM,OAAO,QAAQ,UAAU,IAAI;EACvD;;;;EAKA,cAAcA,QAAY;AACxB,WAAOA,OAAK,WAAW,GAAG,IAAI,MAAM;EACtC;;;;EAKA,QAAQ,WAAiB;AACvB,WAAO,KAAK;EACd;;;;EAKA,SAAS,MAAc,OAAe,SAAS,OAAiB,CAAA,GAAE;AAChE,WAAO,IAAI,WACT,MACA,MACA,KAAK,MACL,KAAK,OACL,KAAK,QACL,KAAK,cAAa,GAClB,IAAI;EAER;;AA0CI,IAAgB,iBAAhB,MAA8B;;;;EAIlC;;;;EAIA;;;;EAIA;;;;EAIA;EACA;EACA;EACA;;;;;;EAMA;EASA;;;;;;;;EASA,YACE,MAAoB,QAAQ,IAAG,GAC/B,UACAE,MACA,EACE,QACA,oBAAoB,KAAK,MACzB,IAAAC,OAAK,UAAS,IACI,CAAA,GAAE;AAEtB,SAAK,MAAM,aAAaA,IAAE;AAC1B,QAAI,eAAe,OAAO,IAAI,WAAW,SAAS,GAAG;AACnD,YAAM,cAAc,GAAG;IACzB;AAGA,UAAM,UAAU,SAAS,QAAQ,GAAG;AACpC,SAAK,QAAQ,uBAAO,OAAO,IAAI;AAC/B,SAAK,WAAW,KAAK,cAAc,OAAO;AAC1C,SAAK,gBAAgB,IAAI,aAAY;AACrC,SAAK,qBAAqB,IAAI,aAAY;AAC1C,SAAK,YAAY,IAAI,cAAc,iBAAiB;AAEpD,UAAM,QAAQ,QAAQ,UAAU,KAAK,SAAS,MAAM,EAAE,MAAMD,IAAG;AAE/D,QAAI,MAAM,WAAW,KAAK,CAAC,MAAM,CAAC,GAAG;AACnC,YAAM,IAAG;IACX;AAEA,QAAI,WAAW,QAAW;AACxB,YAAM,IAAI,UACR,oDAAoD;IAExD;AAEA,SAAK,SAAS;AACd,SAAK,OAAO,KAAK,QAAQ,KAAK,GAAG;AACjC,SAAK,MAAM,KAAK,QAAQ,IAAI,KAAK;AACjC,QAAI,OAAiB,KAAK;AAC1B,QAAI,MAAM,MAAM,SAAS;AACzB,UAAM,UAAU,SAAS;AACzB,QAAI,MAAM,KAAK;AACf,QAAI,WAAW;AACf,eAAW,QAAQ,OAAO;AACxB,YAAM,IAAI;AACV,aAAO,KAAK,MAAM,MAAM;QACtB,UAAU,IAAI,MAAM,CAAC,EAAE,KAAK,IAAI,EAAE,KAAK,OAAO;QAC9C,eAAe,IAAI,MAAM,CAAC,EAAE,KAAK,IAAI,EAAE,KAAK,GAAG;QAC/C,UAAW,QAAQ,WAAW,KAAK,WAAW;OAC/C;AACD,iBAAW;IACb;AACA,SAAK,MAAM;EACb;;;;EAKA,MAAMF,SAAsB,KAAK,KAAG;AAClC,QAAI,OAAOA,WAAS,UAAU;AAC5B,MAAAA,SAAO,KAAK,IAAI,QAAQA,MAAI;IAC9B;AACA,WAAOA,OAAK,MAAK;EACnB;;;;;;;EAyBA,gBAAa;AACX,WAAO,KAAK;EACd;;;;;;;;;;EAWA,WAAW,OAAe;AAGxB,QAAI,IAAI;AACR,aAAS,IAAI,MAAM,SAAS,GAAG,KAAK,GAAG,KAAK;AAC1C,YAAM,IAAI,MAAM,CAAC;AACjB,UAAI,CAAC,KAAK,MAAM;AAAK;AACrB,UAAI,IAAI,GAAG,CAAC,IAAI,CAAC,KAAK;AACtB,UAAI,KAAK,WAAW,CAAC,GAAG;AACtB;MACF;IACF;AACA,UAAM,SAAS,KAAK,cAAc,IAAI,CAAC;AACvC,QAAI,WAAW,QAAW;AACxB,aAAO;IACT;AACA,UAAM,SAAS,KAAK,IAAI,QAAQ,CAAC,EAAE,SAAQ;AAC3C,SAAK,cAAc,IAAI,GAAG,MAAM;AAChC,WAAO;EACT;;;;;;;;;;;;EAaA,gBAAgB,OAAe;AAG7B,QAAI,IAAI;AACR,aAAS,IAAI,MAAM,SAAS,GAAG,KAAK,GAAG,KAAK;AAC1C,YAAM,IAAI,MAAM,CAAC;AACjB,UAAI,CAAC,KAAK,MAAM;AAAK;AACrB,UAAI,IAAI,GAAG,CAAC,IAAI,CAAC,KAAK;AACtB,UAAI,KAAK,WAAW,CAAC,GAAG;AACtB;MACF;IACF;AACA,UAAM,SAAS,KAAK,mBAAmB,IAAI,CAAC;AAC5C,QAAI,WAAW,QAAW;AACxB,aAAO;IACT;AACA,UAAM,SAAS,KAAK,IAAI,QAAQ,CAAC,EAAE,cAAa;AAChD,SAAK,mBAAmB,IAAI,GAAG,MAAM;AACrC,WAAO;EACT;;;;EAKA,SAAS,QAA2B,KAAK,KAAG;AAC1C,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC;AACA,WAAO,MAAM,SAAQ;EACvB;;;;;EAMA,cAAc,QAA2B,KAAK,KAAG;AAC/C,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC;AACA,WAAO,MAAM,cAAa;EAC5B;;;;EAKA,SAAS,QAA2B,KAAK,KAAG;AAC1C,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC;AACA,WAAO,MAAM;EACf;;;;EAKA,QAAQ,QAA2B,KAAK,KAAG;AACzC,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC;AACA,YAAQ,MAAM,UAAU,OAAO,SAAQ;EACzC;EAkCA,MAAM,QACJ,QAAwD,KAAK,KAC7D,OAAmC;IACjC,eAAe;KAChB;AAED,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC,WAAW,EAAE,iBAAiB,WAAW;AACvC,aAAO;AACP,cAAQ,KAAK;IACf;AACA,UAAM,EAAE,cAAa,IAAK;AAC1B,QAAI,CAAC,MAAM,WAAU,GAAI;AACvB,aAAO,CAAA;IACT,OAAO;AACL,YAAM,IAAI,MAAM,MAAM,QAAO;AAC7B,aAAO,gBAAgB,IAAI,EAAE,IAAI,OAAK,EAAE,IAAI;IAC9C;EACF;EAsBA,YACE,QAAwD,KAAK,KAC7D,OAAmC;IACjC,eAAe;KAChB;AAED,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC,WAAW,EAAE,iBAAiB,WAAW;AACvC,aAAO;AACP,cAAQ,KAAK;IACf;AACA,UAAM,EAAE,gBAAgB,KAAI,IAAK;AACjC,QAAI,CAAC,MAAM,WAAU,GAAI;AACvB,aAAO,CAAA;IACT,WAAW,eAAe;AACxB,aAAO,MAAM,YAAW;IAC1B,OAAO;AACL,aAAO,MAAM,YAAW,EAAG,IAAI,OAAK,EAAE,IAAI;IAC5C;EACF;;;;;;;;;;;;;;;;EAiBA,MAAM,MACJ,QAA2B,KAAK,KAAG;AAEnC,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC;AACA,WAAO,MAAM,MAAK;EACpB;;;;EAKA,UAAU,QAA2B,KAAK,KAAG;AAC3C,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC;AACA,WAAO,MAAM,UAAS;EACxB;EAkCA,MAAM,SACJ,QAAwD,KAAK,KAC7D,EAAE,cAAa,IAAiC;IAC9C,eAAe;KAChB;AAED,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC,WAAW,EAAE,iBAAiB,WAAW;AACvC,sBAAgB,MAAM;AACtB,cAAQ,KAAK;IACf;AACA,UAAM,IAAI,MAAM,MAAM,SAAQ;AAC9B,WAAO,gBAAgB,IAAI,GAAG,SAAQ;EACxC;EAuBA,aACE,QAAwD,KAAK,KAC7D,EAAE,cAAa,IAAiC;IAC9C,eAAe;KAChB;AAED,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC,WAAW,EAAE,iBAAiB,WAAW;AACvC,sBAAgB,MAAM;AACtB,cAAQ,KAAK;IACf;AACA,UAAM,IAAI,MAAM,aAAY;AAC5B,WAAO,gBAAgB,IAAI,GAAG,SAAQ;EACxC;EAiCA,MAAM,SACJ,QAAwD,KAAK,KAC7D,EAAE,cAAa,IAAiC;IAC9C,eAAe;KAChB;AAED,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC,WAAW,EAAE,iBAAiB,WAAW;AACvC,sBAAgB,MAAM;AACtB,cAAQ,KAAK;IACf;AACA,UAAM,IAAI,MAAM,MAAM,SAAQ;AAC9B,WAAO,gBAAgB,IAAI,GAAG,SAAQ;EACxC;EAoBA,aACE,QAAwD,KAAK,KAC7D,EAAE,cAAa,IAAiC;IAC9C,eAAe;KAChB;AAED,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC,WAAW,EAAE,iBAAiB,WAAW;AACvC,sBAAgB,MAAM;AACtB,cAAQ,KAAK;IACf;AACA,UAAM,IAAI,MAAM,aAAY;AAC5B,WAAO,gBAAgB,IAAI,GAAG,SAAQ;EACxC;EA6BA,MAAM,KACJ,QAAyC,KAAK,KAC9C,OAAoB,CAAA,GAAE;AAEtB,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC,WAAW,EAAE,iBAAiB,WAAW;AACvC,aAAO;AACP,cAAQ,KAAK;IACf;AACA,UAAM,EACJ,gBAAgB,MAChB,SAAS,OACT,QAAAI,SACA,WAAU,IACR;AACJ,UAAM,UAAiC,CAAA;AACvC,QAAI,CAACA,WAAUA,QAAO,KAAK,GAAG;AAC5B,cAAQ,KAAK,gBAAgB,QAAQ,MAAM,SAAQ,CAAE;IACvD;AACA,UAAM,OAAO,oBAAI,IAAG;AACpB,UAAM,OAAO,CACX,KACA,OACE;AACF,WAAK,IAAI,GAAG;AACZ,UAAI,UAAU,CAAC,IAAI,YAAW;AAE5B,YAAI,IAAI;AACN,iBAAO,GAAG,EAAE;QACd;AAEA,YAAI,MAAM,QAAQ;AAClB,YAAI,CAAC;AAAK,iBAAO,GAAE;AACnB,cAAM,OAAO,MAAK;AAChB,cAAI,EAAE,QAAQ,GAAG;AACf,eAAE;UACJ;QACF;AACA,mBAAW,KAAK,SAAS;AACvB,cAAI,CAACA,WAAUA,QAAO,CAAC,GAAG;AACxB,oBAAQ,KAAK,gBAAgB,IAAI,EAAE,SAAQ,CAAE;UAC/C;AACA,cAAI,UAAU,EAAE,eAAc,GAAI;AAChC,cAAE,SAAQ,EACP,KAAK,OAAM,GAAG,UAAS,IAAK,EAAE,MAAK,IAAK,CAAE,EAC1C,KAAK,OACJ,GAAG,WAAW,MAAM,UAAU,IAAI,KAAK,GAAG,IAAI,IAAI,KAAI,CAAE;UAE9D,OAAO;AACL,gBAAI,EAAE,WAAW,MAAM,UAAU,GAAG;AAClC,mBAAK,GAAG,IAAI;YACd,OAAO;AACL,mBAAI;YACN;UACF;QACF;MACF,GAAG,IAAI;IACT;AAEA,UAAM,QAAQ;AACd,WAAO,IAAI,QAA+B,CAAC,KAAK,QAAO;AACrD,WAAK,OAAO,QAAK;AAEf,YAAI;AAAI,iBAAO,IAAI,EAAE;AAErB,YAAI,OAAgC;MACtC,CAAC;IACH,CAAC;EACH;EA6BA,SACE,QAAyC,KAAK,KAC9C,OAAoB,CAAA,GAAE;AAEtB,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC,WAAW,EAAE,iBAAiB,WAAW;AACvC,aAAO;AACP,cAAQ,KAAK;IACf;AACA,UAAM,EACJ,gBAAgB,MAChB,SAAS,OACT,QAAAA,SACA,WAAU,IACR;AACJ,UAAM,UAAiC,CAAA;AACvC,QAAI,CAACA,WAAUA,QAAO,KAAK,GAAG;AAC5B,cAAQ,KAAK,gBAAgB,QAAQ,MAAM,SAAQ,CAAE;IACvD;AACA,UAAM,OAAO,oBAAI,IAAc,CAAC,KAAK,CAAC;AACtC,eAAW,OAAO,MAAM;AACtB,YAAM,UAAU,IAAI,YAAW;AAC/B,iBAAW,KAAK,SAAS;AACvB,YAAI,CAACA,WAAUA,QAAO,CAAC,GAAG;AACxB,kBAAQ,KAAK,gBAAgB,IAAI,EAAE,SAAQ,CAAE;QAC/C;AACA,YAAI,IAA0B;AAC9B,YAAI,EAAE,eAAc,GAAI;AACtB,cAAI,EAAE,WAAW,IAAI,EAAE,aAAY;AAAM;AACzC,cAAI,EAAE,UAAS;AAAI,cAAE,UAAS;QAChC;AACA,YAAI,EAAE,WAAW,MAAM,UAAU,GAAG;AAClC,eAAK,IAAI,CAAC;QACZ;MACF;IACF;AACA,WAAO;EACT;;;;;;;;;;EAWA,CAAC,OAAO,aAAa,IAAC;AACpB,WAAO,KAAK,QAAO;EACrB;EA+BA,QACE,QAAyC,KAAK,KAC9C,UAAuB,CAAA,GAAE;AAKzB,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC,WAAW,EAAE,iBAAiB,WAAW;AACvC,gBAAU;AACV,cAAQ,KAAK;IACf;AACA,WAAO,KAAK,OAAO,OAAO,OAAO,EAAE,OAAO,aAAa,EAAC;EAC1D;;;;;;EAOA,CAAC,OAAO,QAAQ,IAAC;AACf,WAAO,KAAK,YAAW;EACzB;EAuBA,CAAC,YACC,QAAyC,KAAK,KAC9C,OAAoB,CAAA,GAAE;AAEtB,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC,WAAW,EAAE,iBAAiB,WAAW;AACvC,aAAO;AACP,cAAQ,KAAK;IACf;AACA,UAAM,EACJ,gBAAgB,MAChB,SAAS,OACT,QAAAA,SACA,WAAU,IACR;AACJ,QAAI,CAACA,WAAUA,QAAO,KAAK,GAAG;AAC5B,YAAM,gBAAgB,QAAQ,MAAM,SAAQ;IAC9C;AACA,UAAM,OAAO,oBAAI,IAAc,CAAC,KAAK,CAAC;AACtC,eAAW,OAAO,MAAM;AACtB,YAAM,UAAU,IAAI,YAAW;AAC/B,iBAAW,KAAK,SAAS;AACvB,YAAI,CAACA,WAAUA,QAAO,CAAC,GAAG;AACxB,gBAAM,gBAAgB,IAAI,EAAE,SAAQ;QACtC;AACA,YAAI,IAA0B;AAC9B,YAAI,EAAE,eAAc,GAAI;AACtB,cAAI,EAAE,WAAW,IAAI,EAAE,aAAY;AAAM;AACzC,cAAI,EAAE,UAAS;AAAI,cAAE,UAAS;QAChC;AACA,YAAI,EAAE,WAAW,MAAM,UAAU,GAAG;AAClC,eAAK,IAAI,CAAC;QACZ;MACF;IACF;EACF;EA2BA,OACE,QAAyC,KAAK,KAC9C,OAAoB,CAAA,GAAE;AAEtB,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC,WAAW,EAAE,iBAAiB,WAAW;AACvC,aAAO;AACP,cAAQ,KAAK;IACf;AACA,UAAM,EACJ,gBAAgB,MAChB,SAAS,OACT,QAAAA,SACA,WAAU,IACR;AACJ,UAAM,UAAU,IAAI,SAA4B,EAAE,YAAY,KAAI,CAAE;AACpE,QAAI,CAACA,WAAUA,QAAO,KAAK,GAAG;AAC5B,cAAQ,MAAM,gBAAgB,QAAQ,MAAM,SAAQ,CAAE;IACxD;AACA,UAAM,OAAO,oBAAI,IAAG;AACpB,UAAM,QAAoB,CAAC,KAAK;AAChC,QAAI,aAAa;AACjB,UAAMC,WAAU,MAAK;AACnB,UAAI,SAAS;AACb,aAAO,CAAC,QAAQ;AACd,cAAM,MAAM,MAAM,MAAK;AACvB,YAAI,CAAC,KAAK;AACR,cAAI,eAAe;AAAG,oBAAQ,IAAG;AACjC;QACF;AAEA;AACA,aAAK,IAAI,GAAG;AAEZ,cAAM,YAAY,CAChB,IACA,SACA,eAAwB,UACtB;AAEF,cAAI;AAAI,mBAAO,QAAQ,KAAK,SAAS,EAAE;AAEvC,cAAI,UAAU,CAAC,cAAc;AAC3B,kBAAM,WAA4C,CAAA;AAClD,uBAAW,KAAK,SAAS;AACvB,kBAAI,EAAE,eAAc,GAAI;AACtB,yBAAS,KACP,EACG,SAAQ,EACR,KAAK,CAAC,MACL,GAAG,UAAS,IAAK,EAAE,MAAK,IAAK,CAAC,CAC/B;cAEP;YACF;AACA,gBAAI,SAAS,QAAQ;AACnB,sBAAQ,IAAI,QAAQ,EAAE,KAAK,MACzB,UAAU,MAAM,SAAS,IAAI,CAAC;AAEhC;YACF;UACF;AAEA,qBAAW,KAAK,SAAS;AACvB,gBAAI,MAAM,CAACD,WAAUA,QAAO,CAAC,IAAI;AAC/B,kBAAI,CAAC,QAAQ,MAAM,gBAAgB,IAAI,EAAE,SAAQ,CAAE,GAAG;AACpD,yBAAS;cACX;YACF;UACF;AAEA;AACA,qBAAW,KAAK,SAAS;AACvB,kBAAM,IAAI,EAAE,eAAc,KAAM;AAChC,gBAAI,EAAE,WAAW,MAAM,UAAU,GAAG;AAClC,oBAAM,KAAK,CAAC;YACd;UACF;AACA,cAAI,UAAU,CAAC,QAAQ,SAAS;AAC9B,oBAAQ,KAAK,SAASC,QAAO;UAC/B,WAAW,CAACC,OAAM;AAChB,YAAAD,SAAO;UACT;QACF;AAGA,YAAIC,QAAO;AACX,YAAI,UAAU,WAAW,IAAI;AAC7B,QAAAA,QAAO;MACT;IACF;AACA,IAAAD,SAAO;AACP,WAAO;EACT;EA8BA,WACE,QAAyC,KAAK,KAC9C,OAAoB,CAAA,GAAE;AAEtB,QAAI,OAAO,UAAU,UAAU;AAC7B,cAAQ,KAAK,IAAI,QAAQ,KAAK;IAChC,WAAW,EAAE,iBAAiB,WAAW;AACvC,aAAO;AACP,cAAQ,KAAK;IACf;AACA,UAAM,EACJ,gBAAgB,MAChB,SAAS,OACT,QAAAD,SACA,WAAU,IACR;AACJ,UAAM,UAAU,IAAI,SAA4B,EAAE,YAAY,KAAI,CAAE;AACpE,UAAM,OAAO,oBAAI,IAAG;AACpB,QAAI,CAACA,WAAUA,QAAO,KAAK,GAAG;AAC5B,cAAQ,MAAM,gBAAgB,QAAQ,MAAM,SAAQ,CAAE;IACxD;AACA,UAAM,QAAoB,CAAC,KAAK;AAChC,QAAI,aAAa;AACjB,UAAMC,WAAU,MAAK;AACnB,UAAI,SAAS;AACb,aAAO,CAAC,QAAQ;AACd,cAAM,MAAM,MAAM,MAAK;AACvB,YAAI,CAAC,KAAK;AACR,cAAI,eAAe;AAAG,oBAAQ,IAAG;AACjC;QACF;AACA;AACA,aAAK,IAAI,GAAG;AAEZ,cAAM,UAAU,IAAI,YAAW;AAC/B,mBAAW,KAAK,SAAS;AACvB,cAAI,CAACD,WAAUA,QAAO,CAAC,GAAG;AACxB,gBAAI,CAAC,QAAQ,MAAM,gBAAgB,IAAI,EAAE,SAAQ,CAAE,GAAG;AACpD,uBAAS;YACX;UACF;QACF;AACA;AACA,mBAAW,KAAK,SAAS;AACvB,cAAI,IAA0B;AAC9B,cAAI,EAAE,eAAc,GAAI;AACtB,gBAAI,EAAE,WAAW,IAAI,EAAE,aAAY;AAAM;AACzC,gBAAI,EAAE,UAAS;AAAI,gBAAE,UAAS;UAChC;AACA,cAAI,EAAE,WAAW,MAAM,UAAU,GAAG;AAClC,kBAAM,KAAK,CAAC;UACd;QACF;MACF;AACA,UAAI,UAAU,CAAC,QAAQ;AAAS,gBAAQ,KAAK,SAASC,QAAO;IAC/D;AACA,IAAAA,SAAO;AACP,WAAO;EACT;EAEA,MAAML,SAAsB,KAAK,KAAG;AAClC,UAAM,SAAS,KAAK;AACpB,SAAK,MAAM,OAAOA,WAAS,WAAW,KAAK,IAAI,QAAQA,MAAI,IAAIA;AAC/D,SAAK,IAAI,QAAQ,EAAE,MAAM;EAC3B;;AAwEI,IAAO,kBAAP,cAA+B,eAAc;;;;EAIjD,MAAY;EAEZ,YACE,MAAoB,QAAQ,IAAG,GAC/B,OAAuB,CAAA,GAAE;AAEzB,UAAM,EAAE,SAAS,KAAI,IAAK;AAC1B,UAAM,KAAK,OAAO,MAAM,EAAE,GAAG,MAAM,OAAM,CAAE;AAC3C,SAAK,SAAS;AACd,aAAS,IAA0B,KAAK,KAAK,GAAG,IAAI,EAAE,QAAQ;AAC5D,QAAE,SAAS,KAAK;IAClB;EACF;;;;EAKA,cAAc,KAAW;AAIvB,WAAO,MAAM,MAAM,GAAG,EAAE,KAAK,YAAW;EAC1C;;;;EAKA,QAAQG,MAAW;AACjB,WAAO,IAAI,UACT,KAAK,UACL,OACA,QACA,KAAK,OACL,KAAK,QACL,KAAK,cAAa,GAClB,EAAE,IAAAA,KAAE,CAAE;EAEV;;;;EAKA,WAAW,GAAS;AAClB,WACE,EAAE,WAAW,GAAG,KAAK,EAAE,WAAW,IAAI,KAAK,kBAAkB,KAAK,CAAC;EAEvE;;AAUI,IAAO,kBAAP,cAA+B,eAAc;;;;EAIjD,MAAW;EACX,YACE,MAAoB,QAAQ,IAAG,GAC/B,OAAuB,CAAA,GAAE;AAEzB,UAAM,EAAE,SAAS,MAAK,IAAK;AAC3B,UAAM,KAAK,OAAO,KAAK,EAAE,GAAG,MAAM,OAAM,CAAE;AAC1C,SAAK,SAAS;EAChB;;;;EAKA,cAAc,MAAY;AACxB,WAAO;EACT;;;;EAKA,QAAQA,MAAW;AACjB,WAAO,IAAI,UACT,KAAK,UACL,OACA,QACA,KAAK,OACL,KAAK,QACL,KAAK,cAAa,GAClB,EAAE,IAAAA,KAAE,CAAE;EAEV;;;;EAKA,WAAW,GAAS;AAClB,WAAO,EAAE,WAAW,GAAG;EACzB;;AAWI,IAAO,mBAAP,cAAgC,gBAAe;EACnD,YACE,MAAoB,QAAQ,IAAG,GAC/B,OAAuB,CAAA,GAAE;AAEzB,UAAM,EAAE,SAAS,KAAI,IAAK;AAC1B,UAAM,KAAK,EAAE,GAAG,MAAM,OAAM,CAAE;EAChC;;AAQK,IAAM,OAAO,QAAQ,aAAa,UAAU,YAAY;AASxD,IAAM,aAIX,QAAQ,aAAa,UAAU,kBAC7B,QAAQ,aAAa,WAAW,mBAChC;;;AEhwFJ,SAAS,iBAAAI,sBAAqB;;;ACQ9B,IAAM,gBAAgB,CAAC,OACrB,GAAG,UAAU;AACf,IAAM,aAAa,CAAC,OAAiC,GAAG,UAAU;AAM5D,IAAO,UAAP,MAAO,SAAO;EACT;EACA;EACA;EACA;EACA;EACT;EACA;EACA;EACA;EACA;EACA,kBAA2B;EAE3B,YACE,aACA,UACA,OACA,UAAyB;AAEzB,QAAI,CAAC,cAAc,WAAW,GAAG;AAC/B,YAAM,IAAI,UAAU,oBAAoB;;AAE1C,QAAI,CAAC,WAAW,QAAQ,GAAG;AACzB,YAAM,IAAI,UAAU,iBAAiB;;AAEvC,QAAI,SAAS,WAAW,YAAY,QAAQ;AAC1C,YAAM,IAAI,UAAU,+CAA+C;;AAErE,SAAK,SAAS,YAAY;AAC1B,QAAI,QAAQ,KAAK,SAAS,KAAK,QAAQ;AACrC,YAAM,IAAI,UAAU,oBAAoB;;AAE1C,SAAK,eAAe;AACpB,SAAK,YAAY;AACjB,SAAK,SAAS;AACd,SAAK,YAAY;AAGjB,QAAI,KAAK,WAAW,GAAG;AASrB,UAAI,KAAK,MAAK,GAAI;AAEhB,cAAM,CAAC,IAAI,IAAI,IAAI,IAAI,GAAG,KAAK,IAAI,KAAK;AACxC,cAAM,CAAC,IAAI,IAAI,IAAI,IAAI,GAAG,KAAK,IAAI,KAAK;AACxC,YAAI,MAAM,CAAC,MAAM,IAAI;AAEnB,gBAAM,MAAK;AACX,gBAAM,MAAK;;AAEb,cAAM,IAAI,CAAC,IAAI,IAAI,IAAI,IAAI,EAAE,EAAE,KAAK,GAAG;AACvC,cAAM,IAAI,CAAC,IAAI,IAAI,IAAI,IAAI,EAAE,EAAE,KAAK,GAAG;AACvC,aAAK,eAAe,CAAC,GAAG,GAAG,KAAK;AAChC,aAAK,YAAY,CAAC,GAAG,GAAG,KAAK;AAC7B,aAAK,SAAS,KAAK,aAAa;iBACvB,KAAK,QAAO,KAAM,KAAK,WAAU,GAAI;AAC9C,cAAM,CAAC,IAAI,GAAG,KAAK,IAAI,KAAK;AAC5B,cAAM,CAAC,IAAI,GAAG,KAAK,IAAI,KAAK;AAC5B,YAAI,MAAM,CAAC,MAAM,IAAI;AAEnB,gBAAM,MAAK;AACX,gBAAM,MAAK;;AAEb,cAAM,IAAK,KAAgB;AAC3B,cAAM,IAAI,KAAK;AACf,aAAK,eAAe,CAAC,GAAG,GAAG,KAAK;AAChC,aAAK,YAAY,CAAC,GAAG,GAAG,KAAK;AAC7B,aAAK,SAAS,KAAK,aAAa;;;EAGtC;;;;EAKA,UAAO;AACL,WAAO,KAAK,aAAa,KAAK,MAAM;EACtC;;;;EAKA,WAAQ;AACN,WAAO,OAAO,KAAK,aAAa,KAAK,MAAM,MAAM;EACnD;;;;EAIA,aAAU;AACR,WAAO,KAAK,aAAa,KAAK,MAAM,MAAM;EAC5C;;;;EAIA,WAAQ;AACN,WAAO,KAAK,aAAa,KAAK,MAAM,aAAa;EACnD;;;;EAKA,aAAU;AACR,WAAQ,KAAK,cACX,KAAK,gBACJ,KAAK,WAAW,IACb,KAAK,WAAU,IACb,KAAK,UAAU,CAAC,IAAI,KAAK,UAAU,MAAM,CAAC,EAAE,KAAK,GAAG,IACpD,KAAK,UAAU,KAAK,GAAG,IACzB,KAAK,UAAU,MAAM,KAAK,MAAM,EAAE,KAAK,GAAG;EAClD;;;;EAKA,UAAO;AACL,WAAO,KAAK,SAAS,KAAK,SAAS;EACrC;;;;EAKA,OAAI;AACF,QAAI,KAAK,UAAU;AAAW,aAAO,KAAK;AAC1C,QAAI,CAAC,KAAK,QAAO;AAAI,aAAQ,KAAK,QAAQ;AAC1C,SAAK,QAAQ,IAAI,SACf,KAAK,cACL,KAAK,WACL,KAAK,SAAS,GACd,KAAK,SAAS;AAEhB,SAAK,MAAM,cAAc,KAAK;AAC9B,SAAK,MAAM,SAAS,KAAK;AACzB,SAAK,MAAM,WAAW,KAAK;AAC3B,WAAO,KAAK;EACd;;;;EAKA,QAAK;AACH,UAAM,KAAK,KAAK;AAChB,WAAO,KAAK,WAAW,SACnB,KAAK,SACJ,KAAK,SACJ,KAAK,cAAc,WACnB,KAAK,WAAW,KAChB,GAAG,CAAC,MAAM,MACV,GAAG,CAAC,MAAM,MACV,OAAO,GAAG,CAAC,MAAM,YACjB,CAAC,CAAC,GAAG,CAAC,KACN,OAAO,GAAG,CAAC,MAAM,YACjB,CAAC,CAAC,GAAG,CAAC;EACd;;;;;;;;;EAUA,UAAO;AACL,UAAM,KAAK,KAAK;AAChB,WAAO,KAAK,aAAa,SACrB,KAAK,WACJ,KAAK,WACJ,KAAK,cAAc,WACnB,KAAK,WAAW,KAChB,KAAK,SAAS,KACd,OAAO,GAAG,CAAC,MAAM,YACjB,YAAY,KAAK,GAAG,CAAC,CAAC;EAC9B;;;;;;;EAQA,aAAU;AACR,UAAM,KAAK,KAAK;AAChB,WAAO,KAAK,gBAAgB,SACxB,KAAK,cACJ,KAAK,cACH,GAAG,CAAC,MAAM,MAAM,GAAG,SAAS,KAC7B,KAAK,QAAO,KACZ,KAAK,MAAK;EAClB;;;;EAKA,OAAI;AACF,UAAM,IAAI,KAAK,aAAa,CAAC;AAC7B,WAAO,OAAO,MAAM,YAAY,KAAK,WAAU,KAAM,KAAK,WAAW,IACjE,IACA;EACN;;;;;EAMA,sBAAmB;AACjB,WAAO,EACL,KAAK,WAAW,KAChB,CAAC,KAAK,WAAU,KAChB,CAAC,KAAK;EAEV;;;;EAKA,qBAAkB;AAChB,QAAI,KAAK,WAAW,KAAK,CAAC,KAAK,WAAU,KAAM,CAAC,KAAK;AACnD,aAAO;AACT,SAAK,kBAAkB;AACvB,WAAO;EACT;;;;ACpPF,OAAO,QAAQ;AACf,OAAOC,aAAY;AACnB,OAAO,mBAAmB;AAT1B,IAAMC,QACJ,OAAO,YAAY,YAAY,UAC3B,UACA;AAAA,EACE,QAAQ;AAAA,EACR,QAAQ;AACV;AAIN,IAAM,KAAK,cAAc;AAEzB,IAAMC,OAAM,OAAO,KAAK;AACxB,IAAMC,kBAAiB,OAAO,cAAc;AAC5C,IAAMC,eAAc,OAAO,YAAY;AACvC,IAAMC,gBAAe,OAAO,aAAa;AACzC,IAAMC,iBAAgB,OAAO,cAAc;AAC3C,IAAMC,UAAS,OAAO,QAAQ;AAC9B,IAAMC,QAAO,OAAO,MAAM;AAC1B,IAAMC,SAAQ,OAAO,OAAO;AAC5B,IAAMC,cAAa,OAAO,YAAY;AACtC,IAAMC,YAAW,OAAO,UAAU;AAClC,IAAMC,WAAU,OAAO,SAAS;AAChC,IAAMC,WAAU,OAAO,SAAS;AAChC,IAAMC,UAAS,OAAO,QAAQ;AAC9B,IAAMC,UAAS,OAAO,QAAQ;AAC9B,IAAMC,UAAS,OAAO,QAAQ;AAC9B,IAAMC,SAAQ,OAAO,OAAO;AAC5B,IAAMC,gBAAe,OAAO,cAAc;AAC1C,IAAMC,cAAa,OAAO,YAAY;AACtC,IAAMC,eAAc,OAAO,aAAa;AACxC,IAAMC,cAAa,OAAO,YAAY;AAEtC,IAAMC,aAAY,OAAO,WAAW;AAEpC,IAAMC,SAAQ,OAAO,OAAO;AAC5B,IAAMC,YAAW,OAAO,UAAU;AAClC,IAAMC,WAAU,OAAO,SAAS;AAChC,IAAMC,YAAW,OAAO,UAAU;AAClC,IAAMC,SAAQ,OAAO,OAAO;AAC5B,IAAMC,SAAQ,OAAO,OAAO;AAC5B,IAAMC,WAAU,OAAO,SAAS;AAChC,IAAMC,UAAS,OAAO,QAAQ;AAE9B,IAAMC,SAAQ,QAAM,QAAQ,QAAQ,EAAE,KAAK,EAAE;AAG7C,IAAM,SAAS,OAAO,6BAA6B;AACnD,IAAM,gBACH,UAAU,OAAO,iBAAkB,OAAO,+BAA+B;AAC5E,IAAM,WACH,UAAU,OAAO,YAAa,OAAO,0BAA0B;AAKlE,IAAMC,YAAW,QAAM,OAAO,SAAS,OAAO,YAAY,OAAO;AAEjE,IAAM,gBAAgB,OACpB,aAAa,eACZ,OAAO,MAAM,YACZ,EAAE,eACF,EAAE,YAAY,SAAS,iBACvB,EAAE,cAAc;AAEpB,IAAMC,qBAAoB,OAAK,CAAC,OAAO,SAAS,CAAC,KAAK,YAAY,OAAO,CAAC;AAE1E,IAAMC,QAAN,MAAW;AAAA,EACT,YAAY,KAAK,MAAM,MAAM;AAC3B,SAAK,MAAM;AACX,SAAK,OAAO;AACZ,SAAK,OAAO;AACZ,SAAK,UAAU,MAAM,IAAInB,OAAM,EAAE;AACjC,SAAK,GAAG,SAAS,KAAK,OAAO;AAAA,EAC/B;AAAA,EACA,SAAS;AACP,SAAK,KAAK,eAAe,SAAS,KAAK,OAAO;AAAA,EAChD;AAAA;AAAA,EAEA,cAAc;AAAA,EAAC;AAAA,EACf,MAAM;AACJ,SAAK,OAAO;AACZ,QAAI,KAAK,KAAK,IAAK,MAAK,KAAK,IAAI;AAAA,EACnC;AACF;AAEA,IAAMoB,mBAAN,cAA8BD,MAAK;AAAA,EACjC,SAAS;AACP,SAAK,IAAI,eAAe,SAAS,KAAK,WAAW;AACjD,UAAM,OAAO;AAAA,EACf;AAAA,EACA,YAAY,KAAK,MAAM,MAAM;AAC3B,UAAM,KAAK,MAAM,IAAI;AACrB,SAAK,cAAc,QAAM,KAAK,KAAK,SAAS,EAAE;AAC9C,QAAI,GAAG,SAAS,KAAK,WAAW;AAAA,EAClC;AACF;AAEO,IAAME,YAAN,MAAM,kBAAiBpC,QAAO;AAAA,EACnC,YAAY,SAAS;AACnB,UAAM;AACN,SAAKa,QAAO,IAAI;AAEhB,SAAKC,OAAM,IAAI;AACf,SAAKG,MAAK,IAAI,CAAC;AACf,SAAKD,OAAM,IAAI,CAAC;AAChB,SAAKK,WAAU,IAAK,WAAW,QAAQ,cAAe;AACtD,QAAI,KAAKA,WAAU,EAAG,MAAKV,SAAQ,IAAI;AAAA,QAClC,MAAKA,SAAQ,IAAK,WAAW,QAAQ,YAAa;AACvD,QAAI,KAAKA,SAAQ,MAAM,SAAU,MAAKA,SAAQ,IAAI;AAClD,SAAKgB,MAAK,IAAK,WAAW,CAAC,CAAC,QAAQ,SAAU;AAC9C,SAAKf,QAAO,IAAI,KAAKD,SAAQ,IAAI,IAAI,GAAG,KAAKA,SAAQ,CAAC,IAAI;AAC1D,SAAKT,IAAG,IAAI;AACZ,SAAKE,YAAW,IAAI;AACpB,SAAKC,aAAY,IAAI;AACrB,SAAKE,OAAM,IAAI;AACf,SAAKD,cAAa,IAAI;AACtB,SAAK,WAAW;AAChB,SAAK,WAAW;AAChB,SAAKY,aAAY,IAAI;AACrB,SAAKI,UAAS,IAAI;AAClB,QAAI,WAAW,QAAQ,sBAAsB,MAAM;AACjD,aAAO,eAAe,MAAM,UAAU,EAAE,KAAK,MAAM,KAAKN,OAAM,EAAE,CAAC;AAAA,IACnE;AACA,QAAI,WAAW,QAAQ,qBAAqB,MAAM;AAChD,aAAO,eAAe,MAAM,SAAS,EAAE,KAAK,MAAM,KAAKC,MAAK,EAAE,CAAC;AAAA,IACjE;AACA,SAAKa,OAAM,IAAI,WAAW,QAAQ;AAClC,SAAKD,QAAO,IAAI;AAChB,QAAI,KAAKC,OAAM,GAAG;AAChB,WAAKA,OAAM,EAAE,iBAAiB,SAAS,MAAM,KAAKF,MAAK,EAAE,CAAC;AAC1D,UAAI,KAAKE,OAAM,EAAE,SAAS;AACxB,aAAKF,MAAK,EAAE;AAAA,MACd;AAAA,IACF;AAAA,EACF;AAAA,EAEA,IAAI,eAAe;AACjB,WAAO,KAAKV,aAAY;AAAA,EAC1B;AAAA,EAEA,IAAI,WAAW;AACb,WAAO,KAAKP,SAAQ;AAAA,EACtB;AAAA,EACA,IAAI,SAAS,KAAK;AAChB,QAAI,KAAKU,WAAU,EAAG,OAAM,IAAI,MAAM,mCAAmC;AAEzE,QACE,KAAKV,SAAQ,KACb,QAAQ,KAAKA,SAAQ,MACnB,KAAKC,QAAO,KAAK,KAAKA,QAAO,EAAE,YAAa,KAAKM,aAAY;AAE/D,YAAM,IAAI,MAAM,wBAAwB;AAE1C,QAAI,KAAKP,SAAQ,MAAM,KAAK;AAC1B,WAAKC,QAAO,IAAI,MAAM,IAAI,GAAG,GAAG,IAAI;AACpC,UAAI,KAAKI,OAAM,EAAE;AACf,aAAKA,OAAM,IAAI,KAAKA,OAAM,EAAE,IAAI,WAAS,KAAKJ,QAAO,EAAE,MAAM,KAAK,CAAC;AAAA,IACvE;AAEA,SAAKD,SAAQ,IAAI;AAAA,EACnB;AAAA,EAEA,YAAY,KAAK;AACf,SAAK,WAAW;AAAA,EAClB;AAAA,EAEA,IAAI,aAAa;AACf,WAAO,KAAKU,WAAU;AAAA,EACxB;AAAA,EACA,IAAI,WAAW,IAAI;AACjB,SAAKA,WAAU,IAAI,KAAKA,WAAU,KAAK,CAAC,CAAC;AAAA,EAC3C;AAAA,EAEA,KAAK,OAAO,IAAI;AACd,WAAO,KAAKM,MAAK;AAAA,EACnB;AAAA,EACA,KAAK,OAAO,EAAE,GAAG;AACf,SAAKA,MAAK,IAAI,KAAKA,MAAK,KAAK,CAAC,CAAC;AAAA,EACjC;AAAA;AAAA,EAGA,CAACC,MAAK,IAAI;AACR,SAAKC,QAAO,IAAI;AAChB,SAAK,KAAK,SAAS,KAAKC,OAAM,EAAE,MAAM;AACtC,SAAK,QAAQ,KAAKA,OAAM,EAAE,MAAM;AAAA,EAClC;AAAA,EAEA,IAAI,UAAU;AACZ,WAAO,KAAKD,QAAO;AAAA,EACrB;AAAA,EACA,IAAI,QAAQ,GAAG;AAAA,EAAC;AAAA,EAEhB,MAAM,OAAO,UAAU,IAAI;AACzB,QAAI,KAAKA,QAAO,EAAG,QAAO;AAC1B,QAAI,KAAK3B,IAAG,EAAG,OAAM,IAAI,MAAM,iBAAiB;AAEhD,QAAI,KAAKoB,UAAS,GAAG;AACnB,WAAK;AAAA,QACH;AAAA,QACA,OAAO;AAAA,UACL,IAAI,MAAM,gDAAgD;AAAA,UAC1D,EAAE,MAAM,uBAAuB;AAAA,QACjC;AAAA,MACF;AACA,aAAO;AAAA,IACT;AAEA,QAAI,OAAO,aAAa,WAAY,CAAC,KAAK,UAAY,WAAW;AAEjE,QAAI,CAAC,SAAU,YAAW;AAE1B,UAAM,KAAK,KAAKK,MAAK,IAAII,SAAQ,OAAK,EAAE;AAMxC,QAAI,CAAC,KAAKV,WAAU,KAAK,CAAC,OAAO,SAAS,KAAK,GAAG;AAChD,UAAIY,mBAAkB,KAAK;AACzB,gBAAQ,OAAO,KAAK,MAAM,QAAQ,MAAM,YAAY,MAAM,UAAU;AAAA,eAC7D,cAAc,KAAK,EAAG,SAAQ,OAAO,KAAK,KAAK;AAAA,eAC/C,OAAO,UAAU;AAExB,aAAK,aAAa;AAAA,IACtB;AAIA,QAAI,KAAKZ,WAAU,GAAG;AAEpB,UAAI,KAAK,WAAW,KAAKH,aAAY,MAAM,EAAG,MAAKT,MAAK,EAAE,IAAI;AAE9D,UAAI,KAAK,QAAS,MAAK,KAAK,QAAQ,KAAK;AAAA,UACpC,MAAKU,WAAU,EAAE,KAAK;AAE3B,UAAI,KAAKD,aAAY,MAAM,EAAG,MAAK,KAAK,UAAU;AAElD,UAAI,GAAI,IAAG,EAAE;AAEb,aAAO,KAAK;AAAA,IACd;AAIA,QAAI,CAAC,MAAM,QAAQ;AACjB,UAAI,KAAKA,aAAY,MAAM,EAAG,MAAK,KAAK,UAAU;AAClD,UAAI,GAAI,IAAG,EAAE;AACb,aAAO,KAAK;AAAA,IACd;AAIA,QACE,OAAO,UAAU;AAAA,IAEjB,EAAE,aAAa,KAAKP,SAAQ,KAAK,CAAC,KAAKC,QAAO,EAAE,WAChD;AACA,cAAQ,OAAO,KAAK,OAAO,QAAQ;AAAA,IACrC;AAEA,QAAI,OAAO,SAAS,KAAK,KAAK,KAAKD,SAAQ;AACzC,cAAQ,KAAKC,QAAO,EAAE,MAAM,KAAK;AAGnC,QAAI,KAAK,WAAW,KAAKM,aAAY,MAAM,EAAG,MAAKT,MAAK,EAAE,IAAI;AAE9D,QAAI,KAAK,QAAS,MAAK,KAAK,QAAQ,KAAK;AAAA,QACpC,MAAKU,WAAU,EAAE,KAAK;AAE3B,QAAI,KAAKD,aAAY,MAAM,EAAG,MAAK,KAAK,UAAU;AAElD,QAAI,GAAI,IAAG,EAAE;AAEb,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,KAAK,GAAG;AACN,QAAI,KAAKI,UAAS,EAAG,QAAO;AAE5B,QAAI,KAAKJ,aAAY,MAAM,KAAK,MAAM,KAAK,IAAI,KAAKA,aAAY,GAAG;AACjE,WAAKf,eAAc,EAAE;AACrB,aAAO;AAAA,IACT;AAEA,QAAI,KAAKkB,WAAU,EAAG,KAAI;AAE1B,QAAI,KAAKL,OAAM,EAAE,SAAS,KAAK,CAAC,KAAKK,WAAU,GAAG;AAChD,UAAI,KAAK,SAAU,MAAKL,OAAM,IAAI,CAAC,KAAKA,OAAM,EAAE,KAAK,EAAE,CAAC;AAAA,UACnD,MAAKA,OAAM,IAAI,CAAC,OAAO,OAAO,KAAKA,OAAM,GAAG,KAAKE,aAAY,CAAC,CAAC;AAAA,IACtE;AAEA,UAAM,MAAM,KAAKV,KAAI,EAAE,KAAK,MAAM,KAAKQ,OAAM,EAAE,CAAC,CAAC;AACjD,SAAKb,eAAc,EAAE;AACrB,WAAO;AAAA,EACT;AAAA,EAEA,CAACK,KAAI,EAAE,GAAG,OAAO;AACf,QAAI,MAAM,MAAM,UAAU,MAAM,KAAM,MAAKY,YAAW,EAAE;AAAA,SACnD;AACH,WAAKJ,OAAM,EAAE,CAAC,IAAI,MAAM,MAAM,CAAC;AAC/B,cAAQ,MAAM,MAAM,GAAG,CAAC;AACxB,WAAKE,aAAY,KAAK;AAAA,IACxB;AAEA,SAAK,KAAK,QAAQ,KAAK;AAEvB,QAAI,CAAC,KAAKF,OAAM,EAAE,UAAU,CAAC,KAAKd,IAAG,EAAG,MAAK,KAAK,OAAO;AAEzD,WAAO;AAAA,EACT;AAAA,EAEA,IAAI,OAAO,UAAU,IAAI;AACvB,QAAI,OAAO,UAAU,WAAY,CAAC,KAAK,OAAS,QAAQ;AACxD,QAAI,OAAO,aAAa,WAAY,CAAC,KAAK,UAAY,WAAW;AACjE,QAAI,MAAO,MAAK,MAAM,OAAO,QAAQ;AACrC,QAAI,GAAI,MAAK,KAAK,OAAO,EAAE;AAC3B,SAAKA,IAAG,IAAI;AACZ,SAAK,WAAW;AAMhB,QAAI,KAAK,WAAW,CAAC,KAAKY,OAAM,EAAG,MAAKX,eAAc,EAAE;AACxD,WAAO;AAAA,EACT;AAAA;AAAA,EAGA,CAACY,OAAM,IAAI;AACT,QAAI,KAAKO,UAAS,EAAG;AAErB,SAAKR,OAAM,IAAI;AACf,SAAKD,QAAO,IAAI;AAChB,SAAK,KAAK,QAAQ;AAClB,QAAI,KAAKG,OAAM,EAAE,OAAQ,MAAKP,MAAK,EAAE;AAAA,aAC5B,KAAKP,IAAG,EAAG,MAAKC,eAAc,EAAE;AAAA,QACpC,MAAK,KAAK,OAAO;AAAA,EACxB;AAAA,EAEA,SAAS;AACP,WAAO,KAAKY,OAAM,EAAE;AAAA,EACtB;AAAA,EAEA,QAAQ;AACN,SAAKF,QAAO,IAAI;AAChB,SAAKC,OAAM,IAAI;AAAA,EACjB;AAAA,EAEA,IAAI,YAAY;AACd,WAAO,KAAKQ,UAAS;AAAA,EACvB;AAAA,EAEA,IAAI,UAAU;AACZ,WAAO,KAAKT,QAAO;AAAA,EACrB;AAAA,EAEA,IAAI,SAAS;AACX,WAAO,KAAKC,OAAM;AAAA,EACpB;AAAA,EAEA,CAACK,WAAU,EAAE,OAAO;AAClB,QAAI,KAAKE,WAAU,EAAG,MAAKH,aAAY,KAAK;AAAA,QACvC,MAAKA,aAAY,KAAK,MAAM;AACjC,SAAKF,OAAM,EAAE,KAAK,KAAK;AAAA,EACzB;AAAA,EAEA,CAACI,YAAW,IAAI;AACd,QAAI,KAAKC,WAAU,EAAG,MAAKH,aAAY,KAAK;AAAA,QACvC,MAAKA,aAAY,KAAK,KAAKF,OAAM,EAAE,CAAC,EAAE;AAC3C,WAAO,KAAKA,OAAM,EAAE,MAAM;AAAA,EAC5B;AAAA,EAEA,CAACP,MAAK,EAAE,SAAS;AACf,OAAG;AAAA,IAAC,SAAS,KAAKC,WAAU,EAAE,KAAKU,YAAW,EAAE,CAAC,KAAK,KAAKJ,OAAM,EAAE;AAEnE,QAAI,CAAC,WAAW,CAAC,KAAKA,OAAM,EAAE,UAAU,CAAC,KAAKd,IAAG,EAAG,MAAK,KAAK,OAAO;AAAA,EACvE;AAAA,EAEA,CAACQ,WAAU,EAAE,OAAO;AAClB,SAAK,KAAK,QAAQ,KAAK;AACvB,WAAO,KAAK;AAAA,EACd;AAAA,EAEA,KAAK,MAAM,MAAM;AACf,QAAI,KAAKY,UAAS,EAAG;AAErB,UAAM,QAAQ,KAAKlB,YAAW;AAC9B,WAAO,QAAQ,CAAC;AAChB,QAAI,SAASH,MAAK,UAAU,SAASA,MAAK,OAAQ,MAAK,MAAM;AAAA,QACxD,MAAK,MAAM,KAAK,QAAQ;AAC7B,SAAK,cAAc,CAAC,CAAC,KAAK;AAG1B,QAAI,OAAO;AACT,UAAI,KAAK,IAAK,MAAK,IAAI;AAAA,IACzB,OAAO;AACL,WAAKgB,MAAK,EAAE;AAAA,QACV,CAAC,KAAK,cACF,IAAIiB,MAAK,MAAM,MAAM,IAAI,IACzB,IAAIC,iBAAgB,MAAM,MAAM,IAAI;AAAA,MAC1C;AACA,UAAI,KAAKR,MAAK,EAAG,CAAAI,OAAM,MAAM,KAAKhB,OAAM,EAAE,CAAC;AAAA,UACtC,MAAKA,OAAM,EAAE;AAAA,IACpB;AAEA,WAAO;AAAA,EACT;AAAA,EAEA,OAAO,MAAM;AACX,UAAM,IAAI,KAAKE,MAAK,EAAE,KAAK,CAAAoB,OAAKA,GAAE,SAAS,IAAI;AAC/C,QAAI,GAAG;AACL,WAAKpB,MAAK,EAAE,OAAO,KAAKA,MAAK,EAAE,QAAQ,CAAC,GAAG,CAAC;AAC5C,QAAE,OAAO;AAAA,IACX;AAAA,EACF;AAAA,EAEA,YAAY,IAAI,IAAI;AAClB,WAAO,KAAK,GAAG,IAAI,EAAE;AAAA,EACvB;AAAA,EAEA,GAAG,IAAI,IAAI;AACT,UAAM,MAAM,MAAM,GAAG,IAAI,EAAE;AAC3B,QAAI,OAAO,UAAU,CAAC,KAAKA,MAAK,EAAE,UAAU,CAAC,KAAK,QAAS,MAAKF,OAAM,EAAE;AAAA,aAC/D,OAAO,cAAc,KAAKG,aAAY,MAAM;AACnD,YAAM,KAAK,UAAU;AAAA,aACdc,UAAS,EAAE,KAAK,KAAK5B,YAAW,GAAG;AAC1C,YAAM,KAAK,EAAE;AACb,WAAK,mBAAmB,EAAE;AAAA,IAC5B,WAAW,OAAO,WAAW,KAAKE,cAAa,GAAG;AAChD,UAAI,KAAKqB,MAAK,EAAG,CAAAI,OAAM,MAAM,GAAG,KAAK,MAAM,KAAKzB,cAAa,CAAC,CAAC;AAAA,UAC1D,IAAG,KAAK,MAAM,KAAKA,cAAa,CAAC;AAAA,IACxC;AACA,WAAO;AAAA,EACT;AAAA,EAEA,IAAI,aAAa;AACf,WAAO,KAAKF,YAAW;AAAA,EACzB;AAAA,EAEA,CAACD,eAAc,IAAI;AACjB,QACE,CAAC,KAAKE,aAAY,KAClB,CAAC,KAAKD,YAAW,KACjB,CAAC,KAAKkB,UAAS,KACf,KAAKN,OAAM,EAAE,WAAW,KACxB,KAAKd,IAAG,GACR;AACA,WAAKG,aAAY,IAAI;AACrB,WAAK,KAAK,KAAK;AACf,WAAK,KAAK,WAAW;AACrB,WAAK,KAAK,QAAQ;AAClB,UAAI,KAAKE,OAAM,EAAG,MAAK,KAAK,OAAO;AACnC,WAAKF,aAAY,IAAI;AAAA,IACvB;AAAA,EACF;AAAA,EAEA,KAAK,IAAI,SAAS,OAAO;AAEvB,QAAI,OAAO,WAAW,OAAO,WAAW,OAAOiB,cAAa,KAAKA,UAAS;AACxE;AAAA,aACO,OAAO,QAAQ;AACtB,aAAO,CAAC,KAAKD,WAAU,KAAK,CAAC,OACzB,QACA,KAAKM,MAAK,IACVI,OAAM,MAAM,KAAKP,SAAQ,EAAE,IAAI,CAAC,IAChC,KAAKA,SAAQ,EAAE,IAAI;AAAA,IACzB,WAAW,OAAO,OAAO;AACvB,aAAO,KAAKC,QAAO,EAAE;AAAA,IACvB,WAAW,OAAO,SAAS;AACzB,WAAKlB,OAAM,IAAI;AAEf,UAAI,CAAC,KAAKH,YAAW,KAAK,CAAC,KAAKkB,UAAS,EAAG;AAC5C,YAAMgB,OAAM,MAAM,KAAK,OAAO;AAC9B,WAAK,mBAAmB,OAAO;AAC/B,aAAOA;AAAA,IACT,WAAW,OAAO,SAAS;AACzB,WAAKhC,cAAa,IAAI;AACtB,YAAM,KAAKiB,QAAO,IAAI;AACtB,YAAMe,OACJ,CAAC,KAAKR,OAAM,KAAK,KAAK,UAAU,OAAO,EAAE,SACrC,MAAM,KAAK,SAAS,IAAI,IACxB;AACN,WAAK3B,eAAc,EAAE;AACrB,aAAOmC;AAAA,IACT,WAAW,OAAO,UAAU;AAC1B,YAAMA,OAAM,MAAM,KAAK,QAAQ;AAC/B,WAAKnC,eAAc,EAAE;AACrB,aAAOmC;AAAA,IACT,WAAW,OAAO,YAAY,OAAO,aAAa;AAChD,YAAMA,OAAM,MAAM,KAAK,EAAE;AACzB,WAAK,mBAAmB,EAAE;AAC1B,aAAOA;AAAA,IACT;AAGA,UAAM,MAAM,MAAM,KAAK,IAAI,MAAM,GAAG,KAAK;AACzC,SAAKnC,eAAc,EAAE;AACrB,WAAO;AAAA,EACT;AAAA,EAEA,CAACqB,SAAQ,EAAE,MAAM;AACf,eAAW,KAAK,KAAKP,MAAK,GAAG;AAC3B,UAAI,EAAE,KAAK,MAAM,IAAI,MAAM,MAAO,MAAK,MAAM;AAAA,IAC/C;AACA,UAAM,MAAM,MAAM,KAAK,QAAQ,IAAI;AACnC,SAAKd,eAAc,EAAE;AACrB,WAAO;AAAA,EACT;AAAA,EAEA,CAACsB,QAAO,IAAI;AACV,QAAI,KAAKrB,YAAW,EAAG;AAEvB,SAAKA,YAAW,IAAI;AACpB,SAAK,WAAW;AAChB,QAAI,KAAKuB,MAAK,EAAG,CAAAI,OAAM,MAAM,KAAKL,SAAQ,EAAE,CAAC;AAAA,QACxC,MAAKA,SAAQ,EAAE;AAAA,EACtB;AAAA,EAEA,CAACA,SAAQ,IAAI;AACX,QAAI,KAAKd,QAAO,GAAG;AACjB,YAAM,OAAO,KAAKA,QAAO,EAAE,IAAI;AAC/B,UAAI,MAAM;AACR,mBAAW,KAAK,KAAKK,MAAK,GAAG;AAC3B,YAAE,KAAK,MAAM,IAAI;AAAA,QACnB;AACA,cAAM,KAAK,QAAQ,IAAI;AAAA,MACzB;AAAA,IACF;AAEA,eAAW,KAAK,KAAKA,MAAK,GAAG;AAC3B,QAAE,IAAI;AAAA,IACR;AACA,UAAM,MAAM,MAAM,KAAK,KAAK;AAC5B,SAAK,mBAAmB,KAAK;AAC7B,WAAO;AAAA,EACT;AAAA;AAAA,EAGA,UAAU;AACR,UAAM,MAAM,CAAC;AACb,QAAI,CAAC,KAAKI,WAAU,EAAG,KAAI,aAAa;AAGxC,UAAM,IAAI,KAAK,QAAQ;AACvB,SAAK,GAAG,QAAQ,OAAK;AACnB,UAAI,KAAK,CAAC;AACV,UAAI,CAAC,KAAKA,WAAU,EAAG,KAAI,cAAc,EAAE;AAAA,IAC7C,CAAC;AACD,WAAO,EAAE,KAAK,MAAM,GAAG;AAAA,EACzB;AAAA;AAAA,EAGA,SAAS;AACP,WAAO,KAAKA,WAAU,IAClB,QAAQ,OAAO,IAAI,MAAM,6BAA6B,CAAC,IACvD,KAAK,QAAQ,EAAE;AAAA,MAAK,SAClB,KAAKA,WAAU,IACX,QAAQ,OAAO,IAAI,MAAM,6BAA6B,CAAC,IACvD,KAAKV,SAAQ,IACb,IAAI,KAAK,EAAE,IACX,OAAO,OAAO,KAAK,IAAI,UAAU;AAAA,IACvC;AAAA,EACN;AAAA;AAAA,EAGA,UAAU;AACR,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACtC,WAAK,GAAGW,YAAW,MAAM,OAAO,IAAI,MAAM,kBAAkB,CAAC,CAAC;AAC9D,WAAK,GAAG,SAAS,QAAM,OAAO,EAAE,CAAC;AACjC,WAAK,GAAG,OAAO,MAAM,QAAQ,CAAC;AAAA,IAChC,CAAC;AAAA,EACH;AAAA;AAAA,EAGA,CAAC,aAAa,IAAI;AAChB,QAAI,UAAU;AACd,UAAM,OAAO,MAAM;AACjB,WAAK,MAAM;AACX,gBAAU;AACV,aAAO,QAAQ,QAAQ,EAAE,MAAM,KAAK,CAAC;AAAA,IACvC;AACA,UAAM,OAAO,MAAM;AACjB,UAAI,QAAS,QAAO,KAAK;AACzB,YAAM,MAAM,KAAK,KAAK;AACtB,UAAI,QAAQ,KAAM,QAAO,QAAQ,QAAQ,EAAE,MAAM,OAAO,OAAO,IAAI,CAAC;AAEpE,UAAI,KAAKpB,IAAG,EAAG,QAAO,KAAK;AAE3B,UAAI,UAAU;AACd,UAAI,SAAS;AACb,YAAM,QAAQ,QAAM;AAClB,aAAK,eAAe,QAAQ,MAAM;AAClC,aAAK,eAAe,OAAO,KAAK;AAChC,aAAK,eAAeoB,YAAW,SAAS;AACxC,aAAK;AACL,eAAO,EAAE;AAAA,MACX;AACA,YAAM,SAAS,WAAS;AACtB,aAAK,eAAe,SAAS,KAAK;AAClC,aAAK,eAAe,OAAO,KAAK;AAChC,aAAK,eAAeA,YAAW,SAAS;AACxC,aAAK,MAAM;AACX,gBAAQ,EAAE,OAAc,MAAM,CAAC,CAAC,KAAKpB,IAAG,EAAE,CAAC;AAAA,MAC7C;AACA,YAAM,QAAQ,MAAM;AAClB,aAAK,eAAe,SAAS,KAAK;AAClC,aAAK,eAAe,QAAQ,MAAM;AAClC,aAAK,eAAeoB,YAAW,SAAS;AACxC,aAAK;AACL,gBAAQ,EAAE,MAAM,KAAK,CAAC;AAAA,MACxB;AACA,YAAM,YAAY,MAAM,MAAM,IAAI,MAAM,kBAAkB,CAAC;AAC3D,aAAO,IAAI,QAAQ,CAACiB,MAAK,QAAQ;AAC/B,iBAAS;AACT,kBAAUA;AACV,aAAK,KAAKjB,YAAW,SAAS;AAC9B,aAAK,KAAK,SAAS,KAAK;AACxB,aAAK,KAAK,OAAO,KAAK;AACtB,aAAK,KAAK,QAAQ,MAAM;AAAA,MAC1B,CAAC;AAAA,IACH;AAEA,WAAO;AAAA,MACL;AAAA,MACA,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,CAAC,aAAa,IAAI;AAChB,eAAO;AAAA,MACT;AAAA,IACF;AAAA,EACF;AAAA;AAAA,EAGA,CAAC,QAAQ,IAAI;AACX,QAAI,UAAU;AACd,UAAM,OAAO,MAAM;AACjB,WAAK,MAAM;AACX,WAAK,eAAeC,QAAO,IAAI;AAC/B,WAAK,eAAeD,YAAW,IAAI;AACnC,WAAK,eAAe,OAAO,IAAI;AAC/B,gBAAU;AACV,aAAO,EAAE,MAAM,KAAK;AAAA,IACtB;AAEA,UAAM,OAAO,MAAM;AACjB,UAAI,QAAS,QAAO,KAAK;AACzB,YAAM,QAAQ,KAAK,KAAK;AACxB,aAAO,UAAU,OAAO,KAAK,IAAI,EAAE,MAAM;AAAA,IAC3C;AACA,SAAK,KAAK,OAAO,IAAI;AACrB,SAAK,KAAKC,QAAO,IAAI;AACrB,SAAK,KAAKD,YAAW,IAAI;AAEzB,WAAO;AAAA,MACL;AAAA,MACA,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,CAAC,QAAQ,IAAI;AACX,eAAO;AAAA,MACT;AAAA,IACF;AAAA,EACF;AAAA,EAEA,QAAQ,IAAI;AACV,QAAI,KAAKA,UAAS,GAAG;AACnB,UAAI,GAAI,MAAK,KAAK,SAAS,EAAE;AAAA,UACxB,MAAK,KAAKA,UAAS;AACxB,aAAO;AAAA,IACT;AAEA,SAAKA,UAAS,IAAI;AAGlB,SAAKN,OAAM,EAAE,SAAS;AACtB,SAAKE,aAAY,IAAI;AAErB,QAAI,OAAO,KAAK,UAAU,cAAc,CAAC,KAAKX,OAAM,EAAG,MAAK,MAAM;AAElE,QAAI,GAAI,MAAK,KAAK,SAAS,EAAE;AAAA,QAExB,MAAK,KAAKe,UAAS;AAExB,WAAO;AAAA,EACT;AAAA,EAEA,OAAO,SAAS,GAAG;AACjB,WACE,CAAC,CAAC,MACD,aAAa,aACZ,aAAatB,WACZ,aAAa;AAAA,KAEX,OAAO,EAAE,SAAS;AAAA,IAEhB,OAAO,EAAE,UAAU,cAAc,OAAO,EAAE,QAAQ;AAAA,EAE7D;AACF;;;AC5qBA,IAAMwC,mBACJ,OAAO,YAAY,YACnB,WACA,OAAO,QAAQ,aAAa,WACxB,QAAQ,WACR;AAKA,IAAO,SAAP,MAAa;EACjB;EACA;EACA;EACA;EAEA,YACE,SACA,EACE,SACA,QACA,OACA,YACA,WAAWA,iBAAe,GACX;AAEjB,SAAK,WAAW,CAAA;AAChB,SAAK,WAAW,CAAA;AAChB,SAAK,mBAAmB,CAAA;AACxB,SAAK,mBAAmB,CAAA;AACxB,UAAM,SAAS;MACb,KAAK;MACL;MACA;MACA;MACA;MACA,mBAAmB;MACnB;MACA,WAAW;MACX,UAAU;;AAeZ,eAAW,OAAO,SAAS;AACzB,YAAM,KAAK,IAAI,UAAU,KAAK,MAAM;AACpC,eAAS,IAAI,GAAG,IAAI,GAAG,IAAI,QAAQ,KAAK;AACtC,cAAM,SAAS,GAAG,IAAI,CAAC;AACvB,cAAM,YAAY,GAAG,UAAU,CAAC;AAChC,cAAM,IAAI,IAAI,QAAQ,QAAQ,WAAW,GAAG,QAAQ;AACpD,cAAM,IAAI,IAAI,UAAU,EAAE,WAAU,GAAI,MAAM;AAC9C,cAAM,WAAW,UAAU,UAAU,SAAS,CAAC,MAAM;AACrD,cAAM,WAAW,EAAE,WAAU;AAC7B,YAAI;AAAU,eAAK,SAAS,KAAK,CAAC;;AAC7B,eAAK,SAAS,KAAK,CAAC;AACzB,YAAI,UAAU;AACZ,cAAI;AAAU,iBAAK,iBAAiB,KAAK,CAAC;;AACrC,iBAAK,iBAAiB,KAAK,CAAC;;;;EAIzC;EAEA,QAAQ,GAAO;AACb,UAAM,WAAW,EAAE,SAAQ;AAC3B,UAAM,YAAY,GAAG,QAAQ;AAC7B,UAAM,WAAW,EAAE,SAAQ,KAAM;AACjC,UAAM,YAAY,GAAG,QAAQ;AAC7B,eAAW,KAAK,KAAK,UAAU;AAC7B,UAAI,EAAE,MAAM,QAAQ,KAAK,EAAE,MAAM,SAAS;AAAG,eAAO;;AAEtD,eAAW,KAAK,KAAK,UAAU;AAC7B,UAAI,EAAE,MAAM,QAAQ,KAAK,EAAE,MAAM,SAAS;AAAG,eAAO;;AAEtD,WAAO;EACT;EAEA,gBAAgB,GAAO;AACrB,UAAM,WAAW,EAAE,SAAQ,IAAK;AAChC,UAAM,YAAY,EAAE,SAAQ,KAAM,OAAO;AACzC,eAAW,KAAK,KAAK,kBAAkB;AACrC,UAAI,EAAE,MAAM,QAAQ;AAAG,eAAO;;AAEhC,eAAW,KAAK,KAAK,kBAAkB;AACrC,UAAI,EAAE,MAAM,QAAQ;AAAG;;AAEzB,WAAO;EACT;;;;ACtGI,IAAO,iBAAP,MAAO,gBAAc;EACzB;EACA,YAAY,QAAkC,oBAAI,IAAG,GAAE;AACrD,SAAK,QAAQ;EACf;EACA,OAAI;AACF,WAAO,IAAI,gBAAe,IAAI,IAAI,KAAK,KAAK,CAAC;EAC/C;EACA,UAAU,QAAc,SAAgB;AACtC,WAAO,KAAK,MAAM,IAAI,OAAO,SAAQ,CAAE,GAAG,IAAI,QAAQ,WAAU,CAAE;EACpE;EACA,YAAY,QAAc,SAAgB;AACxC,UAAM,WAAW,OAAO,SAAQ;AAChC,UAAM,SAAS,KAAK,MAAM,IAAI,QAAQ;AACtC,QAAI;AAAQ,aAAO,IAAI,QAAQ,WAAU,CAAE;;AACtC,WAAK,MAAM,IAAI,UAAU,oBAAI,IAAI,CAAC,QAAQ,WAAU,CAAE,CAAC,CAAC;EAC/D;;AAQI,IAAO,cAAP,MAAkB;EACtB,QAA2B,oBAAI,IAAG;EAClC,IAAI,QAAc,UAAmB,OAAc;AACjD,UAAM,KAAK,WAAW,IAAI,MAAM,QAAQ,IAAI;AAC5C,UAAM,UAAU,KAAK,MAAM,IAAI,MAAM;AACrC,SAAK,MAAM,IAAI,QAAQ,YAAY,SAAY,IAAI,IAAI,OAAO;EAChE;;EAEA,UAAO;AACL,WAAO,CAAC,GAAG,KAAK,MAAM,QAAO,CAAE,EAAE,IAAI,CAAC,CAACC,QAAM,CAAC,MAAM;MAClDA;MACA,CAAC,EAAE,IAAI;MACP,CAAC,EAAE,IAAI;KACR;EACH;;AAOI,IAAO,WAAP,MAAe;EACnB,QAA8B,oBAAI,IAAG;EACrC,IAAI,QAAc,SAAgB;AAChC,QAAI,CAAC,OAAO,WAAU,GAAI;AACxB;;AAEF,UAAM,OAAO,KAAK,MAAM,IAAI,MAAM;AAClC,QAAI,MAAM;AACR,UAAI,CAAC,KAAK,KAAK,OAAK,EAAE,WAAU,MAAO,QAAQ,WAAU,CAAE,GAAG;AAC5D,aAAK,KAAK,OAAO;;;AAEd,WAAK,MAAM,IAAI,QAAQ,CAAC,OAAO,CAAC;EACzC;EACA,IAAI,QAAY;AACd,UAAM,OAAO,KAAK,MAAM,IAAI,MAAM;AAElC,QAAI,CAAC,MAAM;AACT,YAAM,IAAI,MAAM,iCAAiC;;AAGnD,WAAO;EACT;EACA,UAAO;AACL,WAAO,KAAK,KAAI,EAAG,IAAI,OAAK,CAAC,GAAG,KAAK,MAAM,IAAI,CAAC,CAAc,CAAC;EACjE;EACA,OAAI;AACF,WAAO,CAAC,GAAG,KAAK,MAAM,KAAI,CAAE,EAAE,OAAO,OAAK,EAAE,WAAU,CAAE;EAC1D;;AASI,IAAO,YAAP,MAAO,WAAS;EACpB;EACA,UAAU,IAAI,YAAW;EACzB,WAAW,IAAI,SAAQ;EACvB;EACA;EACA;EACA;EAEA,YAAY,MAAsB,gBAA+B;AAC/D,SAAK,OAAO;AACZ,SAAK,SAAS,CAAC,CAAC,KAAK;AACrB,SAAK,MAAM,CAAC,CAAC,KAAK;AAClB,SAAK,iBAAiB,iBAClB,eAAe,KAAI,IACnB,IAAI,eAAc;EACxB;EAEA,gBAAgB,QAAc,UAAmB;AAC/C,SAAK,WAAW;AAChB,UAAM,gBAAmC,SAAS,IAAI,OAAK,CAAC,QAAQ,CAAC,CAAC;AAKtE,aAAS,CAAC,GAAG,OAAO,KAAK,eAAe;AACtC,WAAK,eAAe,YAAY,GAAG,OAAO;AAE1C,YAAM,OAAO,QAAQ,KAAI;AACzB,YAAM,WAAW,QAAQ,WAAU,KAAM,KAAK,KAAK,aAAa;AAGhE,UAAI,MAAM;AACR,YAAI,EAAE,QACJ,SAAS,OAAO,KAAK,KAAK,SAAS,SAC/B,KAAK,KAAK,OACV,IAAI;AAEV,cAAMC,QAAO,QAAQ,KAAI;AACzB,YAAI,CAACA,OAAM;AACT,eAAK,QAAQ,IAAI,GAAG,MAAM,KAAK;AAC/B;eACK;AACL,oBAAUA;;;AAId,UAAI,EAAE,SAAQ;AAAI;AAElB,UAAI;AACJ,UAAI;AACJ,UAAI,UAAU;AACd,aACE,QAAQ,IAAI,QAAQ,QAAO,OAAQ,aAClC,OAAO,QAAQ,KAAI,IACpB;AACA,cAAM,IAAI,EAAE,QAAQ,CAAC;AAErB,YAAI,EAAE,UAAS,KAAM,MAAM;AAAM;AACjC,YAAI;AACJ,kBAAU;AACV,kBAAU;;AAEZ,UAAI,QAAQ,QAAO;AACnB,aAAO,QAAQ,KAAI;AACnB,UAAI,SAAS;AACX,YAAI,KAAK,eAAe,UAAU,GAAG,OAAO;AAAG;AAC/C,aAAK,eAAe,YAAY,GAAG,OAAO;;AAM5C,UAAI,OAAO,MAAM,UAAU;AAEzB,YAAI,CAAC,MAAM;AACT,gBAAM,QAAQ,MAAM,QAAQ,MAAM,MAAM,MAAM;AAC9C,eAAK,QAAQ,IAAI,EAAE,QAAQ,CAAC,GAAG,UAAU,KAAK;eACzC;AACL,eAAK,SAAS,IAAI,GAAG,OAAO;;AAE9B;iBACS,MAAM,UAAU;AAMzB,YACE,CAAC,EAAE,eAAc,KACjB,KAAK,UACL,QAAQ,oBAAmB,GAC3B;AACA,eAAK,SAAS,IAAI,GAAG,OAAO;;AAE9B,cAAM,KAAK,MAAM,QAAO;AACxB,cAAM,QAAQ,MAAM,KAAI;AACxB,YAAI,CAAC,SAAU,OAAO,MAAM,OAAO,QAAQ,CAAC,OAAQ;AAGlD,eAAK,QAAQ,IAAI,GAAG,UAAU,OAAO,MAAM,OAAO,GAAG;eAChD;AACL,cAAI,OAAO,MAAM;AAIf,kBAAM,KAAK,EAAE,UAAU;AAEvB,gBAAI,CAAC;AAAO,mBAAK,QAAQ,IAAI,IAAI,UAAU,IAAI;qBACtC,CAAC,KAAK,eAAe,UAAU,IAAI,KAAK,GAAG;AAClD,mBAAK,SAAS,IAAI,IAAI,KAAK;;;;iBAIxB,aAAa,QAAQ;AAC9B,aAAK,SAAS,IAAI,GAAG,OAAO;;;AAIhC,WAAO;EACT;EAEA,iBAAc;AACZ,WAAO,KAAK,SAAS,KAAI;EAC3B;EAEA,QAAK;AACH,WAAO,IAAI,WAAU,KAAK,MAAM,KAAK,cAAc;EACrD;;;;;EAMA,cAAc,QAAc,SAAe;AACzC,UAAM,WAAW,KAAK,SAAS,IAAI,MAAM;AAEzC,UAAM,UAAU,KAAK,MAAK;AAC1B,eAAW,KAAK,SAAS;AACvB,iBAAW,WAAW,UAAU;AAC9B,cAAM,WAAW,QAAQ,WAAU;AACnC,cAAM,IAAI,QAAQ,QAAO;AACzB,cAAM,OAAO,QAAQ,KAAI;AACzB,YAAI,MAAM,UAAU;AAClB,kBAAQ,aAAa,GAAG,SAAS,MAAM,QAAQ;mBACtC,aAAa,QAAQ;AAC9B,kBAAQ,WAAW,GAAG,GAAG,MAAM,QAAQ;eAClC;AACL,kBAAQ,WAAW,GAAG,GAAG,MAAM,QAAQ;;;;AAI7C,WAAO;EACT;EAEA,aACE,GACA,SACA,MACA,UAAiB;AAEjB,QAAI,KAAK,OAAO,CAAC,EAAE,KAAK,WAAW,GAAG,GAAG;AACvC,UAAI,CAAC,QAAQ,QAAO,GAAI;AACtB,aAAK,QAAQ,IAAI,GAAG,UAAU,KAAK;;AAErC,UAAI,EAAE,WAAU,GAAI;AAMlB,YAAI,KAAK,UAAU,CAAC,EAAE,eAAc,GAAI;AACtC,eAAK,SAAS,IAAI,GAAG,OAAO;mBACnB,EAAE,eAAc,GAAI;AAC7B,cAAI,QAAQ,QAAQ,oBAAmB,GAAI;AACzC,iBAAK,SAAS,IAAI,GAAG,IAAI;qBAChB,QAAQ,mBAAkB,GAAI;AACvC,iBAAK,SAAS,IAAI,GAAG,OAAO;;;;;AAOpC,QAAI,MAAM;AACR,YAAM,KAAK,KAAK,QAAO;AACvB,UACE,OAAO,OAAO;MAEd,OAAO,QACP,OAAO,MACP,OAAO,KACP;AACA,aAAK,WAAW,GAAG,IAAI,KAAK,KAAI,GAAI,QAAQ;iBACnC,OAAO,MAAM;AAEtB,cAAM,KAAK,EAAE,UAAU;AAEvB,aAAK,SAAS,IAAI,IAAI,IAAI;iBACjB,cAAc,QAAQ;AAC/B,aAAK,WAAW,GAAG,IAAI,KAAK,KAAI,GAAI,QAAQ;;;EAGlD;EAEA,WACE,GACA,GACA,MACA,UAAiB;AAEjB,QAAI,CAAC,EAAE,KAAK,EAAE,IAAI;AAAG;AACrB,QAAI,CAAC,MAAM;AACT,WAAK,QAAQ,IAAI,GAAG,UAAU,KAAK;WAC9B;AACL,WAAK,SAAS,IAAI,GAAG,IAAI;;EAE7B;EAEA,WAAW,GAAS,GAAW,MAAsB,UAAiB;AAEpE,QAAI,CAAC,EAAE,QAAQ,CAAC;AAAG;AACnB,QAAI,CAAC,MAAM;AACT,WAAK,QAAQ,IAAI,GAAG,UAAU,KAAK;WAC9B;AACL,WAAK,SAAS,IAAI,GAAG,IAAI;;EAE7B;;;;AC7OF,IAAM,aAAa,CACjBC,SACA,SAEA,OAAOA,YAAW,WACd,IAAI,OAAO,CAACA,OAAM,GAAG,IAAI,IACzB,MAAM,QAAQA,OAAM,IACpB,IAAI,OAAOA,SAAQ,IAAI,IACvBA;AAKA,IAAgB,WAAhB,MAAwB;EAC5B;EACA;EACA;EACA,OAAkB,oBAAI,IAAG;EACzB,SAAkB;EAClB,UAAmB;EACnB,YAA2B,CAAA;EAC3B;EACA;EACA;EACA;EAGA,YAAY,UAAqBC,QAAY,MAAO;AAClD,SAAK,WAAW;AAChB,SAAK,OAAOA;AACZ,SAAK,OAAO;AACZ,SAAK,OAAO,CAAC,KAAK,SAAS,KAAK,aAAa,UAAU,OAAO;AAC9D,QAAI,KAAK,QAAQ;AACf,WAAK,UAAU,WAAW,KAAK,QAAQ,IAAI;;AAK7C,SAAK,WAAW,KAAK,YAAY;AAEjC,QAAI,KAAK,QAAQ;AACf,WAAK,SAAS,KAAK;AACnB,WAAK,OAAO,iBAAiB,SAAS,MAAK;AACzC,aAAK,UAAU,SAAS;MAC1B,CAAC;;EAEL;EAEA,SAASA,QAAU;AACjB,WAAO,KAAK,KAAK,IAAIA,MAAI,KAAK,CAAC,CAAC,KAAK,SAAS,UAAUA,MAAI;EAC9D;EACA,iBAAiBA,QAAU;AACzB,WAAO,CAAC,CAAC,KAAK,SAAS,kBAAkBA,MAAI;EAC/C;;EAGA,QAAK;AACH,SAAK,SAAS;EAChB;EACA,SAAM;AAEJ,QAAI,KAAK,QAAQ;AAAS;AAE1B,SAAK,SAAS;AACd,QAAI,KAA8B;AAClC,WAAO,CAAC,KAAK,WAAW,KAAK,KAAK,UAAU,MAAK,IAAK;AACpD,SAAE;;EAEN;EACA,SAAS,IAAa;AACpB,QAAI,KAAK,QAAQ;AAAS;AAE1B,QAAI,CAAC,KAAK,QAAQ;AAChB,SAAE;WACG;AAEL,WAAK,UAAU,KAAK,EAAE;;EAE1B;;;EAIA,MAAM,WAAW,GAAS,OAAc;AACtC,QAAI,SAAS,KAAK,KAAK;AAAO,aAAO;AACrC,QAAI;AACJ,QAAI,KAAK,KAAK,UAAU;AACtB,YAAM,EAAE,eAAc,KAAO,MAAM,EAAE,SAAQ;AAC7C,UAAI,CAAC;AAAK,eAAO;AACjB,UAAI;;AAEN,UAAM,WAAW,EAAE,UAAS,KAAM,KAAK,KAAK;AAC5C,WAAO,KAAK,eAAe,WAAW,MAAM,EAAE,MAAK,IAAK,GAAG,KAAK;EAClE;EAEA,eAAe,GAAqB,OAAc;AAChD,WAAO,MACJ,KAAK,aAAa,YAAY,EAAE,MAAK,KAAM,KAAK,cAChD,CAAC,SAAS,EAAE,WAAU,OACtB,CAAC,KAAK,KAAK,SAAS,CAAC,EAAE,YAAW,MACnC,CAAC,KAAK,SAAS,CAAC,IACd,IACA;EACN;EAEA,eAAe,GAAS,OAAc;AACpC,QAAI,SAAS,KAAK,KAAK;AAAO,aAAO;AACrC,QAAI;AACJ,QAAI,KAAK,KAAK,UAAU;AACtB,YAAM,EAAE,eAAc,KAAM,EAAE,aAAY;AAC1C,UAAI,CAAC;AAAK,eAAO;AACjB,UAAI;;AAEN,UAAM,WAAW,EAAE,UAAS,KAAM,KAAK,KAAK;AAC5C,WAAO,KAAK,eAAe,WAAW,EAAE,UAAS,IAAK,GAAG,KAAK;EAChE;EAKA,YAAY,GAAS,UAAiB;AACpC,QAAI,KAAK,SAAS,CAAC;AAAG;AACtB,UAAM,MACJ,KAAK,KAAK,aAAa,SAAY,WAAW,KAAK,KAAK;AAC1D,SAAK,KAAK,IAAI,CAAC;AACf,UAAM,OAAO,KAAK,KAAK,QAAQ,EAAE,YAAW,IAAK,KAAK,OAAO;AAE7D,QAAI,KAAK,KAAK,eAAe;AAC3B,WAAK,UAAU,CAAC;eACP,KAAK;AACd,YAAMC,OAAM,KAAK,KAAK,QAAQ,EAAE,cAAa,IAAK,EAAE,SAAQ;AAC5D,WAAK,UAAUA,OAAM,IAAI;WACpB;AACL,YAAM,MAAM,KAAK,KAAK,QAAQ,EAAE,cAAa,IAAK,EAAE,SAAQ;AAC5D,YAAM,MACJ,KAAK,KAAK,eAAe,CAAC,IAAI,WAAW,OAAO,KAAK,IAAI,IACrD,MAAM,KAAK,OACX;AACN,WAAK,UAAU,CAAC,MAAM,MAAM,OAAO,MAAM,MAAM,IAAI;;EAEvD;EAEA,MAAM,MAAM,GAAS,UAAmB,OAAc;AACpD,UAAM,IAAI,MAAM,KAAK,WAAW,GAAG,KAAK;AACxC,QAAI;AAAG,WAAK,YAAY,GAAG,QAAQ;EACrC;EAEA,UAAU,GAAS,UAAmB,OAAc;AAClD,UAAM,IAAI,KAAK,eAAe,GAAG,KAAK;AACtC,QAAI;AAAG,WAAK,YAAY,GAAG,QAAQ;EACrC;EAEA,OAAO,QAAc,UAAqB,IAAa;AAErD,QAAI,KAAK,QAAQ;AAAS,SAAE;AAE5B,SAAK,QAAQ,QAAQ,UAAU,IAAI,UAAU,KAAK,IAAI,GAAG,EAAE;EAC7D;EAEA,QACE,QACA,UACA,WACA,IAAa;AAEb,QAAI,KAAK,iBAAiB,MAAM;AAAG,aAAO,GAAE;AAC5C,QAAI,KAAK,QAAQ;AAAS,SAAE;AAC5B,QAAI,KAAK,QAAQ;AACf,WAAK,SAAS,MAAM,KAAK,QAAQ,QAAQ,UAAU,WAAW,EAAE,CAAC;AACjE;;AAEF,cAAU,gBAAgB,QAAQ,QAAQ;AAK1C,QAAI,QAAQ;AACZ,UAAM,OAAO,MAAK;AAChB,UAAI,EAAE,UAAU;AAAG,WAAE;IACvB;AAEA,eAAW,CAAC,GAAG,UAAU,KAAK,KAAK,UAAU,QAAQ,QAAO,GAAI;AAC9D,UAAI,KAAK,SAAS,CAAC;AAAG;AACtB;AACA,WAAK,MAAM,GAAG,UAAU,KAAK,EAAE,KAAK,MAAM,KAAI,CAAE;;AAGlD,eAAW,KAAK,UAAU,eAAc,GAAI;AAC1C,UAAI,KAAK,aAAa,YAAY,EAAE,MAAK,KAAM,KAAK,UAAU;AAC5D;;AAEF;AACA,YAAM,iBAAiB,EAAE,cAAa;AACtC,UAAI,EAAE,cAAa;AACjB,aAAK,QAAQ,GAAG,gBAAgB,WAAW,IAAI;WAC5C;AACH,UAAE,UACA,CAAC,GAAG,YAAY,KAAK,QAAQ,GAAG,SAAS,WAAW,IAAI,GACxD,IAAI;;;AAKV,SAAI;EACN;EAEA,QACE,QACA,SACA,WACA,IAAa;AAEb,gBAAY,UAAU,cAAc,QAAQ,OAAO;AAEnD,QAAI,QAAQ;AACZ,UAAM,OAAO,MAAK;AAChB,UAAI,EAAE,UAAU;AAAG,WAAE;IACvB;AAEA,eAAW,CAAC,GAAG,UAAU,KAAK,KAAK,UAAU,QAAQ,QAAO,GAAI;AAC9D,UAAI,KAAK,SAAS,CAAC;AAAG;AACtB;AACA,WAAK,MAAM,GAAG,UAAU,KAAK,EAAE,KAAK,MAAM,KAAI,CAAE;;AAElD,eAAW,CAACC,SAAQ,QAAQ,KAAK,UAAU,SAAS,QAAO,GAAI;AAC7D;AACA,WAAK,QAAQA,SAAQ,UAAU,UAAU,MAAK,GAAI,IAAI;;AAGxD,SAAI;EACN;EAEA,WAAW,QAAc,UAAqB,IAAa;AAEzD,QAAI,KAAK,QAAQ;AAAS,SAAE;AAE5B,SAAK,YAAY,QAAQ,UAAU,IAAI,UAAU,KAAK,IAAI,GAAG,EAAE;EACjE;EAEA,YACE,QACA,UACA,WACA,IAAa;AAEb,QAAI,KAAK,iBAAiB,MAAM;AAAG,aAAO,GAAE;AAC5C,QAAI,KAAK,QAAQ;AAAS,SAAE;AAC5B,QAAI,KAAK,QAAQ;AACf,WAAK,SAAS,MACZ,KAAK,YAAY,QAAQ,UAAU,WAAW,EAAE,CAAC;AAEnD;;AAEF,cAAU,gBAAgB,QAAQ,QAAQ;AAK1C,QAAI,QAAQ;AACZ,UAAM,OAAO,MAAK;AAChB,UAAI,EAAE,UAAU;AAAG,WAAE;IACvB;AAEA,eAAW,CAAC,GAAG,UAAU,KAAK,KAAK,UAAU,QAAQ,QAAO,GAAI;AAC9D,UAAI,KAAK,SAAS,CAAC;AAAG;AACtB,WAAK,UAAU,GAAG,UAAU,KAAK;;AAGnC,eAAW,KAAK,UAAU,eAAc,GAAI;AAC1C,UAAI,KAAK,aAAa,YAAY,EAAE,MAAK,KAAM,KAAK,UAAU;AAC5D;;AAEF;AACA,YAAM,WAAW,EAAE,YAAW;AAC9B,WAAK,YAAY,GAAG,UAAU,WAAW,IAAI;;AAG/C,SAAI;EACN;EAEA,YACE,QACA,SACA,WACA,IAAa;AAEb,gBAAY,UAAU,cAAc,QAAQ,OAAO;AAEnD,QAAI,QAAQ;AACZ,UAAM,OAAO,MAAK;AAChB,UAAI,EAAE,UAAU;AAAG,WAAE;IACvB;AAEA,eAAW,CAAC,GAAG,UAAU,KAAK,KAAK,UAAU,QAAQ,QAAO,GAAI;AAC9D,UAAI,KAAK,SAAS,CAAC;AAAG;AACtB,WAAK,UAAU,GAAG,UAAU,KAAK;;AAEnC,eAAW,CAACA,SAAQ,QAAQ,KAAK,UAAU,SAAS,QAAO,GAAI;AAC7D;AACA,WAAK,YAAYA,SAAQ,UAAU,UAAU,MAAK,GAAI,IAAI;;AAG5D,SAAI;EACN;;AAGI,IAAO,aAAP,cAEI,SAAW;EACnB;EAQA,YAAY,UAAqBF,QAAY,MAAO;AAClD,UAAM,UAAUA,QAAM,IAAI;AAC1B,SAAK,UAAU,oBAAI,IAAG;EACxB;EAGA,UAAU,GAAgB;AACxB,SAAK,QAAQ,IAAI,CAAC;EACpB;EAEA,MAAM,OAAI;AACR,QAAI,KAAK,QAAQ;AAAS,YAAM,KAAK,OAAO;AAC5C,QAAI,KAAK,KAAK,UAAS,GAAI;AACzB,YAAM,KAAK,KAAK,MAAK;;AAEvB,UAAM,IAAI,QAAQ,CAAC,KAAK,QAAO;AAC7B,WAAK,OAAO,KAAK,MAAM,KAAK,UAAU,MAAK;AACzC,YAAI,KAAK,QAAQ,SAAS;AACxB,cAAI,KAAK,OAAO,MAAM;eACjB;AACL,cAAI,KAAK,OAAO;;MAEpB,CAAC;IACH,CAAC;AACD,WAAO,KAAK;EACd;EAEA,WAAQ;AACN,QAAI,KAAK,QAAQ;AAAS,YAAM,KAAK,OAAO;AAC5C,QAAI,KAAK,KAAK,UAAS,GAAI;AACzB,WAAK,KAAK,UAAS;;AAGrB,SAAK,WAAW,KAAK,MAAM,KAAK,UAAU,MAAK;AAC7C,UAAI,KAAK,QAAQ;AAAS,cAAM,KAAK,OAAO;IAC9C,CAAC;AACD,WAAO,KAAK;EACd;;AAGI,IAAO,aAAP,cAEI,SAAW;EACnB;EAQA,YAAY,UAAqBA,QAAY,MAAO;AAClD,UAAM,UAAUA,QAAM,IAAI;AAC1B,SAAK,UAAU,IAAIG,UAAS;MAC1B,QAAQ,KAAK;MACb,YAAY;KACb;AACD,SAAK,QAAQ,GAAG,SAAS,MAAM,KAAK,OAAM,CAAE;AAC5C,SAAK,QAAQ,GAAG,UAAU,MAAM,KAAK,OAAM,CAAE;EAC/C;EAGA,UAAU,GAAgB;AACxB,SAAK,QAAQ,MAAM,CAAC;AACpB,QAAI,CAAC,KAAK,QAAQ;AAAS,WAAK,MAAK;EACvC;EAEA,SAAM;AACJ,UAAM,SAAS,KAAK;AACpB,QAAI,OAAO,UAAS,GAAI;AACtB,aAAO,MAAK,EAAG,KAAK,MAAK;AACvB,aAAK,OAAO,QAAQ,KAAK,UAAU,MAAM,KAAK,QAAQ,IAAG,CAAE;MAC7D,CAAC;WACI;AACL,WAAK,OAAO,QAAQ,KAAK,UAAU,MAAM,KAAK,QAAQ,IAAG,CAAE;;AAE7D,WAAO,KAAK;EACd;EAEA,aAAU;AACR,QAAI,KAAK,KAAK,UAAS,GAAI;AACzB,WAAK,KAAK,UAAS;;AAErB,SAAK,WAAW,KAAK,MAAM,KAAK,UAAU,MAAM,KAAK,QAAQ,IAAG,CAAE;AAClE,WAAO,KAAK;EACd;;;;AL9cF,IAAMC,mBACJ,OAAO,YAAY,YACnB,WACA,OAAO,QAAQ,aAAa,WACxB,QAAQ,WACR;AAmTA,IAAO,OAAP,MAAW;EACf;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;;;;EAKA;;;;EAKA;;;;;;;;;;;;;EAcA,YAAY,SAA4B,MAAU;AAChD,SAAK,gBAAgB,CAAC,CAAC,KAAK;AAC5B,SAAK,SAAS,KAAK;AACnB,SAAK,SAAS,CAAC,CAAC,KAAK;AACrB,SAAK,MAAM,CAAC,CAAC,KAAK;AAClB,SAAK,cAAc,CAAC,CAAC,KAAK;AAC1B,SAAK,QAAQ,CAAC,CAAC,KAAK;AACpB,SAAK,OAAO,CAAC,CAAC,KAAK;AACnB,QAAI,CAAC,KAAK,KAAK;AACb,WAAK,MAAM;eACF,KAAK,eAAe,OAAO,KAAK,IAAI,WAAW,SAAS,GAAG;AACpE,WAAK,MAAMC,eAAc,KAAK,GAAG;;AAEnC,SAAK,MAAM,KAAK,OAAO;AACvB,SAAK,OAAO,KAAK;AACjB,SAAK,gBAAgB,CAAC,CAAC,KAAK;AAC5B,SAAK,UAAU,CAAC,CAAC,KAAK;AACtB,SAAK,QAAQ,CAAC,CAAC,KAAK;AACpB,SAAK,WAAW,CAAC,CAAC,KAAK;AACvB,SAAK,WAAW,KAAK;AAErB,SAAK,aAAa,CAAC,CAAC,KAAK;AACzB,SAAK,YAAY,CAAC,CAAC,KAAK;AACxB,SAAK,WACH,OAAO,KAAK,aAAa,WAAW,KAAK,WAAW;AACtD,SAAK,OAAO,CAAC,CAAC,KAAK;AACnB,SAAK,SAAS,KAAK;AAEnB,QAAI,KAAK,iBAAiB,KAAK,aAAa,QAAW;AACrD,YAAM,IAAI,MAAM,4CAA4C;;AAG9D,QAAI,OAAO,YAAY,UAAU;AAC/B,gBAAU,CAAC,OAAO;;AAGpB,SAAK,uBACH,CAAC,CAAC,KAAK,wBACN,KAAqB,uBAAuB;AAE/C,QAAI,KAAK,sBAAsB;AAC7B,gBAAU,QAAQ,IAAI,OAAK,EAAE,QAAQ,OAAO,GAAG,CAAC;;AAGlD,QAAI,KAAK,WAAW;AAClB,UAAI,KAAK,YAAY;AACnB,cAAM,IAAI,UAAU,iCAAiC;;AAEvD,gBAAU,QAAQ,IAAI,OAAM,EAAE,SAAS,GAAG,IAAI,IAAI,QAAQ,CAAC,EAAG;;AAGhE,SAAK,UAAU;AAEf,SAAK,WAAW,KAAK,YAAYD;AACjC,SAAK,OAAO,EAAE,GAAG,MAAM,UAAU,KAAK,SAAQ;AAC9C,QAAI,KAAK,QAAQ;AACf,WAAK,SAAS,KAAK;AACnB,UACE,KAAK,WAAW,UAChB,KAAK,WAAW,KAAK,OAAO,QAC5B;AACA,cAAM,IAAI,MAAM,kDAAkD;;WAE/D;AACL,YAAM,SACJ,KAAK,aAAa,UACd,kBACA,KAAK,aAAa,WAClB,mBACA,KAAK,WACL,kBACA;AACN,WAAK,SAAS,IAAI,OAAO,KAAK,KAAK;QACjC,QAAQ,KAAK;QACb,IAAI,KAAK;OACV;;AAEH,SAAK,SAAS,KAAK,OAAO;AAM1B,UAAM,kBACJ,KAAK,aAAa,YAAY,KAAK,aAAa;AAElD,UAAM,MAAwB;;MAE5B,GAAG;MACH,KAAK,KAAK;MACV,WAAW,KAAK;MAChB,SAAS,KAAK;MACd,QAAQ,KAAK;MACb;MACA,WAAW;MACX,OAAO,KAAK;MACZ,UAAU;MACV,mBAAmB;MACnB,UAAU,KAAK;MACf,sBAAsB,KAAK;MAC3B,OAAO,CAAC,CAAC,KAAK,KAAK;;AAGrB,UAAM,MAAM,KAAK,QAAQ,IAAI,OAAK,IAAI,UAAU,GAAG,GAAG,CAAC;AACvD,UAAM,CAAC,UAAU,SAAS,IAAI,IAAI,OAChC,CAAC,KAA4B,MAAK;AAChC,UAAI,CAAC,EAAE,KAAK,GAAG,EAAE,GAAG;AACpB,UAAI,CAAC,EAAE,KAAK,GAAG,EAAE,SAAS;AAC1B,aAAO;IACT,GACA,CAAC,CAAA,GAAI,CAAA,CAAE,CAAC;AAEV,SAAK,WAAW,SAAS,IAAI,CAAC,KAAK,MAAK;AACtC,aAAO,IAAI,QAAQ,KAAK,UAAU,CAAC,GAAG,GAAG,KAAK,QAAQ;IACxD,CAAC;EACH;EAMA,MAAM,OAAI;AAKR,WAAO;MACL,GAAI,MAAM,IAAI,WAAW,KAAK,UAAU,KAAK,OAAO,KAAK;QACvD,GAAG,KAAK;QACR,UACE,KAAK,aAAa,WACd,KAAK,WAAW,KAAK,OAAO,IAAI,MAAK,IACrC;QACN,UAAU,KAAK;QACf,QAAQ,KAAK;OACd,EAAE,KAAI;;EAEX;EAMA,WAAQ;AACN,WAAO;MACL,GAAG,IAAI,WAAW,KAAK,UAAU,KAAK,OAAO,KAAK;QAChD,GAAG,KAAK;QACR,UACE,KAAK,aAAa,WACd,KAAK,WAAW,KAAK,OAAO,IAAI,MAAK,IACrC;QACN,UAAU,KAAK;QACf,QAAQ,KAAK;OACd,EAAE,SAAQ;;EAEf;EAMA,SAAM;AACJ,WAAO,IAAI,WAAW,KAAK,UAAU,KAAK,OAAO,KAAK;MACpD,GAAG,KAAK;MACR,UACE,KAAK,aAAa,WACd,KAAK,WAAW,KAAK,OAAO,IAAI,MAAK,IACrC;MACN,UAAU,KAAK;MACf,QAAQ,KAAK;KACd,EAAE,OAAM;EACX;EAMA,aAAU;AACR,WAAO,IAAI,WAAW,KAAK,UAAU,KAAK,OAAO,KAAK;MACpD,GAAG,KAAK;MACR,UACE,KAAK,aAAa,WACd,KAAK,WAAW,KAAK,OAAO,IAAI,MAAK,IACrC;MACN,UAAU,KAAK;MACf,QAAQ,KAAK;KACd,EAAE,WAAU;EACf;;;;;EAMA,cAAW;AACT,WAAO,KAAK,WAAU,EAAG,OAAO,QAAQ,EAAC;EAC3C;EACA,CAAC,OAAO,QAAQ,IAAC;AACf,WAAO,KAAK,YAAW;EACzB;;;;;EAMA,UAAO;AACL,WAAO,KAAK,OAAM,EAAG,OAAO,aAAa,EAAC;EAC5C;EACA,CAAC,OAAO,aAAa,IAAC;AACpB,WAAO,KAAK,QAAO;EACrB;;;;AM/jBK,IAAM,WAAW,CACtB,SACA,UAAuB,CAAA,MACZ;AACX,MAAI,CAAC,MAAM,QAAQ,OAAO,GAAG;AAC3B,cAAU,CAAC,OAAO;;AAEpB,aAAW,KAAK,SAAS;AACvB,QAAI,IAAI,UAAU,GAAG,OAAO,EAAE,SAAQ;AAAI,aAAO;;AAEnD,SAAO;AACT;;;ACQM,SAAU,eACd,SACA,UAAuB,CAAA,GAAE;AAEzB,SAAO,IAAI,KAAK,SAAS,OAAO,EAAE,WAAU;AAC9C;AAsBM,SAAU,WACd,SACA,UAAuB,CAAA,GAAE;AAEzB,SAAO,IAAI,KAAK,SAAS,OAAO,EAAE,OAAM;AAC1C;AAqBM,SAAU,SACd,SACA,UAAuB,CAAA,GAAE;AAEzB,SAAO,IAAI,KAAK,SAAS,OAAO,EAAE,SAAQ;AAC5C;AAwBA,eAAe,MACb,SACA,UAAuB,CAAA,GAAE;AAEzB,SAAO,IAAI,KAAK,SAAS,OAAO,EAAE,KAAI;AACxC;AAqBM,SAAU,gBACd,SACA,UAAuB,CAAA,GAAE;AAEzB,SAAO,IAAI,KAAK,SAAS,OAAO,EAAE,YAAW;AAC/C;AAqBM,SAAU,YACd,SACA,UAAuB,CAAA,GAAE;AAEzB,SAAO,IAAI,KAAK,SAAS,OAAO,EAAE,QAAO;AAC3C;AAGO,IAAM,aAAa;AACnB,IAAM,SAAS,OAAO,OAAO,YAAY,EAAE,MAAM,eAAc,CAAE;AACjE,IAAM,cAAc;AACpB,IAAM,UAAU,OAAO,OAAO,aAAa;EAChD,MAAM;CACP;AACM,IAAM,OAAO,OAAO,OAAO,UAAU;EAC1C,QAAQ;EACR,SAAS;CACV;AAgBM,IAAM,OAAO,OAAO,OAAO,OAAO;EACvC,MAAM;EACN;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;CACD;AACD,KAAK,OAAO;;;ACxNZ,IAAAE,iBAAmB;AACnB,OAAO,QAAQ;AACf,OAAOC,WAAU;AAUjB,eAAsB,2BACpB,SACA,QAAkB;AAElB,QAAM,WAAqB,CAAA;AAG3B,aAAW,aAAa,OAAO,YAAY;AACzC,QAAI,CAAC,UAAU,SAAS;AACtB;IACF;AAEA,UAAM,iBAAiB,MAAM,cAAc,SAAS,SAAS;AAC7D,aAAS,KAAK,GAAG,cAAc;EACjC;AAIA,SAAO,MAAM,KAAK,IAAI,IAAI,QAAQ,CAAC;AACrC;AAKA,eAAe,cACb,SACA,WAA4B;AAE5B,QAAM,gBAAgBA,MAAK,KAAK,SAAS,UAAU,IAAI;AAGvD,QAAM,gBAAgBA,MAAK,KAAK,eAAe,YAAY;AAC3D,MAAI,SAAK,eAAAC,SAAM;AAEf,MAAI;AACF,UAAM,mBAAmB,MAAM,GAAG,SAAS,eAAe,OAAO;AACjE,aAAK,eAAAA,SAAM,EAAG,IAAI,gBAAgB;EACpC,SAAS,GAAG;AAEV,UAAM,oBAAoBD,MAAK,KAAK,SAAS,YAAY;AACzD,QAAI;AACF,YAAM,mBAAmB,MAAM,GAAG,SAAS,mBAAmB,OAAO;AACrE,eAAK,eAAAC,SAAM,EAAG,IAAI,gBAAgB;IACpC,SAASC,IAAG;IAEZ;EACF;AAGA,KAAG,IAAI;IACL,GAAG,UAAU,OAAO;IACpB;GACD;AAGD,QAAM,WAAqB,CAAA;AAE3B,aAAW,WAAW,UAAU,OAAO,SAAS;AAC9C,UAAM,QAAQ,MAAM,KAAK,SAAS;MAChC,KAAK;MACL,UAAU;;MACV,OAAO;MACP,QAAQ,UAAU,OAAO;KAC1B;AACD,aAAS,KAAK,GAAG,KAAK;EACxB;AAGA,QAAM,cAAc,MAAM,KAAK,IAAI,IAAI,QAAQ,CAAC;AAGhD,SAAO,YACJ,OAAO,UAAQ,CAAC,GAAG,QAAQ,IAAI,CAAC,EAChC,IAAI,UAAO;AAEV,WAAO,UAAU,SAAS,MACtB,OACAF,MAAK,KAAK,UAAU,MAAM,IAAI;EACpC,CAAC;AACL;AAMA,eAAsB,aAAa,SAAoB;AACrD,QAAM,EAAE,SAAS,kBAAkB,CAAA,GAAI,kBAAkB,CAAA,EAAE,IAAK;AAGhE,QAAM,gBAAgBA,MAAK,KAAK,SAAS,YAAY;AACrD,MAAI,SAAK,eAAAC,SAAM;AAEf,MAAI;AACF,UAAM,mBAAmB,MAAM,GAAG,SAAS,eAAe,OAAO;AACjE,aAAK,eAAAA,SAAM,EAAG,IAAI,gBAAgB;EACpC,SAAS,GAAG;EAEZ;AAGA,KAAG,IAAI;IACL;IACA;IACA;IACA;IACA;IACA;IACA;IACA,GAAG;GACJ;AAGD,QAAM,WAAW,gBAAgB,SAAS,IACtC,kBACA,CAAC,0DAA0D;AAG/D,QAAM,WAAqB,CAAA;AAE3B,aAAW,WAAW,UAAU;AAC9B,UAAM,QAAQ,MAAM,KAAK,SAAS;MAChC,KAAK;MACL,UAAU;MACV,OAAO;MACP,QAAQ,CAAC,mBAAmB,SAAS;KACtC;AACD,aAAS,KAAK,GAAG,KAAK;EACxB;AAGA,QAAM,cAAc,MAAM,KAAK,IAAI,IAAI,QAAQ,CAAC;AAGhD,SAAO,YAAY,OAAO,UAAO;AAC/B,UAAM,eAAeD,MAAK,SAAS,SAAS,IAAI;AAChD,WAAO,CAAC,GAAG,QAAQ,YAAY;EACjC,CAAC;AACH;AAEM,SAAU,eAAe,UAAgB;AAC7C,QAAMG,OAAMH,MAAK,QAAQ,QAAQ,EAAE,YAAW;AAE9C,QAAM,cAAsC;IAC1C,OAAO;IACP,QAAQ;IACR,OAAO;IACP,QAAQ;IACR,QAAQ;IACR,QAAQ;IACR,QAAQ;IACR,OAAO;IACP,OAAO;IACP,OAAO;IACP,SAAS;IACT,QAAQ;IACR,OAAO;IACP,QAAQ;IACR,MAAM;IACN,MAAM;IACN,QAAQ;IACR,QAAQ;IACR,OAAO;IACP,UAAU;IACV,OAAO;IACP,OAAO;IACP,UAAU;IACV,WAAW;IACX,OAAO;IACP,QAAQ;IACR,aAAa;;AAGf,SAAO,YAAYG,IAAG,KAAK;AAC7B;;;ACxKM,SAAU,eACd,SACA,UAAgB;AAEhB,QAAM,UAA4B;IAChC,WAAW,CAAA;IACX,SAAS,CAAA;IACT,YAAY,CAAA;;AAGd,QAAM,iBAAiB,SAAS,YAAW;AAE3C,UAAQ,gBAAgB;IACtB,KAAK;IACL,KAAK;AACH,cAAQ,YAAY,mBAAmB,OAAO;AAC9C,cAAQ,UAAU,iBAAiB,OAAO;AAC1C,cAAQ,aAAa,oBAAoB,OAAO;AAChD;IAEF,KAAK;IACL,KAAK;AACH,cAAQ,YAAY,mBAAmB,OAAO;AAC9C,cAAQ,UAAU,iBAAiB,OAAO;AAC1C;IAEF,KAAK;IACL,KAAK;AACH,cAAQ,YAAY,uBAAuB,OAAO;AAClD,cAAQ,UAAU,qBAAqB,OAAO;AAC9C;IAEF,KAAK;AACH,cAAQ,YAAY,oBAAoB,OAAO;AAC/C,cAAQ,UAAU,kBAAkB,OAAO;AAC3C,cAAQ,aAAa,qBAAqB,OAAO;AACjD;IAEF,KAAK;AAEH,cAAQ,YAAY,oBAAoB,OAAO;AAC/C,cAAQ,UAAU,qBAAqB,OAAO;AAC9C;IAEF,KAAK;AACH,cAAQ,YAAY,mBAAmB,OAAO;AAC9C,cAAQ,aAAa,oBAAoB,OAAO;AAChD;IAEF,KAAK;AACH,cAAQ,YAAY,qBAAqB,OAAO;AAChD,cAAQ,UAAU,mBAAmB,OAAO;AAC5C,cAAQ,aAAa,sBAAsB,OAAO;AAClD;IAEF,KAAK;IACL,KAAK;AACH,cAAQ,YAAY,uBAAuB,OAAO;AAClD,cAAQ,UAAU,qBAAqB,OAAO;AAC9C,cAAQ,aAAa,wBAAwB,OAAO;AACpD;IAEF,KAAK;IACL,KAAK;AACH,cAAQ,YAAY,qBAAqB,OAAO;AAChD,cAAQ,UAAU,mBAAmB,OAAO;AAC5C;IAEF,KAAK;IACL,KAAK;AACH,cAAQ,YAAY,qBAAqB,OAAO;AAChD;EACJ;AAEA,SAAO;AACT;AAGA,SAAS,mBAAmB,SAAe;AACzC,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,kBAAkB,QAAQ,SAAS,qCAAqC;AAC9E,aAAWC,UAAS,iBAAiB;AACnC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAGA,QAAM,eAAe,QAAQ,SAAS,8DAA8D;AACpG,aAAWA,UAAS,cAAc;AAChC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAGA,QAAM,gBAAgB,QAAQ,SAAS,wCAAwC;AAC/E,aAAWA,UAAS,eAAe;AAEjC,QAAI,CAAC,CAAC,MAAM,OAAO,SAAS,UAAU,OAAO,EAAE,SAASA,OAAM,CAAC,CAAC,GAAG;AACjE,YAAM,IAAIA,OAAM,CAAC,CAAC;IACpB;EACF;AAGA,QAAM,gBAAgB,QAAQ,SAAS,8CAA8C;AACrF,aAAWA,UAAS,eAAe;AACjC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAEA,SAAS,mBAAmB,SAAe;AACzC,SAAO,mBAAmB,OAAO;AACnC;AAEA,SAAS,iBAAiB,SAAe;AACvC,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,eAAe,QAAQ,SAAS,8CAA8C;AACpF,aAAWA,UAAS,cAAc;AAChC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAEA,SAAS,iBAAiB,SAAe;AACvC,SAAO,iBAAiB,OAAO;AACjC;AAEA,SAAS,oBAAoB,SAAe;AAC1C,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,mBAAmB,QAAQ,SAAS,kCAAkC;AAC5E,aAAWA,UAAS,kBAAkB;AACpC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAGA,QAAM,cAAc,QAAQ,SAAS,iCAAiC;AACtE,aAAWA,UAAS,aAAa;AAC/B,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAGA,SAAS,uBAAuB,SAAe;AAC7C,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,kBAAkB,QAAQ,SAAS,mBAAmB;AAC5D,aAAWA,UAAS,iBAAiB;AACnC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAGA,QAAM,eAAe,QAAQ,SAAS,2BAA2B;AACjE,aAAWA,UAAS,cAAc;AAChC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAEA,SAAS,qBAAqB,SAAe;AAC3C,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,eAAe,QAAQ,SAAS,2BAA2B;AACjE,aAAWA,UAAS,cAAc;AAChC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAGA,SAAS,oBAAoB,SAAe;AAC1C,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,kBAAkB,QAAQ,SAAS,wDAAwD;AACjG,aAAWA,UAAS,iBAAiB;AACnC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAEA,SAAS,kBAAkB,SAAe;AACxC,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,eAAe,QAAQ,SAAS,gCAAgC;AACtE,aAAWA,UAAS,cAAc;AAChC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAEA,SAAS,qBAAqB,SAAe;AAC3C,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,mBAAmB,QAAQ,SAAS,oBAAoB;AAC9D,aAAWA,UAAS,kBAAkB;AACpC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAGA,QAAM,eAAe,QAAQ,SAAS,gBAAgB;AACtD,aAAWA,UAAS,cAAc;AAChC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAGA,SAAS,mBAAmB,SAAe;AACzC,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,kBAAkB,QAAQ,SAAS,4CAA4C;AACrF,aAAWA,UAAS,iBAAiB;AACnC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAEA,SAAS,oBAAoB,SAAe;AAC1C,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,mBAAmB,QAAQ,SAAS,gCAAgC;AAC1E,aAAWA,UAAS,kBAAkB;AACpC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAGA,QAAM,gBAAgB,QAAQ,SAAS,6BAA6B;AACpE,aAAWA,UAAS,eAAe;AACjC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAGA,SAAS,qBAAqB,SAAe;AAC3C,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,gBAAgB,QAAQ,SAAS,gFAAgF;AACvH,aAAWA,UAAS,eAAe;AACjC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAEA,SAAS,mBAAmB,SAAe;AACzC,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,eAAe,QAAQ,SAAS,8CAA8C;AACpF,aAAWA,UAAS,cAAc;AAChC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAEA,SAAS,sBAAsB,SAAe;AAC5C,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,mBAAmB,QAAQ,SAAS,kCAAkC;AAC5E,aAAWA,UAAS,kBAAkB;AACpC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAGA,SAAS,uBAAuB,SAAe;AAC7C,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,gBAAgB,QAAQ,SAAS,sGAAsG;AAC7I,aAAWA,UAAS,eAAe;AACjC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAEA,SAAS,qBAAqB,SAAe;AAC3C,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,eAAe,QAAQ,SAAS,uDAAuD;AAC7F,aAAWA,UAAS,cAAc;AAChC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAEA,SAAS,wBAAwB,SAAe;AAC9C,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,mBAAmB,QAAQ,SAAS,2CAA2C;AACrF,aAAWA,UAAS,kBAAkB;AACpC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAGA,SAAS,qBAAqB,SAAe;AAC3C,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,gBAAgB,QAAQ,SAAS,yBAAyB;AAChE,aAAWA,UAAS,eAAe;AACjC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAEA,SAAS,mBAAmB,SAAe;AACzC,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,eAAe,QAAQ,SAAS,gBAAgB;AACtD,aAAWA,UAAS,cAAc;AAChC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAGA,QAAM,gBAAgB,QAAQ,SAAS,iBAAiB;AACxD,aAAWA,UAAS,eAAe;AACjC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAGA,SAAS,qBAAqB,SAAe;AAC3C,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,kBAAkB,QAAQ,SAAS,6BAA6B;AACtE,aAAWA,UAAS,iBAAiB;AACnC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAGA,QAAM,gBAAgB,QAAQ,SAAS,4BAA4B;AACnE,aAAWA,UAAS,eAAe;AACjC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAGA,QAAM,eAAe,QAAQ,SAAS,2BAA2B;AACjE,aAAWA,UAAS,cAAc;AAChC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAGA,SAAS,oBAAoB,SAAe;AAC1C,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,cAAc,QAAQ,MAAM,mCAAmC;AACrE,MAAI,CAAC;AAAa,WAAO,CAAA;AAEzB,QAAM,gBAAgB,YAAY,CAAC;AAGnC,QAAM,qBAAqB,cAAc,SAAS,iCAAiC;AACnF,aAAWA,UAAS,oBAAoB;AACtC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAGA,QAAM,gBAAgB,cAAc,SAAS,wBAAwB;AACrE,aAAWA,UAAS,eAAe;AACjC,UAAM,IAAIA,OAAM,CAAC,CAAC;EACpB;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;AAGA,SAAS,qBAAqB,SAAe;AAC3C,QAAM,QAAQ,oBAAI,IAAG;AAGrB,QAAM,cAAc,QAAQ,MAAM,mCAAmC;AACrE,MAAI,CAAC;AAAa,WAAO,CAAA;AAEzB,QAAM,gBAAgB,YAAY,CAAC;AAGnC,QAAM,YAAY,cAAc,MAAM,uBAAuB;AAC7D,MAAI,WAAW;AACb,UAAM,IAAI,UAAU,CAAC,CAAC;EACxB;AAGA,QAAM,uBAAuB,cAAc,MAAM,sBAAsB;AACvE,MAAI,sBAAsB;AACxB,UAAM,IAAI,cAAc;EAC1B;AAEA,SAAO,MAAM,KAAK,KAAK;AACzB;;;AClcA,OAAO,YAAY;AACnB,OAAO,gBAAgB;AACvB,OAAO,gBAAgB;AACvB,OAAO,eAAe;AACtB,OAAO,YAAY;AACnB,SAAS,eAAe;AAMxB,IAAM,cAAc,oBAAI,IAAG;AAW3B,IAAM,iBAAgE;EACpE,YAAY,WAAW;EACvB,YAAY;EACZ,KAAK,UAAU;;EACf,QAAQ;;AAMV,SAAS,UAAU,UAA2B;AAC5C,MAAI,CAAC,YAAY,IAAI,QAAQ,GAAG;AAC9B,UAAM,SAAS,IAAI,OAAM;AACzB,UAAM,UAAU,eAAe,QAAQ;AAEvC,QAAI,CAAC,SAAS;AACZ,YAAM,IAAI,MAAM,sCAAsC,QAAQ,EAAE;IAClE;AAEA,WAAO,YAAY,OAAO;AAC1B,gBAAY,IAAI,UAAU,MAAM;EAClC;AAEA,SAAO,YAAY,IAAI,QAAQ;AACjC;AAMM,SAAUC,gBAAe,UAAgB;AAG7C,QAAMC,OAAM,QAAQ,QAAQ,EAAE,MAAM,CAAC,EAAE,YAAW;AAElD,UAAQA,MAAK;IACX,KAAK;IACL,KAAK;AACH,aAAO;IACT,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT,KAAK;AACH,aAAO;IACT;AACE,aAAO;EACX;AACF;AAKM,SAAU,eAAe,UAAgB;AAC7C,SAAOD,gBAAe,QAAQ,MAAM;AACtC;AAaM,SAAU,SAAS,SAAiB,UAA2B;AACnE,MAAI;AACF,UAAM,SAAS,UAAU,QAAQ;AACjC,UAAM,OAAO,OAAO,MAAM,OAAO;AAGjC,QAAI,KAAK,SAAS,UAAU;AAC1B,aAAO;QACL;QACA,OAAO;;IAEX;AAEA,WAAO,EAAE,KAAI;EACf,SAASE,QAAO;AACd,WAAO;MACL,MAAM;MACN,OAAOA,kBAAiB,QAAQA,OAAM,UAAU;;EAEpD;AACF;;;AC1GA,IAAM,kBAAkB;;EAEtB;;EACA;;EACA;;EACA;;EACA;;EACA;;EACA;;;EAGA;;EACA;;EACA;;;EAGA;;;EAGA;;;EAEA;;EACA;;;AAYI,SAAU,oBAAoB,MAAuB;AACzD,MAAI,aAAa;AAEjB,WAAS,SAAS,GAAoB;AACpC,QAAI,gBAAgB,SAAS,EAAE,IAAI,GAAG;AAEpC,UAAI,EAAE,SAAS,qBAAqB;AAClC,cAAM,WAAW,EAAE,kBAAkB,UAAU;AAC/C,YAAI,aAAa,SAAS,SAAS,QAAQ,SAAS,SAAS,OAAO;AAClE;QACF;MACF,OAAO;AACL;MACF;IACF;AAGA,aAAS,IAAI,GAAG,IAAI,EAAE,iBAAiB,KAAK;AAC1C,YAAM,QAAQ,EAAE,WAAW,CAAC;AAC5B,UAAI;AAAO,iBAAS,KAAK;IAC3B;EACF;AAEA,WAAS,IAAI;AACb,SAAO;AACT;;;AC/DA,IAAM,gBAAgB,oBAAI,IAAI;EAC5B;EAAgB;EAAiB;EAAmB;EACpD;EAAgB;EAAiB;EAAgB;EACjD;EAAoB;EAAqB;CAC1C;AAGD,IAAM,oBAAoB,oBAAI,IAAI;EAChC;EAAe;EAAe;EAAsB;CACrD;AAGD,IAAM,eAAe,oBAAI,IAAI,CAAC,kBAAkB,uBAAuB,QAAQ,CAAC;AAUhF,SAAS,mBAAmB,MAAuB;AACjD,MAAI,KAAK,SAAS,uBAAuB,KAAK,SAAS,oBAAoB;AACzE,WAAO;EACT;AACA,QAAM,WAAW,KAAK,kBAAkB,UAAU;AAClD,QAAM,SAAS,UAAU;AAEzB,MAAI,WAAW,QAAQ,WAAW;AAAO,WAAO;AAChD,MAAI,WAAW,QAAQ,WAAW;AAAM,WAAO;AAC/C,SAAO;AACT;AAKA,SAAS,qBACP,QACA,OACA,cAAoB;AAEpB,QAAM,cAAc,OAAO,kBAAkB,WAAW,MAAM;AAC9D,QAAM,eAAe,kBAAkB,IAAI,MAAM,IAAI;AACrD,SAAQ,CAAC,eAAe,CAAC,eAAgB,eAAe,IAAI;AAC9D;AAKA,SAAS,yBAAyB,UAAkB,cAAoB;AACtE,SAAQ,aAAa,IAAI,QAAQ,KAAK,eAAe,IAAK,IAAI;AAChE;AAGA,SAAS,wBACP,GACA,OACA,IACA,KAAqB;AAErB,QAAM,WAAW,EAAE,kBAAkB,UAAU;AAC/C,WAAS,IAAI,GAAG,IAAI,EAAE,iBAAiB,KAAK;AAC1C,UAAM,QAAQ,EAAE,WAAW,CAAC;AAC5B,QAAI,SAAS,UAAU;AAAU,UAAI,SAAS,OAAO,OAAO,EAAE;EAChE;AACF;AAGA,SAAS,wBACP,GACA,OACA,KAAqB;AAErB,WAAS,IAAI,GAAG,IAAI,EAAE,iBAAiB,KAAK;AAC1C,UAAM,QAAQ,EAAE,WAAW,CAAC;AAC5B,QAAI;AAAO,UAAI,SAAS,OAAO,qBAAqB,GAAG,OAAO,KAAK,GAAG,IAAI;EAC5E;AACF;AAGA,SAAS,oBACP,GACA,OACA,KAAqB;AAErB,WAAS,IAAI,GAAG,IAAI,EAAE,iBAAiB,KAAK;AAC1C,UAAM,QAAQ,EAAE,WAAW,CAAC;AAC5B,QAAI;AAAO,UAAI,SAAS,OAAO,OAAO,IAAI;EAC5C;AACF;AAeM,SAAU,6BAA6B,MAAuB;AAClE,MAAI,aAAa;AACjB,QAAM,MAAwB,EAAE,SAAQ;AAExC,WAAS,SAAS,GAAsB,cAAsB,eAA4B;AACxF,UAAM,YAAY,mBAAmB,CAAC;AAEtC,QAAI,WAAW;AACb,oBAAe,kBAAkB,YAAa,IAAI;AAClD,8BAAwB,GAAG,cAAc,WAAW,GAAG;AACvD;IACF;AAEA,QAAI,cAAc,IAAI,EAAE,IAAI,GAAG;AAC7B,oBAAc,IAAI;AAClB,8BAAwB,GAAG,cAAc,GAAG;AAC5C;IACF;AAEA,QAAI,kBAAkB,IAAI,EAAE,IAAI,GAAG;AACjC,oBAAc;AACd,0BAAoB,GAAG,eAAe,GAAG,GAAG;AAC5C;IACF;AAEA,kBAAc,yBAAyB,EAAE,MAAM,YAAY;AAC3D,wBAAoB,GAAG,cAAc,GAAG;EAC1C;AAEA,WAAS,MAAM,GAAG,IAAI;AACtB,SAAO;AACT;;;AChHA,IAAM,mBAAgD;EACpD,YAAY,oBAAI,IAAI;;IAElB;IAAK;IAAK;IAAK;IAAK;IAAK;;IAEzB;IAAM;IAAO;IAAM;IAAO;IAAK;IAAK;IAAM;;IAE1C;IAAM;IAAM;IAAK;;IAEjB;IAAK;IAAM;IAAM;IAAM;IAAM;IAAM;IAAO;IAAO;IAAO;;IAExD;IAAK;IAAK;IAAK;IAAK;IAAM;IAAM;IAChC;IAAM;IAAM;IAAM;IAAO;IAAO;;IAEhC;IAAK;IAAK;IAAK;IAAM;IAAM;IAAM;IAAO;;IAExC;IAAK;IAAK;IAAK;IAAK;IAAK;GAC1B;EACD,QAAQ,oBAAI,IAAI;;IAEd;IAAK;IAAK;IAAK;IAAK;IAAK;IAAM;;IAE/B;IAAM;IAAM;IAAK;IAAK;IAAM;;;IAG5B;IAAK;IAAM;IAAM;IAAM;IAAM;IAAM;IAAO;IAC1C;IAAM;IAAM;IAAM;IAAO;;IAEzB;IAAK;IAAK;IAAK;IAAK;IAAM;;IAE1B;IAAK;IAAK;IAAM;IAChB;IAAK;IAAK;IAAK;IAAK;IAAK;GAC1B;EACD,KAAK,oBAAI,IAAI;;IAEX;IAAK;IAAK;IAAK;IAAK;IAAK;;IAEzB;IAAM;IAAO;IAAM;IAAO;IAAM;IAAK;IAAK;IAAM;IAAM;;IAEtD;IAAM;IAAM;IAAK;IAAO;IAAM;;IAE9B;IAAK;IAAM;IAAM;IAAM;IAAM;IAAM;IAAO;IAC1C;IAAM;IAAM;IAAM;IAAO;IAAO;;IAEhC;IAAK;IAAK;IAAK;IAAK;IAAM;;IAE1B;;IAEA;IAAK;IAAK;IAAM;IAAM;IAAM;IAAM;IAClC;IAAK;IAAK;IAAK;IAAK;IAAK;GAC1B;;AAOH,IAAM,oBAAiD;EACrD,YAAY,oBAAI,IAAI;IAClB;IAAM;IAAQ;IAAO;IAAS;IAAM;IAAU;IAAQ;IACtD;IAAU;IAAS;IAAO;IAAS;IACnC;IAAO;IAAU;IAAU;IAAc;IAAM;IAC/C;IAAS;IAAS;IAAS;IAC3B;IAAS;IAAO;IAAO;IAAY;IAAS;IAAW;IACvD;IAAU;IAAU;IAAQ;GAC7B;EACD,QAAQ,oBAAI,IAAI;IACd;IAAM;IAAQ;IAAQ;IAAO;IAAS;IAAS;IAC/C;IAAU;IAAS;IAAO;IAAU;IACpC;IAAO;IAAM;IAAO;IAAM;IAC1B;IAAS;IAAS;IAAS;IAAY;IACvC;IAAO;IAAS;IAAU;IAC1B;IAAU;IAAQ;IAAM;IACxB;IAAU;IAAY;IAAO;GAC9B;EACD,KAAK,oBAAI,IAAI;IACX;IAAM;IAAU;IAAQ;IAAO;IAAW;IAAS;IAAM;IAAU;IAAQ;IAAW;IACtF;IAAU;IAAS;IAAO;IAAS;IACnC;IAAO;IAAS;IAChB;IAAS;IAAS;IAClB;IAAY;IAAS;IAAW;IAAc;IAAS;IACvD;IAAO;IAAa;IACpB;IAAQ;IAAS;IAAW;IAAW;IAAgB;IACvD;IAAU;IAAU;IAAS;IAAU;IAAW;IAAa;GAChE;;AAOH,IAAM,sBAAsB,oBAAI,IAAI;;EAElC;EACA;EACA;EACA;EACA;EACA;EACA;;EAGA;EACA;EACA;EACA;EACA;;EAGA;EACA;EACA;EACA;CACD;AAKD,IAAM,qBAAqB,oBAAI,IAAI;;EAEjC;EACA;EACA;EACA;EACA;;EAGA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;;EAGA;EACA;EACA;CACD;AAKD,SAAS,mBAAmB,UAAgB;AAC1C,SAAO,iBAAiB,QAAQ,KAAK,iBAAiB;AACxD;AAKA,SAAS,oBAAoB,UAAgB;AAC3C,SAAO,kBAAkB,QAAQ,KAAK,kBAAkB;AAC1D;AAKA,SAAS,WAAW,MAAyB,UAAgB;AAC3D,QAAM,WAAW,KAAK;AACtB,QAAM,WAAW,KAAK;AAGtB,MAAI,oBAAoB,IAAI,QAAQ,GAAG;AACrC,WAAO;EACT;AAGA,QAAM,UAAU,mBAAmB,QAAQ;AAC3C,QAAM,WAAW,oBAAoB,QAAQ;AAE7C,SAAO,QAAQ,IAAI,QAAQ,KAAK,SAAS,IAAI,QAAQ;AACvD;AAKA,SAAS,UAAU,MAAuB;AACxC,SAAO,mBAAmB,IAAI,KAAK,IAAI;AACzC;AAKA,SAAS,eAAe,MAAuB;AAE7C,MAAI,oBAAoB,IAAI,KAAK,IAAI,GAAG;AAEtC,UAAM,WAAW,KAAK,kBAAkB,UAAU;AAClD,QAAI,UAAU;AACZ,aAAO,SAAS;IAClB;AACA,WAAO,KAAK;EACd;AACA,SAAO,KAAK;AACd;AAKA,SAAS,cAAc,MAAuB;AAC5C,SAAO,KAAK;AACd;AAKA,SAAS,UAAU,KAAwB;AACzC,MAAI,MAAM;AACV,aAAW,SAAS,IAAI,OAAM,GAAI;AAChC,WAAO;EACT;AACA,SAAO;AACT;AASM,SAAU,cAAc,MAAyB,UAAgB;AACrE,QAAM,YAAY,oBAAI,IAAG;AACzB,QAAM,WAAW,oBAAI,IAAG;AAExB,WAAS,SAAS,GAAoB;AAEpC,QAAI,WAAW,GAAG,QAAQ,GAAG;AAC3B,YAAM,MAAM,eAAe,CAAC;AAC5B,gBAAU,IAAI,MAAM,UAAU,IAAI,GAAG,KAAK,KAAK,CAAC;IAClD;AAGA,QAAI,UAAU,CAAC,GAAG;AAChB,YAAM,MAAM,cAAc,CAAC;AAC3B,eAAS,IAAI,MAAM,SAAS,IAAI,GAAG,KAAK,KAAK,CAAC;IAChD;AAGA,eAAW,SAAS,EAAE,UAAU;AAC9B,eAAS,KAAK;IAChB;EACF;AAEA,WAAS,IAAI;AAEb,SAAO;IACL,IAAI,UAAU;IACd,IAAI,SAAS;IACb,IAAI,UAAU,SAAS;IACvB,IAAI,UAAU,QAAQ;IACtB;IACA;;AAEJ;AAiBM,SAAU,yBAAyB,QAAsB;AAC7D,QAAM,EAAE,IAAI,IAAI,IAAI,GAAE,IAAK;AAE3B,QAAM,aAAa,KAAK;AACxB,QAAM,SAAS,KAAK;AAGpB,QAAM,SAAS,aAAa,IAAI,SAAS,KAAK,KAAK,UAAU,IAAI;AACjE,QAAM,aAAa,KAAK,IAAK,KAAK,KAAM,KAAK,MAAM;AACnD,QAAM,SAAS,aAAa;AAC5B,QAAM,OAAO,SAAS;AACtB,QAAM,OAAO,SAAS;AAEtB,SAAO;IACL,YAAY,KAAK,MAAM,UAAU;IACjC,QAAQ,KAAK,MAAM,MAAM;IACzB,QAAQ,KAAK,MAAM,SAAS,GAAG,IAAI;IACnC,YAAY,KAAK,MAAM,aAAa,GAAG,IAAI;IAC3C,QAAQ,KAAK,MAAM,MAAM;IACzB,MAAM,KAAK,MAAM,IAAI;IACrB,MAAM,KAAK,MAAM,OAAO,GAAI,IAAI;;AAEpC;AAWM,SAAU,kBAAkB,MAAyB,UAAgB;AACzE,QAAM,SAAS,cAAc,MAAM,QAAQ;AAC3C,SAAO,yBAAyB,MAAM;AACxC;;;ACnUA,SAAS,oBACP,MACA,SACA,aAAoB;AAElB,QAAM,WAAW,KAAK,kBAAkB,MAAM;AAC9C,MAAI,CAAC;AAAU,WAAO;AAEtB,SAAO;IACL,MAAM,SAAS;IACf,MAAM,cAAc,WAAW;IAC/B,WAAW,KAAK,cAAc,MAAM;IACpC,SAAS,KAAK,YAAY,MAAM;IAChC;IACA,WAAW,iBAAiB,MAAM,OAAO;IACzC,YAAY,kBAAkB,MAAM,OAAO;IAC3C,YAAY,kBAAkB,MAAM,OAAO;IAC3C,YAAY,oBAAoB,IAAI;;AAExC;AAKF,SAAS,yBACP,MACA,SACA,aAAoB;AAGlB,QAAM,SAAS,KAAK;AACpB,MAAI,OAAO;AAEX,MAAI,QAAQ,SAAS,uBAAuB;AAC1C,UAAM,WAAW,OAAO,kBAAkB,MAAM;AAChD,WAAO,UAAU,QAAQ;EAC3B;AAEA,SAAO;IACL;IACA,MAAM,cAAc,WAAW;IAC/B,WAAW,KAAK,cAAc,MAAM;IACpC,SAAS,KAAK,YAAY,MAAM;IAChC;IACA,WAAW,iBAAiB,MAAM,OAAO;IACzC,YAAY,kBAAkB,MAAM,OAAO;IAC3C,YAAY,oBAAoB,IAAI;;AAExC;AAKF,SAAS,kBACP,MACA,SACA,aAAoB;AAElB,QAAM,WAAW,KAAK,kBAAkB,MAAM;AAC9C,MAAI,CAAC;AAAU,WAAO;AAEtB,SAAO;IACL,MAAM,SAAS;IACf,MAAM;IACN,WAAW,KAAK,cAAc,MAAM;IACpC,SAAS,KAAK,YAAY,MAAM;IAChC;IACA,WAAW,iBAAiB,MAAM,OAAO;IACzC,YAAY,kBAAkB,MAAM,OAAO;IAC3C,YAAY,kBAAkB,MAAM,OAAO;IAC3C,YAAY,oBAAoB,IAAI;;AAExC;AAKF,SAAS,iBACP,MACA,UACA,cAAqB;AAEnB,QAAM,WAAW,KAAK,kBAAkB,MAAM;AAC9C,MAAI,CAAC;AAAU,WAAO;AAEtB,SAAO;IACL,MAAM,SAAS;IACf,MAAM;IACN,WAAW,KAAK,cAAc,MAAM;IACpC,SAAS,KAAK,YAAY,MAAM;IAChC,WAAW,SAAS,SAAS,IAAI;;AAErC;AAKF,SAAS,qBACP,MACA,UACA,cAAqB;AAEnB,QAAM,WAAW,KAAK,kBAAkB,MAAM;AAC9C,MAAI,CAAC;AAAU,WAAO;AAEtB,SAAO;IACL,MAAM,SAAS;IACf,MAAM;IACN,WAAW,KAAK,cAAc,MAAM;IACpC,SAAS,KAAK,YAAY,MAAM;IAChC,WAAW,aAAa,SAAS,IAAI;;AAEzC;AAKF,SAAS,0BACP,MACA,SACA,aAAoB;AAElB,QAAM,WAAW,KAAK,kBAAkB,MAAM;AAC9C,MAAI,CAAC;AAAU,WAAO;AAEtB,SAAO;IACL,MAAM,SAAS;IACf,MAAM,cAAc,WAAW;IAC/B,WAAW,KAAK,cAAc,MAAM;IACpC,SAAS,KAAK,YAAY,MAAM;IAChC;IACA,WAAW,iBAAiB,MAAM,OAAO;IACzC,YAAY,kBAAkB,MAAM,OAAO;IAC3C,YAAY,oBAAoB,IAAI;;AAExC;AAKF,SAAS,uBACP,MACA,UACA,cAAqB;AAEnB,QAAM,WAAW,KAAK,kBAAkB,MAAM;AAC9C,MAAI,CAAC;AAAU,WAAO;AAEtB,SAAO;IACL,MAAM,SAAS;IACf,MAAM;IACN,WAAW,KAAK,cAAc,MAAM;IACpC,SAAS,KAAK,YAAY,MAAM;IAChC,WAAW,SAAS,SAAS,IAAI;;AAErC;AAYF,IAAM,mBAAoD;;EAExD,wBAAwB;EACxB,YAAY;EACZ,kBAAkB;EAClB,uBAAuB;EACvB,qBAAqB;EACrB,qBAAqB;EACrB,yBAAyB;;EAGzB,uBAAuB;;EACvB,sBAAsB;;;EAGtB,6BAA6B;;EAC7B,oBAAoB;;;;;AAchB,SAAU,kBACd,MACA,SACA,aACA,UAAiB;AAIjB,MAAI,KAAK,SAAS,yBAAyB,aAAa,UAAU;AAChE,WAAO,0BAA0B,MAAM,SAAS,WAAW;EAC7D;AAEA,QAAM,YAAY,iBAAiB,KAAK,IAAI;AAC5C,SAAO,YAAY,UAAU,MAAM,SAAS,WAAW,IAAI;AAC7D;AAKA,SAAS,iBAAiB,MAAyB,SAAe;AAEhE,QAAM,YAAY,KAAK,cAAc;AACrC,QAAM,QAAQ,QAAQ,MAAM,IAAI;AAChC,MAAI,YAAY,MAAM,SAAS,KAAK;AAGpC,MAAI,cAAc;AAClB,SAAO,cAAc,KAAK,YAAY,OAAO,CAAC,UAAU,SAAS,GAAG,KAAK,CAAC,UAAU,SAAS,IAAI,GAAG;AAClG;AACA,iBAAa,OAAO,MAAM,WAAW,KAAK;EAC5C;AAGA,cAAY,UAAU,MAAM,GAAG,EAAE,CAAC,EAAE,MAAM,IAAI,EAAE,CAAC,EAAE,KAAI;AAGvD,MAAI,UAAU,SAAS,KAAK;AAC1B,gBAAY,UAAU,UAAU,GAAG,GAAG,IAAI;EAC5C;AAEA,SAAO;AACT;AAQA,SAAS,kBAAkB,MAAyB,UAAgB;AAClE,QAAM,aAAuB,CAAA;AAG7B,QAAM,aAAa,KAAK,kBAAkB,YAAY;AACtD,MAAI,CAAC;AAAY,WAAO;AAGxB,WAAS,IAAI,GAAG,IAAI,WAAW,iBAAiB,KAAK;AACnD,UAAM,QAAQ,WAAW,WAAW,CAAC;AACrC,QAAI,OAAO;AACT,iBAAW,KAAK,MAAM,IAAI;IAC5B;EACF;AAEA,SAAO;AACT;AAQA,SAAS,kBAAkB,MAAyB,UAAgB;AAClE,QAAM,iBAAiB,KAAK,kBAAkB,aAAa;AAC3D,MAAI,CAAC;AAAgB,WAAO;AAE5B,SAAO,eAAe;AACxB;AAKM,SAAU,eAAe,UAA2B;AACxD,QAAM,UAAoB,CAAA;AAE1B,WAAS,SAAS,MAAuB;AAEvC,QAAI,KAAK,SAAS,oBAAoB;AAEpC,YAAM,aAAa,KAAK,kBAAkB,QAAQ;AAClD,UAAI,YAAY;AAEd,cAAM,aAAa,WAAW,KAAK,QAAQ,SAAS,EAAE;AACtD,gBAAQ,KAAK,UAAU;MACzB,OAAO;AAEL,cAAM,aAAa,KAAK,KAAK,MAAM,IAAI,EAAE,CAAC;AAC1C,gBAAQ,KAAK,UAAU;MACzB;IACF,WAES,KAAK,SAAS,yBAAyB;AAE9C,YAAM,aAAa,KAAK,KAAK,MAAM,IAAI,EAAE,CAAC;AAC1C,cAAQ,KAAK,UAAU;IACzB;AAGA,QAAI,SAAS,UAAU;AACrB,eAAS,IAAI,GAAG,IAAI,KAAK,iBAAiB,KAAK;AAC7C,cAAM,QAAQ,KAAK,WAAW,CAAC;AAC/B,YAAI;AAAO,mBAAS,KAAK;MAC3B;IACF;EACF;AAEA,WAAS,QAAQ;AACjB,SAAO;AACT;;;ACnUM,IAAO,sBAAP,MAA0B;EAC9B,kBAAkB;IAChB;IACA;IACA;IACA;IACA;;IACA;;;EAGF,iBAAiB;IACf;;;EAGF,mBAAmB;IACjB;;IACA;;;EAGF,gBAAgB;IACd;IACA;IACA;;EAGF,sBAAsB,MAAuB;AAC3C,WAAO,KAAK,eAAe,SAAS,KAAK,IAAI;EAC/C;EAEA,0BAA0B,MAAuB;AAC/C,WAAO,KAAK,iBAAiB,SAAS,KAAK,IAAI;EACjD;EAEA,iBAAiB,MAAuB;AACtC,QAAI,KAAK,SAAS,qBAAqB;AACrC,aAAO,KAAK,kBAAkB,MAAM;IACtC;AACA,WAAO;EACT;EAEA,uBAAuB,MAAuB;AAC5C,WAAO,KAAK,SAAS,aACd,KAAK,SAAS,sBACd,KAAK,SAAS;EACvB;EAEA,wBAAwB,MAAuB;AAC7C,QAAI,UAAU,KAAK;AACnB,WAAO,SAAS;AACd,UAAI,QAAQ,SAAS,qBAAqB;AACxC,cAAM,WAAW,QAAQ,kBAAkB,MAAM;AACjD,eAAO,UAAU;MACnB;AACA,gBAAU,QAAQ;IACpB;AACA,WAAO;EACT;;;;EAKA,0BAA0B,MAAuB;AAC/C,UAAMC,UAAS,CAAC,GAAsB,UAA2C;AAC/E,UAAI,QAAQ;AAAG,eAAO;AAEtB,UAAI,KAAK,cAAc,SAAS,EAAE,IAAI,GAAG;AACvC,eAAO;MACT;AAEA,eAAS,IAAI,GAAG,IAAI,EAAE,YAAY,KAAK;AACrC,cAAM,QAAQ,EAAE,MAAM,CAAC;AACvB,YAAI,OAAO;AACT,gBAAM,SAASA,QAAO,OAAO,QAAQ,CAAC;AACtC,cAAI;AAAQ,mBAAO;QACrB;MACF;AAEA,aAAO;IACT;AAEA,UAAM,eAAeA,QAAO,MAAM,CAAC;AACnC,WAAO;MACL,aAAa,iBAAiB;MAC9B;;EAEJ;;AAMI,IAAO,sBAAP,cAAmC,oBAAmB;;;;AC3FtD,IAAO,eAAP,MAAmB;EACvB,kBAAkB;IAChB;;IACA;;;EAGF,iBAAiB;IACf;;IACA;;IACA;;;EAGF,mBAAmB;;;;EAKnB,gBAAgB;IACd;IACA;;EAGF,sBAAsB,MAAuB;AAC3C,WAAO,KAAK,eAAe,SAAS,KAAK,IAAI;EAC/C;EAEA,0BAA0B,OAAwB;AAGhD,WAAO;EACT;EAEA,iBAAiB,MAAuB;AACtC,QAAI,KAAK,SAAS,uBACd,KAAK,SAAS,uBACd,KAAK,SAAS,yBAAyB;AAEzC,aAAO,KAAK,kBAAkB,MAAM;IACtC;AACA,WAAO;EACT;EAEA,uBAAuB,MAAuB;AAC5C,WAAO,KAAK,SAAS;IACd,KAAK,SAAS;IACd,KAAK,SAAS;EACvB;EAEA,wBAAwB,MAAuB;AAC7C,QAAI,UAAU,KAAK;AACnB,WAAO,SAAS;AACd,UAAI,QAAQ,SAAS,uBACjB,QAAQ,SAAS,qBAAqB;AACxC,cAAM,WAAW,QAAQ,kBAAkB,MAAM;AACjD,eAAO,UAAU;MACnB;AACA,gBAAU,QAAQ;IACpB;AACA,WAAO;EACT;EAEA,0BAA0B,OAAwB;AAEhD,WAAO;MACL,aAAa;MACb,cAAc;;EAElB;;;;AChEI,IAAO,kBAAP,MAAsB;EAC1B,kBAAkB;IAChB;IACA;;EAGF,iBAAiB;IACf;;;EAGF,mBAAmB;;;;EAKnB,gBAAgB;IACd;IACA;;EAGF,sBAAsB,MAAuB;AAC3C,WAAO,KAAK,eAAe,SAAS,KAAK,IAAI;EAC/C;EAEA,0BAA0B,OAAwB;AAGhD,WAAO;EACT;EAEA,iBAAiB,MAAuB;AACtC,QAAI,KAAK,SAAS,oBAAoB;AAEpC,aAAO,KAAK,kBAAkB,MAAM;IACtC;AACA,WAAO;EACT;EAEA,uBAAuB,MAAuB;AAC5C,WAAO,KAAK,SAAS;IACd,KAAK,SAAS;EACvB;EAEA,wBAAwB,MAAuB;AAC7C,QAAI,UAAU,KAAK;AACnB,WAAO,SAAS;AACd,UAAI,QAAQ,SAAS,oBAAoB;AACvC,cAAM,WAAW,QAAQ,kBAAkB,MAAM;AACjD,eAAO,UAAU;MACnB;AACA,gBAAU,QAAQ;IACpB;AACA,WAAO;EACT;;;;;EAMA,0BAA0B,OAAwB;AAChD,WAAO;MACL,aAAa;MACb,cAAc;;EAElB;;;;AC3DF,IAAM,oBAAkE;EACtE,YAAY,IAAI,oBAAmB;EACnC,YAAY,IAAI,oBAAmB;EACnC,KAAK,IAAI,aAAY;EACrB,QAAQ,IAAI,gBAAe;;AAUvB,SAAU,aAAa,UAA2B;AACtD,QAAM,YAAY,kBAAkB,QAAQ;AAE5C,MAAI,CAAC,WAAW;AACd,UAAM,IAAI,MAAM,wCAAwC,QAAQ,EAAE;EACpE;AAEA,SAAO;AACT;;;ACVM,SAAU,WACd,UACA,SACA,UAA2B,CAAA,GAAE;AAE7B,QAAM,EAAE,eAAe,EAAC,IAAK;AAG7B,QAAM,WAAWC,gBAAe,QAAQ;AACxC,MAAI,CAAC,UAAU;AACb,UAAM,IAAI,MAAM,kCAAkC,QAAQ,EAAE;EAC9D;AAGA,QAAM,cAAc,SAAS,SAAS,QAAQ;AAG9C,MAAI,CAAC,YAAY,MAAM;AACrB,UAAM,IAAI,MAAM,mBAAmB,QAAQ,KAAK,YAAY,KAAK,EAAE;EACrE;AAEA,QAAM,SAAqB,CAAA;AAC3B,QAAM,QAAQ,QAAQ,MAAM,IAAI;AAChC,QAAM,WAAW,YAAY,KAAK;AAGlC,QAAM,YAAY,aAAa,QAAQ;AAGvC,QAAM,cAAc,eAAe,QAAQ;AAG3C,QAAM,gBAAgB,kBAAkB,UAAU,SAAS;AAE3D,aAAW,QAAQ,eAAe;AAEhC,QAAI,aAAa;AACjB,QAAI,UAAU,0BAA0B,IAAI,GAAG;AAC7C,YAAM,WAAW,UAAU,0BAA0B,IAAI;AACzD,UAAI,SAAS,cAAc;AACzB,qBAAa,SAAS;MACxB;IACF;AAGA,UAAM,kBAAkB,UAAU,wBAAwB,UAAU;AAEpE,UAAM,aAAa,kBAAkB,YAAY,SAAS,iBAAiB,QAAQ;AAGnF,UAAM,cAAc,eAAe,MAAM,KAAK;AAK9C,WAAO,KAAK,YAAY,UAAU,MAAM,aAAa,YAAY,aAAa,QAAQ,CAAC;EACzF;AAGA,QAAM,gBAAgB,cAAc,IAAI,QAAM;IAC5C,OAAO,EAAE,cAAc;IACvB,KAAK,EAAE,YAAY;IACnB;AAEF,QAAM,kBAAkB,qBACtB,OACA,eACA,UACA,cACA,aACA,QAAQ;AAGV,SAAO,KAAK,GAAG,eAAe;AAG9B,SAAO,KAAK,CAAC,GAAG,MAAM,EAAE,SAAS,YAAY,EAAE,SAAS,SAAS;AAEjE,SAAO;AACT;AAGA,SAAS,sBACP,MACA,OACA,WAA0C;AAE1C,MAAI,UAAU,KAAK,CAAC,UAAU,0BAA0B,IAAI;AAAG,WAAO;AACtE,SAAO,UAAU,0BAA0B,IAAI,EAAE;AACnD;AAGA,SAAS,aACP,MACA,OACA,WAA0C;AAE1C,SAAO,SAAS,KAAK,UAAU,gBAAgB,SAAS,KAAK,IAAI;AACnE;AAaA,SAAS,kBACP,UACA,WAA0C;AAE1C,QAAM,QAA6B,CAAA;AAEnC,WAAS,SAAS,MAAyB,OAAa;AAEtD,QAAI,sBAAsB,MAAM,OAAO,SAAS,KAAK,aAAa,MAAM,OAAO,SAAS,GAAG;AACzF,YAAM,KAAK,IAAI;AACf;IACF;AAGA,QAAI,UAAU,sBAAsB,IAAI,GAAG;AACzC,YAAM,OAAO,UAAU,iBAAiB,IAAI;AAC5C,UAAI;AAAM,iBAAS,MAAM,QAAQ,CAAC;AAClC;IACF;AAGA,QAAI,CAAC,UAAU,uBAAuB,IAAI;AAAG;AAC7C,aAAS,IAAI,GAAG,IAAI,KAAK,iBAAiB,KAAK;AAC7C,YAAM,QAAQ,KAAK,WAAW,CAAC;AAC/B,UAAI;AAAO,iBAAS,OAAO,KAAK;IAClC;EACF;AAEA,WAAS,UAAU,CAAC;AACpB,SAAO;AACT;AAKA,SAAS,eAAe,MAAyB,OAAe;AAC9D,QAAM,YAAY,KAAK,cAAc;AACrC,QAAM,UAAU,KAAK,YAAY;AAEjC,SAAO,MAAM,MAAM,WAAW,UAAU,CAAC,EAAE,KAAK,IAAI;AACtD;AAGA,IAAM,uBAA+E;EACnF,UAAU;EACV,QAAQ;EACR,OAAO;EACP,WAAW;;AAIb,IAAM,0BAA0B,oBAAI,IAAI,CAAC,YAAY,QAAQ,CAAC;AAK9D,SAAS,mBAAmB,YAAgD;AAK1E,QAAM,UAAU,EAAE,WAAW,CAAA,GAAgB,SAAS,CAAA,GAAgB,YAAY,CAAA,EAAc;AAEhG,MAAI,YAAY,QAAQ,WAAW,MAAM;AACvC,UAAM,WAAW,qBAAqB,WAAW,IAAI;AACrD,QAAI;AAAU,cAAQ,QAAQ,EAAE,KAAK,WAAW,IAAI;EACtD;AAEA,SAAO;AACT;AAKA,SAAS,aAAa,YAAgD;AACpE,MAAI,CAAC;AAAY,WAAO;AACxB,SAAO,WAAW,SAAS,UAAU,UAAU;AACjD;AAKA,SAAS,YACP,UACA,MACA,SACA,YACA,SACA,UAAgB;AAEhB,QAAM,UAAU,mBAAmB,UAAU;AAC7C,QAAM,uBAAuB,YAAY,QAAQ,wBAAwB,IAAI,WAAW,IAAI;AAG5F,QAAM,sBAAsB,uBACxB,6BAA6B,IAAI,IACjC;AAGJ,QAAM,WAAW,uBACb,kBAAkB,MAAM,QAAQ,IAChC;AAEJ,SAAO;IACL;IACA,UAAU;MACR,MAAM;MACN,WAAW,KAAK,cAAc,MAAM;MACpC,SAAS,KAAK,YAAY,MAAM;MAChC,MAAM,aAAa,UAAU;MAC7B;MACA;MACA,YAAY,YAAY;MACxB,YAAY,YAAY;MACxB,aAAa,YAAY;MACzB,YAAY,YAAY;MACxB;MACA,YAAY,YAAY;MACxB,WAAW,YAAY;MACvB;;MAEA,gBAAgB,UAAU;MAC1B,oBAAoB,UAAU;MAC9B,gBAAgB,UAAU;MAC1B,cAAc,UAAU;;;AAG9B;AAaA,SAAS,oBACP,eACA,YAAkB;AAElB,QAAM,kBAA+B,CAAA;AACrC,MAAI,eAAe;AAGnB,QAAM,eAAe,CAAC,GAAG,aAAa,EAAE,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK;AAExE,aAAW,SAAS,cAAc;AAChC,QAAI,eAAe,MAAM,OAAO;AAE9B,sBAAgB,KAAK;QACnB,OAAO;QACP,KAAK,MAAM,QAAQ;OACpB;IACH;AACA,mBAAe,MAAM,MAAM;EAC7B;AAGA,MAAI,eAAe,YAAY;AAC7B,oBAAgB,KAAK;MACnB,OAAO;MACP,KAAK,aAAa;KACnB;EACH;AAEA,SAAO;AACT;AAKA,SAAS,qBACP,OACA,OACA,UACA,UACA,SAAiB;AAEjB,QAAM,iBAAiB,MAAM,MAAM,MAAM,OAAO,MAAM,MAAM,CAAC;AAC7D,QAAM,UAAU,eAAe,KAAK,IAAI,EAAE,KAAI;AAE9C,SAAO;IACL;IACA,UAAU;MACR,MAAM;MACN,WAAW,MAAM,QAAQ;MACzB,SAAS,MAAM,MAAM;MACrB,MAAM;MACN;;MAEA,SAAS,EAAE,WAAW,CAAA,GAAI,SAAS,CAAA,GAAI,YAAY,CAAA,EAAE;MACrD;;;AAGN;AAKA,SAAS,aAAa,OAAiB,cAAoB;AACzD,QAAM,YAAY,MAAM,SAAS,UAAU,MAAM,SAAS,YAAY;AACtE,SAAO,MAAM,QAAQ,SAAS,KAAK,aAAa;AAClD;AAMA,SAAS,qBACP,OACA,eACA,UACA,cACA,SACA,UAAgB;AAEhB,QAAM,kBAAkB,oBAAoB,eAAe,MAAM,MAAM;AAEvE,SAAO,gBACJ,IAAI,WAAS,qBAAqB,OAAO,OAAO,UAAU,UAAU,OAAO,CAAC,EAC5E,OAAO,WAAS,aAAa,OAAO,YAAY,CAAC;AACtD;AAKM,SAAU,aAAa,UAAgB;AAC3C,SAAO,eAAe,QAAQ;AAChC;;;ACpVA,SAAS,kBAAkB,eAAqB;AAC9C,MAAI;AAGF,QAAI,cAAc,cACf,QAAQ,2BAA2B,EAAE,EACrC,QAAQ,8BAA8B,EAAE,EACxC,KAAI;AAGP,UAAM,SAAS,KAAK,MAAM,WAAW;AAErC,WAAO,OAAO,OAAO,SAAS,WAAW,OAAO,OAAO;EACzD,SAASC,QAAO;EAGhB;AACA,SAAO;AACT;AASA,SAAS,eAAe,SAAe;AAErC,SAAO,QAAQ,QAAQ,8DAA8D,EAAE;AACzF;AAqBA,SAAS,kBAAkB,wBAA8B;AACvD,QAAM,eAAe,oBAAI,IAAG;AAI5B,QAAM,gBAAgB;AACtB,MAAIC;AAEJ,UAAQA,SAAQ,cAAc,KAAK,sBAAsB,OAAO,MAAM;AACpE,iBAAa,IAAIA,OAAM,CAAC,CAAC;EAC3B;AAGA,QAAM,iBAAiB;AAEvB,UAAQA,SAAQ,eAAe,KAAK,sBAAsB,OAAO,MAAM;AACrE,iBAAa,IAAIA,OAAM,CAAC,CAAC;EAC3B;AAGA,QAAM,iBAAiB;AAEvB,UAAQA,SAAQ,eAAe,KAAK,sBAAsB,OAAO,MAAM;AACrE,iBAAa,IAAIA,OAAM,CAAC,CAAC;EAC3B;AAEA,SAAO,MAAM,KAAK,YAAY;AAChC;AAWA,SAAS,iBAAiB,SAAe;AACvC,QAAM,QAAQ,QAAQ,MAAM,IAAI;AAChC,QAAM,SAAwB,CAAA;AAI9B,QAAM,gBAAgB;IACpB,EAAE,MAAM,UAAmB,OAAO,0BAA0B,KAAK,4BAA2B;IAC5F,EAAE,MAAM,SAAkB,OAAO,yBAAyB,KAAK,2BAA0B;IACzF,EAAE,MAAM,cAAuB,OAAO,8BAA8B,KAAK,gCAA+B;;AAG1G,aAAW,WAAW,eAAe;AACnC,QAAI,cAAc;AAElB,WAAO,cAAc,MAAM,QAAQ;AAEjC,YAAM,WAAW,MAAM,UAAU,CAAC,MAAM,QACtC,OAAO,eAAe,QAAQ,MAAM,KAAK,IAAI,CAAC;AAGhD,UAAI,aAAa;AAAI;AAGrB,YAAM,SAAS,MAAM,UAAU,CAAC,MAAM,QACpC,OAAO,YAAY,QAAQ,IAAI,KAAK,IAAI,CAAC;AAG3C,UAAI,WAAW,IAAI;AAEjB;MACF;AAGA,YAAM,eAAe,MAAM,MAAM,UAAU,SAAS,CAAC,EAAE,KAAK,IAAI;AAEhE,aAAO,KAAK;QACV,MAAM,QAAQ;QACd,WAAW;QACX,SAAS;QACT,SAAS;OACV;AAED,oBAAc,SAAS;IACzB;EACF;AAEA,SAAO,OAAO,KAAK,CAAC,GAAG,MAAM,EAAE,YAAY,EAAE,SAAS;AACxD;AAmBA,SAAS,gBACP,SACA,WACA,SACA,UACA,MACA,UAII,CAAA,GAAE;AAEN,SAAO;IACL;IACA,UAAU;MACR,MAAM;MACN;MACA;MACA,UAAU;MACV;MACA,YAAY,QAAQ;MACpB,YAAY,QAAQ;MACpB,SAAS,QAAQ,SAAS,SAAS,QAAQ,UAAU;;;AAG3D;AAKA,SAAS,gBACP,OACA,KACA,YACA,SAAiB;AAEjB,QAAM,SAAsB,CAAA;AAC5B,QAAM,aAAa,MAAM,QAAQ,MAAM,IAAI;AAC3C,QAAM,EAAE,WAAW,cAAc,SAAQ,IAAK,IAAI;AAElD,WAAS,SAAS,GAAG,SAAS,WAAW,QAAQ,UAAU,YAAY,cAAc;AACnF,UAAM,YAAY,KAAK,IAAI,SAAS,WAAW,WAAW,MAAM;AAChE,UAAM,eAAe,WAAW,MAAM,QAAQ,SAAS,EAAE,KAAK,IAAI;AAElE,QAAI,aAAa,KAAI,EAAG,SAAS,GAAG;AAClC,aAAO,KAAK,gBACV,cACA,MAAM,YAAY,SAAS,GAC3B,MAAM,YAAY,WAClB,UACA,SACA,EAAE,YAAY,YAAY,MAAM,MAAM,QAAO,CAAE,CAChD;IACH;AAEA,QAAI,aAAa,WAAW;AAAQ;EACtC;AAEA,SAAO;AACT;AAMA,SAAS,oBACP,OACA,KACA,cAAyB;AAGzB,WAAS,IAAI,MAAM,WAAW,KAAK,MAAM,SAAS,KAAK;AACrD,iBAAa,IAAI,CAAC;EACpB;AAGA,QAAM,aAAa,MAAM,SAAS,WAAW,kBAAkB,MAAM,OAAO,IAAI;AAGhF,QAAM,8BAA8B,IAAI,qBACrC,MAAM,MAAM,WAAW,MAAM,UAAU,CAAC,EACxC,KAAK,IAAI;AACZ,QAAM,UAAU,kBAAkB,2BAA2B;AAE7D,QAAM,iBAAiB,MAAM,UAAU,MAAM,YAAY;AACzD,QAAM,eAAe,IAAI,OAAO,YAAY;AAG5C,MAAI,kBAAkB,cAAc;AAClC,WAAO,CAAC,gBACN,MAAM,SACN,MAAM,YAAY,GAClB,MAAM,UAAU,GAChB,IAAI,OAAO,UACX,SACA,EAAE,YAAY,YAAY,MAAM,MAAM,QAAO,CAAE,CAChD;EACH;AAEA,SAAO,gBAAgB,OAAO,KAAK,YAAY,OAAO;AACxD;AAKA,SAAS,mBACP,cACA,gBACA,SACA,KAAiB;AAEjB,MAAI,aAAa,WAAW;AAAG,WAAO;AAEtC,QAAM,eAAe,aAAa,KAAK,IAAI;AAC3C,MAAI,aAAa,KAAI,EAAG,WAAW;AAAG,WAAO;AAE7C,QAAM,eAAe,IAAI,qBAAqB,MAAM,gBAAgB,OAAO,EAAE,KAAK,IAAI;AACtF,QAAM,UAAU,kBAAkB,YAAY;AAE9C,SAAO,gBACL,cACA,iBAAiB,GACjB,SACA,IAAI,OAAO,UACX,YACA,EAAE,QAAO,CAAE;AAEf;AAKA,SAAS,uBACP,KACA,cAAyB;AAEzB,QAAM,SAAsB,CAAA;AAC5B,QAAM,EAAE,OAAO,OAAM,IAAK;AAC1B,QAAM,EAAE,WAAW,aAAY,IAAK;AAEpC,MAAI,eAAyB,CAAA;AAC7B,MAAI,iBAAiB;AAErB,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AAErC,QAAI,aAAa,IAAI,CAAC,GAAG;AACvB,YAAM,QAAQ,mBAAmB,cAAc,gBAAgB,GAAG,GAAG;AACrE,UAAI;AAAO,eAAO,KAAK,KAAK;AAC5B,qBAAe,CAAA;AACf;IACF;AAGA,QAAI,aAAa,WAAW,GAAG;AAC7B,uBAAiB;IACnB;AAEA,iBAAa,KAAK,MAAM,CAAC,CAAC;AAG1B,QAAI,aAAa,UAAU,WAAW;AACpC,YAAM,QAAQ,mBAAmB,cAAc,gBAAgB,IAAI,GAAG,GAAG;AACzE,UAAI;AAAO,eAAO,KAAK,KAAK;AAG5B,qBAAe,aAAa,MAAM,CAAC,YAAY;AAC/C,uBAAiB,KAAK,IAAI,GAAG,IAAI,IAAI,YAAY;IACnD;EACF;AAGA,QAAM,aAAa,mBAAmB,cAAc,gBAAgB,MAAM,QAAQ,GAAG;AACrF,MAAI;AAAY,WAAO,KAAK,UAAU;AAEtC,SAAO;AACT;AAYM,SAAU,gBACd,UACA,SACA,YAAoB,IACpB,eAAuB,IAAE;AAGzB,QAAM,yBAAyB,eAAe,OAAO;AACrD,QAAM,MAAoB;IACxB,OAAO,QAAQ,MAAM,IAAI;IACzB,sBAAsB,uBAAuB,MAAM,IAAI;IACvD,QAAQ,EAAE,UAAU,WAAW,aAAY;;AAI7C,QAAM,SAAS,iBAAiB,OAAO;AACvC,QAAM,eAAe,oBAAI,IAAG;AAG5B,QAAM,cAAc,OAAO,QAAQ,WAAS,oBAAoB,OAAO,KAAK,YAAY,CAAC;AAGzF,QAAM,iBAAiB,uBAAuB,KAAK,YAAY;AAG/D,SAAO,CAAC,GAAG,aAAa,GAAG,cAAc,EAAE,KAAK,CAAC,GAAG,MAAM,EAAE,SAAS,YAAY,EAAE,SAAS,SAAS;AACvG;;;AC1XA,SAAS,yBAAyB,aAAmB;AACnD,MAAI;AACF,UAAM,WAAW,KAAK,MAAM,WAAW;AACvC,UAAM,eAAe,oBAAI,IAAG;AAG5B,QAAI,SAAS,YAAY,OAAO,SAAS,aAAa,UAAU;AAC9D,iBAAW,WAAW,OAAO,OAAO,SAAS,QAAQ,GAAG;AACtD,YACE,OAAO,YAAY,YACnB,YAAY,QACZ,UAAU,WACV,OAAO,QAAQ,SAAS,UACxB;AACA,uBAAa,IAAI,QAAQ,IAAI;QAC/B;MACF;IACF;AAEA,WAAO,MAAM,KAAK,YAAY;EAChC,SAASC,QAAO;AAEd,YAAQ,KAAK,yCAAyCA,kBAAiB,QAAQA,OAAM,UAAU,OAAOA,MAAK,CAAC,EAAE;AAC9G,WAAO,CAAA;EACT;AACF;AAQA,SAAS,oBAAoB,UAAgB;AAE3C,QAAMC,SAAQ,SAAS,MAAM,wBAAwB;AACrD,SAAOA,SAAQA,OAAM,CAAC,IAAI;AAC5B;AAQM,SAAU,kBACd,UACA,SAAe;AAGf,MAAI,QAAQ,KAAI,EAAG,WAAW,GAAG;AAC/B,WAAO,CAAA;EACT;AAEA,QAAM,QAAQ,QAAQ,MAAM,IAAI;AAChC,QAAM,eAAe,oBAAoB,QAAQ;AACjD,QAAM,oBAAoB,yBAAyB,OAAO;AAE1D,SAAO,CAAC;IACN;IACA,UAAU;MACR,MAAM;MACN,WAAW;MACX,SAAS,MAAM;MACf,UAAU;MACV,MAAM;MACN,YAAY;MACZ,YAAY;MACZ,SAAS,kBAAkB,SAAS,IAAI,oBAAoB;;GAE/D;AACH;;;AChFM,SAAU,UACd,UACA,SACA,UAAwB,CAAA,GAAE;AAE1B,QAAM,EAAE,YAAY,IAAI,eAAe,IAAI,SAAS,MAAM,cAAc,aAAY,IAAK;AAGzF,MAAI,SAAS,SAAS,SAAS,GAAG;AAChC,WAAO,gBAAgB,UAAU,SAAS,WAAW,YAAY;EACnE;AAMA,MAAI,SAAS,SAAS,OAAO,KAAK,sBAAsB,KAAK,QAAQ,GAAG;AACtE,WAAO,kBAAkB,UAAU,OAAO;EAC5C;AAGA,MAAI,UAAU,aAAa,QAAQ,GAAG;AACpC,QAAI;AACF,aAAO,WAAW,UAAU,SAAS;QACnC,cAAc,KAAK,MAAM,YAAY,EAAE;OACxC;IACH,SAASC,QAAO;AAEd,UAAI,gBAAgB,SAAS;AAE3B,cAAM,IAAI,MAAM,2BAA2B,QAAQ,KAAKA,kBAAiB,QAAQA,OAAM,UAAU,OAAOA,MAAK,CAAC,EAAE;MAClH;AAEA,cAAQ,KAAK,2BAA2B,QAAQ,iCAAiCA,MAAK;IACxF;EACF;AAGA,SAAO,aAAa,UAAU,SAAS,WAAW,YAAY;AAChE;AAKA,SAAS,aACP,UACA,SACA,WACA,cAAoB;AAEpB,QAAM,QAAQ,QAAQ,MAAM,IAAI;AAChC,QAAM,SAAsB,CAAA;AAC5B,QAAM,WAAW,eAAe,QAAQ;AAGxC,MAAI,MAAM,WAAW,KAAM,MAAM,WAAW,KAAK,MAAM,CAAC,EAAE,KAAI,MAAO,IAAK;AACxE,WAAO;EACT;AAGA,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK,YAAY,cAAc;AAC/D,UAAM,UAAU,KAAK,IAAI,IAAI,WAAW,MAAM,MAAM;AACpD,UAAM,aAAa,MAAM,MAAM,GAAG,OAAO;AACzC,UAAM,eAAe,WAAW,KAAK,IAAI;AAGzC,QAAI,aAAa,KAAI,EAAG,WAAW,GAAG;AACpC;IACF;AAGA,UAAM,UAAU,eAAe,cAAc,QAAQ;AAErD,WAAO,KAAK;MACV,SAAS;MACT,UAAU;QACR,MAAM;QACN,WAAW,IAAI;QACf;QACA,MAAM;;QACN;QACA;;KAEH;AAGD,QAAI,WAAW,MAAM,QAAQ;AAC3B;IACF;EACF;AAEA,SAAO;AACT;;;AC1GA,SAAS,UAAU,WAA2C;;;ACI9D,IAAY;CAAZ,SAAYC,gBAAa;AAEvB,EAAAA,eAAA,kBAAA,IAAA;AACA,EAAAA,eAAA,gBAAA,IAAA;AAGA,EAAAA,eAAA,iBAAA,IAAA;AACA,EAAAA,eAAA,iBAAA,IAAA;AAGA,EAAAA,eAAA,wBAAA,IAAA;AACA,EAAAA,eAAA,6BAAA,IAAA;AAGA,EAAAA,eAAA,gBAAA,IAAA;AACA,EAAAA,eAAA,mBAAA,IAAA;AACA,EAAAA,eAAA,cAAA,IAAA;AAGA,EAAAA,eAAA,eAAA,IAAA;AAGA,EAAAA,eAAA,gBAAA,IAAA;AACF,GAvBY,kBAAA,gBAAa,CAAA,EAAA;;;ACSnB,IAAO,YAAP,cAAyB,MAAK;EAGhB;EACA;EACA;EACA;EACA;EANlB,YACE,SACgB,MACA,SACA,WAA0B,UAC1B,cAAuB,MACvB,YAAqB,OAAK;AAE1C,UAAM,OAAO;AANG,SAAA,OAAA;AACA,SAAA,UAAA;AACA,SAAA,WAAA;AACA,SAAA,cAAA;AACA,SAAA,YAAA;AAGhB,SAAK,OAAO;AAGZ,QAAI,MAAM,mBAAmB;AAC3B,YAAM,kBAAkB,MAAM,KAAK,WAAW;IAChD;EACF;;;;EAKA,SAAM;AACJ,WAAO;MACL,OAAO,KAAK;MACZ,MAAM,KAAK;MACX,UAAU,KAAK;MACf,aAAa,KAAK;MAClB,SAAS,KAAK;;EAElB;;;;EAKA,cAAW;AACT,WAAO,KAAK;EACd;;;;EAKA,gBAAa;AACX,WAAO,KAAK;EACd;;AAMI,IAAO,cAAP,cAA2B,UAAS;EACxC,YAAY,SAAiB,SAAiC;AAC5D,UAAM,SAAS,cAAc,gBAAgB,SAAS,UAAU,MAAM,KAAK;AAC3E,SAAK,OAAO;EACd;;AAoBI,IAAO,iBAAP,cAA8B,UAAS;EAC3C,YAAY,SAAiB,SAAiC;AAC5D,UAAM,SAAS,cAAc,6BAA6B,SAAS,QAAQ,MAAM,IAAI;AACrF,SAAK,OAAO;EACd;;AAMI,IAAO,gBAAP,cAA6B,UAAS;EAC1C,YAAY,SAAiB,SAAiC;AAC5D,UAAM,SAAS,cAAc,gBAAgB,SAAS,QAAQ,MAAM,IAAI;AACxE,SAAK,OAAO;EACd;;AAUI,SAAU,UACdC,QACA,SACA,mBAA2C;AAE3C,QAAM,UAAUA,kBAAiB,QAAQA,OAAM,UAAU,OAAOA,MAAK;AACrE,QAAM,QAAQA,kBAAiB,QAAQA,OAAM,QAAQ;AAErD,QAAM,eAAe,IAAI,UACvB,GAAG,OAAO,KAAK,OAAO,IACtB,cAAc,gBACd,iBAAiB;AAInB,MAAI,OAAO;AACT,iBAAa,QAAQ,GAAG,aAAa,KAAK;;;EAAmB,KAAK;EACpE;AAEA,SAAO;AACT;;;AC5HO,IAAM,qBAAqB;AAC3B,IAAM,wBAAwB;AAG9B,IAAM,sBAAsB;AAC5B,IAAM,+BAA+B;AAKrC,IAAM,6BAA6B;AAInC,IAAM,2BAA2B;AAEjC,IAAM,2BAA2B;AAGjC,IAAM,uBAAuB;AAC7B,IAAM,0BAA0B;AAGhC,IAAM,eAAe;AAIrB,IAAM,+BAA+B;AAGrC,IAAM,sBAAsB;AAI5B,IAAM,yBAAyB;AAW/B,IAAM,uBAAuB;;;AH7CpC,IAAI,oBAAoB;AACxB,IAAI,mBAAmB;AAEjB,IAAO,kBAAP,MAAsB;EAClB,YAA8C;EACrC,YAAY;EACrB,cAAoC;EAE5C,MAAM,aAAU;AAEd,QAAI,KAAK,aAAa;AACpB,aAAO,KAAK;IACd;AAEA,QAAI,KAAK,WAAW;AAClB;IACF;AAEA,SAAK,eAAe,YAAW;AAC7B,UAAI;AAEF,aAAK,YAAY,MAAM,SAAS,sBAAsB,KAAK,SAAS;MACtE,SAASC,QAAgB;AACvB,aAAK,cAAc;AACnB,cAAM,UAAUA,QAAO,sCAAsC;MAC/D;IACF,GAAE;AAEF,WAAO,KAAK;EACd;EAEA,MAAM,MAAM,MAAY;AACtB,UAAM,KAAK,WAAU;AAErB,QAAI,CAAC,KAAK,WAAW;AACnB,YAAM,IAAI,eAAe,iCAAiC;IAC5D;AAEA,QAAI;AACF,YAAM,SAAS,MAAM,KAAK,UAAU,MAAM;QACxC,SAAS;QACT,WAAW;OACZ;AAED,aAAO,OAAO;IAChB,SAASA,QAAgB;AACvB,YAAM,UAAUA,QAAO,gCAAgC,EAAE,YAAY,KAAK,OAAM,CAAE;IACpF;EACF;EAEA,MAAM,WAAW,OAAe;AAC9B,UAAM,KAAK,WAAU;AAErB,QAAI,CAAC,KAAK,WAAW;AACnB,YAAM,IAAI,eAAe,iCAAiC;IAC5D;AAEA,QAAI;AAGF,YAAM,UAAU,MAAM,QAAQ,IAC5B,MAAM,IAAI,UAAQ,KAAK,MAAM,IAAI,CAAC,CAAC;AAErC,aAAO;IACT,SAASA,QAAgB;AACvB,YAAM,UAAUA,QAAO,uCAAuC,EAAE,WAAW,MAAM,OAAM,CAAE;IAC3F;EACF;;;;AIzEF,YAAY,aAAa;AACzB,OAAOC,WAAU;AACjB,OAAO,QAAQ;AACf,OAAO,YAAY;;;ACKZ,IAAM,sBAAsB;;;ACRnC,OAAOC,SAAQ;AACf,OAAOC,WAAU;AAEjB,IAAM,eAAe;AAQrB,eAAsB,iBAAiB,WAAiB;AACtD,MAAI;AACF,UAAM,kBAAkBA,MAAK,KAAK,WAAW,YAAY;AACzD,UAAM,YAAY,KAAK,IAAG,EAAG,SAAQ;AACrC,UAAMD,IAAG,UAAU,iBAAiB,WAAW,OAAO;EACxD,SAASE,QAAO;AAEd,YAAQ,MAAM,0CAA0CA,MAAK,EAAE;EACjE;AACF;AASA,eAAsB,gBAAgB,WAAiB;AACrD,MAAI;AACF,UAAM,kBAAkBD,MAAK,KAAK,WAAW,YAAY;AACzD,UAAM,UAAU,MAAMD,IAAG,SAAS,iBAAiB,OAAO;AAC1D,UAAM,YAAY,SAAS,QAAQ,KAAI,GAAI,EAAE;AAC7C,WAAO,MAAM,SAAS,IAAI,IAAI;EAChC,SAASE,QAAO;AAEd,WAAO;EACT;AACF;;;ACzBM,SAAU,mBAAmB,OAAa;AAC9C,MAAI,QAAQ;AAAK,WAAO;AACxB,MAAI,QAAQ;AAAK,WAAO;AACxB,MAAI,QAAQ;AAAK,WAAO;AACxB,SAAO;AACT;;;ACAA,IAAY;CAAZ,SAAYC,cAAW;AAErB,EAAAA,aAAA,UAAA,IAAA;AAGA,EAAAA,aAAA,YAAA,IAAA;AAGA,EAAAA,aAAA,gBAAA,IAAA;AACF,GATY,gBAAA,cAAW,CAAA,EAAA;AAwBvB,IAAM,eAA6B;;EAEjC;IACE,QAAQ,YAAY;IACpB,UAAU;IACV,UAAU;MACR;MACA;MACA;;;;EAKJ;IACE,QAAQ,YAAY;IACpB,UAAU;IACV,UAAU;MACR;MACA;MACA;MACA;MACA;;;;EAKJ;IACE,QAAQ,YAAY;IACpB,UAAU;IACV,UAAU;MACR;MACA;MACA;;;;AASN,IAAM,qBAAqB,aAAa;AAMxC,IAAI,oBAAyC;AAM7C,SAAS,iBAAc;AACrB,MAAI,sBAAsB,MAAM;AAC9B,wBAAoB,CAAC,GAAG,YAAY,EAAE,KAAK,CAAC,GAAG,MAAM,EAAE,WAAW,EAAE,QAAQ;EAC9E;AACA,SAAO;AACT;AAwBM,SAAU,oBAAoB,OAAa;AAC/C,QAAM,QAAQ,MAAM,YAAW,EAAG,KAAI;AAGtC,QAAM,cAAc,eAAc;AAElC,aAAW,QAAQ,aAAa;AAC9B,QAAI,KAAK,SAAS,KAAK,aAAW,QAAQ,KAAK,KAAK,CAAC,GAAG;AACtD,aAAO,KAAK;IACd;EACF;AAIA,SAAO,YAAY;AACrB;;;AC3IA,OAAOC,WAAU;AAOjB,SAAS,oBAAoB,UAAgB;AAC3C,QAAM,QAAQ,SAAS,YAAW;AAClC,QAAM,WAAWC,MAAK,SAAS,QAAQ,EAAE,YAAW;AAEpD,MAAI,SAAS,WAAW,QAAQ;AAAG,WAAO;AAC1C,MAAI,SAAS,WAAW,WAAW;AAAG,WAAO;AAC7C,MAAI,SAAS,SAAS,KAAK,KAAK,SAAS,SAAS,MAAM,KAAK,SAAS,SAAS,WAAW,GAAG;AAC3F,WAAO;EACT;AACA,MACE,MAAM,SAAS,QAAQ,KACvB,MAAM,SAAS,iBAAiB,KAChC,MAAM,SAAS,QAAQ,KACvB,MAAM,SAAS,WAAW,GAC1B;AACA,WAAO;EACT;AACA,MACE,MAAM,SAAS,cAAc,KAC7B,MAAM,SAAS,UAAU,KACzB,MAAM,SAAS,QAAQ,GACvB;AACA,WAAO;EACT;AAEA,SAAO;AACT;AAEA,SAAS,WAAW,UAAgB;AAClC,QAAM,QAAQ,SAAS,YAAW;AAElC,MACE,MAAM,SAAS,QAAQ,KACvB,MAAM,SAAS,SAAS,KACxB,MAAM,SAAS,aAAa,GAC5B;AACA,WAAO;EACT;AAEA,MACE,MAAM,SAAS,QAAQ,KACvB,MAAM,SAAS,QAAQ,KACvB,MAAM,SAAS,QAAQ,KACvB,MAAM,SAAS,QAAQ,GACvB;AACA,WAAO;EACT;AAEA,SAAO;AACT;AAEA,SAAS,cAAc,UAAgB;AACrC,QAAM,QAAQ,SAAS,YAAW;AAElC,MACE,MAAM,SAAS,SAAS,KACxB,MAAM,SAAS,aAAa,KAC5B,MAAM,SAAS,WAAW,KAC1B,MAAM,SAAS,OAAO,GACtB;AACA,WAAO;EACT;AAEA,MACE,MAAM,SAAS,QAAQ,KACvB,MAAM,SAAS,UAAU,KACzB,MAAM,SAAS,QAAQ,KACvB,MAAM,SAAS,UAAU,GACzB;AACA,WAAO;EACT;AAEA,SAAO;AACT;AAUM,IAAO,uBAAP,MAA2B;EAC/B,OAAO;EAEP,MAAM,OAAe,UAAkB,WAAiB;AACtD,UAAM,cAAc,MAAM,YAAW,EAAG,MAAM,KAAK;AACnD,UAAM,eAAe,SAAS,YAAW,EAAG,MAAM,GAAG;AAErD,QAAI,cAAc;AAElB,eAAW,SAAS,aAAa;AAC/B,UAAI,MAAM,UAAU;AAAG;AACvB,UAAI,aAAa,KAAK,SAAO,IAAI,SAAS,KAAK,CAAC,GAAG;AACjD,uBAAe;MACjB;IACF;AAEA,WAAO,YAAY;EACrB;;AAOI,IAAO,2BAAP,MAA+B;EACnC,OAAO;EAEP,MAAM,OAAe,UAAkB,WAAiB;AACtD,UAAM,WAAWA,MAAK,SAAS,UAAUA,MAAK,QAAQ,QAAQ,CAAC,EAAE,YAAW;AAC5E,UAAM,cAAc,MAAM,YAAW,EAAG,MAAM,KAAK;AAEnD,QAAI,cAAc;AAElB,eAAW,SAAS,aAAa;AAC/B,UAAI,MAAM,UAAU;AAAG;AAEvB,UAAI,aAAa,OAAO;AACtB,uBAAe;MACjB,WAAW,SAAS,SAAS,KAAK,GAAG;AACnC,uBAAe;MACjB;IACF;AAEA,WAAO,YAAY;EACrB;;AAYI,IAAO,2BAAP,MAA+B;EAGf;EAFpB,OAAO;EAEP,YAAoB,QAAmB;AAAnB,SAAA,SAAA;EAAsB;EAE1C,MAAM,OAAe,UAAkB,WAAiB;AACtD,YAAQ,KAAK,QAAQ;MACnB,KAAK,YAAY;AACf,eAAO,KAAK,sBAAsB,OAAO,UAAU,SAAS;MAE9D,KAAK,YAAY;AACf,eAAO,KAAK,wBAAwB,OAAO,UAAU,SAAS;MAEhE,KAAK,YAAY;AACf,eAAO,KAAK,4BAA4B,OAAO,UAAU,SAAS;MAEpE;AACE,eAAO;IACX;EACF;EAEQ,sBAAsB,QAAgB,UAAkB,OAAa;AAM3E,QAAI,WAAW,QAAQ,GAAG;AACxB,eAAS;IACX;AAEA,WAAO;EACT;EAEQ,wBAAwB,QAAgB,UAAkB,OAAa;AAM7E,QAAI,oBAAoB,QAAQ,GAAG;AACjC,eAAS;AAET,YAAM,QAAQ,SAAS,YAAW;AAClC,UACE,MAAM,SAAS,cAAc,KAC7B,MAAM,SAAS,UAAU,KACzB,MAAM,SAAS,MAAM,GACrB;AACA,iBAAS;MACX;IACF;AAGA,QAAI,cAAc,QAAQ,GAAG;AAC3B,eAAS;IACX;AAEA,WAAO;EACT;EAEQ,4BAA4B,QAAgB,UAAkB,OAAa;AAMjF,QAAI,WAAW,QAAQ,GAAG;AACxB,eAAS;IACX;AAEA,WAAO;EACT;;;;ACzMI,IAAO,mBAAP,MAAuB;EACnB,aAAiC,CAAA;;;;;;;;EASzC,YAAY,UAA0B;AACpC,SAAK,WAAW,KAAK,QAAQ;AAC7B,WAAO;EACT;;;;;;;;;EAUA,MAAM,OAAe,UAAkB,WAAiB;AACtD,QAAI,QAAQ;AAEZ,eAAW,YAAY,KAAK,YAAY;AACtC,cAAQ,SAAS,MAAM,OAAO,UAAU,KAAK;IAC/C;AAEA,WAAO;EACT;;;;;EAMA,mBAAgB;AACd,WAAO,KAAK,WAAW,IAAI,OAAK,EAAE,IAAI;EACxC;;;;EAKA,mBAAgB;AACd,WAAO,KAAK,WAAW;EACzB;;;;EAKA,QAAK;AACH,SAAK,aAAa,CAAA;EACpB;;;;ACvDF,IAAM,gBAAgB,IAAI,qBAAoB;AAC9C,IAAM,oBAAoB,IAAI,yBAAwB;AAMtD,IAAM,uBAAuB;EAC3B,CAAC,YAAY,QAAQ,GAAG,IAAI,yBAAyB,YAAY,QAAQ;EACzE,CAAC,YAAY,UAAU,GAAG,IAAI,yBAAyB,YAAY,UAAU;EAC7E,CAAC,YAAY,cAAc,GAAG,IAAI,yBAAyB,YAAY,cAAc;;AAQvF,IAAM,qBAAqB;EACzB,CAAC,YAAY,QAAQ,GAAG,IAAI,iBAAgB,EACzC,YAAY,aAAa,EACzB,YAAY,iBAAiB,EAC7B,YAAY,qBAAqB,YAAY,QAAQ,CAAC;EACzD,CAAC,YAAY,UAAU,GAAG,IAAI,iBAAgB,EAC3C,YAAY,aAAa,EACzB,YAAY,iBAAiB,EAC7B,YAAY,qBAAqB,YAAY,UAAU,CAAC;EAC3D,CAAC,YAAY,cAAc,GAAG,IAAI,iBAAgB,EAC/C,YAAY,aAAa,EACzB,YAAY,iBAAiB,EAC7B,YAAY,qBAAqB,YAAY,cAAc,CAAC;;AAsCjE,SAAS,cAAc,GAAW;AAChC,SAAO,QACL,EAAE,WACF,EAAE,QAAQ,KAAI,EAAG,SAAS,KAC1B,EAAE,QACF,EAAE,KAAK,SAAS,CAAC;AAErB;AAMA,SAAS,qBAAqB,KAAyB;AACrD,SAAO,QAAQ,OAAO,IAAI,SAAS,KAAK,IAAI,CAAC,MAAM,EAAE;AACvD;AAMA,SAAS,kBACP,GACA,YAA+C;AAE/C,MAAI,eAAe;AAAY,WAAO,EAAE,iBAAiB,CAAA;AACzD,MAAI,eAAe;AAAS,WAAO,EAAE,cAAc,CAAA;AACnD,MAAI,eAAe;AAAa,WAAO,EAAE,kBAAkB,CAAA;AAC3D,SAAO;IACL,GAAI,EAAE,iBAAiB,CAAA;IACvB,GAAI,EAAE,cAAc,CAAA;IACpB,GAAI,EAAE,kBAAkB,CAAA;;AAE5B;AAMA,SAAS,0BAA0B,GAAW;AAC5C,SAAO;IACL,MAAM,EAAE;IACR,WAAW,EAAE;IACb,SAAS,EAAE;IACX,MAAM,EAAE;IACR,UAAU,EAAE;IACZ,YAAY,EAAE,cAAc;IAC5B,YAAY,EAAE;IACd,aAAa,EAAE,eAAe;IAC9B,YAAY,EAAE,cAAc;IAC5B,qBAAqB,EAAE,uBAAuB;IAC9C,YAAY,qBAAqB,EAAE,UAAU,IAAI,EAAE,aAAa;IAChE,WAAW,EAAE,aAAa;IAC1B,SAAS,qBAAqB,EAAE,OAAO,IAAI,EAAE,UAAU;;IAEvD,gBAAgB,EAAE,kBAAkB,OAAO,EAAE,iBAAiB;IAC9D,oBAAoB,EAAE,sBAAsB,OAAO,EAAE,qBAAqB;IAC1E,gBAAgB,EAAE,kBAAkB,OAAO,EAAE,iBAAiB;IAC9D,cAAc,EAAE,gBAAgB,OAAO,EAAE,eAAe;;AAE5D;AAUA,SAAS,uBACP,OACA,UACA,WAAiB;AAEjB,MAAI,CAAC,OAAO;AACV,WAAO;EACT;AAEA,QAAM,SAAS,oBAAoB,KAAK;AAGxC,SAAO,mBAAmB,MAAM,EAAE,MAAM,OAAO,UAAU,SAAS;AACpE;AAKA,SAAS,uBACP,GACA,OAAc;AAEd,QAAM,YAAY,EAAE,aAAa;AACjC,QAAM,eAAe,uBAAuB,OAAO,EAAE,MAAM,SAAS;AAEpE,SAAO;IACL,SAAS,EAAE;IACX,UAAU,0BAA0B,CAAC;IACrC,OAAO;IACP,WAAW,mBAAmB,YAAY;;AAE9C;AAKA,eAAsB,OACpB,OACA,aACA,QAAgB,GAChB,OAAc;AAEd,MAAI,CAAC,OAAO;AACV,UAAM,IAAI,cAAc,iCAAiC;EAC3D;AAEA,MAAI;AACF,UAAM,UAAU,MAAM,MACnB,OAAO,MAAM,KAAK,WAAW,CAAC,EAC9B,MAAM,QAAQ,EAAE,EAChB,QAAO;AAEV,UAAM,WAAY,QACf,OAAO,aAAa,EACpB,IAAI,CAAC,MAAgB,uBAAuB,GAAG,KAAK,CAAC,EACrD,KAAK,CAAC,GAAG,MAAM,EAAE,QAAQ,EAAE,KAAK,EAChC,MAAM,GAAG,KAAK;AAEjB,WAAO;EACT,SAASC,QAAO;AACd,UAAM,WAAW,OAAOA,MAAK;AAG7B,QAAI,SAAS,SAAS,YAAY,KAAK,SAAS,SAAS,QAAQ,GAAG;AAClE,YAAM,IAAI,cACR,sHACA,EAAE,eAAeA,OAAK,CAAE;IAE5B;AAEA,UAAM,UAAUA,QAAO,kCAAkC;EAC3D;AACF;AAKA,eAAsB,eACpB,OACA,SAIC;AAED,MAAI,CAAC,OAAO;AACV,UAAM,IAAI,cAAc,iCAAiC;EAC3D;AAEA,QAAM,EAAE,UAAU,SAAS,QAAQ,IAAG,IAAK;AAE3C,MAAI;AACF,UAAM,aAAa,MAAM,mBAAmB,EAAE,KAAK,CAAC;AACpD,UAAM,QAAQ,MAAM,OAAO,UAAU,EAClC,MAAM,YAAY,EAClB,MAAM,KAAK,IAAI,QAAQ,GAAG,GAAG,CAAC;AAEjC,UAAM,UAAU,MAAM,MAAM,QAAO;AAEnC,QAAI,WAAY,QAAkC,OAAO,aAAa;AAEtE,QAAI,UAAU;AACZ,iBAAW,SAAS,OAAO,CAAC,MAC1B,EAAE,YAAY,EAAE,SAAS,YAAW,MAAO,SAAS,YAAW,CAAE;IAErE;AAEA,QAAI,SAAS;AACX,YAAM,QAAQ,IAAI,OAAO,SAAS,GAAG;AACrC,iBAAW,SAAS,OAAO,CAAC,MAC1B,MAAM,KAAK,EAAE,OAAO,KAAK,MAAM,KAAK,EAAE,IAAI,CAAC;IAE/C;AAEA,WAAO,SAAS,MAAM,GAAG,KAAK,EAAE,IAAI,CAAC,OAAiB;MACpD,SAAS,EAAE;MACX,UAAU,0BAA0B,CAAC;MACrC,OAAO;MACP,WAAW,mBAAmB,CAAC;MAC/B;EACJ,SAASA,QAAO;AACd,UAAM,UAAUA,QAAO,4BAA4B;EACrD;AACF;AAMA,IAAM,sBAAmD;EACvD,UAAU,oBAAI,IAAI,CAAC,YAAY,QAAQ,CAAC;EACxC,OAAO,oBAAI,IAAI,CAAC,OAAO,CAAC;EACxB,WAAW,oBAAI,IAAI,CAAC,WAAW,CAAC;;AAGlC,SAAS,kBACP,QACA,YACA,SAAiB;AAGjB,MAAI,OAAO,YAAY;AACrB,WAAO,oBAAoB,UAAU,GAAG,IAAI,OAAO,UAAU,KAAK;EACpE;AAGA,SAAO,QAAQ,SAAS,KAAK,QAAQ,KAAK,CAAC,MAAc,EAAE,SAAS,KAAK,MAAM,EAAE;AACnF;AAYA,SAAS,oBACP,GACA,EAAE,UAAU,SAAS,WAAU,GAAsB;AAGrD,MAAI,aAAa,CAAC,EAAE,YAAY,EAAE,SAAS,YAAW,MAAO,SAAS,YAAW,IAAK;AACpF,WAAO;EACT;AAEA,QAAM,UAAU,kBAAkB,GAAG,UAAU;AAC/C,QAAM,gBAAgB,EAAE,cAAc;AAGtC,MAAI,QAAQ,WAAW,KAAK,CAAC,eAAe;AAC1C,WAAO;EACT;AAGA,MAAI,SAAS;AACX,UAAM,QAAQ,IAAI,OAAO,SAAS,GAAG;AACrC,UAAM,cAAc,QAAQ,KAAK,CAAC,MAAc,MAAM,KAAK,CAAC,CAAC,KAAK,MAAM,KAAK,aAAa;AAC1F,QAAI,CAAC;AAAa,aAAO;EAC3B;AAGA,MAAI,YAAY;AACd,WAAO,kBAAkB,GAAG,YAAY,OAAO;EACjD;AAEA,SAAO;AACT;AAKA,SAASC,oBAAmB,GAAW;AACrC,SAAO;IACL,WAAW,qBAAqB,EAAE,aAAa,IAAI,EAAE,gBAAgB,CAAA;IACrE,SAAS,qBAAqB,EAAE,UAAU,IAAI,EAAE,aAAa,CAAA;IAC7D,YAAY,qBAAqB,EAAE,cAAc,IAAI,EAAE,iBAAiB,CAAA;;AAE5E;AAKA,eAAsB,aACpB,OACA,SAKC;AAED,MAAI,CAAC,OAAO;AACV,UAAM,IAAI,cAAc,iCAAiC;EAC3D;AAEA,QAAM,EAAE,UAAU,SAAS,YAAY,QAAQ,GAAE,IAAK;AACtD,QAAM,aAAiC,EAAE,UAAU,SAAS,WAAU;AAEtE,MAAI;AACF,UAAM,aAAa,MAAM,mBAAmB,EAAE,KAAK,CAAC;AACpD,UAAM,QAAQ,MAAM,OAAO,UAAU,EAClC,MAAM,YAAY,EAClB,MAAM,KAAK,IAAI,QAAQ,IAAI,GAAG,CAAC;AAElC,UAAM,UAAU,MAAM,MAAM,QAAO;AAEnC,UAAM,WAAY,QACf,OAAO,CAAC,MAAM,cAAc,CAAC,KAAK,oBAAoB,GAAG,UAAU,CAAC;AAEvE,WAAO,SAAS,MAAM,GAAG,KAAK,EAAE,IAAI,CAAC,OAAiB;MACpD,SAAS,EAAE;MACX,UAAU;QACR,GAAG,0BAA0B,CAAC;QAC9B,SAASA,oBAAmB,CAAC;;MAE/B,OAAO;MACP,WAAW,mBAAmB,CAAC;MAC/B;EACJ,SAASD,QAAO;AACd,UAAM,UAAUA,QAAO,yBAAyB;EAClD;AACF;AAOA,eAAsB,QACpB,OACA,UAGI,CAAA,GAAE;AAEN,MAAI,CAAC,OAAO;AACV,UAAM,IAAI,cAAc,iCAAiC;EAC3D;AAEA,MAAI;AAEF,UAAM,YAAY,MAAM,MAAM,UAAS;AAMvC,UAAM,iBAAiB;AACvB,UAAM,UAAU,MAAM,eAAe,OAAO;MAC1C,GAAG;MACH,OAAO,KAAK,IAAI,WAAW,cAAc;KAC1C;AAED,WAAO;EACT,SAASA,QAAO;AACd,UAAM,UAAUA,QAAO,2BAA2B;EACpD;AACF;;;AC9XA,SAAS,uBACP,QACA,SACA,UAAuB;AAEvB,SAAO;IACL,QAAQ,MAAM,KAAK,MAAM;IACzB;IACA,MAAM,SAAS;IACf,WAAW,SAAS;IACpB,SAAS,SAAS;IAClB,MAAM,SAAS;IACf,UAAU,SAAS;;IAEnB,eAAe,iBAAiB,SAAS,SAAS,SAAS;IAC3D,YAAY,iBAAiB,SAAS,SAAS,OAAO;IACtD,gBAAgB,iBAAiB,SAAS,SAAS,UAAU;;IAE7D,YAAY,SAAS,cAAc;IACnC,YAAY,SAAS,cAAc;IACnC,aAAa,SAAS,eAAe;IACrC,YAAY,SAAS,cAAc;IACnC,qBAAqB,SAAS,uBAAuB;IACrD,YAAY,iBAAiB,SAAS,UAAU;IAChD,WAAW,SAAS,aAAa;IACjC,SAAS,iBAAiB,SAAS,OAAO;;IAE1C,gBAAgB,SAAS,kBAAkB;IAC3C,oBAAoB,SAAS,sBAAsB;IACnD,gBAAgB,SAAS,kBAAkB;IAC3C,cAAc,SAAS,gBAAgB;;AAE3C;AAKA,SAAS,iBAAiB,KAAyB;AACjD,SAAO,OAAO,IAAI,SAAS,IAAI,MAAM,CAAC,EAAE;AAC1C;AAKA,SAAS,iBAAiB,OAAqB;AAC7C,QAAM,OAAO,KAAK,MAAM,MAAM,QAAQ,SAAS,CAAC;AAChD,SAAO;IACL;MACE,SAAS,MAAM,QAAQ,MAAM,GAAG,IAAI;MACpC,WAAW,MAAM,UAAU,MAAM,GAAG,IAAI;MACxC,UAAU,MAAM,SAAS,MAAM,GAAG,IAAI;;IAExC;MACE,SAAS,MAAM,QAAQ,MAAM,IAAI;MACjC,WAAW,MAAM,UAAU,MAAM,IAAI;MACrC,UAAU,MAAM,SAAS,MAAM,IAAI;;;AAGzC;AAKA,SAAS,wBAAwB,OAAqB;AACpD,SAAO,MAAM,QAAQ,IAAI,CAAC,QAAQ,MAChC,uBAAuB,QAAQ,MAAM,SAAS,CAAC,GAAG,MAAM,UAAU,CAAC,CAAC,CAAC;AAEzE;AAUA,eAAsB,YACpB,IACA,OACA,WACA,SACA,WACA,UAAkB;AAElB,MAAI,CAAC,IAAI;AACP,UAAM,IAAI,cAAc,iCAAiC;EAC3D;AAEA,MAAI,QAAQ,WAAW,UAAU,UAAU,QAAQ,WAAW,SAAS,QAAQ;AAC7E,UAAM,IAAI,cAAc,qEAAqE;MAC3F,eAAe,QAAQ;MACvB,iBAAiB,UAAU;MAC3B,gBAAgB,SAAS;KAC1B;EACH;AAGA,MAAI,QAAQ,WAAW,GAAG;AACxB,WAAO;EACT;AAGA,MAAI,QAAQ,SAAS,0BAA0B;AAC7C,QAAI,eAAe;AACnB,aAAS,IAAI,GAAG,IAAI,QAAQ,QAAQ,KAAK,0BAA0B;AACjE,YAAM,eAAe,QAAQ,MAAM,GAAG,KAAK,IAAI,IAAI,0BAA0B,QAAQ,MAAM,CAAC;AAC5F,YAAM,gBAAgB,UAAU,MAAM,GAAG,KAAK,IAAI,IAAI,0BAA0B,QAAQ,MAAM,CAAC;AAC/F,YAAM,gBAAgB,SAAS,MAAM,GAAG,KAAK,IAAI,IAAI,0BAA0B,QAAQ,MAAM,CAAC;AAE9F,qBAAe,MAAM,oBAAoB,IAAI,cAAc,WAAW,cAAc,eAAe,aAAa;IAClH;AACA,QAAI,CAAC,cAAc;AACjB,YAAM,IAAI,cAAc,4CAA4C;IACtE;AACA,WAAO;EACT,OAAO;AACL,WAAO,oBAAoB,IAAI,OAAO,WAAW,SAAS,WAAW,QAAQ;EAC/E;AACF;AAQA,eAAe,oBACb,IACA,OACA,WACA,SACA,WACA,UAAkB;AAElB,QAAM,QAA0B,CAAC,EAAE,SAAS,WAAW,SAAQ,CAAE;AACjE,QAAM,gBAAkC,CAAA;AACxC,MAAI,eAAe;AACnB,MAAI;AAEJ,SAAO,MAAM,SAAS,GAAG;AACvB,UAAM,QAAQ,MAAM,MAAK;AACzB,UAAM,eAAe,MAAM,eAAe,IAAI,cAAc,WAAW,KAAK;AAE5E,QAAI,aAAa,SAAS;AACxB,qBAAe,aAAa;IAC9B,OAAO;AACL,kBAAY,aAAa;AACzB,yBAAmB,OAAO,OAAO,aAAa;IAChD;EACF;AAEA,uBAAqB,eAAe,SAAS;AAE7C,MAAI,CAAC,cAAc;AACjB,UAAM,IAAI,cAAc,4CAA4C;EACtE;AAEA,SAAO;AACT;AAeA,eAAe,eACb,IACA,cACA,WACA,OAAqB;AAErB,MAAI;AACF,UAAM,UAAU,wBAAwB,KAAK;AAE7C,QAAI,CAAC,cAAc;AACjB,YAAM,WAAW,MAAM,GAAG,YAAY,WAAW,OAAO;AACxD,aAAO,EAAE,SAAS,MAAM,OAAO,SAAQ;IACzC,OAAO;AACL,YAAM,aAAa,IAAI,OAAO;AAC9B,aAAO,EAAE,SAAS,MAAM,OAAO,aAAY;IAC7C;EACF,SAASE,QAAO;AAEd,WAAO,EAAE,SAAS,OAAO,OAAO,cAAc,OAAOA,OAAc;EACrE;AACF;AAKA,SAAS,mBACP,OACA,OACA,eAA+B;AAE/B,MAAI,MAAM,QAAQ,SAAS,0BAA0B;AAEnD,UAAM,CAAC,WAAW,UAAU,IAAI,iBAAiB,KAAK;AACtD,UAAM,KAAK,WAAW,UAAU;EAClC,OAAO;AAEL,kBAAc,KAAK,KAAK;EAC1B;AACF;AAMA,SAAS,qBAAqB,eAAiC,WAAiB;AAC9E,MAAI,cAAc,WAAW;AAAG;AAEhC,QAAM,cAAc,cAAc,OAAO,CAAC,KAAK,UAAU,MAAM,MAAM,QAAQ,QAAQ,CAAC;AACtF,QAAM,IAAI,cACR,oBAAoB,WAAW,mCAC/B;IACE,eAAe,cAAc;IAC7B,cAAc;IACd,YAAY,cAAc,CAAC,EAAE,UAAU,CAAC,EAAE;IAC1C,WAAW,WAAW;GACvB;AAEL;;;AC3RA,OAAOC,SAAQ;AACf,OAAOC,WAAU;AAgBjB,eAAsB,MACpB,IACA,OACA,WACA,QAAe;AAEf,MAAI,CAAC,IAAI;AACP,UAAM,IAAI,cAAc,iCAAiC;EAC3D;AAEA,MAAI;AAGF,QAAI,QAAQ;AACV,YAAM,WAAWC,MAAK,KAAK,QAAQ,GAAG,SAAS,QAAQ;AACvD,UAAI;AACF,cAAMC,IAAG,GAAG,UAAU,EAAE,WAAW,MAAM,OAAO,KAAI,CAAE;MACxD,SAAS,KAAU;AAEjB,YAAI,KAAK,SAAS,eAAe,KAAK,SAAS,SAAS,WAAW,GAAG;AACpE,cAAI;AACF,kBAAM,GAAG,UAAU,SAAS;AAE5B,kBAAMA,IAAG,GAAG,UAAU,EAAE,WAAW,MAAM,OAAO,KAAI,CAAE;UACxD,QAAQ;UAER;QACF;MACF;IACF,OAAO;AAEL,UAAI,OAAO;AACT,cAAM,GAAG,UAAU,SAAS;MAC9B;IACF;EACF,SAASC,QAAO;AACd,UAAM,UAAUA,QAAO,iCAAiC;EAC1D;AACF;AAKA,eAAsB,aACpB,OACA,UAAgB;AAEhB,MAAI,CAAC,OAAO;AACV,UAAM,IAAI,cAAc,iCAAiC;EAC3D;AAEA,MAAI;AACF,UAAM,MAAM,OAAO,WAAW,QAAQ,GAAG;EAC3C,SAASA,QAAO;AACd,UAAM,UAAUA,QAAO,4CAA4C;EACrE;AACF;AAKA,eAAsB,WACpB,IACA,OACA,WACA,QACA,UACA,SACA,WACA,UAAkB;AAElB,MAAI,CAAC,OAAO;AACV,UAAM,IAAI,cAAc,iCAAiC;EAC3D;AAEA,MAAI;AAEF,UAAM,aAAa,OAAO,QAAQ;AAGlC,QAAI,eAAe;AACnB,QAAI,QAAQ,SAAS,GAAG;AACtB,qBAAe,MAAM,YAAY,IAAI,OAAO,WAAW,SAAS,WAAW,QAAQ;AACnF,UAAI,CAAC,cAAc;AACjB,cAAM,IAAI,cAAc,wCAAwC;MAClE;IACF;AAGA,UAAM,iBAAiB,MAAM;AAE7B,WAAO;EACT,SAASA,QAAO;AACd,UAAM,UAAUA,QAAO,0CAA0C;EACnE;AACF;;;AThGM,IAAO,WAAP,MAAO,UAAQ;EACX,KAA+B;EAC/B,QAA6B;EACrB;EACC,YAAY;EACrB,mBAA2B;EAC3B,iBAAyB;EAEjC,YAAY,aAAmB;AAE7B,UAAM,cAAcC,MAAK,SAAS,WAAW;AAG7C,UAAM,WAAW,OACd,WAAW,KAAK,EAChB,OAAO,WAAW,EAClB,OAAO,KAAK,EACZ,UAAU,GAAG,CAAC;AAEjB,SAAK,SAASA,MAAK,KACjB,GAAG,QAAO,GACV,SACA,WACA,GAAG,WAAW,IAAI,QAAQ,EAAE;EAEhC;EAEA,MAAM,aAAU;AACd,QAAI;AACF,WAAK,KAAK,MAAc,gBAAQ,KAAK,MAAM;AAE3C,UAAI;AACF,aAAK,QAAQ,MAAM,KAAK,GAAG,UAAU,KAAK,SAAS;MACrD,QAAQ;AAEN,aAAK,QAAQ;MACf;AAGA,UAAI;AACF,aAAK,iBAAiB,MAAM,gBAAgB,KAAK,MAAM;MACzD,QAAQ;AAEN,aAAK,iBAAiB;MACxB;IACF,SAASC,QAAgB;AACvB,YAAM,UAAUA,QAAO,wCAAwC,EAAE,QAAQ,KAAK,OAAM,CAAE;IACxF;EACF;EAEA,MAAM,YACJ,SACA,WACA,UAAkB;AAElB,QAAI,CAAC,KAAK,IAAI;AACZ,YAAM,IAAI,cAAc,iCAAiC;IAC3D;AAGA,SAAK,QAAQ,MAAe,YAC1B,KAAK,IACL,KAAK,OACL,KAAK,WACL,SACA,WACA,QAAQ;EAEZ;EAEA,MAAM,OACJ,aACA,QAAgB,GAChB,OAAc;AAEd,QAAI,CAAC,KAAK,OAAO;AACf,YAAM,IAAI,cAAc,iCAAiC;IAC3D;AAEA,QAAI;AACF,aAAO,MAAe,OAAO,KAAK,OAAO,aAAa,OAAO,KAAK;IACpE,SAASA,QAAO;AACd,YAAM,WAAW,OAAOA,MAAK;AAG7B,UAAI,SAAS,SAAS,YAAY,KAAK,SAAS,SAAS,QAAQ,GAAG;AAElE,YAAI;AACF,gBAAM,KAAK,WAAU;AACrB,cAAI,CAAC,KAAK,OAAO;AACf,kBAAM,IAAI,cAAc,oDAAoD;UAC9E;AACA,iBAAO,MAAe,OAAO,KAAK,OAAO,aAAa,OAAO,KAAK;QACpE,SAAS,YAAqB;AAC5B,gBAAM,IAAI,cACR,sHACA,EAAE,eAAe,WAAU,CAAE;QAEjC;MACF;AAEA,YAAMA;IACR;EACF;EAEA,MAAM,eAAe,SAIpB;AACC,QAAI,CAAC,KAAK,OAAO;AACf,YAAM,IAAI,cAAc,iCAAiC;IAC3D;AACA,WAAgB,eAAe,KAAK,OAAO,OAAO;EACpD;;;;;;;EAQA,MAAM,QAAQ,UAGV,CAAA,GAAE;AACJ,QAAI,CAAC,KAAK,OAAO;AACf,YAAM,IAAI,cAAc,iCAAiC;IAC3D;AACA,WAAgB,QAAQ,KAAK,OAAO,OAAO;EAC7C;EAEA,MAAM,aAAa,SAKlB;AACC,QAAI,CAAC,KAAK,OAAO;AACf,YAAM,IAAI,cAAc,iCAAiC;IAC3D;AACA,WAAgB,aAAa,KAAK,OAAO,OAAO;EAClD;EAEA,MAAM,QAAK;AACT,QAAI,CAAC,KAAK,IAAI;AACZ,YAAM,IAAI,cAAc,iCAAiC;IAC3D;AAEA,SAAK,QAAQ;AACb,UAAqB,MAAM,KAAK,IAAI,MAAM,KAAK,WAAW,KAAK,MAAM;EACvE;EAEA,MAAM,aAAa,UAAgB;AACjC,QAAI,CAAC,KAAK,OAAO;AACf,YAAM,IAAI,cAAc,iCAAiC;IAC3D;AACA,UAAqB,aAAa,KAAK,OAAO,QAAQ;EACxD;EAEA,MAAM,WACJ,UACA,SACA,WACA,UAAkB;AAElB,QAAI,CAAC,KAAK,IAAI;AACZ,YAAM,IAAI,cAAc,4CAA4C;IACtE;AACA,QAAI,CAAC,KAAK,OAAO;AACf,YAAM,IAAI,cAAc,uCAAuC;IACjE;AACA,SAAK,QAAQ,MAAqB,WAChC,KAAK,IACL,KAAK,OACL,KAAK,WACL,KAAK,QACL,UACA,SACA,WACA,QAAQ;EAEZ;EAEA,MAAM,eAAY;AAChB,UAAM,MAAM,KAAK,IAAG;AAGpB,QAAI,MAAM,KAAK,mBAAmB,KAAM;AACtC,aAAO;IACT;AAEA,SAAK,mBAAmB;AAExB,QAAI;AACF,YAAM,UAAU,MAAM,gBAAgB,KAAK,MAAM;AAEjD,UAAI,UAAU,KAAK,gBAAgB;AACjC,aAAK,iBAAiB;AACtB,eAAO;MACT;AAEA,aAAO;IACT,SAASA,QAAO;AAEd,aAAO;IACT;EACF;EAEA,MAAM,YAAS;AACb,QAAI;AAEF,WAAK,QAAQ;AACb,WAAK,KAAK;AAGV,YAAM,KAAK,WAAU;IACvB,SAASA,QAAO;AACd,YAAM,UAAUA,QAAO,wCAAwC;IACjE;EACF;EAEA,oBAAiB;AACf,WAAO,KAAK;EACd;EAEA,iBAAc;AACZ,QAAI,KAAK,mBAAmB,GAAG;AAC7B,aAAO;IACT;AACA,WAAO,IAAI,KAAK,KAAK,cAAc,EAAE,eAAc;EACrD;EAEA,MAAM,UAAO;AACX,QAAI,CAAC,KAAK,OAAO;AACf,aAAO;IACT;AAEA,QAAI;AACF,YAAM,QAAQ,MAAM,KAAK,MAAM,UAAS;AAExC,UAAI,UAAU,GAAG;AACf,eAAO;MACT;AAGA,YAAM,SAAS,MAAM,KAAK,MACvB,OAAO,MAAM,mBAAmB,EAAE,KAAK,CAAC,CAAC,EACzC,MAAM,KAAK,IAAI,OAAO,CAAC,CAAC,EACxB,QAAO;AAEV,YAAM,cAAe,OAA4B,KAAK,CAAC,MACrD,EAAE,WACF,EAAE,QAAQ,KAAI,EAAG,SAAS,CAAC;AAG7B,aAAO;IACT,QAAQ;AAEN,aAAO;IACT;EACF;EAEA,aAAa,KAAK,aAAmB;AACnC,UAAM,KAAK,IAAI,UAAS,WAAW;AACnC,UAAM,GAAG,WAAU;AACnB,WAAO;EACT;;;;AU3RF,OAAOC,SAAQ;AACf,OAAOC,WAAU;;;ACuGX,SAAU,eACd,QAAqC;AAErC,SAAO,cAAc,UAAU,EAAE,gBAAgB;AACnD;AAOM,SAAU,eACd,QAAqC;AAErC,SAAO,gBAAgB;AACzB;AAMO,IAAM,gBAA4B;EACvC,SAAS;EACT,MAAM;IACJ,WAAW;IACX,cAAc;IACd,aAAa;IACb,oBAAoB;;EAEtB,UAAU;IACR,QAAQ;;IACR,aAAa;;;EAEf,KAAK;IACH,MAAM;IACN,WAAW;IACX,qBAAqB;;EAEvB,cAAc;IACZ,SAAS;IACT,gBAAgB;;EAElB,cAAc;IACZ,SAAS;;IACT,YAAY;;EAEd,YAAY;IACV,SAAS;IACT,YAAY;MACV,WAAW;;MACX,YAAY;;MACZ,yBAAyB;;MACzB,eAAe;;;;EAGnB,YAAY,CAAA;;;;;ACrJR,SAAU,gBAAgBC,WAAsB,MAAyB;AAC7E,SAAO;IACL,SAAS,KAAK,WAAWA,UAAS;IAClC,MAAM;MACJ,GAAGA,UAAS;MACZ,GAAG,KAAK;;IAEV,UAAU;MACR,GAAGA,UAAS;MACZ,GAAG,KAAK;;IAEV,KAAK;MACH,GAAGA,UAAS;MACZ,GAAG,KAAK;;IAEV,cAAc;MACZ,GAAGA,UAAS;MACZ,GAAG,KAAK;;IAEV,cAAc;MACZ,GAAGA,UAAS;MACZ,GAAG,KAAK;;IAEV,YAAY,KAAK,aAAa;MAC5B,SAAS,KAAK,WAAW,WAAWA,UAAS,YAAY,WAAW;MACpE,YAAY;QACV,GAAGA,UAAS,YAAY;QACxB,GAAI,KAAK,WAAW,cAAc,CAAA;;QAElCA,UAAS;IACb,YAAY,KAAK,cAAcA,UAAS;;AAE5C;;;AClCM,SAAU,eAAe,QAAW;AAMxC,MAAI,CAAC,QAAQ;AACX,WAAO;EACT;AAGA,MAAI,OAAO,eAAe,UAAa,CAAC,OAAO,UAAU;AACvD,WAAO;EACT;AAGA,MAAI,OAAO,eAAe,UAAa,OAAO,aAAa,QAAW;AACpE,WAAO;EACT;AAGA,MAAI,OAAO,aAAa,QAAW;AACjC,WAAO;EACT;AAGA,MAAI,OAAO,WAAW,OAAO,QAAQ,WAAW,KAAK,GAAG;AACtD,WAAO;EACT;AAEA,SAAO;AACT;AAOM,SAAU,cAAc,WAAmD,eAAsB;AAErG,QAAM,YAAwB;IAC5B,SAAS,iBAAiB;IAC1B,MAAM;MACJ,WAAY,UAAkB,UAAU,aAAc,UAAkB,MAAM,aAAa,cAAc,KAAK;MAC9G,cAAe,UAAkB,UAAU,gBAAiB,UAAkB,MAAM,gBAAgB,cAAc,KAAK;MACvH,aAAc,UAAkB,UAAU,eAAgB,UAAkB,MAAM,eAAe,cAAc,KAAK;MACpH,oBAAqB,UAAkB,UAAU,sBAAuB,UAAkB,MAAM,sBAAsB,cAAc,KAAK;;IAE3I,UAAU;MACR,QAAS,UAAkB,UAAU,UAAU,cAAc,SAAS;MACtE,aAAc,UAAkB,UAAU,eAAe,cAAc,SAAS;;IAElF,KAAK;MACH,MAAM,UAAU,KAAK,QAAQ,cAAc,IAAI;MAC/C,WAAW,UAAU,KAAK,aAAa,cAAc,IAAI;MACzD,qBAAqB,UAAU,KAAK,uBAAuB,cAAc,IAAI;;IAE/E,cAAc;MACZ,SAAS,UAAU,cAAc,WAAW,cAAc,aAAa;MACvE,gBAAgB,UAAU,cAAc,kBAAkB,cAAc,aAAa;;IAEvF,cAAc;MACZ,SAAS,UAAU,cAAc,WAAW,cAAc,aAAa;MACvE,YAAY,UAAU,cAAc,cAAc,cAAc,aAAa;;IAE/E,YAAa,UAAkB,cAAc,CAAA;;AAI/C,MAAK,UAAkB,YAAY,UAAU,WAAW,WAAW,GAAG;AACpE,UAAM,mBAAsC;MAC1C,MAAM;MACN,MAAM;MACN,SAAS;MACT,QAAQ;QACN,SAAU,UAAkB,SAAS,WAAW,CAAC,iDAAiD;QAClG,SAAU,UAAkB,SAAS,WAAW;UAC9C;UACA;UACA;UACA;UACA;UACA;UACA;UACA;;;;AAKN,cAAU,WAAW,KAAK,gBAAgB;EAC5C,WAAW,UAAU,WAAW,WAAW,GAAG;AAE5C,UAAM,mBAAsC;MAC1C,MAAM;MACN,MAAM;MACN,SAAS;MACT,QAAQ;QACN,SAAS,CAAC,iDAAiD;QAC3D,SAAS;UACP;UACA;UACA;UACA;UACA;UACA;UACA;UACA;;;;AAKN,cAAU,WAAW,KAAK,gBAAgB;EAC5C;AAEA,SAAO;AACT;;;AH3FM,IAAO,gBAAP,MAAO,eAAa;EAChB,OAAgB,kBAAkB;;;;;;;;;EAU1C,MAAM,KAAK,UAAkB,QAAQ,IAAG,GAAE;AACxC,UAAM,aAAa,KAAK,cAAc,OAAO;AAE7C,QAAI;AACF,YAAM,gBAAgB,MAAMC,IAAG,SAAS,YAAY,OAAO;AAC3D,YAAM,aAAa,KAAK,MAAM,aAAa;AAG3C,UAAI,KAAK,eAAe,UAAU,GAAG;AACnC,gBAAQ,IAAI,qDAA8C;AAE1D,cAAM,SAAS,MAAM,KAAK,QAAQ,OAAO;AAEzC,YAAI,OAAO,YAAY,OAAO,YAAY;AACxC,gBAAM,iBAAiBC,MAAK,SAAS,OAAO,UAAU;AACtD,kBAAQ,IAAI,8CAAyC,cAAc,EAAE;AACrE,kBAAQ,IAAI,+DAAwD;QACtE;AAEA,eAAO,OAAO;MAChB;AAGA,YAAM,eAAe,gBAAgB,eAAe,UAAiC;AAGrF,YAAM,aAAa,KAAK,SAAS,YAAY;AAC7C,UAAI,CAAC,WAAW,OAAO;AACrB,cAAM,IAAI,YACR;EAA2B,WAAW,OAAO,KAAK,IAAI,CAAC,IACvD,EAAE,QAAQ,WAAW,QAAQ,UAAU,WAAW,SAAQ,CAAE;MAEhE;AAGA,UAAI,WAAW,SAAS,SAAS,GAAG;AAClC,gBAAQ,KAAK,uCAA6B;AAC1C,mBAAW,SAAS,QAAQ,CAAAC,aAAW,QAAQ,KAAK,MAAMA,QAAO,EAAE,CAAC;MACtE;AAEA,aAAO;IACT,SAASC,QAAO;AACd,UAAKA,OAAgC,SAAS,UAAU;AAEtD,eAAO;MACT;AAEA,UAAIA,kBAAiB,aAAa;AAChC,cAAMA;MACR;AAEA,UAAIA,kBAAiB,aAAa;AAChC,cAAM,IAAI,YACR,oDACA,EAAE,MAAM,YAAY,eAAeA,OAAM,QAAO,CAAE;MAEtD;AAEA,YAAM,UAAUA,QAAO,gCAAgC,EAAE,MAAM,WAAU,CAAE;IAC7E;EACF;;;;;;;;;EAUA,MAAM,KAAK,SAAiB,QAAkB;AAC5C,UAAM,aAAa,KAAK,cAAc,OAAO;AAG7C,UAAM,aAAa,KAAK,SAAS,MAAM;AACvC,QAAI,CAAC,WAAW,OAAO;AACrB,YAAM,IAAI,YACR;EAAuC,WAAW,OAAO,KAAK,IAAI,CAAC,IACnE,EAAE,QAAQ,WAAW,OAAM,CAAE;IAEjC;AAEA,QAAI;AACF,YAAM,aAAa,KAAK,UAAU,QAAQ,MAAM,CAAC,IAAI;AACrD,YAAMH,IAAG,UAAU,YAAY,YAAY,OAAO;IACpD,SAASG,QAAO;AACd,YAAM,UAAUA,QAAO,gCAAgC,EAAE,MAAM,WAAU,CAAE;IAC7E;EACF;;;;;;;EAQA,MAAM,OAAO,UAAkB,QAAQ,IAAG,GAAE;AAC1C,UAAM,aAAa,KAAK,cAAc,OAAO;AAC7C,QAAI;AACF,YAAMH,IAAG,OAAO,UAAU;AAC1B,aAAO;IACT,QAAQ;AACN,aAAO;IACT;EACF;;;;;;;;;EAUA,MAAM,QAAQ,UAAkB,QAAQ,IAAG,GAAE;AAC3C,UAAM,aAAa,KAAK,cAAc,OAAO;AAE7C,QAAI;AAEF,YAAM,gBAAgB,MAAMA,IAAG,SAAS,YAAY,OAAO;AAC3D,YAAM,YAAY,KAAK,MAAM,aAAa;AAG1C,UAAI,CAAC,KAAK,eAAe,SAAS,GAAG;AACnC,eAAO;UACL,UAAU;UACV,QAAQ;;MAEZ;AAGA,YAAM,YAAY,cAAiB,SAAS;AAG5C,YAAM,aAAa,KAAK,SAAS,SAAS;AAC1C,UAAI,CAAC,WAAW,OAAO;AACrB,cAAM,IAAI,YACR;EAA8C,WAAW,OAAO,KAAK,IAAI,CAAC,IAC1E,EAAE,QAAQ,WAAW,OAAM,CAAE;MAEjC;AAGA,YAAM,aAAa,GAAG,UAAU;AAChC,YAAMA,IAAG,SAAS,YAAY,UAAU;AAGxC,YAAM,KAAK,KAAK,SAAS,SAAS;AAElC,aAAO;QACL,UAAU;QACV;QACA,QAAQ;;IAEZ,SAASG,QAAO;AACd,UAAKA,OAAgC,SAAS,UAAU;AACtD,eAAO;UACL,UAAU;UACV,QAAQ;;MAEZ;AAEA,UAAIA,kBAAiB,aAAa;AAChC,cAAMA;MACR;AAEA,YAAM,UAAUA,QAAO,kCAAkC,EAAE,MAAM,WAAU,CAAE;IAC/E;EACF;;;;;;;EAQA,eAAe,QAAe;AAC5B,WAAO,eAAoB,MAAM;EACnC;;;;;;;;EASA,SAAS,QAAe;AACtB,UAAM,SAAmB,CAAA;AACzB,UAAM,WAAqB,CAAA;AAG3B,QAAI,CAAC,UAAU,OAAO,WAAW,UAAU;AACzC,aAAO;QACL,OAAO;QACP,QAAQ,CAAC,iCAAiC;QAC1C,UAAU,CAAA;;IAEd;AAEA,UAAM,MAAM;AAGZ,QAAI,CAAC,IAAI,SAAS;AAChB,aAAO,KAAK,iCAAiC;IAC/C;AAGA,QAAI,eAAe,GAAoC,GAAG;AACxD,WAAK,qBAAqB,KAAmB,QAAQ,QAAQ;IAC/D,WAAW,eAAe,GAAoC,GAAG;AAC/D,WAAK,qBAAqB,KAAyB,QAAQ,QAAQ;IACrE,OAAO;AACL,aAAO,KAAK,wFAAwF;IACtG;AAEA,WAAO;MACL,OAAO,OAAO,WAAW;MACzB;MACA;;EAEJ;;;;;;;;EASA,gBAAgB,QAA2B;AACzC,UAAM,SAAmB,CAAA;AACzB,UAAM,WAAqB,CAAA;AAG3B,QAAI,OAAO,MAAM;AACf,WAAK,mBAAmB,OAAO,MAAM,QAAQ,QAAQ;IACvD;AAGA,QAAI,OAAO,KAAK;AACd,WAAK,kBAAkB,OAAO,KAAK,QAAQ,QAAQ;IACrD;AAGA,QAAI,OAAO,cAAc;AACvB,WAAK,2BAA2B,OAAO,cAAc,QAAQ,QAAQ;IACvE;AAGA,QAAI,OAAO,cAAc;AACvB,WAAK,2BAA2B,OAAO,cAAc,QAAQ,QAAQ;IACvE;AAGA,QAAI,OAAO,YAAY;AACrB,WAAK,mBAAmB,OAAO,YAAY,QAAQ,QAAQ;IAC7D;AAEA,WAAO;MACL,OAAO,OAAO,WAAW;MACzB;MACA;;EAEJ;;;;EAKQ,cAAc,SAAe;AACnC,WAAOF,MAAK,KAAK,SAAS,eAAc,eAAe;EACzD;;;;EAKQ,qBACN,QACA,QACA,UAAkB;AAGlB,QAAI,CAAC,OAAO,MAAM;AAChB,aAAO,KAAK,8BAA8B;AAC1C;IACF;AACA,SAAK,mBAAmB,OAAO,MAAM,QAAQ,QAAQ;AAGrD,QAAI,CAAC,OAAO,KAAK;AACf,aAAO,KAAK,6BAA6B;AACzC;IACF;AACA,SAAK,kBAAkB,OAAO,KAAK,QAAQ,QAAQ;AAGnD,QAAI,CAAC,OAAO,cAAc;AACxB,aAAO,KAAK,sCAAsC;AAClD;IACF;AACA,SAAK,2BAA2B,OAAO,cAAc,QAAQ,QAAQ;AAGrE,QAAI,CAAC,OAAO,cAAc;AACxB,aAAO,KAAK,sCAAsC;AAClD;IACF;AACA,SAAK,2BAA2B,OAAO,cAAc,QAAQ,QAAQ;AAGrE,QAAI,CAAC,OAAO,YAAY;AACtB,aAAO,KAAK,oCAAoC;AAChD;IACF;AACA,SAAK,mBAAmB,OAAO,YAAY,QAAQ,QAAQ;EAC7D;;;;EAKQ,qBACN,QACA,QACA,UAAkB;AAElB,aAAS,KAAK,sFAAsF;AAGpG,QAAI,CAAC,OAAO,UAAU;AACpB,aAAO,KAAK,kCAAkC;AAC9C;IACF;AAEA,UAAM,EAAE,SAAQ,IAAK;AAErB,QAAI,OAAO,SAAS,cAAc,YAAY,SAAS,aAAa,GAAG;AACrE,aAAO,KAAK,8CAA8C;IAC5D;AAEA,QAAI,OAAO,SAAS,iBAAiB,YAAY,SAAS,eAAe,GAAG;AAC1E,aAAO,KAAK,qDAAqD;IACnE;AAEA,QAAI,OAAO,SAAS,gBAAgB,YAAY,SAAS,cAAc,KAAK,SAAS,cAAc,IAAI;AACrG,aAAO,KAAK,+CAA+C;IAC7D;AAEA,QAAI,OAAO,SAAS,uBAAuB,YAAY,SAAS,sBAAsB,GAAG;AACvF,aAAO,KAAK,uDAAuD;IACrE;AAGA,QAAI,OAAO,KAAK;AACd,WAAK,kBAAkB,OAAO,KAAK,QAAQ,QAAQ;IACrD;EACF;;;;EAKQ,mBACNG,OACA,QACA,UAAkB;AAElB,QAAIA,MAAK,cAAc,QAAW;AAChC,UAAI,OAAOA,MAAK,cAAc,YAAYA,MAAK,aAAa,GAAG;AAC7D,eAAO,KAAK,0CAA0C;MACxD,WAAWA,MAAK,YAAY,IAAI;AAC9B,iBAAS,KAAK,kFAAkF;MAClG,WAAWA,MAAK,YAAY,KAAK;AAC/B,iBAAS,KAAK,wEAAwE;MACxF;IACF;AAEA,QAAIA,MAAK,iBAAiB,QAAW;AACnC,UAAI,OAAOA,MAAK,iBAAiB,YAAYA,MAAK,eAAe,GAAG;AAClE,eAAO,KAAK,iDAAiD;MAC/D;IACF;AAEA,QAAIA,MAAK,gBAAgB,QAAW;AAClC,UAAI,OAAOA,MAAK,gBAAgB,YAAYA,MAAK,cAAc,KAAKA,MAAK,cAAc,IAAI;AACzF,eAAO,KAAK,2CAA2C;MACzD;IACF;AAEA,QAAIA,MAAK,uBAAuB,QAAW;AACzC,UAAI,OAAOA,MAAK,uBAAuB,YAAYA,MAAK,sBAAsB,GAAG;AAC/E,eAAO,KAAK,mDAAmD;MACjE,WAAWA,MAAK,qBAAqB,KAAK;AACxC,iBAAS,KAAK,4EAA4E;MAC5F;IACF;EACF;;;;EAKQ,kBACN,KACA,QACA,WAAmB;AAEnB,QAAI,IAAI,SAAS,QAAW;AAC1B,UAAI,OAAO,IAAI,SAAS,YAAY,IAAI,OAAO,QAAQ,IAAI,OAAO,OAAO;AACvE,eAAO,KAAK,yCAAyC;MACvD;IACF;AAEA,QAAI,IAAI,cAAc,QAAW;AAC/B,UAAI,IAAI,cAAc,WAAW,IAAI,cAAc,UAAU;AAC3D,eAAO,KAAK,kDAAkD;MAChE;IACF;AAEA,QAAI,IAAI,wBAAwB,QAAW;AACzC,UAAI,OAAO,IAAI,wBAAwB,WAAW;AAChD,eAAO,KAAK,2CAA2C;MACzD;IACF;EACF;;;;EAKQ,2BACN,cACA,QACA,WAAmB;AAEnB,QAAI,aAAa,YAAY,QAAW;AACtC,UAAI,OAAO,aAAa,YAAY,WAAW;AAC7C,eAAO,KAAK,wCAAwC;MACtD;IACF;AAEA,QAAI,aAAa,mBAAmB,QAAW;AAC7C,UAAI,OAAO,aAAa,mBAAmB,YAAY,aAAa,iBAAiB,KAAK;AACxF,eAAO,KAAK,oDAAoD;MAClE,WAAW,aAAa,iBAAiB,KAAM;AAC7C,kBAAU,KAAK,8EAA8E;MAC/F;IACF;EACF;;;;EAKQ,2BACN,cACA,QACA,UAAkB;AAElB,QAAI,aAAa,YAAY,QAAW;AACtC,UAAI,OAAO,aAAa,YAAY,WAAW;AAC7C,eAAO,KAAK,wCAAwC;MACtD;IACF;AAEA,QAAI,aAAa,eAAe,QAAW;AACzC,UAAI,OAAO,aAAa,eAAe,YAAY,aAAa,aAAa,GAAG;AAC9E,eAAO,KAAK,uDAAuD;MACrE,WAAW,aAAa,aAAa,KAAK;AACxC,iBAAS,KAAK,qFAAqF;MACrG;IACF;EACF;;;;EAKQ,mBACN,YACA,QACA,UAAkB;AAElB,QAAI,CAAC,MAAM,QAAQ,UAAU,GAAG;AAC9B,aAAO,KAAK,6BAA6B;AACzC;IACF;AAEA,eAAW,QAAQ,CAAC,WAAW,UAAS;AACtC,UAAI,CAAC,aAAa,OAAO,cAAc,UAAU;AAC/C,eAAO,KAAK,cAAc,KAAK,qBAAqB;AACpD;MACF;AAEA,YAAM,KAAK;AAGX,UAAI,CAAC,GAAG,MAAM;AACZ,eAAO,KAAK,cAAc,KAAK,gCAAgC;MACjE;AAEA,UAAI,GAAG,SAAS,QAAW;AACzB,eAAO,KAAK,cAAc,KAAK,gCAAgC;MACjE,WAAW,OAAO,GAAG,SAAS,UAAU;AACtC,eAAO,KAAK,cAAc,KAAK,yBAAyB;MAC1D,WAAWH,MAAK,WAAW,GAAG,IAAI,GAAG;AACnC,eAAO,KAAK,cAAc,KAAK,iCAAiC,GAAG,IAAI,EAAE;MAC3E;AAEA,UAAI,GAAG,YAAY,QAAW;AAC5B,eAAO,KAAK,cAAc,KAAK,mCAAmC;MACpE,WAAW,OAAO,GAAG,YAAY,WAAW;AAC1C,eAAO,KAAK,cAAc,KAAK,6BAA6B;MAC9D;AAEA,UAAI,CAAC,GAAG,QAAQ;AACd,eAAO,KAAK,cAAc,KAAK,kCAAkC;MACnE,OAAO;AACL,aAAK,wBAAwB,GAAG,QAAQ,cAAc,KAAK,YAAY,QAAQ,QAAQ;MACzF;IACF,CAAC;EACH;;;;EAKQ,wBACN,QACA,QACA,QACA,WAAmB;AAEnB,QAAI,CAAC,UAAU,OAAO,WAAW,UAAU;AACzC,aAAO,KAAK,GAAG,MAAM,oBAAoB;AACzC;IACF;AAGA,QAAI,CAAC,MAAM,QAAQ,OAAO,OAAO,GAAG;AAClC,aAAO,KAAK,GAAG,MAAM,2BAA2B;IAClD,OAAO;AACL,aAAO,QAAQ,QAAQ,CAAC,SAAkB,MAAa;AACrD,YAAI,OAAO,YAAY,UAAU;AAC/B,iBAAO,KAAK,GAAG,MAAM,YAAY,CAAC,oBAAoB;QACxD;MACF,CAAC;IACH;AAGA,QAAI,CAAC,MAAM,QAAQ,OAAO,OAAO,GAAG;AAClC,aAAO,KAAK,GAAG,MAAM,2BAA2B;IAClD,OAAO;AACL,aAAO,QAAQ,QAAQ,CAAC,SAAkB,MAAa;AACrD,YAAI,OAAO,YAAY,UAAU;AAC/B,iBAAO,KAAK,GAAG,MAAM,YAAY,CAAC,oBAAoB;QACxD;MACF,CAAC;IACH;EACF;;AAIK,IAAM,gBAAgB,IAAI,cAAa;;;AIvlB9C,OAAOI,SAAQ;AACf,OAAOC,WAAU;;;ACQjB,IAAI,cAAc;AAKZ,SAAU,oBAAiB;AAC/B,SAAO;AACT;;;ADVA,IAAM,gBAAgB;AA8BhB,IAAO,kBAAP,MAAsB;EAClB;EACA;;;;;EAMA,aAAa,QAAQ,QAAO;;;;;EAMpC,YAAY,WAAiB;AAC3B,SAAK,YAAY;AACjB,SAAK,eAAeC,MAAK,KAAK,WAAW,aAAa;EACxD;;;;;;;;;;EAWA,MAAM,OAAI;AACR,QAAI;AACF,YAAM,UAAU,MAAMC,IAAG,SAAS,KAAK,cAAc,OAAO;AAC5D,YAAM,WAAW,KAAK,MAAM,OAAO;AAGnC,UAAI,SAAS,kBAAkB,sBAAsB;AACnD,gBAAQ,MACN,wBAAwB,SAAS,aAAa,kCAAkC,oBAAoB,EAAE;AAExG,gBAAQ,MAAM,iDAAiD;AAG/D,cAAM,KAAK,MAAK;AAChB,eAAO;MACT;AAEA,aAAO;IACT,SAASC,QAAO;AAEd,UAAKA,OAAgC,SAAS,UAAU;AACtD,eAAO;MACT;AAGA,cAAQ,MAAM,4CAA4CA,MAAK,EAAE;AACjE,aAAO;IACT;EACF;;;;;;;EAQA,MAAM,KAAK,UAAuB;AAChC,QAAI;AAEF,YAAMD,IAAG,MAAM,KAAK,WAAW,EAAE,WAAW,KAAI,CAAE;AAGlD,YAAM,iBAAgC;QACpC,GAAG;QACH,eAAe;QACf,aAAa,kBAAiB;QAC9B,aAAa,KAAK,IAAG;;AAGvB,YAAM,UAAU,KAAK,UAAU,gBAAgB,MAAM,CAAC;AACtD,YAAMA,IAAG,UAAU,KAAK,cAAc,SAAS,OAAO;IACxD,SAASC,QAAO;AAEd,cAAQ,MAAM,4CAA4CA,MAAK,EAAE;IACnE;EACF;;;;;;;;EASA,MAAM,WAAW,UAAkB,OAAgB;AAEjD,SAAK,aAAa,KAAK,WAAW,KAAK,YAAW;AAChD,YAAM,WAAW,MAAM,KAAK,KAAI,KAAM,KAAK,YAAW;AACtD,eAAS,MAAM,QAAQ,IAAI;AAC3B,YAAM,KAAK,KAAK,QAAQ;IAC1B,CAAC,EAAE,MAAM,CAAAA,WAAQ;AACf,cAAQ,MAAM,wCAAwC,QAAQ,KAAKA,MAAK,EAAE;AAE1E,aAAO;IACT,CAAC;AAGD,UAAM,KAAK;EACb;;;;;;;;;;EAWA,MAAM,WAAW,UAAgB;AAE/B,SAAK,aAAa,KAAK,WAAW,KAAK,YAAW;AAChD,YAAM,WAAW,MAAM,KAAK,KAAI;AAChC,UAAI,CAAC,UAAU;AAEb;MACF;AAEA,aAAO,SAAS,MAAM,QAAQ;AAC9B,YAAM,KAAK,KAAK,QAAQ;IAC1B,CAAC,EAAE,MAAM,CAAAA,WAAQ;AACf,cAAQ,MAAM,8CAA8C,QAAQ,KAAKA,MAAK,EAAE;AAEhF,aAAO;IACT,CAAC;AAGD,UAAM,KAAK;EACb;;;;;;;EAQA,MAAM,YAAY,SAAoB;AAEpC,SAAK,aAAa,KAAK,WAAW,KAAK,YAAW;AAChD,YAAM,WAAW,MAAM,KAAK,KAAI,KAAM,KAAK,YAAW;AAEtD,iBAAW,SAAS,SAAS;AAC3B,iBAAS,MAAM,MAAM,QAAQ,IAAI;MACnC;AAEA,YAAM,KAAK,KAAK,QAAQ;IAC1B,CAAC,EAAE,MAAM,CAAAA,WAAQ;AACf,cAAQ,MAAM,wCAAwC,QAAQ,MAAM,WAAWA,MAAK,EAAE;AAEtF,aAAO;IACT,CAAC;AAGD,UAAM,KAAK;EACb;;;;;;;EAQA,MAAM,eAAe,UAAkB;AAErC,SAAK,aAAa,KAAK,WAAW,KAAK,YAAW;AAChD,YAAM,WAAW,MAAM,KAAK,KAAI,KAAM,KAAK,YAAW;AAEtD,eAAS,WAAW;AACpB,YAAM,KAAK,KAAK,QAAQ;IAC1B,CAAC,EAAE,MAAM,CAAAA,WAAQ;AACf,cAAQ,MAAM,kDAAkDA,MAAK,EAAE;AAEvE,aAAO;IACT,CAAC;AAGD,UAAM,KAAK;EACb;;;;;;EAOA,MAAM,kBAAe;AACnB,UAAM,WAAW,MAAM,KAAK,KAAI;AAChC,QAAI,CAAC;AAAU,aAAO,CAAA;AAEtB,WAAO,OAAO,KAAK,SAAS,KAAK;EACnC;;;;;;;EAQA,MAAM,gBAAgB,cAAiC;AACrD,UAAM,WAAW,MAAM,KAAK,KAAI;AAChC,QAAI,CAAC,UAAU;AAEb,aAAO,MAAM,KAAK,aAAa,KAAI,CAAE;IACvC;AAEA,UAAM,eAAyB,CAAA;AAE/B,eAAW,CAAC,UAAU,KAAK,KAAK,cAAc;AAC5C,YAAM,QAAQ,SAAS,MAAM,QAAQ;AAErC,UAAI,CAAC,OAAO;AAEV,qBAAa,KAAK,QAAQ;MAC5B,WAAW,MAAM,eAAe,OAAO;AAErC,qBAAa,KAAK,QAAQ;MAC5B;IACF;AAEA,WAAO;EACT;;;;;;;;EASA,MAAM,gBAAgB,cAAyB;AAC7C,UAAM,WAAW,MAAM,KAAK,KAAI;AAChC,QAAI,CAAC;AAAU,aAAO,CAAA;AAEtB,UAAM,eAAyB,CAAA;AAE/B,eAAW,YAAY,OAAO,KAAK,SAAS,KAAK,GAAG;AAClD,UAAI,CAAC,aAAa,IAAI,QAAQ,GAAG;AAC/B,qBAAa,KAAK,QAAQ;MAC5B;IACF;AAEA,WAAO;EACT;;;;EAKA,MAAM,QAAK;AACT,QAAI;AACF,YAAMD,IAAG,OAAO,KAAK,YAAY;IACnC,SAASC,QAAO;AAEd,UAAKA,OAAgC,SAAS,UAAU;AACtD,gBAAQ,MAAM,6CAA6CA,MAAK,EAAE;MACpE;IACF;EACF;;;;;;EAOQ,cAAW;AACjB,WAAO;MACL,eAAe;MACf,aAAa,kBAAiB;MAC9B,aAAa,KAAK,IAAG;MACrB,OAAO,CAAA;;EAEX;;;;AEzTF,SAAS,YAAY;AACrB,SAAS,iBAAiB;AAC1B,OAAOC,SAAQ;AACf,OAAOC,WAAU;AAEjB,IAAM,YAAY,UAAU,IAAI;AAQhC,eAAsB,UAAU,SAAe;AAC7C,MAAI;AACF,UAAM,SAASA,MAAK,KAAK,SAAS,MAAM;AACxC,UAAMD,IAAG,OAAO,MAAM;AACtB,WAAO;EACT,QAAQ;AACN,WAAO;EACT;AACF;AASA,eAAsB,iBAAiB,SAAe;AACpD,MAAI;AACF,UAAM,EAAE,OAAM,IAAK,MAAM,UAAU,mCAAmC;MACpE,KAAK;MACL,SAAS;;KACV;AACD,WAAO,OAAO,KAAI;EACpB,SAASE,QAAO;AACd,UAAM,IAAI,MAAM,iCAAiCA,MAAK,EAAE;EAC1D;AACF;AASA,eAAsB,iBAAiB,SAAe;AACpD,MAAI;AACF,UAAM,EAAE,OAAM,IAAK,MAAM,UAAU,sBAAsB;MACvD,KAAK;MACL,SAAS;KACV;AACD,WAAO,OAAO,KAAI;EACpB,SAASA,QAAO;AACd,UAAM,IAAI,MAAM,iCAAiCA,MAAK,EAAE;EAC1D;AACF;AAWA,eAAsB,gBACpB,SACA,SACA,OAAa;AAEb,MAAI;AACF,UAAM,EAAE,OAAM,IAAK,MAAM,UACvB,wBAAwB,OAAO,MAAM,KAAK,IAC1C;MACE,KAAK;MACL,SAAS;;KACV;AAGH,UAAM,QAAQ,OACX,KAAI,EACJ,MAAM,IAAI,EACV,OAAO,OAAO,EACd,IAAI,UAAQD,MAAK,KAAK,SAAS,IAAI,CAAC;AAEvC,WAAO;EACT,SAASC,QAAO;AACd,UAAM,IAAI,MAAM,gCAAgCA,MAAK,EAAE;EACzD;AACF;AA6CA,eAAsB,8BACpB,SACA,YACA,UAAgB;AAEhB,MAAI;AACF,UAAM,EAAE,OAAM,IAAK,MAAM,UACvB,wBAAwB,UAAU,IAAI,QAAQ,IAC9C;MACE,KAAK;MACL,SAAS;KACV;AAGH,UAAM,QAAQ,OACX,KAAI,EACJ,MAAM,IAAI,EACV,OAAO,OAAO,EACd,IAAI,UAAQC,MAAK,KAAK,SAAS,IAAI,CAAC;AAEvC,WAAO;EACT,SAASC,QAAO;AACd,UAAM,IAAI,MAAM,gDAAgDA,MAAK,EAAE;EACzE;AACF;AAOA,eAAsB,iBAAc;AAClC,MAAI;AACF,UAAM,UAAU,iBAAiB,EAAE,SAAS,IAAI,CAAE;AAClD,WAAO;EACT,QAAQ;AACN,WAAO;EACT;AACF;;;ACjLA,OAAOC,SAAQ;AACf,OAAOC,YAAU;AAmBX,IAAO,kBAAP,MAAsB;EAClB;EACA;EACA,eAAgC;EAExC,YAAY,SAAiB,WAAiB;AAC5C,SAAK,UAAU;AACf,SAAK,YAAYC,OAAK,KAAK,WAAW,iBAAiB;EACzD;;;;;EAMQ,MAAM,YAAS;AACrB,QAAI;AACF,YAAM,UAAU,MAAMC,IAAG,SAAS,KAAK,WAAW,OAAO;AACzD,aAAO,KAAK,MAAM,OAAO;IAC3B,QAAQ;AAEN,aAAO;IACT;EACF;;;;EAKQ,MAAM,UAAU,OAAe;AACrC,QAAI;AACF,YAAM,UAAU,KAAK,UAAU,OAAO,MAAM,CAAC;AAC7C,YAAMA,IAAG,UAAU,KAAK,WAAW,SAAS,OAAO;IACrD,SAASC,QAAO;AAEd,cAAQ,MAAM,6CAA6CA,MAAK,EAAE;IACpE;EACF;;;;;;;EAQQ,MAAM,qBAAkB;AAC9B,UAAM,SAAS,MAAM,iBAAiB,KAAK,OAAO;AAClD,UAAM,SAAS,MAAM,iBAAiB,KAAK,OAAO;AAElD,WAAO;MACL;MACA;MACA,WAAW,KAAK,IAAG;;EAEvB;;;;;;;EAQA,MAAM,aAAU;AAEd,UAAM,SAAS,MAAM,UAAU,KAAK,OAAO;AAC3C,QAAI,CAAC,QAAQ;AACX,aAAO;IACT;AAEA,QAAI;AAEF,WAAK,eAAe,MAAM,KAAK,mBAAkB;AAGjD,YAAM,gBAAgB,MAAM,KAAK,UAAS;AAE1C,UAAI,CAAC,eAAe;AAElB,cAAM,KAAK,UAAU,KAAK,YAAY;AACtC,eAAO;MACT;AAGA,YAAM,gBAAgB,cAAc,WAAW,KAAK,aAAa;AACjE,YAAM,gBAAgB,cAAc,WAAW,KAAK,aAAa;AAEjE,UAAI,CAAC,iBAAiB,CAAC,eAAe;AAEpC,eAAO;MACT;AAGA,UAAI,eAAyB,CAAA;AAE7B,UAAI,eAAe;AAEjB,YAAI;AACF,yBAAe,MAAM,gBACnB,KAAK,SACL,cAAc,QACd,KAAK,aAAa,MAAM;QAE5B,SAASA,QAAO;AAEd,kBAAQ,MAAM,iDAAiDA,MAAK,EAAE;AACtE,yBAAe,MAAM,8BACnB,KAAK,SACL,cAAc,QACd,KAAK,aAAa,MAAM;QAE5B;MACF,WAAW,eAAe;AAExB,uBAAe,MAAM,8BACnB,KAAK,SACL,cAAc,QACd,KAAK,aAAa,MAAM;MAE5B;AAGA,YAAM,KAAK,UAAU,KAAK,YAAY;AAEtC,aAAO;IACT,SAASA,QAAO;AACd,cAAQ,MAAM,4CAA4CA,MAAK,EAAE;AACjE,aAAO;IACT;EACF;;;;;;;EAQA,MAAM,gBAAa;AAEjB,UAAM,SAAS,MAAM,UAAU,KAAK,OAAO;AAC3C,QAAI,CAAC,QAAQ;AACX,aAAO;IACT;AAEA,QAAI;AAEF,YAAM,WAAW,MAAM,KAAK,mBAAkB;AAG9C,UAAI,CAAC,KAAK,cAAc;AACtB,aAAK,eAAe;AACpB,cAAM,KAAK,UAAU,QAAQ;AAC7B,eAAO;MACT;AAGA,YAAM,gBAAgB,KAAK,aAAa,WAAW,SAAS;AAC5D,YAAM,gBAAgB,KAAK,aAAa,WAAW,SAAS;AAE5D,UAAI,CAAC,iBAAiB,CAAC,eAAe;AAEpC,eAAO;MACT;AAGA,UAAI,eAAyB,CAAA;AAE7B,UAAI,eAAe;AAEjB,YAAI;AACF,yBAAe,MAAM,gBACnB,KAAK,SACL,KAAK,aAAa,QAClB,SAAS,MAAM;QAEnB,SAASA,QAAO;AAEd,kBAAQ,MAAM,iDAAiDA,MAAK,EAAE;AACtE,yBAAe,MAAM,8BACnB,KAAK,SACL,KAAK,aAAa,QAClB,SAAS,MAAM;QAEnB;MACF,WAAW,eAAe;AAExB,uBAAe,MAAM,8BACnB,KAAK,SACL,KAAK,aAAa,QAClB,SAAS,MAAM;MAEnB;AAGA,WAAK,eAAe;AACpB,YAAM,KAAK,UAAU,QAAQ;AAE7B,aAAO;IACT,SAASA,QAAO;AACd,cAAQ,MAAM,wCAAwCA,MAAK,EAAE;AAC7D,aAAO;IACT;EACF;;;;;EAMA,WAAQ;AACN,WAAO,KAAK;EACd;;;;;EAMA,MAAM,cAAW;AACf,QAAI;AACF,WAAK,eAAe,MAAM,KAAK,mBAAkB;AACjD,YAAM,KAAK,UAAU,KAAK,YAAY;IACxC,SAASA,QAAO;AACd,cAAQ,MAAM,sCAAsCA,MAAK,EAAE;IAC7D;EACF;;;;AChPF,OAAOC,SAAQ;AACf,OAAOC,YAAU;;;ACDjB,OAAOC,SAAQ;AACf,OAAOC,YAAU;;;ACiCX,SAAU,GAAM,OAAQ;AAC5B,SAAO,EAAE,IAAI,MAAM,MAAK;AAC1B;AAKM,SAAU,IAAOC,QAAQ;AAC7B,SAAO,EAAE,IAAI,OAAO,OAAAA,OAAK;AAC3B;AAKM,SAAU,KAAW,QAAoB;AAC7C,SAAO,OAAO;AAChB;;;AD9BM,SAAU,wBAAwB,UAAkB,SAAgB;AAExE,QAAM,QAAQ,WAAW,QAAQ,IAAG,GAAI,QAAQ,OAAO,GAAG,EAAE,QAAQ,OAAO,EAAE;AAC7E,QAAM,aAAa,SAAS,QAAQ,OAAO,GAAG;AAG9C,MAAI,CAACC,OAAK,WAAW,QAAQ,GAAG;AAC9B,WAAO;EACT;AAGA,MAAI,WAAW,WAAW,OAAO,GAAG,GAAG;AACrC,WAAO,WAAW,MAAM,KAAK,SAAS,CAAC;EACzC;AACA,MAAI,WAAW,WAAW,IAAI,GAAG;AAC/B,WAAO,WAAW,MAAM,KAAK,MAAM;EACrC;AAGA,SAAOA,OAAK,SAAS,MAAM,QAAQ,EAAE,QAAQ,OAAO,GAAG;AACzD;AAsCA,eAAe,mBACb,UACA,SACA,YACA,QACA,SAAgB;AAGhB,QAAM,YAAY,eAAe,MAAM,IACnC,OAAO,KAAK,YACX,eAAe,MAAM,IAAI,OAAO,SAAS,YAAY;AAC1D,QAAM,eAAe,eAAe,MAAM,IACtC,OAAO,KAAK,eACX,eAAe,MAAM,IAAI,OAAO,SAAS,eAAe;AAC7D,QAAM,SAAS,eAAe,MAAM,IAChC,OAAO,SAAS,SAChB;AACJ,QAAM,cAAc,eAAe,MAAM,IACrC,OAAO,SAAS,cAChB;AAGJ,QAAM,SAAS,UAAU,UAAU,SAAS;IAC1C;IACA;IACA;IACA;GACD;AAED,MAAI,OAAO,WAAW,GAAG;AAEvB,QAAI,SAAS;AACX,cAAQ,MAAM,sBAAsB,QAAQ,EAAE;IAChD;AACA,WAAO;EACT;AAIA,QAAM,QAAQ,OAAO,IAAI,OAAK,EAAE,OAAO;AACvC,QAAM,UAA0B,CAAA;AAEhC,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK,4BAA4B;AACjE,UAAM,aAAa,MAAM,MAAM,GAAG,KAAK,IAAI,IAAI,4BAA4B,MAAM,MAAM,CAAC;AACxF,UAAM,eAAe,MAAM,WAAW,WAAW,UAAU;AAC3D,YAAQ,KAAK,GAAG,YAAY;AAG5B,QAAI,MAAM,SAAS,4BAA4B;AAC7C,YAAM,IAAI,QAAQ,aAAW,aAAa,OAAO,CAAC;IACpD;EACF;AAEA,SAAO;IACL,YAAY,OAAO;IACnB;IACA;IACA;;AAEJ;AA8FA,eAAe,6BACb,UACA,gBACA,YACA,QACA,SAAgB;AAEhB,MAAI;AAEF,UAAM,QAAQ,MAAMC,IAAG,KAAK,QAAQ;AACpC,UAAM,UAAU,MAAMA,IAAG,SAAS,UAAU,OAAO;AAGnD,UAAM,SAAS,MAAM,mBAAmB,gBAAgB,SAAS,YAAY,QAAQ,OAAO;AAE5F,WAAO,GAAG;MACR,UAAU;;MACV;MACA,OAAO,MAAM;KACd;EACH,SAASC,QAAO;AACd,WAAO,IAAI,qBAAqB,cAAc,KAAKA,MAAK,EAAE;EAC5D;AACF;AAmBA,eAAsB,mBACpB,WACA,UACA,YACA,QACA,UAAmC,CAAA,GAAE;AAErC,QAAM,EAAE,QAAO,IAAK;AACpB,MAAI,iBAAiB;AAGrB,QAAM,kBAAkF,CAAA;AAGxF,aAAW,YAAY,WAAW;AAGhC,UAAM,iBAAiB,wBAAwB,QAAQ;AAEvD,UAAM,SAAS,MAAM,6BAA6B,UAAU,gBAAgB,YAAY,QAAQ,WAAW,KAAK;AAEhH,QAAI,KAAK,MAAM,GAAG;AAChB,YAAM,EAAE,UAAU,YAAY,QAAQ,eAAe,MAAK,IAAK,OAAO;AAEtE,UAAI,kBAAkB,MAAM;AAE1B,YAAI;AACF,gBAAM,SAAS,aAAa,UAAU;QACxC,SAASA,QAAO;QAEhB;AAGA,cAAM,WAAW,IAAI,gBAAgB,SAAS,MAAM;AACpD,cAAM,SAAS,WAAW,YAAY;UACpC,UAAU;UACV,cAAc;UACd,YAAY;SACb;AAED;AACA;MACF;AAGA,UAAI;AACF,cAAM,SAAS,aAAa,UAAU;MACxC,SAASA,QAAO;MAEhB;AAGA,YAAM,SAAS,YACb,cAAc,SACd,cAAc,OAAO,IAAI,OAAK,EAAE,QAAQ,GACxC,cAAc,KAAK;AAIrB,sBAAgB,KAAK;QACnB,UAAU;QACV,YAAY,cAAc;QAC1B;OACD;AAED,UAAI,SAAS;AACX,gBAAQ,MAAM,yBAAoB,UAAU,KAAK,cAAc,UAAU,UAAU;MACrF;AAEA;IACF,OAAO;AAEL,UAAI,SAAS;AACX,gBAAQ,MAAM,UAAU,OAAO,KAAK,EAAE;MACxC;AAEA,UAAI;AACF,cAAM,SAAS,aAAa,cAAc;AAC1C,cAAM,WAAW,IAAI,gBAAgB,SAAS,MAAM;AACpD,cAAM,SAAS,WAAW,cAAc;MAC1C,SAASA,QAAO;AAEd,YAAI,SAAS;AACX,kBAAQ,MAAM,gBAAgB,cAAc,eAAe;QAC7D;MACF;AAGA;IACF;EACF;AAGA,MAAI,gBAAgB,SAAS,GAAG;AAC9B,UAAM,WAAW,IAAI,gBAAgB,SAAS,MAAM;AACpD,UAAM,SAAS,YACb,gBAAgB,IAAI,YAAU;MAC5B,UAAU,MAAM;MAChB,cAAc,MAAM;;MACpB,YAAY,MAAM;MAClB,CAAC;EAEP;AAEA,SAAO;AACT;;;ADnWA,eAAe,mBACb,SACA,QACA,eAAwC;AAExC,MAAI,CAAC;AAAe,WAAO,EAAE,SAAS,MAAK;AAE3C,QAAM,eAAe,MAAM,eAAc;AACzC,QAAM,SAAS,MAAM,UAAU,OAAO;AACtC,MAAI,CAAC,gBAAgB,CAAC;AAAQ,WAAO,EAAE,SAAS,MAAK;AAErD,QAAM,aAAa,IAAI,gBAAgB,SAAS,MAAM;AACtD,QAAM,WAAW,WAAU;AAC3B,QAAM,eAAe,WAAW,SAAQ;AAExC,MAAI,CAAC;AAAc,WAAO,EAAE,SAAS,MAAK;AAE1C,QAAM,UAAU,aAAa,WAAW,cAAc,UACtC,aAAa,WAAW,cAAc;AAEtD,SAAO,EAAE,SAAS,aAAY;AAChC;AAKA,SAAS,uBACP,mBACA,gBACA,yBACA,UAAkB;AAElB,QAAM,kBAAkB,IAAI,IAAI,iBAAiB;AACjD,QAAM,QAAkB,CAAA;AACxB,QAAM,WAAqB,CAAA;AAC3B,QAAM,UAAoB,CAAA;AAG1B,aAAW,YAAY,mBAAmB;AACxC,QAAI,eAAe,IAAI,QAAQ,GAAG;AAChC,UAAI,wBAAwB,IAAI,QAAQ,GAAG;AACzC,iBAAS,KAAK,QAAQ;MACxB,OAAO;AACL,cAAM,KAAK,QAAQ;MACrB;IACF;EACF;AAGA,aAAW,YAAY,UAAU;AAC/B,QAAI,CAAC,wBAAwB,IAAI,QAAQ,KAAK,CAAC,gBAAgB,IAAI,QAAQ,GAAG;AAC5E,YAAM,KAAK,QAAQ;IACrB;EACF;AAGA,aAAW,kBAAkB,yBAAyB;AACpD,QAAI,CAAC,eAAe,IAAI,cAAc,GAAG;AACvC,cAAQ,KAAK,cAAc;IAC7B;EACF;AAEA,SAAO,EAAE,OAAO,UAAU,QAAO;AACnC;AAKA,SAAS,uBACP,eACA,SAAe;AAEf,QAAM,aAAa,oBAAI,IAAG;AAC1B,aAAW,YAAY,OAAO,KAAK,aAAa,GAAG;AACjD,eAAW,IAAI,wBAAwB,UAAU,OAAO,CAAC;EAC3D;AACA,SAAO;AACT;AAKA,eAAe,sBACb,SACA,eACA,eACA,QAAqC;AAErC,QAAM,uBAAuB,MAAM,gBACjC,SACA,cAAc,SAAU,QACxB,aAAa;AAEf,QAAM,oBAAoB,qBAAqB,IAAI,QAAM,wBAAwB,IAAI,OAAO,CAAC;AAE7F,QAAM,WAAW,MAAM,YAAY,SAAS,MAAM;AAClD,QAAM,iBAAiB,IAAI,IAAI,QAAQ;AACvC,QAAM,0BAA0B,uBAAuB,cAAc,OAAO,OAAO;AAEnF,QAAM,EAAE,OAAO,UAAU,QAAO,IAAK,uBACnC,mBACA,gBACA,yBACA,QAAQ;AAGV,SAAO,EAAE,OAAO,UAAU,SAAS,QAAQ,oBAAmB;AAChE;AAKA,eAAe,sBACb,SACA,eACA,QAAqC;AAErC,QAAM,WAAW,MAAM,YAAY,SAAS,MAAM;AAClD,QAAM,iBAAiB,IAAI,IAAI,QAAQ;AAEvC,QAAM,UAAoB,CAAA;AAC1B,aAAW,YAAY,OAAO,KAAK,cAAc,KAAK,GAAG;AACvD,UAAM,iBAAiB,wBAAwB,UAAU,OAAO;AAChE,QAAI,CAAC,eAAe,IAAI,cAAc,GAAG;AACvC,cAAQ,KAAK,cAAc;IAC7B;EACF;AAEA,SAAO,EAAE,OAAO,UAAU,UAAU,CAAA,GAAI,SAAS,QAAQ,oBAAmB;AAC9E;AAMA,eAAsB,cACpB,SACA,UACA,QAAqC;AAErC,QAAM,WAAW,IAAI,gBAAgB,SAAS,MAAM;AACpD,QAAM,gBAAgB,MAAM,SAAS,KAAI;AAGzC,MAAI,CAAC,eAAe;AAClB,UAAM,WAAW,MAAM,YAAY,SAAS,MAAM;AAClD,WAAO,EAAE,OAAO,UAAU,UAAU,CAAA,GAAI,SAAS,CAAA,GAAI,QAAQ,OAAM;EACrE;AAGA,QAAM,WAAW,MAAM,mBAAmB,SAAS,SAAS,QAAQ,cAAc,QAAQ;AAE1F,MAAI,SAAS,WAAW,SAAS,cAAc;AAC7C,QAAI;AACF,aAAO,MAAM,sBAAsB,SAAS,eAAe,SAAS,aAAa,QAAQ,MAAM;IACjG,SAASC,QAAO;AACd,cAAQ,KAAK,yDAAyDA,MAAK,EAAE;AAC7E,aAAO,MAAM,sBAAsB,SAAS,eAAe,MAAM;IACnE;EACF;AAGA,SAAO,MAAM,oBAAoB,SAAS,eAAe,MAAM;AACjE;AAMA,eAAe,YACb,SACA,QAAqC;AAErC,MAAI;AAEJ,MAAI,eAAe,MAAM,KAAK,OAAO,WAAW,SAAS,GAAG;AAC1D,YAAQ,MAAM,2BAA2B,SAAS,MAAM;EAC1D,WAAW,eAAe,MAAM,GAAG;AACjC,YAAQ,MAAM,aAAa;MACzB;MACA,iBAAiB,OAAO,SAAS;MACjC,iBAAiB,OAAO,SAAS;KAClC;EACH,OAAO;AACL,YAAQ,MAAM,aAAa;MACzB;MACA,iBAAiB,CAAA;MACjB,iBAAiB,CAAA;KAClB;EACH;AAGA,SAAO,MAAM,IAAI,QAAM,wBAAwB,IAAI,OAAO,CAAC;AAC7D;AAKA,eAAe,oBACb,SACA,eACA,QAAqC;AAErC,QAAM,QAAkB,CAAA;AACxB,QAAM,WAAqB,CAAA;AAC3B,QAAM,UAAoB,CAAA;AAG1B,QAAM,eAAe,MAAM,YAAY,SAAS,MAAM;AACtD,QAAM,iBAAiB,IAAI,IAAI,YAAY;AAI3C,QAAM,0BAA0B,oBAAI,IAAG;AACvC,aAAW,CAAC,UAAU,KAAK,KAAK,OAAO,QAAQ,cAAc,KAAK,GAAG;AACnE,UAAM,iBAAiB,wBAAwB,UAAU,OAAO;AAChE,4BAAwB,IAAI,gBAAgB,KAAK;EACnD;AAIA,QAAM,YAAY,oBAAI,IAAG;AAEzB,aAAW,YAAY,cAAc;AACnC,QAAI;AAEF,YAAM,eAAeC,OAAK,WAAW,QAAQ,IAAI,WAAWA,OAAK,KAAK,SAAS,QAAQ;AACvF,YAAM,QAAQ,MAAMC,IAAG,KAAK,YAAY;AACxC,gBAAU,IAAI,UAAU,MAAM,OAAO;IACvC,QAAQ;AAEN;IACF;EACF;AAGA,aAAW,CAAC,UAAU,KAAK,KAAK,WAAW;AACzC,UAAM,QAAQ,wBAAwB,IAAI,QAAQ;AAElD,QAAI,CAAC,OAAO;AAEV,YAAM,KAAK,QAAQ;IACrB,WAAW,MAAM,eAAe,OAAO;AAErC,eAAS,KAAK,QAAQ;IACxB;EACF;AAGA,aAAW,kBAAkB,wBAAwB,KAAI,GAAI;AAC3D,QAAI,CAAC,eAAe,IAAI,cAAc,GAAG;AACvC,cAAQ,KAAK,cAAc;IAC7B;EACF;AAEA,SAAO;IACL;IACA;IACA;IACA,QAAQ;;AAEZ;;;AG9OA,eAAsB,6BACpB,OACA,YAA4B;AAE5B,QAAM,UAA0B,CAAA;AAEhC,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK,4BAA4B;AACjE,UAAM,aAAa,MAAM,MAAM,GAAG,KAAK,IAAI,IAAI,4BAA4B,MAAM,MAAM,CAAC;AACxF,UAAM,eAAe,MAAM,WAAW,WAAW,UAAU;AAC3D,YAAQ,KAAK,GAAG,YAAY;AAG5B,UAAM,IAAI,QAAQ,aAAW,aAAa,OAAO,CAAC;EACpD;AAEA,SAAO;AACT;AAoBM,IAAO,sBAAP,MAA0B;EAUX;EACA;EACA;EACA;EAZF,cAAkC,CAAA;EAClC,eAAiC,CAAA;EAC1C,sBAAsB;;EAGtB,gBAAsC;EACtC,kBAAwC;EAEhD,YACmB,UACA,YACA,QACA,iBAAgC;AAHhC,SAAA,WAAA;AACA,SAAA,aAAA;AACA,SAAA,SAAA;AACA,SAAA,kBAAA;EAChB;;;;;;;;;EAUH,MAAM,UACJ,QACA,UACA,OAAa;AAEb,QAAI,OAAO,WAAW,GAAG;AACvB;IACF;AAGA,QAAI,KAAK,eAAe;AACtB,YAAM,KAAK;IACb;AAGA,QAAI;AACJ,SAAK,gBAAgB,IAAI,QAAc,aAAU;AAC/C,oBAAc;IAChB,CAAC;AAED,QAAI;AAEF,iBAAW,SAAS,QAAQ;AAC1B,aAAK,YAAY,KAAK;UACpB;UACA,SAAS,MAAM;SAChB;MACH;AAGA,WAAK,aAAa,KAAK;QACrB;QACA,YAAY,OAAO;QACnB;OACD;AAGD,UAAI,KAAK,YAAY,UAAU,KAAK,OAAO,gBAAgB;AACzD,cAAM,KAAK,kBAAiB;MAC9B;IACF;AAEE,kBAAW;AACX,WAAK,gBAAgB;IACvB;EACF;;;;;EAMA,MAAM,QAAK;AACT,SAAK,gBAAgB,aAAa,4BAA4B;AAC9D,UAAM,KAAK,kBAAiB;EAC9B;;;;EAKA,aAAU;AACR,WAAO;MACL,iBAAiB,KAAK;MACtB,cAAc,CAAC,GAAG,KAAK,YAAY;;EAEvC;;;;;EAMQ,MAAM,oBAAiB;AAE7B,QAAI,KAAK,iBAAiB;AACxB,WAAK,kBAAkB,KAAK,gBAAgB,KAAK,MAAM,KAAK,UAAS,CAAE;IACzE,OAAO;AACL,WAAK,kBAAkB,KAAK,UAAS;IACvC;AACA,WAAO,KAAK;EACd;;;;;EAMQ,MAAM,YAAS;AACrB,QAAI,KAAK,YAAY,WAAW,GAAG;AACjC;IACF;AAEA,UAAM,iBAAiB,KAAK;AAE5B,QAAI;AAEF,YAAM,YAAY,KAAK,YAAY,OAAO,GAAG,KAAK,YAAY,MAAM;AAGpE,eAAS,IAAI,GAAG,IAAI,UAAU,QAAQ,KAAK,KAAK,OAAO,oBAAoB;AACzE,cAAM,QAAQ,UAAU,MACtB,GACA,KAAK,IAAI,IAAI,KAAK,OAAO,oBAAoB,UAAU,MAAM,CAAC;AAEhE,cAAM,QAAQ,MAAM,IAAI,UAAQ,KAAK,OAAO;AAG5C,aAAK,gBAAgB,aAAa,0BAA0B;AAC5D,cAAM,mBAAmB,MAAM,6BAA6B,OAAO,KAAK,UAAU;AAClF,aAAK,uBAAuB,MAAM;AAGlC,aAAK,gBAAgB,aAAa,aAAa,MAAM,MAAM,YAAY;AACvE,cAAM,KAAK,SAAS,YAClB,kBACA,MAAM,IAAI,UAAQ,KAAK,MAAM,QAAQ,GACrC,KAAK;AAIP,cAAM,IAAI,QAAQ,aAAW,aAAa,OAAO,CAAC;MACpD;AAEA,WAAK,gBAAgB,aAAa,qBAAqB;IACzD;AAEE,UAAI,KAAK,oBAAoB,gBAAgB;AAC3C,aAAK,kBAAkB;MACzB;IACF;EACF;;;;A5D1JF,SAAS,kBAAkB,QAAqC;AAC9D,MAAI,eAAe,MAAM,GAAG;AAC1B,WAAO;MACL,aAAa,OAAO,KAAK;MACzB,oBAAoB,OAAO,KAAK;MAChC,WAAW,OAAO,KAAK;MACvB,cAAc,OAAO,KAAK;MAC1B,QAAQ,OAAO,SAAS;MACxB,aAAa,OAAO,SAAS;;EAEjC;AAEA,SAAO;IACL,aAAa;IACb,oBAAoB;IACpB,WAAW;IACX,cAAc;IACd,QAAQ;IACR,aAAa;;AAEjB;AAGA,eAAe,iBACb,SACA,QAAqC;AAErC,MAAI,eAAe,MAAM,KAAK,OAAO,WAAW,SAAS,GAAG;AAC1D,WAAO,2BAA2B,SAAS,MAAM;EACnD;AACA,MAAI,eAAe,MAAM,GAAG;AAC1B,WAAO,aAAa;MAClB;MACA,iBAAiB,OAAO,SAAS;MACjC,iBAAiB,OAAO,SAAS;KAClC;EACH;AACA,SAAO,aAAa,EAAE,SAAS,iBAAiB,CAAA,GAAI,iBAAiB,CAAA,EAAE,CAAE;AAC3E;AAKA,eAAe,eACb,SACA,UACA,UAAyB;AAEzB,QAAM,eAAe,MAAM,eAAc;AACzC,QAAM,SAAS,MAAM,UAAU,OAAO;AAEtC,MAAI,CAAC,gBAAgB,CAAC,QAAQ;AAC5B;EACF;AAEA,QAAM,aAAa,IAAI,gBAAgB,SAAS,SAAS,MAAM;AAC/D,QAAM,WAAW,WAAU;AAC3B,QAAM,WAAW,WAAW,SAAQ;AAEpC,MAAI,UAAU;AACZ,UAAM,SAAS,eAAe,QAAQ;EACxC;AACF;AAKA,eAAe,gBACb,cACA,UACA,UAAyB;AAEzB,MAAI,aAAa,WAAW,GAAG;AAC7B,WAAO;EACT;AAEA,MAAI,eAAe;AAEnB,aAAW,YAAY,cAAc;AACnC,QAAI;AACF,YAAM,SAAS,aAAa,QAAQ;AACpC,YAAM,SAAS,WAAW,QAAQ;AAClC;IACF,QAAQ;IAER;EACF;AAEA,SAAO;AACT;AAKA,eAAe,cACb,YACA,eACA,UACA,YACA,QACA,SAAwB;AAExB,QAAM,eAAe,CAAC,GAAG,YAAY,GAAG,aAAa;AAErD,MAAI,aAAa,WAAW,GAAG;AAC7B,WAAO;EACT;AAEA,QAAM,QAAQ,MAAM,mBAClB,cACA,UACA,YACA,QACA,EAAE,SAAS,QAAQ,QAAO,CAAE;AAG9B,QAAM,iBAAiB,SAAS,MAAM;AACtC,SAAO;AACT;AAMA,eAAe,oBACb,SACA,UACA,QACA,SACA,WAAiB;AAEjB,QAAM,WAAW,IAAI,gBAAgB,SAAS,MAAM;AACpD,QAAM,gBAAgB,MAAM,SAAS,KAAI;AAEzC,MAAI,CAAC,eAAe;AAClB,WAAO;EACT;AAEA,QAAM,UAAU,MAAM,cAAc,SAAS,UAAU,MAAM;AAE7D,MAAI,QAAQ,WAAW,QAAQ;AAC7B,WAAO;EACT;AAEA,QAAM,eAAe,QAAQ,MAAM,SAAS,QAAQ,SAAS;AAC7D,QAAM,eAAe,QAAQ,QAAQ;AAErC,MAAI,iBAAiB,KAAK,iBAAiB,GAAG;AAC5C,YAAQ,aAAa;MACnB,OAAO;MACP,SAAS;MACT,YAAY;MACZ,gBAAgB;KACjB;AACD,WAAO;MACL,SAAS;MACT,cAAc;MACd,eAAe;MACf,YAAY,KAAK,IAAG,IAAK;MACzB,aAAa;;EAEjB;AAEA,UAAQ,aAAa;IACnB,OAAO;IACP,SAAS,YAAY,YAAY,oBAAoB,YAAY;GAClE;AAGD,QAAM,aAAa,QAAQ,cAAc,IAAI,gBAAe;AAC5D,MAAI,CAAC,QAAQ,YAAY;AACvB,UAAM,WAAW,WAAU;EAC7B;AAGA,QAAM,gBAAgB,QAAQ,SAAS,UAAU,QAAQ;AACzD,QAAM,eAAe,MAAM,cACzB,QAAQ,OACR,QAAQ,UACR,UACA,YACA,QACA,OAAO;AAIT,QAAM,eAAe,SAAS,UAAU,QAAQ;AAEhD,UAAQ,aAAa;IACnB,OAAO;IACP,SAAS,WAAW,YAAY,QAAQ,iBAAiB,IAAI,MAAM,EAAE,aAAa,YAAY;IAC9F,YAAY,eAAe;IAC3B,gBAAgB,eAAe;GAChC;AAED,SAAO;IACL,SAAS;IACT,cAAc;IACd,eAAe;;IACf,YAAY,KAAK,IAAG,IAAK;IACzB,aAAa;;AAEjB;AAQA,eAAe,uBACb,MACA,gBACA,aACA,iBACA,UAAiB;AAEjB,MAAI;AAEF,UAAM,QAAQ,MAAMC,KAAG,KAAK,IAAI;AAChC,UAAM,UAAU,MAAMA,KAAG,SAAS,MAAM,OAAO;AAE/C,UAAM,SAAS,UAAU,MAAM,SAAS;MACtC,WAAW,YAAY;MACvB,cAAc,YAAY;MAC1B,QAAQ,YAAY;MACpB,aAAa,YAAY;KAC1B;AAED,QAAI,OAAO,WAAW,GAAG;AACvB,sBAAgB,eAAc;AAC9B,aAAO;IACT;AAGA,UAAM,eAAe,UAAU,QAAQ,MAAM,MAAM,OAAO;AAC1D,oBAAgB,eAAc;AAE9B,WAAO;EACT,QAAQ;AACN,oBAAgB,eAAc;AAC9B,WAAO;EACT;AACF;AAKA,eAAe,iBACb,SACA,UACA,QACA,SACA,WAAiB;AAGjB,UAAQ,aAAa,EAAE,OAAO,gBAAgB,SAAS,6BAA4B,CAAE;AACrF,QAAM,SAAS,MAAK;AAGpB,UAAQ,aAAa,EAAE,OAAO,YAAY,SAAS,uBAAsB,CAAE;AAC3E,QAAM,QAAQ,MAAM,iBAAiB,SAAS,MAAM;AAEpD,MAAI,MAAM,WAAW,GAAG;AACtB,WAAO;MACL,SAAS;MACT,cAAc;MACd,eAAe;MACf,YAAY,KAAK,IAAG,IAAK;MACzB,aAAa;MACb,OAAO;;EAEX;AAGA,UAAQ,aAAa;IACnB,OAAO;IACP,SAAS;IACT,YAAY,MAAM;GACnB;AAED,QAAM,aAAa,QAAQ,cAAc,IAAI,gBAAe;AAC5D,MAAI,CAAC,QAAQ,YAAY;AACvB,UAAM,WAAW,WAAU;EAC7B;AAGA,QAAM,cAAc,kBAAkB,MAAM;AAC5C,QAAM,iBAAiB,EAAE,OAAO,EAAC;AAGjC,QAAM,kBAAkB;IACtB,gBAAgB,MAAK;AACnB,qBAAe;AACf,cAAQ,aAAa;QACnB,OAAO;QACP,SAAS;QACT,YAAY,MAAM;QAClB,gBAAgB,eAAe;OAChC;IACH;IACA,iBAAiB,MAAK;IAAE;IACxB,mBAAmB,MAAM,eAAe;IACxC,OAAO,MAAK;IAAE;IACd,MAAM,MAAK;IAAE;;AAGf,QAAM,iBAAiB,IAAI,oBAAoB,UAAU,YAAY;IACnE,gBAAgB;IAChB,oBAAoB,YAAY;KAC/B,eAAe;AAElB,UAAQ,aAAa;IACnB,OAAO;IACP,SAAS,cAAc,MAAM,MAAM;IACnC,YAAY,MAAM;IAClB,gBAAgB;GACjB;AAED,MAAI;AAEF,UAAM,QAAQ,OAAO,YAAY,WAAW;AAC5C,UAAM,eAAe,MAAM,IAAI,UAC7B,MAAM,MAAM,uBACV,MACA,gBACA,aACA,iBACA,QAAQ,WAAW,KAAK,CACzB,CAAC;AAGJ,UAAM,QAAQ,IAAI,YAAY;AAG9B,UAAM,eAAe,MAAK;EAC5B,SAASC,QAAO;AACd,WAAO;MACL,SAAS;MACT,cAAc,eAAe;MAC7B,eAAe;MACf,YAAY,KAAK,IAAG,IAAK;MACzB,aAAa;MACb,OAAOA,kBAAiB,QAAQA,OAAM,UAAU,OAAOA,MAAK;;EAEhE;AAGA,UAAQ,aAAa,EAAE,OAAO,UAAU,SAAS,2BAA0B,CAAE;AAC7E,QAAM,EAAE,iBAAiB,aAAY,IAAK,eAAe,WAAU;AAEnE,QAAM,WAAW,IAAI,gBAAgB,SAAS,MAAM;AACpD,QAAM,SAAS,YACb,aAAa,IAAI,YAAU;IACzB,UAAU,MAAM;IAChB,cAAc,MAAM;IACpB,YAAY,MAAM;IAClB,CAAC;AAIL,QAAM,eAAe,SAAS,UAAU,QAAQ;AAGhD,QAAM,iBAAiB,SAAS,MAAM;AAEtC,UAAQ,aAAa;IACnB,OAAO;IACP,SAAS;IACT,YAAY,MAAM;IAClB,gBAAgB,eAAe;IAC/B,iBAAiB;GAClB;AAED,SAAO;IACL,SAAS;IACT,cAAc,eAAe;IAC7B,eAAe;IACf,YAAY,KAAK,IAAG,IAAK;IACzB,aAAa;;AAEjB;AA8BA,eAAsB,cAAc,UAA2B,CAAA,GAAE;AAC/D,QAAM,UAAU,QAAQ,WAAW,QAAQ,IAAG;AAC9C,QAAM,YAAY,KAAK,IAAG;AAE1B,MAAI;AACF,YAAQ,aAAa,EAAE,OAAO,gBAAgB,SAAS,2BAA0B,CAAE;AAGnF,UAAM,SAAS,QAAQ,UAAU,MAAM,cAAc,KAAK,OAAO;AAGjE,YAAQ,aAAa,EAAE,OAAO,gBAAgB,SAAS,kCAAiC,CAAE;AAC1F,UAAM,WAAW,IAAI,SAAS,OAAO;AACrC,UAAM,SAAS,WAAU;AAGzB,QAAI,CAAC,QAAQ,OAAO;AAClB,YAAM,oBAAoB,MAAM,oBAAoB,SAAS,UAAU,QAAQ,SAAS,SAAS;AACjG,UAAI,mBAAmB;AACrB,eAAO;MACT;IACF;AAGA,WAAO,MAAM,iBAAiB,SAAS,UAAU,QAAQ,SAAS,SAAS;EAE7E,SAASA,QAAO;AACd,WAAO;MACL,SAAS;MACT,cAAc;MACd,eAAe;MACf,YAAY,KAAK,IAAG,IAAK;MACzB,aAAa;MACb,OAAOA,kBAAiB,QAAQA,OAAM,UAAU,OAAOA,MAAK;;EAEhE;AACF;;;A6DtgBO,IAAM,aAAa,EAAE,KAAK,GAAG,QAAQ,GAAG,MAAM,GAAG,UAAU,EAAC;;;ACW7D,SAAU,cAAcC,QAAc,eAAqB;AAC/D,MAAI,aAAaA,OAAK,QAAQ,SAAS,EAAE,EAAE,KAAI,EAAG,QAAQ,OAAO,GAAG;AAIpE,eAAa,WAAW,QAAQ,sBAAsB,EAAE;AAGxD,MAAI,WAAW,WAAW,gBAAgB,GAAG,GAAG;AAC9C,iBAAa,WAAW,UAAU,cAAc,SAAS,CAAC;EAC5D;AAEA,SAAO;AACT;AAaM,SAAU,kBAAkB,KAAa,SAAe;AAC5D,QAAM,QAAQ,IAAI,QAAQ,OAAO;AACjC,MAAI,UAAU;AAAI,WAAO;AAGzB,QAAM,aAAa,QAAQ,IAAI,IAAI,QAAQ,CAAC,IAAI;AAChD,MAAI,eAAe,OAAO,UAAU;AAAG,WAAO;AAI9C,QAAM,WAAW,QAAQ,QAAQ;AACjC,MAAI,aAAa,IAAI;AAAQ,WAAO;AACpC,QAAM,YAAY,IAAI,QAAQ;AAC9B,SAAO,cAAc;AACvB;AAeM,SAAU,YAAY,kBAA0B,kBAAwB;AAE5E,MAAI,qBAAqB;AAAkB,WAAO;AAGlD,MAAI,kBAAkB,kBAAkB,gBAAgB,GAAG;AACzD,WAAO;EACT;AAGA,MAAI,kBAAkB,kBAAkB,gBAAgB,GAAG;AACzD,WAAO;EACT;AAIA,QAAM,gBAAgB,iBAAiB,QAAQ,eAAe,EAAE;AAChE,MAAI,kBAAkB,eAAe,gBAAgB,KACjD,kBAAkB,kBAAkB,aAAa,GAAG;AACtD,WAAO;EACT;AAEA,SAAO;AACT;AASM,SAAU,iBAAiB,UAAkB,eAAqB;AACtE,MAAI,YAAY,SAAS,QAAQ,OAAO,GAAG;AAC3C,MAAI,UAAU,WAAW,gBAAgB,GAAG,GAAG;AAC7C,gBAAY,UAAU,UAAU,cAAc,SAAS,CAAC;EAC1D;AACA,SAAO;AACT;AAgBM,SAAUC,YAAW,UAAgB;AACzC,SAAO,wBAAwB,KAAK,QAAQ,KACrC,uCAAuC,KAAK,QAAQ;AAC7D;;;AC3HO,IAAM,6BAA6B;EACxC,KAAK;;EACL,QAAQ;;EACR,MAAM;;;AAOD,IAAM,wBAAwB;EACnC,2BAA2B;;EAC3B,cAAc;;EACd,cAAc;;EACd,UAAU;;EACV,UAAU;;EACV,YAAY;;EACZ,YAAY;;;AAqCd,SAAS,qBAAqB,eAAqB;AACjD,QAAM,QAAQ,oBAAI,IAAG;AACrB,SAAO,CAACC,WAAwB;AAC9B,UAAM,SAAS,MAAM,IAAIA,MAAI;AAC7B,QAAI,WAAW;AAAW,aAAO;AACjC,UAAM,aAAa,cAAcA,QAAM,aAAa;AACpD,UAAM,IAAIA,QAAM,UAAU;AAC1B,WAAO;EACT;AACF;AAUA,SAAS,iBACP,QACA,qBAA6C;AAE7C,QAAM,cAAc,oBAAI,IAAG;AAE3B,aAAW,SAAS,QAAQ;AAC1B,UAAM,UAAU,MAAM,SAAS,WAAW,CAAA;AAC1C,eAAW,OAAO,SAAS;AACzB,YAAM,mBAAmB,oBAAoB,GAAG;AAChD,UAAI,YAAY,YAAY,IAAI,gBAAgB;AAChD,UAAI,CAAC,WAAW;AACd,oBAAY,CAAA;AACZ,oBAAY,IAAI,kBAAkB,SAAS;MAC7C;AACA,gBAAU,KAAK,KAAK;IACtB;EACF;AAEA,SAAO;AACT;AASA,SAAS,oBACP,kBACA,aAAwC;AAExC,QAAM,kBAAkC,CAAA;AACxC,QAAM,eAAe,oBAAI,IAAG;AAE5B,QAAM,WAAW,CAAC,UAA6B;AAC7C,UAAM,UAAU,GAAG,MAAM,SAAS,IAAI,IAAI,MAAM,SAAS,SAAS,IAAI,MAAM,SAAS,OAAO;AAC5F,QAAI,CAAC,aAAa,IAAI,OAAO,GAAG;AAC9B,sBAAgB,KAAK,KAAK;AAC1B,mBAAa,IAAI,OAAO;IAC1B;EACF;AAGA,QAAM,gBAAgB,YAAY,IAAI,gBAAgB;AACtD,MAAI,eAAe;AACjB,eAAW,SAAS,eAAe;AACjC,eAAS,KAAK;IAChB;EACF;AAKA,aAAW,CAAC,kBAAkB,MAAM,KAAK,YAAY,QAAO,GAAI;AAC9D,QAAI,qBAAqB,oBAAoB,YAAY,kBAAkB,gBAAgB,GAAG;AAC5F,iBAAW,SAAS,QAAQ;AAC1B,iBAAS,KAAK;MAChB;IACF;EACF;AAEA,SAAO;AACT;AASA,SAAS,kBACP,QACA,eAAqB;AAErB,QAAM,eAAe,oBAAI,IAAG;AAE5B,aAAW,SAAS,QAAQ;AAC1B,UAAM,YAAY,iBAAiB,MAAM,SAAS,MAAM,aAAa;AACrE,QAAI,WAAW,aAAa,IAAI,SAAS;AACzC,QAAI,CAAC,UAAU;AACb,iBAAW,CAAA;AACX,mBAAa,IAAI,WAAW,QAAQ;IACtC;AACA,aAAS,KAAK,KAAK;EACrB;AAEA,SAAO;AACT;AAQA,SAAS,0BACP,cAAyC;AAEzC,QAAM,mBAAyC,CAAA;AAE/C,aAAW,CAAC,UAAU,MAAM,KAAK,aAAa,QAAO,GAAI;AACvD,UAAM,eAAe,OAClB,IAAI,OAAK,EAAE,SAAS,UAAU,EAC9B,OAAO,CAAC,MAAmB,OAAO,MAAM,YAAY,IAAI,CAAC;AAE5D,QAAI,aAAa,SAAS,GAAG;AAC3B,YAAM,MAAM,aAAa,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC;AAClD,YAAM,MAAM,MAAM,aAAa;AAC/B,YAAM,MAAM,KAAK,IAAI,GAAG,YAAY;AAEpC,uBAAiB,KAAK;QACpB;QACA,eAAe,KAAK,MAAM,MAAM,EAAE,IAAI;QACtC,eAAe;QACf,iBAAiB;QACjB,sBAAsB,aAAa;OACpC;IACH;EACF;AAEA,SAAO;AACT;AAQA,SAAS,kCACP,kBAAsC;AAEtC,MAAI,iBAAiB,WAAW,GAAG;AACjC,WAAO;EACT;AAEA,QAAM,UAAU,iBAAiB,IAAI,OAAK,EAAE,aAAa;AACzD,QAAM,WAAW,iBAAiB,IAAI,OAAK,EAAE,aAAa;AAC1D,QAAM,WAAW,QAAQ,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,IAAI,QAAQ;AAC9D,QAAM,YAAY,KAAK,IAAI,GAAG,QAAQ;AAGtC,QAAM,2BAA2B,iBAC9B,OAAO,OAAK,EAAE,gBAAgB,sBAAsB,yBAAyB,EAC7E,KAAK,CAAC,GAAG,MAAM,EAAE,gBAAgB,EAAE,aAAa,EAChD,MAAM,GAAG,CAAC,EACV,IAAI,QAAM;IACT,UAAU,EAAE;IACZ,eAAe,EAAE;IACjB,eAAe,EAAE;IACjB;AAGJ,QAAM,sBAAsB,6BAA6B,UAAU,SAAS;AAE5E,SAAO;IACL,mBAAmB,KAAK,MAAM,WAAW,EAAE,IAAI;IAC/C,eAAe;IACf,yBAAyB,iBAAiB;IAC1C;IACA;;AAEJ;AASA,SAAS,6BAA6B,eAAuB,eAAqB;AAChF,MAAI,gBAAgB,sBAAsB,gBAAgB,gBAAgB,sBAAsB,cAAc;AAC5G,WAAO;EACT;AACA,MAAI,gBAAgB,sBAAsB,YAAY,gBAAgB,sBAAsB,UAAU;AACpG,WAAO;EACT;AACA,MAAI,gBAAgB,sBAAsB,cAAc,gBAAgB,sBAAsB,YAAY;AACxG,WAAO;EACT;AACA,SAAO;AACT;AAQA,SAAS,4BAA4B,OAAa;AAChD,MAAI,SAAS,2BAA2B,KAAK;AAC3C,WAAO;EACT;AACA,MAAI,SAAS,2BAA2B,QAAQ;AAC9C,WAAO;EACT;AACA,MAAI,SAAS,2BAA2B,MAAM;AAC5C,WAAO;EACT;AACA,SAAO;AACT;AAUM,SAAU,oBACd,gBACA,WACA,eAAqB;AAGrB,QAAM,sBAAsB,qBAAqB,aAAa;AAG9D,QAAM,cAAc,iBAAiB,WAAW,mBAAmB;AAGnE,QAAM,mBAAmB,oBAAoB,cAAc;AAC3D,QAAM,kBAAkB,oBAAoB,kBAAkB,WAAW;AAGzE,QAAM,eAAe,kBAAkB,iBAAiB,aAAa;AAGrE,QAAM,mBAAmB,0BAA0B,YAAY;AAC/D,QAAM,oBAAoB,kCAAkC,gBAAgB;AAG5E,QAAM,aAAa,MAAM,KAAK,aAAa,KAAI,CAAE,EAAE,IAAI,eAAa;IAClE;IACA,YAAYC,YAAW,QAAQ;IAC/B;AAGF,MAAI,YAAY,4BAA4B,WAAW,MAAM;AAG7D,MAAI,mBAAmB,qBAAqB;AAC1C,QAAI,WAAW,kBAAkB,mBAAmB,IAAI,WAAW,SAAS,GAAG;AAC7E,kBAAY,kBAAkB;IAChC;EACF;AAEA,SAAO;IACL;IACA,gBAAgB,WAAW;IAC3B;IACA;;AAEJ;;;ACvUA,IAAM,WAAW,EAAE,SAAS,GAAK,OAAO,EAAG;AAKrC,IAAO,qBAAP,MAAyB;EAEnB;EACA;EAFV,YACU,UACA,QAAkB;AADlB,SAAA,WAAA;AACA,SAAA,SAAA;EACP;;;;;;EAOH,MAAM,QAAQ,OAAgB;AAI5B,UAAM,YAAY,MAAM,KAAK,SAAS,QAAO;AAG7C,UAAM,SAAS,QACX,UAAU,OAAO,OAAK,KAAK,eAAe,EAAE,SAAS,MAAM,KAAK,CAAC,IACjE;AAGJ,UAAM,aAAa,KAAK,eAAe,MAAM;AAG7C,UAAM,SAAS,KAAK,YAAY,YAAY,MAAM;AAGlD,SAAK,uBAAuB,QAAQ,SAA2B;AAE/D,WAAO;EACT;;;;;EAMQ,kBAAkB,UAAgB;AACxC,UAAM,gBAAgB,QAAQ,IAAG;AAEjC,UAAM,aAAa,SAAS,QAAQ,OAAO,GAAG;AAC9C,UAAM,iBAAiB,cAAc,QAAQ,OAAO,GAAG;AAGvD,QAAI,WAAW,WAAW,iBAAiB,GAAG,GAAG;AAC/C,aAAO,WAAW,MAAM,eAAe,SAAS,CAAC;IACnD;AACA,QAAI,WAAW,WAAW,cAAc,GAAG;AACzC,aAAO,WAAW,MAAM,eAAe,MAAM;IAC/C;AACA,WAAO;EACT;;;;;EAMQ,eAAeC,YAAmB,aAAqB;AAG7D,UAAM,sBAAsBA,WAAU,QAAQ,OAAO,GAAG;AACxD,WAAO,YAAY,KAAK,YAAS;AAC/B,YAAM,mBAAmB,OAAO,QAAQ,OAAO,GAAG;AAElD,aAAO,wBAAwB,oBACxB,oBAAoB,SAAS,MAAM,gBAAgB;IAC5D,CAAC;EACH;;;;EAKQ,gBACN,UACA,YACA,eACA,YAA6C;AAE7C,UAAM,mBAAmB,gBAAgB,SAAS;AAClD,UAAM,iBAAiB,gBAAgB,SAAS;AAEhD,QAAI,aAAa;AAAkB,aAAO;AAE1C,UAAM,oBAAoB,cAAc,iBAAiB,UAAU;AACnE,UAAM,qBAAqB,sBAAsB,UAAU,iBAAiB;AAG5E,UAAM,UAAU,eAAe,eAC3B,UAAU,UAAU,6CAA6C,KAAK,MAAM,kBAAkB,CAAC,MAC/F,eAAe,UAAU,sBAAsB,KAAK,MAAM,kBAAkB,CAAC;AAEjF,WAAO;MACL,UAAU,SAAS;MACnB,WAAW,SAAS;MACpB,SAAS,SAAS;MAClB,YAAY,SAAS,cAAc;MACnC,YAAY,SAAS;MACrB,UAAU,SAAS;MACnB;MACA,WAAW,KAAK,MAAM,kBAAkB;MACxC,UAAU;MACV;MACA;;EAEJ;;;;;EAMQ,wBACN,QAA2D;AAE3D,UAAM,OAAO,oBAAI,IAAG;AACpB,UAAM,SAA0B,CAAA;AAEhC,eAAW,EAAE,SAAQ,KAAM,QAAQ;AACjC,UAAI,SAAS,eAAe,cAAc,SAAS,eAAe;AAAU;AAE5E,YAAM,MAAM,GAAG,SAAS,IAAI,IAAI,SAAS,SAAS,IAAI,SAAS,OAAO;AACtE,UAAI,KAAK,IAAI,GAAG;AAAG;AAEnB,WAAK,IAAI,GAAG;AACZ,aAAO,KAAK,QAAQ;IACtB;AAEA,WAAO;EACT;;;;;;EAOQ,gBAAgB,QAAc;AACpC,WAAO,SAAS;EAClB;;;;EAKQ,WAAW,SAAe;AAChC,QAAI,WAAW,IAAI;AACjB,YAAM,QAAQ,KAAK,MAAM,UAAU,EAAE;AACrC,YAAM,OAAO,KAAK,MAAM,UAAU,EAAE;AACpC,aAAO,OAAO,IAAI,GAAG,KAAK,KAAK,IAAI,MAAM,GAAG,KAAK;IACnD;AACA,WAAO,GAAG,KAAK,MAAM,OAAO,CAAC;EAC/B;;;;EAKQ,wBACN,UACA,aACA,WACA,YAA+C;AAE/C,UAAM,mBAAmB,YAAY,SAAS;AAC9C,UAAM,iBAAiB,YAAY,SAAS;AAE5C,QAAI,cAAc;AAAkB,aAAO;AAE3C,UAAM,oBAAoB,eAAe,iBAAiB,UAAU;AACpE,UAAM,qBAAqB,sBAAsB,UAAU,iBAAiB;AAG5E,QAAI;AACJ,QAAI,eAAe,mBAAmB;AACpC,YAAM,cAAc,KAAK,gBAAgB,WAAW;AACpD,YAAM,mBAAmB,KAAK,gBAAgB,kBAAkB;AAChE,gBAAU,uBAAuB,KAAK,WAAW,WAAW,CAAC,sBAAsB,KAAK,WAAW,gBAAgB,CAAC;IACtH,OAAO;AACL,gBAAU,kBAAkB,YAAY,QAAQ,CAAC,CAAC,sBAAsB,mBAAmB,QAAQ,CAAC,CAAC;IACvG;AAEA,UAAM,kBAAmC;MACvC,QAAQ,SAAS,kBAAkB;MACnC,YAAY,SAAS,sBAAsB;MAC3C,QAAQ,SAAS,kBAAkB;MACnC,MAAM,SAAS,gBAAgB;;AAMjC,QAAI;AACJ,QAAI;AACJ,QAAI,eAAe,mBAAmB;AAEpC,mBAAa,KAAK,MAAM,KAAK,gBAAgB,WAAW,CAAC;AACzD,yBAAmB,KAAK,MAAM,KAAK,gBAAgB,kBAAkB,CAAC;IACxE,OAAO;AAEL,mBAAa;AACb,yBAAmB;IACrB;AAEA,WAAO;MACL,UAAU,SAAS;MACnB,WAAW,SAAS;MACpB,SAAS,SAAS;MAClB,YAAY,SAAS,cAAc;MACnC,YAAY,SAAS;MACrB,UAAU,SAAS;MACnB;MACA,WAAW;MACX,UAAU;MACV;MACA;MACA;;EAEJ;;;;EAKQ,qBACN,UACA,YAAsG;AAEtG,UAAM,aAAoC,CAAA;AAG1C,QAAI,SAAS,YAAY;AACvB,YAAM,IAAI,KAAK,gBAAgB,UAAU,SAAS,YAAY,WAAW,WAAW,YAAY;AAChG,UAAI;AAAG,mBAAW,KAAK,CAAC;IAC1B;AAGA,QAAI,SAAS,qBAAqB;AAChC,YAAM,IAAI,KAAK,gBAAgB,UAAU,SAAS,qBAAqB,WAAW,YAAY,WAAW;AACzG,UAAI;AAAG,mBAAW,KAAK,CAAC;IAC1B;AAGA,QAAI,WAAW,kBAAkB,SAAS,gBAAgB;AACxD,YAAM,IAAI,KAAK,wBAAwB,UAAU,SAAS,gBAAgB,WAAW,gBAAgB,iBAAiB;AACtH,UAAI;AAAG,mBAAW,KAAK,CAAC;IAC1B;AAGA,QAAI,WAAW,iBAAiB,SAAS,cAAc;AACrD,YAAM,IAAI,KAAK,wBAAwB,UAAU,SAAS,cAAc,WAAW,eAAe,eAAe;AACjH,UAAI;AAAG,mBAAW,KAAK,CAAC;IAC1B;AAEA,WAAO;EACT;;;;;;;EAQQ,gBAAgB,SAAe;AACrC,WAAO,UAAU;EACnB;;;;;EAMQ,eAAe,QAA2D;AAChF,UAAM,mBAAmB,KAAK,OAAO,YAAY;AAGjD,UAAM,iBAAiB,kBAAkB,0BACrC,KAAK,gBAAgB,iBAAiB,uBAAuB,IAC7D,KAAK,gBAAgB,EAAE;AAE3B,UAAM,aAAa;MACjB,WAAW,kBAAkB,aAAa;MAC1C,YAAY,kBAAkB,cAAc;MAC5C;;MACA,eAAe,kBAAkB,iBAAiB;;;AAEpD,UAAM,iBAAiB,KAAK,wBAAwB,MAAM;AAE1D,WAAO,eAAe,QAAQ,cAC5B,KAAK,qBAAqB,UAAU,UAAU,CAAC;EAEnD;;;;EAKQ,YACN,YACA,WAA8D;AAG9D,UAAM,oBAAoB,oBAAI,IAAG;AACjC,eAAW,aAAa,YAAY;AAClC,YAAM,iBAAiB,KAAK,kBAAkB,UAAU,QAAQ;AAEhE,gBAAU,WAAW;AACrB,YAAM,WAAW,kBAAkB,IAAI,cAAc,KAAK,CAAA;AAC1D,eAAS,KAAK,SAAS;AACvB,wBAAkB,IAAI,gBAAgB,QAAQ;IAChD;AAGA,UAAM,gBAAgB,IAAI,IAAI,UAAU,IAAI,OAAK,KAAK,kBAAkB,EAAE,SAAS,IAAI,CAAC,CAAC;AAGzF,UAAM,QAA4C,CAAA;AAClD,eAAW,YAAY,eAAe;AACpC,YAAM,iBAAiB,kBAAkB,IAAI,QAAQ,KAAK,CAAA;AAC1D,YAAM,QAAQ,IAAI;QAChB,YAAY;QACZ,YAAY,CAAA;;QACZ,kBAAkB,CAAA;;QAClB,WAAW,KAAK,mBAAmB,cAAc;;IAErD;AAGA,UAAM,aAAa,WAAW,OAAO,OAAK,EAAE,aAAa,OAAO,EAAE;AAClE,UAAM,eAAe,WAAW,OAAO,OAAK,EAAE,aAAa,SAAS,EAAE;AAGtE,UAAM,mBAAmB,UACtB,OAAO,OAAK,EAAE,SAAS,eAAe,UAAa,EAAE,SAAS,aAAa,CAAC,EAC5E,IAAI,OAAK,EAAE,SAAS,UAAW;AAElC,UAAM,gBAAgB,iBAAiB,SAAS,IAC5C,iBAAiB,OAAO,CAAC,KAAK,QAAQ,MAAM,KAAK,CAAC,IAAI,iBAAiB,SACvE;AAEJ,UAAM,gBAAgB,iBAAiB,SAAS,IAC5C,KAAK,IAAI,GAAG,gBAAgB,IAC5B;AAEJ,WAAO;MACL,SAAS;QACP,eAAe,cAAc;QAC7B,iBAAiB,WAAW;QAC5B,YAAY,EAAE,OAAO,YAAY,SAAS,aAAY;QACtD,eAAe,KAAK,MAAM,gBAAgB,EAAE,IAAI;;QAChD;;MAEF;;EAEJ;;;;EAKQ,mBAAmB,YAAiC;AAC1D,QAAI,WAAW,WAAW;AAAG,aAAO;AAEpC,UAAM,YAAY,WAAW,KAAK,OAAK,EAAE,aAAa,OAAO;AAC7D,UAAM,aAAa,WAAW,OAAO,OAAK,EAAE,aAAa,OAAO,EAAE;AAElE,QAAI,cAAc;AAAG,aAAO;AAC5B,QAAI;AAAW,aAAO;AACtB,QAAI,WAAW,UAAU;AAAG,aAAO;AACnC,WAAO;EACT;;;;;;;EAQQ,uBACN,QACA,WAAyB;AAEzB,UAAM,gBAAgB,QAAQ,IAAG;AAGjC,UAAM,sBAAsB,OAAO,QAAQ,OAAO,KAAK,EACpD,OAAO,CAAC,CAAC,GAAG,IAAI,MAAM,KAAK,WAAW,SAAS,CAAC,EAChD,IAAI,CAAC,CAAC,UAAU,CAAC,MAAM,QAAQ;AAElC,eAAW,YAAY,qBAAqB;AAC1C,YAAM,WAAW,OAAO,MAAM,QAAQ;AAGtC,YAAM,cAAc,oBAAoB,UAAU,WAAW,aAAa;AAG1E,eAAS,aAAa,YAAY,WAAW,IAAI,OAAK,EAAE,QAAQ;AAChE,eAAS,iBAAiB,YAAY;AAItC,UAAI,WAAW,YAAY,SAAS,IAAI,WAAW,SAAS,SAAS,GAAG;AACtE,iBAAS,YAAY,YAAY;MACnC;AAGA,UAAI,YAAY,mBAAmB;AACjC,iBAAS,6BAA6B;UACpC,mBAAmB,YAAY,kBAAkB;UACjD,eAAe,YAAY,kBAAkB;UAC7C,yBAAyB,YAAY,kBAAkB;;MAE3D;IACF;EACF;;;;AClVK,IAAM,aAAa,CAAC,YAAqB,cAAe,KAAK,OAAO;AAGpE,IAAM,sBAAsB,MAAM;;;ACpFzC,YAAY,UAAU;AACtB,YAAY,YAAY;AAmBjB,SAAS,eAAiC;AAC/C,QAAM,EAAE,QAAQ,IAAI;AAEpB,MAAI,CAAC,QAAQ,QAAQ,cAAc;AACjC,IAAK,aAAQ,+CAA+C;AAC5D,WAAO;AAAA,EACT;AAEA,QAAM,KAAK,QAAQ,QAAQ;AAE3B,SAAO;AAAA,IACL,OAAO,QAAQ,KAAK;AAAA,IACpB,MAAM,QAAQ,KAAK;AAAA,IACnB,YAAY,GAAG;AAAA,IACf,OAAO,GAAG;AAAA,IACV,SAAS,GAAG,KAAK;AAAA,IACjB,SAAS,GAAG,KAAK;AAAA,EACnB;AACF;AAKA,eAAsB,kBACpB,SACA,WACmB;AACnB,QAAM,QAAkB,CAAC;AACzB,MAAI,OAAO;AACX,QAAM,UAAU;AAEhB,SAAO,MAAM;AACX,UAAM,WAAW,MAAM,QAAQ,KAAK,MAAM,UAAU;AAAA,MAClD,OAAO,UAAU;AAAA,MACjB,MAAM,UAAU;AAAA,MAChB,aAAa,UAAU;AAAA,MACvB,UAAU;AAAA,MACV;AAAA,IACF,CAAC;AAED,eAAW,QAAQ,SAAS,MAAM;AAEhC,UAAI,KAAK,WAAW,WAAW;AAC7B,cAAM,KAAK,KAAK,QAAQ;AAAA,MAC1B;AAAA,IACF;AAEA,QAAI,SAAS,KAAK,SAAS,SAAS;AAClC;AAAA,IACF;AACA;AAAA,EACF;AAEA,SAAO;AACT;AAKA,eAAsB,cACpB,SACA,WACA,MACe;AAEf,QAAM,kBAAkB,MAAM,oBAAoB,SAAS,SAAS;AAEpE,MAAI,iBAAiB;AACnB,IAAK,UAAK,6BAA6B,gBAAgB,EAAE,EAAE;AAC3D,UAAM,QAAQ,KAAK,OAAO,cAAc;AAAA,MACtC,OAAO,UAAU;AAAA,MACjB,MAAM,UAAU;AAAA,MAChB,YAAY,gBAAgB;AAAA,MAC5B;AAAA,IACF,CAAC;AAAA,EACH,OAAO;AACL,IAAK,UAAK,sBAAsB;AAChC,UAAM,QAAQ,KAAK,OAAO,cAAc;AAAA,MACtC,OAAO,UAAU;AAAA,MACjB,MAAM,UAAU;AAAA,MAChB,cAAc,UAAU;AAAA,MACxB;AAAA,IACF,CAAC;AAAA,EACH;AACF;AAKA,eAAe,oBACb,SACA,WACgC;AAChC,QAAM,iBAAiB;AAEvB,QAAM,WAAW,MAAM,QAAQ,KAAK,OAAO,aAAa;AAAA,IACtD,OAAO,UAAU;AAAA,IACjB,MAAM,UAAU;AAAA,IAChB,cAAc,UAAU;AAAA,EAC1B,CAAC;AAED,aAAW,WAAW,SAAS,MAAM;AACnC,QAAI,QAAQ,MAAM,SAAS,cAAc,GAAG;AAC1C,aAAO,EAAE,IAAI,QAAQ,GAAG;AAAA,IAC1B;AAAA,EACF;AAEA,SAAO;AACT;AAKA,eAAsB,eACpB,SACA,WACA,UACA,WACA,SACwB;AACxB,MAAI;AACF,UAAM,WAAW,MAAM,QAAQ,KAAK,MAAM,WAAW;AAAA,MACnD,OAAO,UAAU;AAAA,MACjB,MAAM,UAAU;AAAA,MAChB,MAAM;AAAA,MACN,KAAK,UAAU;AAAA,IACjB,CAAC;AAED,QAAI,aAAa,SAAS,MAAM;AAC9B,YAAM,UAAU,OAAO,KAAK,SAAS,KAAK,SAAS,QAAQ,EAAE;AAAA,QAC3D;AAAA,MACF;AACA,YAAM,QAAQ,QAAQ,MAAM,IAAI;AAEhC,YAAM,UAAU,MAAM,MAAM,YAAY,GAAG,OAAO,EAAE,KAAK,IAAI;AAC7D,aAAO;AAAA,IACT;AAAA,EACF,SAASC,QAAO;AACd,IAAK,aAAQ,6BAA6B,QAAQ,KAAKA,MAAK,EAAE;AAAA,EAChE;AAEA,SAAO;AACT;AAKO,SAAS,cAAc,OAAwB;AACpD,SAAc,kBAAW,KAAK;AAChC;AAcA,eAAsB,aACpB,SACA,WACA,UACA,aACe;AACf,MAAI,SAAS,WAAW,GAAG;AAEzB,UAAM,cAAc,SAAS,WAAW,WAAW;AACnD;AAAA,EACF;AAEA,EAAK,UAAK,wBAAwB,SAAS,MAAM,gBAAgB;AAEjE,MAAI;AAEF,UAAM,QAAQ,KAAK,MAAM,aAAa;AAAA,MACpC,OAAO,UAAU;AAAA,MACjB,MAAM,UAAU;AAAA,MAChB,aAAa,UAAU;AAAA,MACvB,WAAW,UAAU;AAAA,MACrB,OAAO;AAAA;AAAA,MACP,MAAM;AAAA,MACN,UAAU,SAAS,IAAI,CAAC,OAAO;AAAA,QAC7B,MAAM,EAAE;AAAA,QACR,MAAM,EAAE;AAAA,QACR,MAAM,EAAE;AAAA,MACV,EAAE;AAAA,IACJ,CAAC;AAED,IAAK,UAAK,4BAA4B;AAAA,EACxC,SAASA,QAAO;AAEd,IAAK,aAAQ,iCAAiCA,MAAK,EAAE;AACrD,IAAK,UAAK,oCAAoC;AAC9C,UAAM,cAAc,SAAS,WAAW,WAAW;AAAA,EACrD;AACF;AAKA,IAAM,2BAA2B;AACjC,IAAM,yBAAyB;AAM/B,eAAsB,oBACpB,SACA,WACA,eACe;AACf,MAAI;AAEF,UAAM,EAAE,MAAM,GAAG,IAAI,MAAM,QAAQ,KAAK,MAAM,IAAI;AAAA,MAChD,OAAO,UAAU;AAAA,MACjB,MAAM,UAAU;AAAA,MAChB,aAAa,UAAU;AAAA,IACzB,CAAC;AAED,UAAM,cAAc,GAAG,QAAQ;AAC/B,UAAM,eAAe,GAAG,wBAAwB;AAAA,EAAK,aAAa;AAAA,EAAK,sBAAsB;AAE7F,QAAI;AAGJ,UAAM,WAAW,YAAY,QAAQ,wBAAwB;AAC7D,UAAM,SAAS,YAAY,QAAQ,sBAAsB;AAEzD,QAAI,aAAa,MAAM,WAAW,MAAM,SAAS,UAAU;AAEzD,gBACE,YAAY,MAAM,GAAG,QAAQ,IAC7B,eACA,YAAY,MAAM,SAAS,uBAAuB,MAAM;AAC1D,MAAK,UAAK,iDAAiD;AAAA,IAC7D,OAAO;AAEL,gBAAU,YAAY,KAAK,IAAI,gBAAgB;AAC/C,MAAK,UAAK,sCAAsC;AAAA,IAClD;AAGA,UAAM,QAAQ,KAAK,MAAM,OAAO;AAAA,MAC9B,OAAO,UAAU;AAAA,MACjB,MAAM,UAAU;AAAA,MAChB,aAAa,UAAU;AAAA,MACvB,MAAM;AAAA,IACR,CAAC;AAED,IAAK,UAAK,8CAA8C;AAAA,EAC1D,SAASA,QAAO;AAEd,IAAK,aAAQ,oCAAoCA,MAAK,EAAE;AAAA,EAC1D;AACF;AAMO,SAAS,gBAAgB,OAA4B;AAC1D,QAAM,QAAQ,oBAAI,IAAY;AAC9B,MAAI,cAAc;AAElB,aAAW,aAAa,MAAM,MAAM,IAAI,GAAG;AAEzC,UAAM,YAAY,UAAU,MAAM,uCAAuC;AACzE,QAAI,WAAW;AACb,oBAAc,SAAS,UAAU,CAAC,GAAG,EAAE;AACvC;AAAA,IACF;AAGA,QAAI,UAAU,WAAW,GAAG,KAAK,UAAU,WAAW,GAAG,GAAG;AAC1D,UAAI,CAAC,UAAU,WAAW,KAAK,GAAG;AAChC,cAAM,IAAI,WAAW;AACrB;AAAA,MACF;AAAA,IACF;AAAA,EAEF;AAEA,SAAO;AACT;AAMA,eAAsB,eACpB,SACA,WACmC;AACnC,QAAM,YAAY,oBAAI,IAAyB;AAG/C,QAAM,WAAW,QAAQ,SAAS,SAAS,QAAQ,KAAK,MAAM,WAAW;AAAA,IACvE,OAAO,UAAU;AAAA,IACjB,MAAM,UAAU;AAAA,IAChB,aAAa,UAAU;AAAA,IACvB,UAAU;AAAA,EACZ,CAAC;AAED,mBAAiB,YAAY,UAAU;AACrC,eAAW,QAAQ,SAAS,MAAM;AAChC,UAAI,CAAC,KAAK,MAAO;AAEjB,YAAM,QAAQ,gBAAgB,KAAK,KAAK;AACxC,UAAI,MAAM,OAAO,GAAG;AAClB,kBAAU,IAAI,KAAK,UAAU,KAAK;AAAA,MACpC;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;;;ACrVA,YAAYC,WAAU;;;ACAtB,OAAOC,cAAa;;;ACCpB,YAAYC,WAAU;AACtB,OAAO,aAAa;AAsCpB,SAAS,eAAe,UAAkB,YAAoB,YAA4B;AACxF,SAAO,GAAG,QAAQ,KAAK,UAAU,KAAK,UAAU;AAClD;AAKA,SAAS,mBACP,QACA,OACqE;AACrE,MAAI,CAAC,OAAQ,QAAO,oBAAI,IAAI;AAK5B,QAAM,UAAU,QAAQ,KAAK,EAC1B,IAAI,eAAa,EAAE,UAAU,UAAU,OAAO,MAAM,QAAQ,EAAE,EAAE,EAChE,OAAO,CAAC,EAAE,SAAS,MAAM,CAAC,CAAC,QAAQ,EACnC;AAAA,IAAQ,CAAC,EAAE,UAAU,SAAS,MAC7B,SAAS,WAAW,IAAI,eAAa;AAAA,MACnC,eAAe,UAAU,UAAU,YAAY,UAAU,UAAU;AAAA,MACnE,EAAE,YAAY,UAAU,YAAY,UAAU;AAAA,IAChD,CAAa;AAAA,EACf,EACC,IAAI;AAEP,SAAO,IAAI,IAAI,OAAO;AACxB;AAKA,SAAS,kBACP,gBACA,gBACA,OACA,WAC6B;AAC7B,MAAI,mBAAmB,KAAM,QAAO;AACpC,MAAI,QAAQ,EAAG,QAAO;AACtB,SAAO,kBAAkB,YAAY,IAAI,UAAU;AACrD;AAKA,SAAS,YACP,WACA,gBACA,gBACA,UACiB;AACjB,QAAM,QAAQ,mBAAmB,QAAQ,mBAAmB,OACxD,iBAAiB,iBACjB,kBAAkB,EAAE,kBAAkB;AAE1C,SAAO;AAAA,IACL,UAAU,UAAU;AAAA,IACpB,YAAY,UAAU;AAAA,IACtB,YAAY,UAAU;AAAA,IACtB,WAAW,UAAU;AAAA,IACrB,YAAY,UAAU;AAAA,IACtB;AAAA,IACA;AAAA,IACA;AAAA,IACA,WAAW,UAAU;AAAA,IACrB;AAAA,EACF;AACF;AAKO,SAAS,gBACd,YACA,YACA,cACmB;AACnB,QAAM,UAAU,mBAAmB,YAAY,YAAY;AAC3D,QAAM,UAAU,mBAAmB,YAAY,YAAY;AAC3D,QAAM,eAAe,oBAAI,IAAY;AAGrC,QAAM,aAAa,QAAQ,MAAM,KAAK,QAAQ,QAAQ,CAAC,CAAC,EACrD,IAAI,CAAC,CAAC,KAAK,QAAQ,MAAM;AACxB,UAAM,WAAW,QAAQ,IAAI,GAAG;AAChC,QAAI,SAAU,cAAa,IAAI,GAAG;AAElC,UAAM,iBAAiB,UAAU,cAAc;AAC/C,UAAM,iBAAiB,SAAS;AAChC,UAAM,QAAQ,mBAAmB,OAAO,iBAAiB,iBAAiB;AAC1E,UAAM,WAAW,kBAAkB,gBAAgB,gBAAgB,OAAO,SAAS,UAAU,SAAS;AAEtG,WAAO,YAAY,SAAS,WAAW,gBAAgB,gBAAgB,QAAQ;AAAA,EACjF,CAAC,EACA,IAAI;AAGP,QAAM,gBAAgB,QAAQ,MAAM,KAAK,QAAQ,QAAQ,CAAC,CAAC,EACxD,OAAO,CAAC,CAAC,GAAG,MAAM,CAAC,aAAa,IAAI,GAAG,CAAC,EACxC,IAAI,CAAC,CAAC,GAAG,QAAQ,MAAM,YAAY,SAAS,WAAW,SAAS,YAAY,MAAM,SAAS,CAAC,EAC5F,IAAI;AAEP,QAAM,SAAS,CAAC,GAAG,YAAY,GAAG,aAAa;AAG/C,SAAO,KAAK,CAAC,GAAG,MAAM;AAEpB,UAAM,gBAAgB,EAAE,OAAO,GAAG,SAAS,GAAG,KAAK,GAAG,UAAU,GAAG,SAAS,EAAE;AAC9E,QAAI,cAAc,EAAE,QAAQ,MAAM,cAAc,EAAE,QAAQ,GAAG;AAC3D,aAAO,cAAc,EAAE,QAAQ,IAAI,cAAc,EAAE,QAAQ;AAAA,IAC7D;AAEA,WAAO,EAAE,QAAQ,EAAE;AAAA,EACrB,CAAC;AAED,SAAO;AACT;AAKO,SAAS,sBAAsB,QAAyC;AAC7E,QAAM,aAAa,QAAQ,MAAM;AAGjC,QAAM,cAAc,WAAW,IAAI,OAAK;AACtC,QAAI,EAAE,aAAa,WAAY,QAAO;AACtC,QAAI,EAAE,aAAa,MAAO,QAAO;AACjC,QAAI,EAAE,aAAa,UAAW,QAAO;AAErC,QAAI,EAAE,QAAQ,EAAG,QAAO;AACxB,QAAI,EAAE,UAAU,EAAG,QAAO;AAC1B,WAAO;AAAA,EACT,CAAC;AAED,QAAM,SAAS,YAAY,QAAQ,EAAE,IAAI;AAEzC,SAAO;AAAA,IACL,YAAY,WAAW,IAAI,OAAO;AAAA,IAClC,UAAU,OAAO,UAAU,KAAK;AAAA,IAChC,UAAU,OAAO,UAAU,KAAK;AAAA,IAChC,cAAc,OAAO,KAAK,KAAK;AAAA,IAC/B,kBAAkB,OAAO,SAAS,KAAK;AAAA,IACvC,WAAW,OAAO,WAAW,KAAK;AAAA,EACpC;AACF;AAKO,SAAS,YAAY,OAAuB;AACjD,MAAI,QAAQ,EAAG,QAAO,IAAI,KAAK;AAC/B,MAAI,QAAQ,EAAG,QAAO,GAAG,KAAK;AAC9B,SAAO;AACT;AAKO,SAAS,oBAAoB,UAA+C;AACjF,UAAQ,UAAU;AAAA,IAChB,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,IACT,KAAK;AACH,aAAO;AAAA,EACX;AACF;AAKO,SAAS,gBAAgB,SAA6B;AAC3D,QAAM,OAAO,QAAQ,cAAc,IAAI,MAAM;AAC7C,EAAK,WAAK,qBAAqB,IAAI,GAAG,QAAQ,UAAU,EAAE;AAC1D,EAAK,WAAK,eAAe,QAAQ,QAAQ,eAAe,QAAQ,QAAQ,EAAE;AAC1E,EAAK,WAAK,UAAU,QAAQ,YAAY,cAAc,QAAQ,gBAAgB,EAAE;AAClF;;;AC/NO,SAAS,WAAW,SAAyB;AAClD,QAAM,OAAO,UAAU,IAAI,MAAM;AACjC,QAAM,iBAAiB,KAAK,MAAM,KAAK,IAAI,OAAO,CAAC;AACnD,MAAI,kBAAkB,IAAI;AACxB,UAAM,QAAQ,KAAK,MAAM,iBAAiB,EAAE;AAC5C,UAAM,OAAO,iBAAiB;AAC9B,WAAO,OAAO,IAAI,GAAG,IAAI,GAAG,KAAK,KAAK,IAAI,MAAM,GAAG,IAAI,GAAG,KAAK;AAAA,EACjE;AACA,SAAO,GAAG,IAAI,GAAG,cAAc;AACjC;AAQO,SAAS,iBAAiB,YAAoB,OAAuB;AAC1E,MAAI,eAAe,iBAAiB;AAClC,WAAO,MAAM,QAAQ,CAAC;AAAA,EACxB;AAEA,MAAI,eAAe,mBAAmB;AACpC,WAAO,WAAW,KAAK;AAAA,EACzB;AACA,SAAO,OAAO,KAAK,MAAM,KAAK,CAAC;AACjC;;;AFhBA,SAAS,eAAe,GAAyE;AAC/F,SAAO,GAAG,EAAE,QAAQ,KAAK,EAAE,UAAU,KAAK,EAAE,UAAU;AACxD;AAKA,SAAS,cAAc,QAAgE;AACrF,MAAI,CAAC,OAAQ,QAAO,oBAAI,IAAI;AAE5B,SAAO,IAAI;AAAA,IACTC,SAAQ,MAAM,EACX,IAAI,OAAK,CAAC,eAAe,CAAC,GAAG,CAAC,CAA8B,EAC5D,IAAI;AAAA,EACT;AACF;AAKO,SAAS,eAAe,YAA4B;AACzD,UAAQ,YAAY;AAAA,IAClB,KAAK;AAAa,aAAO;AAAA,IACzB,KAAK;AAAc,aAAO;AAAA,IAC1B,KAAK;AAAmB,aAAO;AAAA,IAC/B,KAAK;AAAiB,aAAO;AAAA,IAC7B;AAAS,aAAO;AAAA,EAClB;AACF;AAKO,SAAS,sBAAsB,YAAoB,OAAuB;AAC/E,UAAQ,YAAY;AAAA,IAClB,KAAK;AACH,aAAO,IAAI,WAAW,KAAK,CAAC;AAAA,IAC9B,KAAK;AACH,aAAO,MAAM,QAAQ,CAAC;AAAA,IACxB,KAAK;AACH,aAAO,GAAG,KAAK;AAAA,IACjB;AACE,aAAO,MAAM,SAAS;AAAA,EAC1B;AACF;AAKO,SAAS,qBAAqB,YAAoB,OAAuB;AAC9E,UAAQ,YAAY;AAAA,IAClB,KAAK;AACH,aAAO,WAAW,KAAK;AAAA,IACzB,KAAK;AACH,aAAO,MAAM,QAAQ,CAAC;AAAA,IACxB;AACE,aAAO,MAAM,SAAS;AAAA,EAC1B;AACF;AAKA,SAAS,oBAAoB,GAAwB,UAAgD;AACnG,QAAM,QAAQ,SAAS,IAAI,eAAe,CAAC,CAAC;AAC5C,QAAM,WAAW,QAAQ,KAAK,YAAY,MAAM,KAAK,CAAC,MAAM;AAC5D,QAAM,cAAc,eAAe,EAAE,UAAU;AAC/C,QAAM,eAAe,sBAAsB,EAAE,YAAY,EAAE,UAAU;AACrE,QAAM,mBAAmB,qBAAqB,EAAE,YAAY,EAAE,SAAS;AACvE,SAAO,OAAO,EAAE,UAAU,KAAK,EAAE,UAAU,MAAM,WAAW,IAAI,YAAY,GAAG,QAAQ,gBAAgB,gBAAgB,MAAM,EAAE,QAAQ;AACzI;AAKA,SAAS,uBACP,OACA,UACQ;AACR,SAAO,OAAO,QAAQ,KAAK,EACxB,OAAO,CAAC,CAAC,GAAG,IAAI,MAAM,KAAK,WAAW,SAAS,CAAC,EAChD,IAAI,CAAC,CAAC,UAAU,IAAI,MAAM;AACzB,UAAM,gBAAgB,KAAK,WACxB,IAAI,OAAK,oBAAoB,GAAG,QAAQ,CAAC,EACzC,KAAK,IAAI;AACZ,WAAO,KAAK,QAAQ,aAAa,KAAK,SAAS;AAAA,EAAM,aAAa;AAAA,EACpE,CAAC,EACA,KAAK,MAAM;AAChB;AAKA,SAAS,kBAAkB,QAA0C;AACnE,MAAI,CAAC,UAAU,OAAO,WAAW,EAAG,QAAO;AAE3C,QAAM,WAAW,OAAO,OAAO,OAAK,EAAE,aAAa,UAAU;AAC7D,QAAM,WAAW,OAAO,OAAO,QAAM,EAAE,aAAa,WAAW,EAAE,aAAa,cAAc,EAAE,QAAQ,CAAC;AACvG,QAAM,WAAW,OAAO,OAAO,OAAK,EAAE,aAAa,KAAK;AACxD,QAAM,UAAU,OAAO,OAAO,OAAK,EAAE,aAAa,SAAS;AAE3D,QAAM,eAAe,CAAC,MAA+B;AACnD,UAAM,OAAO,EAAE,kBAAkB;AACjC,UAAM,KAAK,EAAE,kBAAkB;AAC/B,WAAO,OAAO,EAAE,UAAU,KAAK,IAAI,WAAM,EAAE,KAAK,YAAY,EAAE,KAAK,CAAC;AAAA,EACtE;AAEA,QAAM,WAAW;AAAA,IACf;AAAA;AAAA,IACA,mBAAmB,SAAS,MAAM;AAAA,IAClC,mBAAmB,SAAS,MAAM;AAAA,IAClC,cAAc,SAAS,MAAM;AAAA,IAC7B,kBAAkB,QAAQ,MAAM;AAAA,EAClC;AAEA,MAAI,SAAS,SAAS,EAAG,UAAS,KAAK;AAAA;AAAA,EAAgC,SAAS,IAAI,YAAY,EAAE,KAAK,IAAI,CAAC,EAAE;AAC9G,MAAI,SAAS,SAAS,EAAG,UAAS,KAAK;AAAA;AAAA,EAA+B,SAAS,IAAI,YAAY,EAAE,KAAK,IAAI,CAAC,EAAE;AAC7G,MAAI,SAAS,SAAS,EAAG,UAAS,KAAK;AAAA;AAAA,EAA6B,SAAS,IAAI,OAAK,OAAO,EAAE,UAAU,gBAAgB,EAAE,cAAc,EAAE,EAAE,KAAK,IAAI,CAAC,EAAE;AAEzJ,SAAO,SAAS,KAAK,IAAI;AAC3B;AAKA,SAAS,qBAAqB,cAA2C;AACvE,SAAO,MAAM,KAAK,aAAa,QAAQ,CAAC,EACrC,IAAI,CAAC,CAAC,KAAK,IAAI,MAAM;AACpB,UAAM,CAAC,UAAU,UAAU,IAAI,IAAI,MAAM,IAAI;AAC7C,WAAO,OAAO,QAAQ,MAAM,UAAU;AAAA;AAAA,EAAa,IAAI;AAAA;AAAA,EACzD,CAAC,EACA,KAAK,MAAM;AAChB;AAKO,SAAS,kBACd,QACA,WACA,cACA,SAAmC,MAC3B;AACR,QAAM,EAAE,SAAS,MAAM,IAAI;AAC3B,QAAM,WAAW,cAAc,MAAM;AACrC,QAAM,mBAAmB,OAAO,QAAQ,KAAK,EAAE,OAAO,CAAC,CAAC,GAAG,IAAI,MAAM,KAAK,WAAW,SAAS,CAAC;AAC/F,QAAM,oBAAoB,uBAAuB,OAAO,QAAQ;AAChE,QAAM,kBAAkB,qBAAqB,YAAY;AACzD,QAAM,eAAe,kBAAkB,MAAM;AAE7C,SAAO;AAAA;AAAA;AAAA,oBAGW,UAAU,KAAK,IAAI,UAAU,IAAI;AAAA,aACxC,UAAU,UAAU,MAAM,UAAU,KAAK;AAAA,+BACvB,iBAAiB,MAAM;AAAA,0BAC5B,QAAQ,eAAe,KAAK,QAAQ,WAAW,KAAK,YAAY,QAAQ,WAAW,OAAO;AAAA,EAClH,YAAY;AAAA;AAAA;AAAA,EAGZ,iBAAiB;AAAA;AAAA;AAAA;AAAA,EAIjB,mBAAmB,8BAA8B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAiBnD;AAkCA,SAAS,oBAAoB,QAAmD;AAC9E,SAAOC,SAAQ,MAAM,EAClB,QAAQ,YAAY,EAEpB,IAAI,CAAC,UAAe,MAAM,IAAI,OAAO,CAAC,EACtC,IAAI;AACT;AAMA,SAAS,+BAA+B,eAA+C;AACrF,QAAM,cAAc,CAAC,cAAc,aAAa,mBAAmB,eAAe;AAClF,QAAM,WAAmC;AAAA,IACvC,YAAY;AAAA,IACZ,WAAW;AAAA,IACX,iBAAiB;AAAA,IACjB,eAAe;AAAA,EACjB;AACA,SAAOA,SAAQ,WAAW,EACvB,IAAI,gBAAc;AACjB,UAAM,cAAc,cAAc,UAAU,KAAK;AACjD,UAAM,QAAQ,SAAS,UAAU,KAAK;AACtC,UAAM,OAAO,eAAe,IAAI,MAAM;AACtC,WAAO,GAAG,KAAK,IAAI,IAAI,GAAG,iBAAiB,YAAY,WAAW,CAAC;AAAA,EACrE,CAAC,EACA,IAAI,EACJ,KAAK,KAAK;AACf;AAKA,SAAS,iBAAiB,QAAmE;AAC3F,SAAO,OAAO,OAAO,CAAC,KAAK,MAAM;AAC/B,QAAI,CAAC,YAAY,SAAS,EAAE,SAAS,EAAE,QAAQ,EAAG,KAAI;AAAA,aAC7C,CAAC,WAAW,SAAS,KAAK,EAAE,SAAS,EAAE,QAAQ,EAAG,KAAI;AAC/D,WAAO;AAAA,EACT,GAAG,EAAE,UAAU,GAAG,UAAU,EAAE,CAAC;AACjC;AAKA,SAAS,cAAc,YAA4B;AACjD,MAAI,aAAa,EAAG,QAAO;AAC3B,MAAI,aAAa,EAAG,QAAO;AAC3B,SAAO;AACT;AAKA,SAAS,mBAAmB,QAAsD;AAChF,MAAI,CAAC,UAAU,OAAO,WAAW,EAAG,QAAO;AAE3C,QAAM,EAAE,UAAU,SAAS,IAAI,iBAAiB,MAAM;AACtD,QAAM,gBAAgB,oBAAoB,MAAM;AAChD,QAAM,kBAAkB,+BAA+B,aAAa;AACpE,QAAM,aAAa,OAAO,OAAO,aAAa,EAAE,OAAO,CAAC,KAAK,MAAM,MAAM,GAAG,CAAC;AAC7E,QAAM,QAAQ,cAAc,UAAU;AAEtC,MAAI,UAAU;AAAA;AAAA,yBAA8B,eAAe,IAAI,KAAK;AACpE,MAAI,WAAW,EAAG,YAAW,MAAM,QAAQ;AAC3C,MAAI,WAAW,EAAG,YAAW,MAAM,QAAQ;AAC3C,SAAO;AACT;AAKA,SAAS,iBAAiB,YAAgD;AACxE,MAAI,CAAC,cAAc,WAAW,eAAe,EAAG,QAAO;AACvD,SAAO;AAAA,YAAe,WAAW,YAAY,eAAe,CAAC,MAAM,WAAW,KAAK,QAAQ,CAAC,CAAC;AAC/F;AAKA,SAAS,mBAAmB,YAA6B;AACvD,MAAI,CAAC,WAAY,QAAO;AACxB,SAAO;AAAA;AAAA;AAAA;AACT;AAKO,SAAS,oBACd,UACA,QACA,aAAa,OACb,YACA,QACQ;AACR,QAAM,EAAE,QAAQ,IAAI;AACpB,QAAM,eAAe,mBAAmB,MAAM;AAC9C,QAAM,eAAe,mBAAmB,UAAU;AAClD,QAAM,aAAa,iBAAiB,UAAU;AAE9C,SAAO;AAAA;AAAA;AAAA,EAGP,QAAQ,eAAe,SAAS,QAAQ,oBAAoB,IAAI,KAAK,GAAG,uBAAuB,YAAY,GAAG,YAAY;AAAA;AAAA;AAAA;AAAA,EAI1H,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBAOU,QAAQ,aAAa;AAAA,wBACjB,QAAQ,cAAc,QAAQ,CAAC,CAAC;AAAA,oBACpC,QAAQ,aAAa,GAAG,UAAU;AAAA;AAAA;AAAA;AAAA;AAKtD;AAKO,SAAS,gBAAgB,WAAwC;AACtE,SAAO,GAAG,UAAU,QAAQ,KAAK,UAAU,UAAU;AACvD;AAMA,SAAS,gBACP,QACA,cACoC;AACpC,QAAM,aAAa,QAAQ,QAAQ,mBAAmB;AACtD,QAAM,SAAS,QAAQ,QAAQ,WAAW,SAAS;AACnD,QAAM,QAAQ,cAAc,cAAc;AAC1C,QAAM,gBAAgB,cAAc,gBAAgB;AACpD,QAAM,cAAc,KAAK,IAAI,GAAG,aAAa,aAAa;AAG1D,MAAI,QAAQ,GAAG;AACb,QAAI,cAAc,GAAG;AACnB,aAAO;AAAA,QACL,OAAO;AAAA,QACP,SAAS,uCAAuC,KAAK,IAAI,KAAK,CAAC,KAAK,WAAW,sBAAsB,gBAAgB,IAAI,KAAK,GAAG,UAAU,gBAAgB,IAAI,MAAM,EAAE;AAAA,MACzK;AAAA,IACF;AACA,WAAO,EAAE,OAAO,UAAK,SAAS,+CAA+C,KAAK,IAAI,KAAK,CAAC,IAAI;AAAA,EAClG;AAGA,MAAI,gBAAgB,KAAK,SAAS,GAAG;AACnC,WAAO;AAAA,MACL,OAAO;AAAA,MACP,SAAS,yBAAyB,aAAa,gBAAgB,kBAAkB,IAAI,QAAQ,OAAO;AAAA,IACtG;AAAA,EACF;AAEA,MAAI,gBAAgB,GAAG;AACrB,WAAO;AAAA,MACL,OAAO;AAAA,MACP,SAAS,yBAAyB,aAAa,gBAAgB,kBAAkB,IAAI,QAAQ,OAAO;AAAA,IACtG;AAAA,EACF;AAGA,MAAI,aAAa,GAAG;AAClB,WAAO;AAAA,MACL,OAAO;AAAA,MACP,SAAS,gBAAgB,WAAW,sBAAsB,gBAAgB,IAAI,KAAK,GAAG;AAAA,IACxF;AAAA,EACF;AAGA,MAAI,QAAQ,GAAG;AACb,WAAO,EAAE,OAAO,gBAAM,SAAS,gEAAgE;AAAA,EACjG;AAEA,SAAO,EAAE,OAAO,UAAK,SAAS,yCAAyC;AACzE;AAgBA,SAAS,eAAe,YAA4B;AAClD,UAAQ,YAAY;AAAA,IAClB,KAAK;AAAc,aAAO;AAAA,IAC1B,KAAK;AAAa,aAAO;AAAA,IACzB,KAAK;AAAmB,aAAO;AAAA,IAC/B,KAAK;AAAiB,aAAO;AAAA,IAC7B;AAAS,aAAO;AAAA,EAClB;AACF;AAMO,SAAS,sBACd,QACA,cACA,QACQ;AACR,QAAM,SAAS,gBAAgB,QAAQ,YAAY;AAGnD,MAAI,cAAc;AAClB,MAAI,UAAU,OAAO,QAAQ,kBAAkB,GAAG;AAEhD,UAAM,WAAWC,SAAQ,OAAO,OAAO,OAAO,KAAK,CAAC,EACjD,QAAQ,OAAK,EAAE,UAAU,EACzB,QAAQ,YAAY,EACpB,IAAI;AAIP,UAAM,gBAAwC,SAC1CA,SAAQ,MAAM,EACX,QAAQ,YAAY,EAEpB,IAAI,CAAC,UAAe,MAAM,IAAI,OAAO,CAAC,EACtC,IAAI,IACP,CAAC;AAGL,UAAM,cAAc,CAAC,cAAc,aAAa,mBAAmB,eAAe;AAClF,UAAM,OAAOA,SAAQ,WAAW,EAC7B,OAAO,gBAAc,SAAS,UAAU,IAAI,CAAC,EAC7C,IAAI,gBAAc;AACjB,YAAM,QAAQ,eAAe,UAAU;AACvC,YAAM,QAAQ,eAAe,UAAU;AACvC,YAAM,QAAQ,SAAS,UAAU;AACjC,YAAM,QAAQ,cAAc,UAAU,KAAK;AAC3C,YAAM,WAAW,SAAU,SAAS,IAAI,IAAI,KAAK,KAAK,GAAG,KAAK,KAAM;AACpE,aAAO,KAAK,KAAK,IAAI,KAAK,MAAM,KAAK,MAAM,QAAQ;AAAA,IACrD,CAAC,EACA,IAAI;AAEP,QAAI,KAAK,SAAS,GAAG;AACnB,oBAAc;AAAA;AAAA;AAAA,EAGlB,KAAK,KAAK,IAAI,CAAC;AAAA;AAAA,IAEb;AAAA,EACF;AAEA,SAAO;AAAA;AAAA,EAEP,OAAO,KAAK,IAAI,OAAO,OAAO;AAAA,EAC9B,WAAW;AAAA;AAEb;AAKA,SAAS,sBAAsB,WAAwC;AACrE,MAAI,CAAC,UAAU,YAAY,WAAW,WAAW,EAAG,QAAO;AAC3D,MAAI,CAAC,UAAU,gBAAiB,QAAO;AAEvC,QAAM,UAAU,UAAU;AAC1B,SAAO;AAAA,gCAAmC,QAAQ,QAAQ,eAAe,CAAC,iBAAiB,QAAQ,YAAY,QAAQ,CAAC,CAAC,aAAa,QAAQ,QAAQ,eAAe,CAAC,gBAAgB,QAAQ,MAAM,QAAQ,CAAC,CAAC;AAChN;AA4EO,SAAS,2BACd,YACA,cACQ;AACR,QAAM,iBAAiB,WACpB,IAAI,CAAC,GAAG,MAAM;AACb,UAAM,MAAM,GAAG,EAAE,QAAQ,KAAK,EAAE,UAAU;AAC1C,UAAM,UAAU,aAAa,IAAI,GAAG;AACpC,UAAM,iBAAiB,UACnB;AAAA;AAAA;AAAA,EAAoB,OAAO;AAAA,UAC3B;AAEJ,UAAM,aAAa,EAAE,cAAc;AACnC,UAAM,cAAc,eAAe,UAAU;AAC7C,UAAM,eAAe,sBAAsB,YAAY,EAAE,UAAU;AACnE,UAAM,mBAAmB,qBAAqB,YAAY,EAAE,SAAS;AACrE,UAAM,kBAAkB,sBAAsB,CAAC;AAE/C,WAAO,OAAO,IAAI,CAAC,KAAK,EAAE,QAAQ,KAAK,EAAE,UAAU;AAAA,oBACrC,EAAE,UAAU,OAAO,EAAE,UAAU;AAAA,oBAC/B,YAAY,IAAI,WAAW,gBAAgB,gBAAgB,IAAI,eAAe;AAAA,kBAChF,EAAE,QAAQ,GAAG,cAAc;AAAA,EACzC,CAAC,EACA,KAAK,MAAM;AAGd,QAAM,WAAW,WACd,IAAI,CAAC,MAAM,MAAM,EAAE,QAAQ,KAAK,EAAE,UAAU,wBAAwB,EACpE,KAAK,KAAK;AAEb,SAAO;AAAA;AAAA;AAAA;AAAA,EAIP,cAAc;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAiCd,QAAQ;AAAA;AAAA;AAGV;;;ADjnBA,IAAM,qBAAqB;AAe3B,IAAI,aAAyB;AAAA,EAC3B,cAAc;AAAA,EACd,kBAAkB;AAAA,EAClB,aAAa;AAAA,EACb,MAAM;AACR;AAKO,SAAS,kBAAwB;AACtC,eAAa;AAAA,IACX,cAAc;AAAA,IACd,kBAAkB;AAAA,IAClB,aAAa;AAAA,IACb,MAAM;AAAA,EACR;AACF;AAKO,SAAS,gBAA4B;AAC1C,SAAO,EAAE,GAAG,WAAW;AACzB;AAMA,SAAS,WACP,OACM;AACN,MAAI,CAAC,MAAO;AAEZ,aAAW,gBAAgB,MAAM;AACjC,aAAW,oBAAoB,MAAM;AACrC,aAAW,eAAe,MAAM;AAChC,aAAW,QAAQ,MAAM,QAAQ;AACnC;AAOO,SAAS,sBAAsB,SAAgD;AAEpF,QAAM,iBAAiB,QAAQ,MAAM,8BAA8B;AACnE,QAAM,WAAW,iBAAiB,eAAe,CAAC,IAAI,SAAS,KAAK;AAEpE,EAAK,WAAK,0BAA0B,QAAQ,MAAM,SAAS;AAE3D,MAAI;AACF,UAAM,SAAS,KAAK,MAAM,OAAO;AACjC,IAAK,WAAK,uBAAuB,OAAO,KAAK,MAAM,EAAE,MAAM,WAAW;AACtE,WAAO;AAAA,EACT,SAAS,YAAY;AACnB,IAAK,cAAQ,8BAA8B,UAAU,EAAE;AAAA,EACzD;AAGA,QAAM,cAAc,QAAQ,MAAM,aAAa;AAC/C,MAAI,aAAa;AACf,QAAI;AACF,YAAM,SAAS,KAAK,MAAM,YAAY,CAAC,CAAC;AACxC,MAAK,WAAK,2CAA2C,OAAO,KAAK,MAAM,EAAE,MAAM,WAAW;AAC1F,aAAO;AAAA,IACT,SAAS,YAAY;AACnB,MAAK,cAAQ,8BAA8B,UAAU,EAAE;AAAA,IACzD;AAAA,EACF;AAEA,EAAK,cAAQ;AAAA,EAA2B,OAAO,EAAE;AACjD,SAAO;AACT;AAKA,eAAsB,eACpB,QACA,QACA,OACiB;AACjB,EAAK,WAAK,kCAAkC,KAAK,EAAE;AAEnD,QAAM,WAAW,MAAM,MAAM,oBAAoB;AAAA,IAC/C,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,eAAe,UAAU,MAAM;AAAA,MAC/B,gBAAgB;AAAA,MAChB,gBAAgB;AAAA,MAChB,WAAW;AAAA,IACb;AAAA,IACA,MAAM,KAAK,UAAU;AAAA,MACnB;AAAA,MACA,UAAU;AAAA,QACR;AAAA,UACE,MAAM;AAAA,UACN,SACE;AAAA,QACJ;AAAA,QACA;AAAA,UACE,MAAM;AAAA,UACN,SAAS;AAAA,QACX;AAAA,MACF;AAAA,MACA,YAAY;AAAA,MACZ,aAAa;AAAA;AAAA;AAAA;AAAA,MAGb,OAAO;AAAA,QACL,SAAS;AAAA,MACX;AAAA,IACF,CAAC;AAAA,EACH,CAAC;AAED,MAAI,CAAC,SAAS,IAAI;AAChB,UAAM,YAAY,MAAM,SAAS,KAAK;AACtC,UAAM,IAAI;AAAA,MACR,yBAAyB,SAAS,MAAM,MAAM,SAAS;AAAA,IACzD;AAAA,EACF;AAEA,QAAM,OAAQ,MAAM,SAAS,KAAK;AAElC,MAAI,CAAC,KAAK,WAAW,KAAK,QAAQ,WAAW,GAAG;AAC9C,UAAM,IAAI,MAAM,6BAA6B;AAAA,EAC/C;AAEA,QAAM,SAAS,KAAK,QAAQ,CAAC,EAAE,QAAQ;AAGvC,MAAI,KAAK,OAAO;AACd,eAAW,KAAK,KAAK;AACrB,UAAM,UAAU,KAAK,MAAM,OAAO,MAAM,KAAK,MAAM,KAAK,QAAQ,CAAC,CAAC,MAAM;AACxE,IAAK;AAAA,MACH,WAAW,KAAK,MAAM,aAAa,QAAQ,KAAK,MAAM,iBAAiB,OAAO,OAAO;AAAA,IACvF;AAAA,EACF;AAEA,SAAO;AACT;AAKA,eAAe,uBACb,QACA,QACA,OAC6B;AAC7B,QAAM,WAAW,MAAM,MAAM,oBAAoB;AAAA,IAC/C,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,eAAe,UAAU,MAAM;AAAA,MAC/B,gBAAgB;AAAA,MAChB,gBAAgB;AAAA,MAChB,WAAW;AAAA,IACb;AAAA,IACA,MAAM,KAAK,UAAU;AAAA,MACnB;AAAA,MACA,UAAU;AAAA,QACR;AAAA,UACE,MAAM;AAAA,UACN,SACE;AAAA,QACJ;AAAA,QACA,EAAE,MAAM,QAAQ,SAAS,OAAO;AAAA,MAClC;AAAA,MACA,YAAY;AAAA,MACZ,aAAa;AAAA,MACb,OAAO,EAAE,SAAS,KAAK;AAAA,IACzB,CAAC;AAAA,EACH,CAAC;AAED,MAAI,CAAC,SAAS,IAAI;AAChB,UAAM,YAAY,MAAM,SAAS,KAAK;AACtC,UAAM,IAAI,MAAM,yBAAyB,SAAS,MAAM,MAAM,SAAS,EAAE;AAAA,EAC3E;AAEA,QAAM,OAAQ,MAAM,SAAS,KAAK;AAElC,MAAI,CAAC,KAAK,WAAW,KAAK,QAAQ,WAAW,GAAG;AAC9C,UAAM,IAAI,MAAM,6BAA6B;AAAA,EAC/C;AAEA,SAAO;AACT;AAMO,SAAS,wBACd,aACA,YACkC;AAClC,QAAM,UAAU,oBAAI,IAAiC;AACrD,QAAM,kBAAkB,CAAC,MACvB,QAAQ,EAAE,UAAU;AAEtB,MAAI,CAAC,aAAa;AAChB,eAAW,aAAa,YAAY;AAClC,cAAQ,IAAI,WAAW,gBAAgB,SAAS,CAAC;AAAA,IACnD;AACA,WAAO;AAAA,EACT;AAEA,aAAW,aAAa,YAAY;AAClC,UAAM,MAAM,GAAG,UAAU,QAAQ,KAAK,UAAU,UAAU;AAC1D,UAAM,UAAU,YAAY,GAAG;AAE/B,QAAI,SAAS;AACX,cAAQ,IAAI,WAAW,QAAQ,QAAQ,QAAQ,IAAI,CAAC;AAAA,IACtD,OAAO;AACL,MAAK,cAAQ,4BAA4B,GAAG,EAAE;AAC9C,cAAQ,IAAI,WAAW,gBAAgB,SAAS,CAAC;AAAA,IACnD;AAAA,EACF;AAEA,SAAO;AACT;AAUA,eAAsB,qBACpB,YACA,cACA,QACA,OAC2C;AAC3C,MAAI,WAAW,WAAW,GAAG;AAC3B,WAAO,oBAAI,IAAI;AAAA,EACjB;AAEA,EAAK,WAAK,2BAA2B,WAAW,MAAM,6BAA6B;AAEnF,QAAM,SAAS,2BAA2B,YAAY,YAAY;AAClE,QAAM,OAAO,MAAM,uBAAuB,QAAQ,QAAQ,KAAK;AAE/D,MAAI,KAAK,OAAO;AACd,eAAW,KAAK,KAAK;AACrB,UAAM,UAAU,KAAK,MAAM,OAAO,MAAM,KAAK,MAAM,KAAK,QAAQ,CAAC,CAAC,MAAM;AACxE,IAAK,WAAK,iBAAiB,KAAK,MAAM,aAAa,QAAQ,KAAK,MAAM,iBAAiB,OAAO,OAAO,EAAE;AAAA,EACzG;AAEA,QAAM,cAAc,sBAAsB,KAAK,QAAQ,CAAC,EAAE,QAAQ,OAAO;AACzE,SAAO,wBAAwB,aAAa,UAAU;AACxD;;;ApEjOA,SAAS,YAA0B;AACjC,QAAM,cAAmB,eAAS,cAAc,KAAK;AACrD,QAAM,sBAA2B,eAAS,uBAAuB,MAAM;AAEvE,SAAO;AAAA,IACL,kBAAuB,eAAS,sBAAsB,EAAE,UAAU,KAAK,CAAC;AAAA,IACxE,OAAY,eAAS,OAAO,KAAK;AAAA,IACjC,WAAgB,eAAS,WAAW,KAAK;AAAA,IACzC,aAAkB,eAAS,cAAc,KAAK,QAAQ,IAAI,gBAAgB;AAAA,IAC1E,aAAa,gBAAgB,YAAY,YAAY;AAAA,IACrD;AAAA,IACA,wBAA6B,eAAS,qBAAqB,KAAK;AAAA,EAClE;AACF;AAKA,SAAS,uBAAuBC,QAAuC;AACrE,MAAI,CAACA,QAAM;AACT,IAAK,WAAK,kEAAkE;AAC5E,WAAO;AAAA,EACT;AAEA,MAAI;AACF,QAAI,CAAI,gBAAWA,MAAI,GAAG;AACxB,MAAK,cAAQ,uCAAuCA,MAAI,EAAE;AAC1D,aAAO;AAAA,IACT;AAEA,UAAM,UAAa,kBAAaA,QAAM,OAAO;AAC7C,UAAM,SAAS,KAAK,MAAM,OAAO;AAEjC,QAAI,CAAC,OAAO,SAAS,CAAC,OAAO,SAAS;AACpC,MAAK,cAAQ,6CAA6C;AAC1D,aAAO;AAAA,IACT;AAEA,IAAK,WAAK,+BAA+B,OAAO,QAAQ,eAAe,aAAa;AACpF,WAAO;AAAA,EACT,SAASC,QAAO;AACd,IAAK,cAAQ,uCAAuCA,MAAK,EAAE;AAC3D,WAAO;AAAA,EACT;AACF;AAQA,SAAS,kBAAqF;AAC5F,QAAM,SAAS,UAAU;AACzB,EAAK,WAAK,gBAAgB,OAAO,KAAK,EAAE;AACxC,EAAK,WAAK,yBAAyB,OAAO,SAAS,EAAE;AACrD,EAAK,WAAK,iBAAiB,OAAO,WAAW,EAAE;AAE/C,MAAI,CAAC,OAAO,aAAa;AACvB,UAAM,IAAI,MAAM,0BAA0B;AAAA,EAC5C;AAEA,QAAM,YAAY,aAAa;AAC/B,MAAI,CAAC,WAAW;AACd,IAAK,cAAQ,qCAAqC;AAClD,WAAO;AAAA,EACT;AAEA,EAAK,WAAK,iBAAiB,UAAU,UAAU,KAAK,UAAU,KAAK,EAAE;AACrE,SAAO,EAAE,QAAQ,WAAW,SAAS,cAAc,OAAO,WAAW,EAAE;AACzE;AAMA,SAAS,sBAAsB,OAA2B;AACxD,QAAM,iBAAiB,oBAAI,IAAI;AAAA,IAC7B;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,CAAC;AAED,QAAM,kBAAkB;AAAA,IACtB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,SAAO,MAAM,OAAO,CAAC,SAAS;AAE5B,UAAMC,OAAM,KAAK,MAAM,KAAK,YAAY,GAAG,CAAC;AAC5C,QAAI,CAAC,eAAe,IAAIA,IAAG,GAAG;AAC5B,aAAO;AAAA,IACT;AAGA,eAAW,WAAW,iBAAiB;AACrC,UAAI,QAAQ,KAAK,IAAI,GAAG;AACtB,eAAO;AAAA,MACT;AAAA,IACF;AAEA,WAAO;AAAA,EACT,CAAC;AACH;AAKA,eAAe,kBAAkB,SAAkB,WAAyC;AAC1F,QAAM,kBAAkB,MAAM,kBAAkB,SAAS,SAAS;AAClE,EAAK,WAAK,SAAS,gBAAgB,MAAM,sBAAsB;AAE/D,QAAM,iBAAiB,sBAAsB,eAAe;AAC5D,EAAK,WAAK,GAAG,eAAe,MAAM,yCAAyC;AAE3E,SAAO;AACT;AAKA,eAAe,sBACb,OACA,WACkC;AAClC,MAAI,MAAM,WAAW,GAAG;AACtB,IAAK,WAAK,qBAAqB;AAC/B,WAAO;AAAA,EACT;AAEA,MAAI;AACF,UAAM,UAAU,QAAQ,IAAI;AAG5B,QAAI;AACJ,QAAI;AACF,eAAS,MAAM,WAAW,OAAO;AACjC,MAAK,WAAK,oBAAoB;AAAA,IAChC,QAAQ;AACN,MAAK,WAAK,sCAAsC;AAChD,eAAS,oBAAoB;AAAA,IAC/B;AAGA,UAAM,eAAe,SAAS,WAAW,EAAE;AAC3C,WAAO,aAAa;AAAA,MAClB,GAAG,OAAO;AAAA,MACV,SAAS;AAAA,MACT,YAAY;AAAA,QACV,WAAW;AAAA,QACX,YAAY;AAAA,QACZ,yBAAyB;AAAA,QACzB,eAAe;AAAA,QACf,GAAG,OAAO,YAAY;AAAA,MACxB;AAAA,IACF;AAGA,IAAK,WAAK,gCAAyB;AACnC,UAAM,cAAc;AAAA,MAClB;AAAA,MACA;AAAA,IACF,CAAC;AACD,IAAK,WAAK,0BAAqB;AAG/B,UAAM,WAAW,MAAM,SAAS,KAAK,OAAO;AAG5C,IAAK,WAAK,mCAA4B;AACtC,UAAM,WAAW,IAAI,mBAAmB,UAAU,MAAM;AACxD,UAAM,SAAS,MAAM,SAAS,QAAQ,KAAK;AAC3C,IAAK,WAAK,gBAAW,OAAO,QAAQ,eAAe,aAAa;AAEhE,WAAO;AAAA,EACT,SAASD,QAAO;AACd,IAAK,YAAM,sCAAsCA,MAAK,EAAE;AACxD,WAAO;AAAA,EACT;AACF;AAKA,eAAe,2BACb,QACA,SACA,WACmF;AAEnF,QAAM,aAAa,OAAO,OAAO,OAAO,KAAK,EAC1C,QAAQ,CAAC,aAAa,SAAS,UAAU,EACzC,KAAK,CAAC,GAAG,MAAM;AACd,QAAI,EAAE,aAAa,EAAE,SAAU,QAAO,EAAE,aAAa,UAAU,KAAK;AACpE,WAAO,EAAE,aAAa,EAAE;AAAA,EAC1B,CAAC,EACA,MAAM,GAAG,EAAE;AAGd,QAAM,eAAe,oBAAI,IAAoB;AAC7C,aAAW,aAAa,YAAY;AAClC,UAAM,UAAU,MAAM;AAAA,MACpB;AAAA,MACA;AAAA,MACA,UAAU;AAAA,MACV,UAAU;AAAA,MACV,UAAU;AAAA,IACZ;AACA,QAAI,SAAS;AACX,mBAAa,IAAI,gBAAgB,SAAS,GAAG,OAAO;AAAA,IACtD;AAAA,EACF;AACA,EAAK,WAAK,aAAa,aAAa,IAAI,2BAA2B;AAEnE,SAAO,EAAE,YAAY,aAAa;AACpC;AAKA,eAAe,kBACb,SACA,gBACA,WACkC;AAClC,MAAI;AACF,IAAK,WAAK,+BAA+B,QAAQ,UAAU,GAAG,CAAC,CAAC,KAAK;AAGrE,UAAM,cAAc,SAAS,sBAAsB,EAAE,UAAU,QAAQ,CAAC,EAAE,KAAK;AAG/E,aAAS,wBAAwB,OAAO,IAAI,EAAE,OAAO,OAAO,CAAC;AAC7D,IAAK,WAAK,gCAA2B;AAGrC,IAAK,WAAK,qCAAqC;AAC/C,UAAM,aAAa,MAAM,sBAAsB,gBAAgB,SAAS;AAGxE,aAAS,wBAAwB,WAAW,IAAI,EAAE,OAAO,OAAO,CAAC;AACjE,IAAK,WAAK,yBAAoB;AAE9B,QAAI,YAAY;AACd,MAAK,WAAK,gBAAgB,WAAW,QAAQ,eAAe,aAAa;AAAA,IAC3E;AAEA,WAAO;AAAA,EACT,SAASA,QAAO;AACd,IAAK,cAAQ,kCAAkCA,MAAK,EAAE;AAEtD,QAAI;AACF,YAAM,cAAc,SAAS,sBAAsB,EAAE,UAAU,QAAQ,CAAC,EAAE,KAAK;AAC/E,eAAS,wBAAwB,WAAW,IAAI,EAAE,OAAO,OAAO,CAAC;AAAA,IACnE,SAAS,cAAc;AACrB,MAAK,cAAQ,2BAA2B,YAAY,EAAE;AAAA,IACxD;AACA,WAAO;AAAA,EACT;AACF;AAKA,eAAe,MAAqB;AAClC,MAAI;AACF,IAAK,WAAK,2CAAoC;AAC9C,IAAK,WAAK,iBAAiB,QAAQ,OAAO,EAAE;AAC5C,IAAK,WAAK,sBAAsB,QAAQ,IAAI,CAAC,EAAE;AAE/C,UAAM,QAAQ,gBAAgB;AAC9B,QAAI,CAAC,OAAO;AACV,MAAK,WAAK,sDAA4C;AACtD;AAAA,IACF;AACA,UAAM,EAAE,QAAQ,WAAW,QAAQ,IAAI;AAEvC,UAAM,iBAAiB,MAAM,kBAAkB,SAAS,SAAS;AACjE,QAAI,eAAe,WAAW,GAAG;AAC/B,MAAK,WAAK,4CAA4C;AACtD;AAAA,IACF;AAGA,QAAI,iBAA0C;AAE9C,QAAI,OAAO,qBAAqB;AAC9B,MAAK,WAAK,6DAAsD;AAChE,uBAAiB,MAAM,kBAAkB,UAAU,SAAS,gBAAgB,OAAO,SAAS;AAAA,IAC9F,WAAW,OAAO,wBAAwB;AAExC,MAAK,cAAQ,mFAAmF;AAChG,uBAAiB,uBAAuB,OAAO,sBAAsB;AAAA,IACvE;AAEA,UAAM,SAAS,MAAM,sBAAsB,gBAAgB,OAAO,SAAS;AAC3E,QAAI,CAAC,QAAQ;AACX,MAAK,cAAQ,iCAAiC;AAC9C;AAAA,IACF;AACA,IAAK,WAAK,sBAAsB,OAAO,QAAQ,eAAe,mBAAmB;AAGjF,UAAM,SAAS,iBACX,gBAAgB,gBAAgB,QAAQ,cAAc,IACtD;AAEJ,UAAM,eAAe,SAAS,sBAAsB,MAAM,IAAI;AAE9D,QAAI,cAAc;AAChB,sBAAgB,YAAY;AAC5B,MAAK,gBAAU,eAAe,aAAa,UAAU;AACrD,MAAK,gBAAU,YAAY,aAAa,QAAQ;AAChD,MAAK,gBAAU,YAAY,aAAa,QAAQ;AAAA,IAClD;AAGA,UAAM,QAAQ,sBAAsB,QAAQ,cAAc,MAAM;AAChE,UAAM,oBAAoB,SAAS,WAAW,KAAK;AAEnD,QAAI,OAAO,QAAQ,oBAAoB,GAAG;AACxC,MAAK,WAAK,gCAAgC;AAE1C;AAAA,IACF;AAEA,UAAM,EAAE,YAAY,aAAa,IAAI,MAAM,2BAA2B,QAAQ,SAAS,SAAS;AAEhG,oBAAgB;AAChB,QAAI,OAAO,gBAAgB,WAAW;AACpC,YAAM,kBAAkB,SAAS,WAAW,QAAQ,cAAc,QAAQ,OAAO,MAAM;AAAA,IACzF,OAAO;AACL,YAAM,eAAe,SAAS,WAAW,QAAQ,YAAY,cAAc,QAAQ,MAAM;AAAA,IAC3F;AAEA,IAAK,gBAAU,cAAc,OAAO,QAAQ,eAAe;AAC3D,IAAK,gBAAU,UAAU,OAAO,QAAQ,WAAW,KAAK;AACxD,IAAK,gBAAU,YAAY,OAAO,QAAQ,WAAW,OAAO;AAAA,EAC9D,SAASA,QAAO;AACd,UAAM,UAAUA,kBAAiB,QAAQA,OAAM,UAAU;AACzD,UAAM,QAAQA,kBAAiB,QAAQA,OAAM,QAAQ;AAErD,IAAK,YAAM,kBAAkB,OAAO,EAAE;AACtC,QAAI,OAAO;AACT,MAAK,YAAM;AAAA,EAAiB,KAAK,EAAE;AAAA,IACrC;AAEA,IAAK,gBAAU,OAAO;AAAA,EACxB;AACF;AAMA,SAAS,gBACP,WACA,WACe;AACf,QAAM,YAAY,UAAU,IAAI,UAAU,QAAQ;AAClD,MAAI,CAAC,UAAW,QAAO;AAGvB,MAAI,UAAU,IAAI,UAAU,SAAS,GAAG;AACtC,WAAO,UAAU;AAAA,EACnB;AAGA,WAAS,OAAO,UAAU,WAAW,QAAQ,UAAU,SAAS,QAAQ;AACtE,QAAI,UAAU,IAAI,IAAI,GAAG;AACvB,aAAO;AAAA,IACT;AAAA,EACF;AAEA,SAAO;AACT;AAMA,SAASE,gBAAe,GAAyE;AAC/F,SAAO,GAAG,EAAE,QAAQ,KAAK,EAAE,UAAU,KAAK,EAAE,UAAU;AACxD;AAKA,SAASC,eAAc,QAAgE;AACrF,MAAI,CAAC,OAAQ,QAAO,oBAAI,IAAI;AAE5B,SAAO,IAAI;AAAA,IACTC,SAAQ,MAAM,EACX,IAAI,OAAK,CAACF,gBAAe,CAAC,GAAG,CAAC,CAA8B,EAC5D,IAAI;AAAA,EACT;AACF;AAKA,SAAS,kBACP,qBACA,YACA,UACe;AACf,SAAOE,SAAQ,mBAAmB,EAC/B,OAAO,CAAC,EAAE,UAAU,MAAM,WAAW,IAAI,SAAS,CAAC,EACnD,IAAI,CAAC,EAAE,WAAW,YAAY,MAAM;AACnC,UAAM,UAAU,WAAW,IAAI,SAAS;AACxC,UAAM,QAAQ,SAAS,IAAIF,gBAAe,SAAS,CAAC;AACpD,UAAM,WAAW,QAAQ,KAAK,YAAY,MAAM,KAAK,CAAC,MAAM;AAC5D,UAAM,gBAAgB,QAClB,oBAAoB,MAAM,QAAQ,IACjC,UAAU,aAAa,UAAU,cAAO;AAG7C,UAAM,WAAW,gBAAgB,UAAU,YACvC,QAAQ,UAAU,UAAU,qBAAqB,UAAU,SAAS,OACpE;AAGJ,UAAM,cAAc,eAAe,UAAU,cAAc,YAAY;AACvE,UAAM,eAAe,sBAAsB,UAAU,cAAc,cAAc,UAAU,UAAU;AACrG,UAAM,mBAAmB,qBAAqB,UAAU,cAAc,cAAc,UAAU,SAAS;AAEvG,IAAK,WAAK,sBAAsB,UAAU,QAAQ,IAAI,WAAW,KAAK,UAAU,UAAU,IAAI,QAAQ,EAAE;AAExG,WAAO;AAAA,MACL,MAAM,UAAU;AAAA,MAChB,MAAM;AAAA,MACN,MAAM,GAAG,aAAa,MAAM,YAAY,OAAO,CAAC,EAAE,YAAY,IAAI,YAAY,MAAM,CAAC,CAAC,KAAK,YAAY,KAAK,QAAQ,gBAAgB,gBAAgB,IAAI,QAAQ;AAAA;AAAA,EAAO,OAAO;AAAA,IAChL;AAAA,EACF,CAAC,EACA,IAAI;AACT;AAKA,SAASG,gBAAe,YAA4B;AAClD,UAAQ,YAAY;AAAA,IAClB,KAAK;AAAc,aAAO;AAAA,IAC1B,KAAK;AAAa,aAAO;AAAA,IACzB,KAAK;AAAmB,aAAO;AAAA,IAC/B,KAAK;AAAiB,aAAO;AAAA,IAC7B;AAAS,aAAO;AAAA,EAClB;AACF;AAKA,SAAS,mBACP,qBACA,UACQ;AACR,MAAI,oBAAoB,WAAW,EAAG,QAAO;AAE7C,QAAM,gBAAgB,oBACnB,IAAI,OAAK;AACR,UAAM,QAAQ,SAAS,IAAIH,gBAAe,CAAC,CAAC;AAC5C,UAAM,WAAW,QAAQ,KAAK,YAAY,MAAM,KAAK,CAAC,MAAM;AAC5D,UAAM,QAAQG,gBAAe,EAAE,UAAU;AACzC,UAAM,cAAc,eAAe,EAAE,cAAc,YAAY;AAC/D,UAAM,eAAe,sBAAsB,EAAE,cAAc,cAAc,EAAE,UAAU;AACrF,WAAO,OAAO,EAAE,UAAU,WAAW,EAAE,QAAQ,OAAO,KAAK,IAAI,WAAW,IAAI,YAAY,GAAG,QAAQ;AAAA,EACvG,CAAC,EACA,KAAK,IAAI;AAEZ,SAAO;AAAA;AAAA;AAAA,wBAA8B,oBAAoB,MAAM,aAAa,oBAAoB,WAAW,IAAI,KAAK,GAAG;AAAA;AAAA,EAAkD,aAAa;AAAA;AAAA;AAAA;AAAA;AACxL;AAKA,SAAS,iBAAiB,mBAAkD;AAC1E,MAAI,kBAAkB,WAAW,EAAG,QAAO;AAE3C,QAAM,cAAc,kBACjB,IAAI,OAAK,SAAS,EAAE,UAAU,WAAW,EAAE,QAAQ,kBAAkB,EAAE,UAAU,EAAE,EACnF,KAAK,IAAI;AAEZ,SAAO;AAAA;AAAA;AAAA,wBAA8B,kBAAkB,MAAM,0BAA0B,kBAAkB,WAAW,IAAI,KAAK,GAAG;AAAA;AAAA,EAA6B,WAAW;AAAA;AAAA;AAAA;AAAA;AAC1K;AAKA,SAAS,kBAAkB,OAAsD;AAC/E,SAAO,MAAM,cAAc,IACvB;AAAA,YAAe,MAAM,YAAY,eAAe,CAAC,MAAM,MAAM,KAAK,QAAQ,CAAC,CAAC,MAC5E;AACN;AAKA,SAASC,qBAAoB,QAAmD;AAE9E,SAAOF,SAAQ,MAAM,EAClB,QAAQ,YAAY,EAEpB,IAAI,CAAC,UAAe,MAAM,IAAI,OAAO,CAAC,EACtC,IAAI;AACT;AAKA,SAAS,qBAAqB,eAA+C;AAC3E,QAAM,cAAc,CAAC,cAAc,aAAa,mBAAmB,eAAe;AAClF,SAAOA,SAAQ,WAAW,EACvB,IAAI,gBAAc;AACjB,UAAM,cAAc,cAAc,UAAU,KAAK;AACjD,UAAM,QAAQC,gBAAe,UAAU;AACvC,UAAM,OAAO,eAAe,IAAI,MAAM;AACtC,WAAO,GAAG,KAAK,IAAI,IAAI,GAAG,iBAAiB,YAAY,WAAW,CAAC;AAAA,EACrE,CAAC,EACA,IAAI,EACJ,KAAK,KAAK;AACf;AAKA,SAASE,oBAAmB,QAA0C;AACpE,MAAI,CAAC,UAAU,OAAO,WAAW,EAAG,QAAO;AAE3C,QAAM,eAAe,sBAAsB,MAAM;AACjD,QAAM,gBAAgBD,qBAAoB,MAAM;AAChD,QAAM,kBAAkB,qBAAqB,aAAa;AAC1D,QAAM,QAAQ,aAAa,aAAa,IAAI,iBAAO,aAAa,aAAa,IAAI,iBAAO;AAExF,MAAI,UAAU;AAAA;AAAA,yBAA8B,eAAe,IAAI,KAAK;AACpE,MAAI,aAAa,WAAW,EAAG,YAAW,KAAK,aAAa,QAAQ;AACpE,MAAI,aAAa,WAAW,EAAG,YAAW,KAAK,aAAa,QAAQ;AACpE,SAAO;AACT;AAKA,SAAS,mBACP,QACA,QACA,eACQ;AACR,QAAM,EAAE,QAAQ,IAAI;AACpB,QAAM,cAAc,kBAAkB,cAAc,CAAC;AACrD,QAAM,eAAeC,oBAAmB,MAAM;AAE9C,SAAO;AAAA;AAAA;AAAA,EAGP,QAAQ,eAAe,SAAS,QAAQ,oBAAoB,IAAI,KAAK,GAAG,uBAAuB,YAAY;AAAA;AAAA,2DAElD,aAAa;AAAA;AAAA;AAAA;AAAA;AAAA,oBAKpD,QAAQ,aAAa;AAAA,wBACjB,QAAQ,cAAc,QAAQ,CAAC,CAAC;AAAA,oBACpC,QAAQ,aAAa,GAAG,WAAW;AAAA;AAAA;AAAA;AAAA;AAKvD;AAKA,eAAe,eACb,SACA,WACA,QACA,YACA,cACA,QACA,SAAmC,MACpB;AACf,QAAM,YAAY,MAAM,eAAe,SAAS,SAAS;AACzD,EAAK,WAAK,eAAe,UAAU,IAAI,QAAQ;AAG/C,QAAM,sBAAsF,CAAC;AAC7F,QAAM,sBAA6C,CAAC;AAEpD,aAAW,KAAK,YAAY;AAC1B,UAAM,cAAc,gBAAgB,GAAG,SAAS;AAChD,QAAI,gBAAgB,MAAM;AACxB,0BAAoB,KAAK,EAAE,WAAW,GAAG,YAAY,CAAC;AAAA,IACxD,OAAO;AACL,0BAAoB,KAAK,CAAC;AAAA,IAC5B;AAAA,EACF;AAEA,EAAK;AAAA,IACH,GAAG,oBAAoB,MAAM,IAAI,WAAW,MAAM,yCAC9C,oBAAoB,MAAM;AAAA,EAChC;AAEA,QAAM,WAAWJ,eAAc,MAAM;AAIrC,QAAM,0BAA0B,oBAAoB,OAAO,CAAC,EAAE,UAAU,MAAM;AAC5E,UAAM,MAAMD,gBAAe,SAAS;AACpC,UAAM,QAAQ,SAAS,IAAI,GAAG;AAE9B,WAAO,CAAC,SAAS,MAAM,aAAa,SAAS,MAAM,QAAQ;AAAA,EAC7D,CAAC;AAED,QAAM,eAAe,oBAAoB,SAAS,wBAAwB;AAC1E,MAAI,eAAe,GAAG;AACpB,IAAK,WAAK,YAAY,YAAY,0DAA0D;AAAA,EAC9F;AAEA,MAAI,wBAAwB,WAAW,GAAG;AACxC,IAAK,WAAK,6CAA6C;AAEvD,QAAI,oBAAoB,SAAS,GAAG;AAElC,YAAMM,iBAAgB,mBAAmB,qBAAqB,QAAQ;AAEtE,YAAM,gBAAgB,oBACnB,OAAO,CAAC,EAAE,UAAU,MAAM;AACzB,cAAM,MAAMN,gBAAe,SAAS;AACpC,cAAM,QAAQ,SAAS,IAAI,GAAG;AAC9B,eAAO,SAAS,MAAM,aAAa,SAAS,MAAM,UAAU;AAAA,MAC9D,CAAC,EACA,IAAI,OAAK,EAAE,SAAS;AACvB,YAAMO,eAAc,iBAAiB,aAAa;AAClD,YAAMC,eAAc,mBAAmB,QAAQ,QAAQF,iBAAgBC,YAAW;AAClF,YAAM,cAAc,SAAS,WAAWC,YAAW;AAAA,IACrD;AACA;AAAA,EACF;AAGA,QAAM,wBAAwB,wBAAwB,IAAI,OAAK,EAAE,SAAS;AAC1E,EAAK,WAAK,8BAA8B,sBAAsB,MAAM,6BAA6B;AACjG,QAAM,aAAa,MAAM;AAAA,IACvB;AAAA,IACA;AAAA,IACA,OAAO;AAAA,IACP,OAAO;AAAA,EACT;AAGA,QAAM,eAAe,kBAAkB,yBAAyB,YAAY,QAAQ;AACpF,EAAK,WAAK,SAAS,aAAa,MAAM,4CAA4C;AAIlF,QAAM,oBAAoB,oBACvB,OAAO,CAAC,EAAE,UAAU,MAAM;AACzB,UAAM,MAAMR,gBAAe,SAAS;AACpC,UAAM,QAAQ,SAAS,IAAI,GAAG;AAC9B,WAAO,SAAS,MAAM,aAAa,SAAS,MAAM,UAAU;AAAA,EAC9D,CAAC,EACA,IAAI,OAAK,EAAE,SAAS;AAEvB,QAAM,gBAAgB,mBAAmB,qBAAqB,QAAQ;AACtE,QAAM,cAAc,iBAAiB,iBAAiB;AACtD,QAAM,cAAc,mBAAmB,QAAQ,QAAQ,gBAAgB,WAAW;AAElF,QAAM,aAAa,SAAS,WAAW,cAAc,WAAW;AAChE,EAAK,WAAK,sBAAsB,aAAa,MAAM,gBAAgB;AACrE;AAOA,eAAe,kBACb,SACA,WACA,QACA,cACA,QACA,aAAa,OACb,SAAmC,MACpB;AACf,QAAM,SAAS,kBAAkB,QAAQ,WAAW,cAAc,MAAM;AACxE,EAAK,YAAM,kBAAkB,OAAO,MAAM,aAAa;AAEvD,QAAM,WAAW,MAAM;AAAA,IACrB;AAAA,IACA,OAAO;AAAA,IACP,OAAO;AAAA,EACT;AAEA,QAAM,QAAQ,cAAc;AAC5B,QAAM,UAAU,oBAAoB,UAAU,QAAQ,YAAY,OAAO,MAAM;AAC/E,QAAM,cAAc,SAAS,WAAW,OAAO;AAC/C,EAAK,WAAK,+CAA+C;AAC3D;AAGA,IAAI,EAAE,MAAM,CAACF,WAAU;AACrB,EAAK,gBAAUA,kBAAiB,QAAQA,OAAM,UAAU,OAAOA,MAAK,CAAC;AACrE,UAAQ,KAAK,CAAC;AAChB,CAAC;","names":["expand","match","path","Ignore","core","fs","collect","fs","run","glob","i","acc","ext","glob","hasMagic","start","final","ext","qmark","star","expand","regExpEscape","v","bf","p","ret","res","path","p","sep","fs","filter","process","sync","fileURLToPath","Stream","proc","EOF","MAYBE_EMIT_END","EMITTED_END","EMITTING_END","EMITTED_ERROR","CLOSED","READ","FLUSH","FLUSHCHUNK","ENCODING","DECODER","FLOWING","PAUSED","RESUME","BUFFER","PIPES","BUFFERLENGTH","BUFFERPUSH","BUFFERSHIFT","OBJECTMODE","DESTROYED","ERROR","EMITDATA","EMITEND","EMITEND2","ASYNC","ABORT","ABORTED","SIGNAL","defer","isEndish","isArrayBufferView","Pipe","PipeProxyErrors","Minipass","p","ret","res","defaultPlatform","path","rest","ignore","path","abs","target","Minipass","defaultPlatform","fileURLToPath","import_ignore","path","ignore","e","ext","match","detectLanguage","ext","error","search","detectLanguage","error","match","error","match","error","LienErrorCode","error","error","path","fs","path","error","QueryIntent","path","path","error","buildLegacySymbols","error","fs","path","path","fs","error","path","error","fs","path","defaults","fs","path","warning","error","core","fs","path","path","fs","error","fs","path","error","path","error","fs","path","path","fs","error","fs","path","fs","path","error","path","fs","error","error","path","fs","fs","error","path","isTestFile","path","isTestFile","chunkFile","error","core","collect","core","collect","collect","collect","path","error","ext","createDeltaKey","buildDeltaMap","collect","getMetricEmoji","groupDeltasByMetric","formatDeltaDisplay","uncoveredNote","skippedNote","summaryBody"]}